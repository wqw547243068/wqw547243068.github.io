---
layout: post
title:  "OCR技术"
date:   2019-11-05 16:52:00
categories: 计算机视觉
tags: 深度学习 计算机视觉 GAN OCR ocr 
excerpt: 光学字符识别 OCR 技术概要
mathjax: true
permalink: /ocr
---

* content
{:toc}


# OCR

- `光学字符识别`(`OCR`,Optical Character Recognition)是指对文本资料进行扫描，然后对图像文件进行分析处理，获取文字及版面信息的过程。OCR技术非常专业，一般多是印刷、打印行业的从业人员使用，可以快速的将纸质资料转换为电子资料。

## OCR 历史

OCR技术发展历程分为几类：
- 概念提出： 1929年由德国科学家Tausheck最早提出OCR概念，后来美国科学家Handel也提出利用技术对文字进行识别想法。最先对印刷体汉字识别进行研究的是IBM公司，于1966年发表第一篇关于汉字识别的文章，采用模板匹配法识别印刷体汉字。
- 发展研究： 早在60、70年代，世界各国就开始有OCR的研究，而初期以文字识别方法研究为主，且识别的文字仅为0至9的数字。
  - 以日本为例，1960年左右开始研究OCR的基本识别理论，初期以数字为对象，直至1965至1970年之间开始有一些简单的产品，如印刷文字的邮政编码识别系统。
- 形成产品： 在70年代，中国开始对数字、英文字母及符号识别进行研究，1986年，我国提出“863”高新科技研究计划，汉字识别的研究进入一个实质性阶段，相继推出中文OCR产品。早期OCR软件，因为识别率、硬件设备成本高及产品化等多方面的因素，未能达到实际要求。
- 百花齐放： 进入20世纪90年代之后，随着信息自动化普及，大大推进了OCR技术的进一步发展，使OCR的识别正确率和速度满足广大用户需求。随着人工智能技术不断发展，OCR软件产品已趋于成熟，可以识别各类语言、各类场景下识别，代表有全能扫描王、天若OCR等。

作者：[GoAI](https://juejin.cn/post/7260146586860912699)

## OCR 应用场景

应用场景
- ![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1eebb0147cf447b89da6b0e97b005ce1~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)


按照**识别场景**划分，可分为:
-   **文档文字识别**：可以将图书馆、报社、博物馆、档案馆等的纸质版图书、报纸、杂志、历史文献档案资料等进行电子化管理，实现精准地保存文献资料。
-   **自然场景文字识别**：识别自然场景图像中的文字信息如车牌、广告干词、路牌等信息。对车辆进行识别可以实现停车场收费管理、交通流量控制指标测量、车辆定位、防盗、高速公路超速自动化监管等功能。
-   **票据文字识别**：可以对增值税发票、报销单、车票等不同格式的票据进行文字识别，可以避免财务人员手动输入大量票据信息，如今已广泛应用于财务管理、银行、金融等众多领域。。
-   **证件识别**：可以快速识别身份证、银行卡、驾驶证等卡证类信息，将证件文字信息直接转换为可编辑文本，可以大大提高工作效率、减少人工成本、还可以实时进行相关人员的身份核验，以便安全管理。

按照**文字形成方式**划分，可分为:
-   **标准印刷体文字的识别**（包括印刷体数字、汉字、英文）;
-   **手写文字的识别**（包括手写数字、汉字、英文）;
-   **即存在印刷体又存在手写体的文字识别**；
-   **艺术体、合成文字等复杂字体识别**；

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/28e873e7c1504a5aaeee11148d5e32a9~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

主要指标有：
- `拒识率`、`误识率`、`识别速度`、用户界面的友好性，产品的稳定性，易用性及可行性等


## OCR 识别技术


### OCR技术流程

OCR技术流程进行介绍。典型的OCR技术pipline如下图所示： 
- 输入 → 图像预处理 → 文字检测 → 文本识别 → 输出
- ![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9ca30e39795c40a189f9ed78d0658606~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

其中，`文本检测`和`识别`是OCR技术的两个重要核心技术。

#### 1 图像预处理

图像预处理是OCR流程的第一步，用于提高字符识别的准确性。常见的预处理操作包括灰度化、二值化和去噪。
- 灰度化将彩色图像转换为灰度图像，将每个像素的RGB值转换为相应的灰度值。在灰度图像中每个像素只有一个灰度值，简化后续的处理步骤。
- 二值化将灰度图像转换为二值图像，将灰度值高于某个阈值的像素设为白色，低于阈值的像素设为黑色。这将图像转换为黑白二值图像，方便后续的文本定位和字符分割。
- 去噪是为了减少图像中的噪声和干扰，以提高后续处理的准确性。常用的去噪方法包括中值滤波、高斯滤波和形态学操作。

此外，针对不规则文本识别，在预处理阶段可以先进行校正操作再进行识别。

#### 2 文字检测

文本检测的任务是定位出输入图像中的文字区域。

近年来，使用深度学习进行文本检测成为主流技术，一类方法将文本检测视为目标检测中的一个特定场景，基于通用目标检测算法进行改进适配，如TextBoxes 基于一阶段目标检测器SSD 算法，调整目标框使之适合极端长宽比的文本行，CTPN则是基于Faster RCNN架构改进而来。但是文本检测与目标检测在目标信息以及任务本身上仍存在一些区别，如文本一般长宽比较大，往往呈“条状”，文本行之间可能比较密集，弯曲文本等，因此又衍生了很多专用于文本检测的算法，如EAST、PSENet、DBNet 等等。

#### 3 文字识别

文本识别的任务是识别出图像中的文字内容。

文本识别一般输入来自于文本检测得到的文本框截取出的图像文字区域。文本识别一般可以根据待识别文本形状分为**规则**文本识别和**不规则**文本识别两大类。不规则文本场景具有很大的挑战性，也是目前文本识别领域的主要研究方向。
- **规则**文本主要指印刷字体、扫描文本等，文本大致处在水平线位置，如下图左半部分；
- **不规则**文本往往不在水平位置，存在弯曲、遮挡、模糊等问题，如下图右半部分。
- ![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8201b8bc88b4223b45a3b62b5e5e47d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)


### 识别难点

#### 自然场景：

> 自然场景下的文本通常出现在复杂的背景中，且文本的字体、颜色、大小和方向都可能不同。例如路标、广告牌和商品包装等。 不同于传统的扫描图像文本，自然场景文本因表现形式丰富，图像背景复杂，以及图像拍摄引入的干扰因素等的影响，其识别的难点包括但不限于以下几个方面:

-   **图片背景多变：** 经常面临低亮度、低对比度、光照不均、透视变形和残缺遮挡等问题，还可能会受到噪声的影响，例如风沙、雨雪等天气条件，以及拍摄设备本身的噪声等，使得对其的分析与处理难度远高于传统的扫描文档图像。
-   **文字弯曲：** 文本的布局可能存在扭曲、褶皱、换向等问题，其中的文字也可能字体多样、字号字重颜色不一的问题。
-   **文本格式：** 自然场景中的文字数量较多，且分布较为分散，这使得算法的训练难度加大。针对长文本，需要处理文本行之间的连续性和上下文关系。针对多行文本，需要进行有效的文本区域分割和识别。
-   **数据规模与资源** 为训练和优化深度学习OCR模型，需要大规模的数据集和充足的计算资源。然而，自然场景OCR数据集往往比较难以获取和标注，同时深度学习模型的训练也需要较大的计算开销。

#### 文档文字：

尽管普通文档识别相较于场景文本识别来说通常难度较小，但在特定领域中仍存在许多挑战。例如，针对票据扫描的目标检测，由于扫描仪分辨率低、纸张和油墨质量差等因素的影响，导致所扫描的票据质量低下。此外，字体过小以及干扰文本也是需要考虑的问题。

此外，针对复杂场景（复杂版面、数学公式、表格、结构化符号/图形等）的识别效果仍存在一定提升空间。

#### 识别难点解决办法：

> 关于上述不同场景OCR技术面临许多挑战，需要更强大算法来应对文本的多样性和背景的复杂性。那么我们从那些角度入手解决上述问题呢？

以下为作者简单列出几点通用的解决方法，：
1.  **数据增强：** 通过对训练数据进行增强，如随机旋转、缩放、裁剪、变换和加噪声等，可以使OCR模型更好地适应不同的图像条件和多样性。
2.  **多尺度检测：** 设计多尺度的检测模型可以在不同大小和分辨率的文本实例中进行检测，从而提高对不同文本大小和形状的适应性。
3.  **背景抑制：** 采用背景抑制技术，通过将注意力集中在文本区域，忽略或减弱背景干扰，从而提高文本检测的准确性。
4.  **多任务学习：** 将文本检测和识别任务结合起来进行多任务学习，可以更好地处理复杂场景中的文本实例，并提高整体性能。
5.  **引入先验知识：** 利用先验知识，如字符形状、文本的统计信息等，对文本进行建模，可以提高对复杂文本实例的理解和识别。
6.  **迁移学习/强化学习：** 使用迁移学习或强化学习技术来优化OCR模型，使其能够在不同场景下进行更好的适应和调整。


## OCR 数据集

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4391e558fe404aa790aa4562c608399f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

### 规则数据集

规则数据集
- IIIT5K-Words (IIIT) 2000 for Train; 3000 for Test
- Street View Text (SVT) 257 for Train; 647 for Test
- ICDAR 2003(IC03) 、ICDAR2013 (IC13)
  - 由500张左右英文标注的自然场景图片构成，标注形式为两点水平标注，坐标格式为左上角，和右下角

### 不规则数据集

不规则数据集
- ICDAR2015 (IC15) 4468 for Train; 2077 for Test;
  - 1500张（训练1000，测试500）英文标注的自然场景图片构成，标注形式为四点标注，坐标格式依次为为左上角，右上角，右下角和左下角
- SVT Perspective (SP) 645 for Test
- CUTE80 (CT) 288 for Test

### 合成数据集

SynthText(ST) 5.5million个图像

### 中文场景数据集

中文场景数据集
- Chinese Text in the Wild (CTW)：

CTW数据集是一个针对中文场景文本的数据集，用于文本检测和识别任务。CTW数据集包含了超过40,000张高分辨率的中文场景图像，这些图像从不同来源和环境中获取，具有广泛的多样性。
- ![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/049ccb55465341e29073e79c09a20e59~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)


## OCR 模型

### 总结

OCR识别模型
- 评价指标为准确率

|  |  | Regular Dataset | Irregular dataset |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Year | IIIT | SVT | IC13(857) | IC13(1015) | IC15(1811) | IC15(2077) | SVTP | CUTE |  |
| [CRNN](https://ieeexplore.ieee.org/abstract/document/7801919) | 2015 | 78.2 | 80.8 | \- | 86.7 | \- | \- | \- | \- |  |
| [ASTER(L2R)](https://ieeexplore.ieee.org/abstract/document/8395027) | 2015 | 92.67 | 91.16 | \- | 90.74 | 76.1 | \- | 78.76 | 76.39 |  |
| [CombBest](https://openaccess.thecvf.com/content_ICCV_2019/html/Baek_What_Is_Wrong_With_Scene_Text_Recognition_Model_Comparisons_Dataset_ICCV_2019_paper.html) | 2019 | 87.9 | 87.5 | 93.6 | 92.3 | 77.6 | 71.8 | 79.2 | 74 |  |
| [ESIR](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_ESIR_End-To-End_Scene_Text_Recognition_via_Iterative_Image_Rectification_CVPR_2019_paper.html) | 2019 | 93.3 | 90.2 | \- | 91.3 | \- | 76.9 | 79.6 | 83.3 |  |
| [SE-ASTER](https://openaccess.thecvf.com/content_CVPR_2020/html/Qiao_SEED_Semantics_Enhanced_Encoder-Decoder_Framework_for_Scene_Text_Recognition_CVPR_2020_paper.html) | 2020 | 93.8 | 89.6 | \- | 92.8 | 80 |  | 81.4 | 83.6 |  |
| [DAN](https://ojs.aaai.org/index.php/AAAI/article/view/6903) | 2020 | 94.3 | 89.2 | \- | 93.9 | \- | 74.5 | 80 | 84.4 |  |
| [RobustScanner](https://link.juejin.cn?target=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-030-58529-7_9 "https://link.springer.com/chapter/10.1007/978-3-030-58529-7_9") | 2020 | 95.3 | 88.1 | \- | 94.8 | \- | 77.1 | 79.5 | 90.3 |  |
| [AutoSTR](https://link.springer.com/content/pdf/10.1007/978-3-030-58586-0_44.pdf) | 2020 | 94.7 | 90.9 | \- | 94.2 | 81.8 | \- | 81.7 | \- |  |
| [Yang et al.](https://www.sciencedirect.com/science/article/abs/pii/S0925231220311176) | 2020 | 94.7 | 88.9 | \- | 93.2 | 79.5 | 77.1 | 80.9 | 85.4 |  |
| [SATRN](https://openaccess.thecvf.com/content_CVPRW_2020/html/w34/Lee_On_Recognizing_Texts_of_Arbitrary_Shapes_With_2D_Self-Attention_CVPRW_2020_paper.html) | 2020 | 92.8 | 91.3 | \- | 94.1 | \- | 79 | 86.5 | 87.8 |  |
| [SRN](https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_Towards_Accurate_Scene_Text_Recognition_With_Semantic_Reasoning_Networks_CVPR_2020_paper.html) | 2020 | 94.8 | 91.5 | 95.5 | \- | 82.7 | \- | 85.1 | 87.8 |  |
| [GA-SPIN](https://arxiv.org/abs/2005.13117) | 2021 | 95.2 | 90.9 | \- | 94.8 | 82.8 | 79.5 | 83.2 | 87.5 |  |
| [PREN2D](https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.html) | 2021 | 95.6 | 94 | 96.4 | \- | 83 | \- | 87.6 | 91.7 |  |
| [Bhunia et al.](https://openaccess.thecvf.com/content/ICCV2021/html/Bhunia_Joint_Visual_Semantic_Reasoning_Multi-Stage_Decoder_for_Text_Recognition_ICCV_2021_paper.html) | 2021 | 95.2 | 92.2 | \- | 95.5 | \- | **84** | 85.7 | 89.7 |  |
| [Luo et al.](https://link.springer.com/article/10.1007/s11263-020-01411-1) | 2021 | 95.6 | 90.6 | \- | **96.0** | 83.9 | 81.4 | 85.1 | 91.3 |  |
| [VisionLAN](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_From_Two_to_One_A_New_Scene_Text_Recognizer_With_ICCV_2021_paper.html) | 2021 | 95.8 | 91.7 | 95.7 | \- | 83.7 | \- | 86 | 88.5 |  |
| [ABINet](https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.html) | 2021 | 96.2 | 93.5 | 97.4 | \- | 86.0 | \- | 89.3 | 89.2 |  |
| [MATRN](https://arxiv.org/abs/2111.15263) | 2021 | **96.7** | **94.9** | **97.9** | **95.8** | **86.6** | 82.9 | **90.5** | **94.1** |  |


## OCR工具

主流OCR识别应用平台
-   百度开放平台:[PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)
-   商汤科技OpenMMLab : [MMOCR](https://github.com/open-mmlab/mmocr)
-   谷歌开源OCR引擎:[Tesseract](https://github.com/tesseract-ocr/tesseract)
- [微软Azure图像识别](https://azure.microsoft.com/zh-cn/services/cognitive-services/computer-vision)
- [有道智云文字识别](https://ai.youdao.com)
- [阿里云图文识别](https://www.aliyun.com/product/cdi)
- [腾讯OCR文字识别](https://cloud.tencent.com/product/ocr)


### 简易工具

- 【2021-7-26】免费在线OCR工具 [ocrmaker](http://ocrmaker.com/)
- [UU Tool](https://uutool.cn/ocr/)：截图黏贴图片到网站，提取文本；text转语音
- [城华OCR](https://zhcn.109876543210.com/)，将图片转成各种文档格式，限制次数
- [白描](https://web.baimiaoapp.com/image-to-excel)：提取图片中的文字、数学公式等
- Chrome插件
  - Copyfish Free OCR, 中文支持不佳，手工设置语言后，依然乱码
  - 【2024-2-8】[一键读图(OCR)](https://chrome.google.com/webstore/detail/%E4%B8%80%E9%94%AE%E8%AF%BB%E5%9B%BEocr/agepkkdokhlaoiaenedmjbfnblfdiboc/related),可识别中文

### 对比总结

【2022-1-25】kaggle笔记：各类OCR方法对比：[Keras-OCR vs EasyOCR vs PYTESSERACT](https://www.kaggle.com/odins0n/keras-ocr-vs-easyocr-vs-pytesseract)
- ![](https://www.kaggleusercontent.com/kf/72864633/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..bibMciKL4OvFX6946nkcFw.H2h7vNPLD0EzD2z6onWrw4R9VV561rtI-O7dAgl4zRkrjH216E96Cg8_ZO6-4Xny6XZL45qeH7xqBdHs7DWKpxJwl6PSES-c3wCDkH1pZifDsjEiIhboIFocwMjIEWDWNFlTY-gafig2CIc9OMmr8Kj2HyhJ_Xmg88Lbsa25dpCF2XkWG6DDLww1eL9wmXE66SzF7sM1_rsUxLvmAplprAQVNPOo2dVSKaGtD5Q1FOD8NvkeRPVeA-MiFGHe8bCtu0paeoX7aPC1z6WzunEsbpGjAeHOWrHXDtYZMPde_Qc77FVe2Qc91b6W_aAYgFoWuehxHKhOgp-jtcSA8cr_UocTj3chqBQgJKkwFodQdZInVeknz7L1HA9IGJgpWEy8DPZcNjhNuXgoWqpjqJLslljIJa-8N3Dy3qqu5p8Ku54YnzDSak2rMgdn_ThhC5AtDM3_7aB_s6vI4LoeVFxYTJ4JLVyw3v_YqIOe1BG7qD-QN2bqZixhJvtajOYzllcLP21NqMesuo7dHa-favmNVYo6o9zirwLvyYFrW4z0BpdBGkf_nQ_6n452u6GMiaRwmpNgNpD3zVv1BRCNbvMrJyzm5Mb7iqmedml2Yi6NFMxEgyOvb6rclteSyWU8_CMhP0bl3KGxEgeqNSD9Z02teSGWd9Gl8Nb6F9SByo90TtEZPJy7kIpa9Y9VPHwV7JAD.PtUtOX_gh2gJUMvxM9Wyvw/__results___files/__results___14_1.png)

CONCLUSIONS 对比结论
* **Keras-OCR** is image specific OCR tool. If text is inside the image and their fonts and colors are unorganized, Keras-ocr consumes time if used on CPU 
* **EasyOCR** is lightweight model which is giving a good performance for receipt or PDF conversion. It is giving more accurate results with organized texts like pdf files, receipts, bills. EasyOCR also performs well on noisy images 适合**发票**、**pdf格式**、噪声图片
* **Pytesseract** is performing well for **high-resolution** images. Certain morphological operations such as dilation, erosion, OTSU binarization can help increase pytesseract performance. It also provides better results on handwritten text as compared to EasyOCR 适合**高分辨率**图、**手写**字体
* All these results can be further improved by performing specific image operations.



### Tesseract

Tesseract OCR 引擎最先由HP实验室于1985年开始研发，至1995年时已经成为OCR业内最准确的三款识别引擎之一。
- 目前公认最优秀、最精确的开源OCR系统，用于识别图片中的文字并将其转换为可编辑的文本。
- Tesseract 能将**印刷体**文字图像转换成**可编辑**文本，支持**多种语言**，并且在许多平台上都可使用，包括Windows、Mac OS和Linux。
- Tesseract可以处理各种图像文件格式，如 JPEG、PNG、TIFF等。
- Tesseract 主要功能是识别图像中的**文字**，并将其转换成机器可读的文本内容。它采用了一系列图像处理、特征提取和机器学习技术来实现文字识别的过程。Tesseract算法的基础是使用训练好的模型来识别字符，并通过上下文和语言模型来提高识别准确性。

- Tesseract 目前已作为**开源**项目, 发布在Google Project，其最新版本3.0已经支持中文OCR，并提供了一个命令行工具。
- 官方文档: [tesseract-ocr](https://tesseract-ocr.github.io/tessdoc/Installation.html)
- GitHub地址：[tesseract](https://github.com/tesseract-ocr/tesseract)


#### windows

【2024-11-30】windows exe 下载[地址](https://digi.bib.uni-mannheim.de/tesseract/)
- 滑到尾部, 安装 win64版本: [tesseract-ocr-w64-setup-v5.3.0.20221214.exe](https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-w64-setup-v5.3.0.20221214.exe)
- 安装正常, 但执行出错, [libpng](http://www.libpng.org/pub/png/libpng.html) 版本不对
- 错误信息: `libpng warning: Application built with libpng-1.4.3 but running with 1.5.14`

改进：更换版本即可
- 安装[官方文档](https://tesseract-ocr.github.io/tessdoc/)上的windows版本: [Windows - Tesseract at UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki)
  - [tesseract-ocr-w64-setup-5.5.0.20241111.exe (64 bit)](https://github.com/tesseract-ocr/tesseract/releases/download/5.5.0/tesseract-ocr-w64-setup-5.5.0.20241111.exe)
- 配置环境变量: 

```sh
# PATH 添加安装目录
E:\program_file\Tesseract-OCR
# 设置 变量
TESSDATA_PREFIX = E:\program_file\Tesseract-OCR\tessdata
```

保存后，启动 power shell

```sh
# 版本信息
tesseract -v
# 显示支持的语种
tesseract --list-langs
# 默认英语
tesseract  .\data\b.jpg out_b
# 指定语种
tesseract -l chi_sim  .\data\a.png out_a
```

执行完后，当前目录下生成 文件 out_a.txt, out_b.txt, 包含生成的文件内容

#### linux 

linux 安装：
- `pip install pytesseract`


#### 代码调用

调用代码
- 先确保已安装 tesseract 工具包

```python
# coding:utf-8
# pip install opencv-python
import cv2                        # OpenCV: Computer vision and image manipulation package
import pytesseract                # python Tesseract: OCR in python

import matplotlib.pyplot as plt   # plotting
import numpy as np                # Numpy for arrays
from PIL import Image             # Pillow: helps us read remote images
import requests                   # Requests: to fetch remote URLs
from io import BytesIO            # Helps read remote images

def get_image(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    return img

img = get_image('https://github.com/jalammar/jalammar.github.io/raw/master/notebooks/cv/label.png')
# OCR结果
print(pytesseract.image_to_string(img))
```

### EasyOCR

【2020-8-7】[一个超好用的开源OCR](https://www.toutiao.com/i6858234401206043140/?tt_from=mobile_qq&utm_campaign=client_share&timestamp=1596809559&app=news_article&utm_source=mobile_qq&utm_medium=toutiao_android&use_new_style=1&req_id=20200807221239010147083076216022E3&group_id=6858234401206043140)：[EasyOCR](https://github.com/JaidedAI/EasyOCR)，目前能够支持80种语言，其中有中文(简体和繁体)、日语、泰语、韩语等
- EasyOCR 模型主要分为两个，基于CRAFT的文字检测模型和基于ResNet+LSTM+CTC的识别模型
- 官方体验地址: [EasyOCR](https://www.jaided.ai/easyocr/)
- ![](http://p6-tt.byteimg.com/large/pgc-image/2402e44dff954e4985f6762de5b07ce6?from=pc)
- 第三方基于easyOCR提供了几个demo地址，大家可以试试自己的数据看看效果：
  - [Demo1](https://colab.fan/easyocr)
  - [Demo2](https://hub.docker.com/r/challisa/easyocr)
  - [Demo3](https://easyocrgpu-wook-2.endpoint.ainize.ai/)
  - ![](http://p3-tt.byteimg.com/large/pgc-image/a56400ef928d419c8ef29c64abede5da?from=pc)

OCR 框架
- ![](https://github.com/JaidedAI/EasyOCR/raw/master/examples/easyocr_framework.jpeg)


#### windows


安装
- 前置依赖: torch, torchvision 
  - 注意选择对应的 torch 版本, 如果不用 gpu, 设置 CUDA = None
- 终端 power shell

命令行方式

```sh
easyocr -f chinese.jpg # 指定图片
easyocr -l ch_sim en -f chinese.jpg # 指定语种
easyocr -l ch_sim en -f chinese.jpg --detail=0 # 精简输出
easyocr -l ch_sim en -f chinese.jpg --detail=1 # 完整输出（默认）
easyocr -l ch_sim en -f chinese.jpg --gpu=True # 使用 GPU
```


#### 代码调用

实践
- 【2023-9-15】不支持中国银行卡，以国外为主

```py
# coding:utf-8
# pip install easyocr

import easyocr

test_file = 'e:\\code_new\\ocr\\data\\a.png' # 中文
#test_file = 'e:\\code_new\\ocr\\data\\b.jpg' # 英文

# 语种模型加载，只下载、加载一次，到内存里
reader = easyocr.Reader(['ch_sim','en']) # this needs to run only once to load the model into memory
# result = reader.readtext(test_file) # list 结构，包含解析内容及对应的box区域、置信度
# ([[86, 80], [134, 80], [134, 128], [86, 128]], '西', 0.40452659130096436)
result = reader.readtext(test_file, detail=0) # list 结构, 只显示解析出的文本内容

print(f'OCR结果:  {test_file=}')
# 逐行输出
for res in result:
    print(f'{res}')

```



### Pix2Text

【2022-9-21】[Pix2Text: 替代 Mathpix 的免费 Python 开源工具](https://www.toutiao.com/article/7145465980930556450)
- [Pix2Text](https://github.com/breezedeus/pix2text) 期望成为 Mathpix 的免费开源 Python 替代工具，完成与 Mathpix 类似的功能。当前 Pix2Text 可识别截屏图片中的数学公式、英文、或者中文文字。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a81b8f2c95794d0596a1d7b803df2a34~noop.image?_iz=58558&from=article.pc_detail&x-expires=1664345981&x-signature=1blBfmn0jnAV0%2FOB5VuIKt1Jd3Q%3D)

Pix2Text首先利用图片分类模型来判断图片类型，然后基于不同的图片类型，把图片交由不同的识别系统进行文字识别：
- 如果图片类型为 **formula** ，表示图片为数学公式，此时调用 LaTeX-OCR 识别图片中的数学公式，返回其Latex表示；
- 如果图片类型为 **english**，表示图片中包含的是英文文字，此时使用 CnOCR (https://github.com/breezedeus/cnocr) 中的英文模型识别其中的英文文字；英文模型对于纯英文的文字截图，识别效果比通用模型好；
- 如果图片类型为 **general**，表示图片中包含的是常见文字，此时使用 CnOCR 中的通用模型识别其中的中或英文文字。


```python
#pip install pix2text -i https://pypi.doubanio.com/simple
from pix2text import Pix2Text

img_fp = './docs/examples/formula.jpg'
p2t = Pix2Text()
out_text = p2t(img_fp)  # 也可以使用 `p2t.recognize(img_fp)` 获得相同的结果
print(out_text)
```


### 中文OCR比赛第一

【2022-1-25】[第一次比赛，拿了世界人工智能大赛 Top1 ！](https://blog.csdn.net/Datawhale/article/details/122613233)，“世界人工智能创新大赛”——手写体 OCR 识别竞赛（任务一），取得了Top1的成绩
- [赛题地址](http://ailab.aiwin.org.cn/competitions/65)
- 背景：银行日常业务中涉及到各类凭证的识别录入，例如身份证录入、支票录入、对账单录入等。以往的录入方式主要是以人工录入为主，效率较低，人力成本较高。近几年来，OCR相关技术以其自动执行、人为干预较少等特点正逐步替代传统的人工录入方式。但OCR技术在实际应用中也存在一些问题，在各类凭证字段的识别中，手写体由于其字体差异性大、字数不固定、语义关联性较低、凭证背景干扰等原因，导致OCR识别率准确率不高，需要大量人工校正，对日常的银行录入业务造成了一定的影响
- 数据集：原始手写体图像共分为三类，分别涉及银行名称、年月日、金额三大类，分别示意如下：
  - ![](https://img-blog.csdnimg.cn/img_convert/4cfda26453767dec3b2d436540d3c6b8.png)
- 相应图片切片中可能混杂有一定量的干扰信息
  - ![](https://img-blog.csdnimg.cn/img_convert/cd77146fdad3c8b41f455b2992a6b784.png)

OCR比赛最常用的模型是 CRNN + CTC，选择代码：Attention_ocr.pytorch-master.zip

模型改进：crnn的卷积部分类似VGG，我对模型的改进主要有一下几个方面：
- 1、加入激活函数Swish。
- 2、加入BatchNorm。
- 3、加入SE注意力机制。
- 4、适当加深模型。

```python
self.cnn = nn.Sequential(
   nn.Conv2d(nc, 64, 3, 1, 1), Swish(), nn.BatchNorm2d(64),
   nn.MaxPool2d(2, 2),  # 64x16x50
   nn.Conv2d(64, 128, 3, 1, 1), Swish(), nn.BatchNorm2d(128),
   nn.MaxPool2d(2, 2),  # 128x8x25
   nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), Swish(),  # 256x8x25
   nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), Swish(),  # 256x8x25
   SELayer(256, 16),
   nn.MaxPool2d((2, 2), (2, 1), (0, 1)),  # 256x4x25
   nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), Swish(),  # 512x4x25
   nn.Conv2d(512, 512, 1), nn.BatchNorm2d(512), Swish(),
   nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), Swish(),  # 512x4x25
   SELayer(512, 16),
   nn.MaxPool2d((2, 2), (2, 1), (0, 1)),  # 512x2x25
   nn.Conv2d(512, 512, 2, 1, 0), nn.BatchNorm2d(512), Swish()
)  # 512x1x25
# SE和Swish
class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=True),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class Swish(nn.Module):
    def forward(self, x):
        return x * torch.sigmoid(x)
```

### META Nougat

【2023-8-30】Meta推出OCR神器，PDF、数学公式都能转[Nougat](https://www.toutiao.com/article/7272995038735630905)

存储在 PDF 等文件中的信息很难转成其他格式，尤其对数学公式更是显得无能为力，因为转换过程中很大程度上会丢失信息。

[Nougat](https://facebookresearch.github.io/nougat/) 基于 Transformer 模型构建而成，可以轻松的将 PDF 文档转换为 MultiMarkdown，扫描版的 PDF 也能转换，让人头疼的数学公式也不在话下。
- 论文[地址](https://arxiv.org/pdf/2308.13418v1.pdf)
- 项目[主页](https://facebookresearch.github.io/nougat)

2 个 Swin Transformer ，一个参数量为 350M，可处理的序列长度为 4096，另一参数量为 250M，序列长度为 3584。在推理过程中，使用贪婪解码生成文本。


### 大模型 GOT

【2024-9-17】[GOT有望成为视觉大模型第一个杀手级应用？](https://mp.weixin.qq.com/s/OKQpg4r_DXT6xIiCJ-w8Lg)

#### 传统 OCR 问题

传统 OCR 技术方案问题
- 以**流水线**方式组织模块，错误传递
  - 模块: 元素选择、区域裁剪、字符识别
- 泛化性能不佳: 各模块为子任务设计

#### GOT 介绍

大型视觉语言模型 （LVLM） 具备了卓越的文本识别能力，针对 OCR 特定功能进行优化，提升诸如高密度文本或特殊字符的识别成为可能。

`阶跃星辰`、`旷视科技`、`中科院大学`和清华的研究人员提出 `GOT`?（General?OCR?Theory） 的新型 **通用OCR模型**。

GOT 旨在**统一框架内解决所有 OCR 需求**，提供更通用和高效的系统，用于识别各种格式，包括：纯文本、数学、分子式、表格、图表、乐谱，甚至几何形状。
- 论文：[General OCR Theory:Towards OCR-2.0 via a Unified End-to-end Model](https://arxiv.org/abs/2409.01704)
- 项目：[GOT-OCR2.0](https://github.com/Ucas-HaoranWei/GOT-OCR2.0)    

突出特点:
- OCR 2.0 **端到端**方式解决OCR问题
- 训练、推理成本低
- 用 Markdown，LaTeX Tikz 矢量图, Smiles 简化分子语言等生成格式化输出，对处理科学论文和数学内容特别有用。
- 模型支持交互式 OCR **基于区域**的识别。    

GOT 在各种 OCR 任务中展现出强大的性能:
- OCR F1分数 - 英文文档0.952 , 中文文档0.961; 
- 场景文本 OCR 准确率 - 英文 0.926，中文 0.934，具备跨语言的广泛适用性。   

模型在复杂字符（例如乐谱或几何形状中的字符）识别，数学和分子公式的渲染等任务中都表现良好。

研究人员还将**动态分辨率策略**和**多页 OCR 技术**整合到模型中，从而在高分辨率图像或多页文档常见的实际场景中更加实用。

考虑到现实场景中，线下的、存量的各种财务、医疗、供应链单据亟待完成线上化、数字化，因而笔者判断更智能、更通用、更高效的OCR应用具备杀手潜力。



#### GOT 架构

GOT 模型架构：
- 一个高压缩编码器和一个具有 5.8 亿参数的长上下文解码器。


编码器将输入图像压缩为 256 个“词元”，每个词元 1024 维，而解码器配备8000 个词元，用来生成相应的 OCR 输出。




#### 使用

```sh
# plain texts OCR:
python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type ocr
# format texts OCR:
python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type format
# fine-grained OCR:
python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type format/ocr --box [x1,y1,x2,y2]
python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type format/ocr --color red/green/blue
# multi-crop OCR:
python3 GOT/demo/run_ocr_2.0_crop.py  --model-name  /GOT_weights/ --image-file  /an/image/file.png 
# Note: This feature is not batch inference!! It works on the token level. Please read the paper and then correct use multi-page OCR (the image path contains multiple .png files):
python3 GOT/demo/run_ocr_2.0_crop.py  --model-name  /GOT_weights/ --image-file  /images/path/  --multi-page
# render the formatted OCR results:
python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type format --render
```



#### 训练


huggingface 使用

```py
from transformers import AutoModel, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True)
model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)
model = model.eval().cuda()

# input your test image
image_file = 'xxx.jpg'

# plain texts OCR
res = model.chat(tokenizer, image_file, ocr_type='ocr')

# format texts OCR:
# res = model.chat(tokenizer, image_file, ocr_type='format')

# fine-grained OCR:
# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_box='')
# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_box='')
# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_color='')
# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_color='')

# multi-crop OCR:
# res = model.chat_crop(tokenizer, image_file, ocr_type='ocr')
# res = model.chat_crop(tokenizer, image_file, ocr_type='format')

# render the formatted OCR results:
# res = model.chat(tokenizer, image_file, ocr_type='format', render=True, save_render_file = './demo.html')

print(res)
```

训练
- Stage 1: Pre-training Vision encoder, opt-125m
- Stage 2: Joint-training Encoder-decoder, Qwen-0.5b
- Stage 3: Post-training Lanuage decoder, Qwen-0.5b

```sh
deepspeed   /GOT-OCR-2.0-master/GOT/train/train_GOT.py \
 --deepspeed /GOT-OCR-2.0-master/zero_config/zero2.json    --model_name_or_path /GOT_weights/ \
 --use_im_start_end True   \
 --bf16 True   \
 --gradient_accumulation_steps 2    \
 --evaluation_strategy "no"   \
 --save_strategy "steps"  \
 --save_steps 200   \
 --save_total_limit 1   \
 --weight_decay 0.    \
 --warmup_ratio 0.001     \
 --lr_scheduler_type "cosine"    \
 --logging_steps 1    \
 --tf32 True     \
 --model_max_length 8192    \
 --gradient_checkpointing True   \
 --dataloader_num_workers 8    \
 --report_to none  \
 --per_device_train_batch_size 2    \
 --num_train_epochs 1  \
 --learning_rate 2e-5   \
 --datasets pdf-ocr+scence \
 --output_dir /your/output/path
```


## 验证码识别

- 验证码是一种区分用户是计算机还是人的公共全自动程序。可以防止：恶意破解密码、刷票、论坛灌水，有效防止某个黑客对某一个特定注册用户用特定程序暴力破解方式进行不断的登陆尝试，实际上用验证码是现在很多网站通行的方式。由于验证码可以由计算机生成并评判，但是必须只有人类才能解答，所以回答出问题的用户就可以被认为是人类。

目前验证码通常的种类及特点如下：
 - （1）最基础的英文验证码：纯粹的英文与数字组合，白色背景，这是最容易实现OCR识别的验证码。
 - （2）字体变形的英文验证码：可以通过简单的机器学习实现对英文与数字的识别，准确率较高。
 - （3）加上扰乱背景线条的验证码：可以通过程序去除干扰线，准确率较高。
 - （4）中文验证码：中文由于字体多样，形状多变，数量组合众多，实现起来难度较大，准确率不高。
 - （5）中文字体变形验证码：准确率更低。
 - （6）中英文混合验证码：非常考验OCR程序的判断能力，基本上识别起来非常有难度。
 - （7）提问式验证码：这是需要OCR结合人工智能才能实现，目前基本上无法识别。
 - （8）GIF动态图验证码：由于GIF图片是动态图，无法定位哪一帧是验证码，所以难度很大。
 - （9）划动式验证码：虽然程序可以模拟人的操作，但是具体拖动到哪个位置很难处理。
 - （10）视频验证码：目前OCR识别还未实现。
 - （11）手机验证码：手机验证码实现自动化是很容易的，但是手机号码不那么容易获得。
 - （12）印象验证码：目前无解。

![](https://pic1.zhimg.com/80/v2-2b9748a5ca5498ba1955eec9a5b79db4_720w.jpg)

- 附录：
   - [利用Tesseract-OCR实现验证码识别](https://zhuanlan.zhihu.com/p/34530032)

- 「Happy Captcha」，一款易于使用的 Java 验证码软件包，旨在花最短的时间，最少的代码量，实现 Web 站点的验证码功能。
   - Captcha缩写含义：Completely Automated Public Turing test to tell Computers and Humans Apart
- 效果图
   - ![](https://pic3.zhimg.com/v2-971f594800cdd101950f916f92cb7b1e_b.webp)

## 技术方案

### GAN 方法

【2018-12-14】[基于GAN的验证码识别工具，0.5秒宣告验证码死刑！](https://baijiahao.baidu.com/s?id=1619803729564462538)
- 中英两国研究人员联合开发了一套基于GAN的验证码AI识别系统，能在0.5秒之内识别出验证码，从 实际测试结果看，可以说宣布了对验证码的“死刑判决”。
  - ![](https://ss2.baidu.com/6ONYsjip0QIZ8tyhnq/it/u=280512761,907748494&fm=173&app=49&f=JPEG?w=640&h=273&s=0D30E51281D85DC04A55B0CB0000D0B3)
  - [论文地址](http://www.lancaster.ac.uk/staff/wangz3/publications/ccs18.pdf)，博文介绍：[An A.I. cracks the internet’s squiggly letter bot test in 0.5 seconds](https://www.digitaltrends.com/cool-tech/ai-cracks-captcha-05-seconds/)
- 该系统已在不同的33个验证码系统中进行了成功测试，其中11个来自世界上最受欢迎的一些网站，包括eBay和维基百科等。
- 这种方法的新颖之处在于：使用生成对抗网络（GAN）来创建训练数据。不需要收集和标记数以百万计的验证码文本数据，只需要500组数据就可以成功学习。而且可以使用这些数据，来生成数百万甚至数十亿的合成训练数据，建立高性能的图像分类器。
- 结果显示，<font color='red'>该系统比迄今为止所见的任何验证码识别器系统的识别精度都高。</font>
- ![](https://ss1.baidu.com/6ONXsjip0QIZ8tyhnq/it/u=1299396691,4195542946&fm=173&app=49&f=JPEG?w=640&h=416&s=A498E633795644CA4A6580DA0000C0B3)


### 扩散模型

详见：[图像生成专题](image-generation)


# 结束