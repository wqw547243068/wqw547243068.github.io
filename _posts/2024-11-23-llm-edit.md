---
layout: post
title:   大模型落地技术：模型编辑
date:   2024-11-23 16:52:00
categories: 大模型
tags: llm 编辑 模型 
excerpt: 大模型工业落地的技术经验：如何快速修复基座模型的知识点？
mathjax: true
permalink: /llm_edit
---

* content
{:toc}


# 模型编辑

更多LLM技术落地方案见站内专题：[大模型应用技术方案](llm_solution)

## 问题

预训练大语言模型, 生成内容可能存在**偏见、毒性、知识错误**等问题。
- 偏见: 内容中包含刻板印象和社会偏见等不公正的观点
- 毒性: 内容中包含有害成分
- 知识错误: 信息与事实不符。
  - 例如，当被问到“斑马的皮肤是什么颜色的？”时，ChatGPT 错误地回答“肉色”，而实际上斑马的皮肤是黑色的，这就是一个知识错误


## 思考

解决方法
- （1）模型重训练: 将大语言模型“回炉重造”——用清洗过的数据重新进行预训练，但成本过高，舍本逐末。
- （2）模型微调: 对大语言模型“继续教育”——利用高效微调技术向大语言模型注入新知识，但因为新知识相关样本有限，容易诱发过拟合和灾难性遗忘，得不偿失。
- （3）模型编辑: 仅对模型中的特定知识点进行修正的模型编辑技术应运而生






# 结束
