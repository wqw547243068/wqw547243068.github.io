---
layout: post
title:  TransformerçŸ¥è¯†ç‚¹æ±‡æ€»
date:   2019-12-10 16:52:00
categories: æ·±åº¦å­¦ä¹  
tags: æ·±åº¦å­¦ä¹  NLP Transformer BERT GPT Attention BeamSearch seq2seq æ¨æ¤éºŸ XLNet å¾ªç¯æ™ºèƒ½ roformer rwkv è‹å‰‘æ— æ£€ç´¢ èŠ¯ç‰‡ åºåˆ—åŒ– æ³¨æ„åŠ› ä¸‰è“ä¸€æ£• å¸•ç´¯æ‰˜ retnet yoco
excerpt: Attention is all you need!
mathjax: true
permalink: /transformer
---

* content
{:toc}



# Transformer å­¦ä¹ ç¬”è®°

- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html),Harvard NLPå‡ºå“ï¼Œå«pytorchç‰ˆä»£ç å®ç°
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Transformeræ¨¡å‹çš„PyTorchå®ç°](https://luozhouyang.github.io/transformer/),[A PyTorch implementation of the Transformer model in "Attention is All You Need"](https://github.com/jadore801120/attention-is-all-you-need-pytorch)
- ã€2021-1-21ã€‘[The Transformer Family](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html)
  - ![](https://lilianweng.github.io/lil-log/assets/images/transformer.png)
- ã€2023-6-14ã€‘ææ²å‡ºå“ï¼Œ[åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://zh-v2.d2l.ai/index.html)ï¼Œé¢å‘ä¸­æ–‡è¯»è€…çš„èƒ½è¿è¡Œã€å¯è®¨è®ºçš„æ·±åº¦å­¦ä¹ æ•™ç§‘ä¹¦ï¼Œå« PyTorchã€NumPy/MXNetã€TensorFlow å’Œ PaddlePaddle å®ç°ï¼ŒåŒ…å« [NLP é¢„è®­ç»ƒç« èŠ‚](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/index.html), [Transformerå®è·µ](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert.html)



## Transformer å¯è§†åŒ–


ã€2024-4-2ã€‘ä¸‰è“ä¸€æ£•å‡ºå“: [å¯è§†åŒ–è®²è§£ transformer](https://www.youtube.com/watch?v=wjZofJX0v4M)

<iframe width="560" height="315" src="https://www.youtube.com/embed/wjZofJX0v4M?si=e3vpGav59jQoQdrt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


ã€2023-7-28ã€‘[å…³äº AI çš„æ·±åº¦ç ”ç©¶ï¼šChatGPT æ­£åœ¨äº§ç”Ÿå¿ƒæ™ºå—ï¼Ÿ](https://www.bilibili.com/video/BV1uu4y1m7ak/?spm_id_from=333.1007.0.0)ï¼ŒTransformer åŸç† 3D å¯è§†åŒ–
- <iframe src="//player.bilibili.com/player.html?aid=829105480&bvid=BV1uu4y1m7ak&cid=1213654982&page=1&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"  height="600" width="100%"> </iframe>

## æ€»ç»“

Transformerï¼Œä»**NLP**é¢†åŸŸæ¨ªè·¨åˆ°**è¯­éŸ³**å’Œ**å›¾åƒ**é¢†åŸŸï¼Œæœ€ç»ˆç»Ÿä¸€å‡ ä¹**æ‰€æœ‰æ¨¡æ€**çš„æ¶æ„ã€‚
- åŸºäº Transformers æ¶æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLM)ï¼Œå¦‚ `GPT`ã€`T5` å’Œ `BERT`ï¼Œå·²ç»åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç† (NLP) ä»»åŠ¡ä¸­å–å¾—äº† SOTA ç»“æœã€‚
- æ­¤å¤–ï¼Œæ¶‰è¶³å…¶ä»–é¢†åŸŸï¼Œä¾‹å¦‚ï¼š**è®¡ç®—æœºè§†è§‰** (`VIT`ã€`Stable Diffusion`ã€`LayoutLM`) å’Œ**éŸ³é¢‘** (`Whisper`ã€`XLS-R`)

Google 2017å¹´å‘çš„ä¸€ç¯‡è®ºæ–‡ï¼Œæ ‡é¢˜å«ã€ŠAttention Is All You Needã€‹ï¼Œæ ¸å¿ƒæ˜¯`Self-Attention`æœºåˆ¶ï¼Œä¸­æ–‡ä¹Ÿå«`è‡ªæ³¨æ„åŠ›`ã€‚
- åœ¨è¯­è¨€æ¨¡å‹å»ºæ¨¡è¿‡ç¨‹ä¸­ï¼ŒæŠŠæ³¨æ„åŠ›æ”¾åœ¨é‚£äº›é‡è¦çš„Tokenä¸Šã€‚

åŸºäºtransformerçš„å¤šæ¨¡æ€æ¨¡å‹
- `ViT`: 2020, å›¾åƒä»»åŠ¡
- `CLIP`: 2021, æ–‡æœ¬å’Œå›¾åƒæ··åˆ
- `KOSMOS-1`: 2023, å¤šæ¨¡æ€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹

ã€2024-3-8ã€‘transformer [Transformer é€å±‚å›¾è§£](https://zhuanlan.zhihu.com/p/604450283), medium æ–‡ç« ç¿»è¯‘
- æ•´ä½“ç»“æ„
  - ![](https://pic1.zhimg.com/80/v2-7c5f1ff66fc2c38ceb500d4f3ae688b4_1440w.webp)
- è¯åµŒå…¥ï¼ˆEmbedding ï¼‰ + ä½ç½®ç¼–ç ï¼ˆPosition Encodingï¼‰
  - Transformer è¾“å…¥å…³æ³¨æ¯ä¸ªè¯çš„ä¿¡æ¯ï¼šå«ä¹‰å’Œåºåˆ—ä½ç½®ã€‚
    - åµŒå…¥å±‚å¯¹è¯å«ä¹‰ç¼–ç ã€‚
    - ä½ç½®ç¼–ç å±‚è¡¨ç¤ºè¯çš„ä½ç½®ã€‚ä¸€æ¡æ­£å¼¦æ›²çº¿(å¶æ•°)å’Œä½™å¼¦æ›²çº¿(å¥‡æ•°)
  - ![](https://pic4.zhimg.com/80/v2-354f0896f625a165a7673a570a0b9013_1440w.webp)
- çŸ©é˜µç»´åº¦ï¼ˆMatrix Dimensionsï¼‰
  - åµŒå…¥å±‚æ¥å—ä¸€ä¸ª (samples, sequence_length) å½¢çŠ¶çš„**äºŒç»´å•è¯IDçŸ©é˜µ**ï¼Œå°†æ¯ä¸ªå•è¯IDç¼–ç æˆä¸€ä¸ª**å•è¯å‘é‡**ï¼Œå…¶å¤§å°ä¸º embedding_sizeï¼Œå¾—åˆ°ï¼ˆsamples, sequence_length, embedding_size) å½¢çŠ¶çš„**ä¸‰ç»´è¾“å‡ºçŸ©é˜µ**ã€‚
  - ç”±åµŒå…¥å±‚å’Œä½ç½®ç¼–ç å±‚äº§ç”Ÿçš„ï¼ˆsamples, sequence_length, embedding_size) å½¢çŠ¶åœ¨æ¨¡å‹ä¸­è¢«ä¿ç•™ä¸‹æ¥ï¼Œéšæ•°æ®åœ¨ç¼–ç å™¨å’Œè§£ç å™¨å †æ ˆä¸­æµåŠ¨ï¼Œç›´åˆ°å®ƒè¢«æœ€ç»ˆçš„è¾“å‡ºå±‚æ”¹å˜å½¢çŠ¶ï¼ˆå®é™…ä¸Šå˜æˆäº†samples, sequence_length, vocab_size) ã€‚
  - ![](https://pic3.zhimg.com/80/v2-5484c46f15803fadde7127f7b7ed9fca_1440w.webp)
- ç¼–ç å™¨ ï¼ˆEncoderï¼‰
  - ç¼–ç å™¨å’Œè§£ç å™¨å †æ ˆåˆ†åˆ«ç”±å‡ ä¸ªï¼ˆé€šå¸¸æ˜¯ 6 ä¸ªï¼‰ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆï¼ŒæŒ‰é¡ºåºè¿æ¥ã€‚
  - å †æ ˆä¸­çš„ç¬¬ä¸€ä¸ªç¼–ç å™¨ä»åµŒå…¥å’Œä½ç½®ç¼–ç ä¸­æ¥æ”¶å…¶è¾“å…¥ã€‚å †æ ˆä¸­çš„å…¶ä»–ç¼–ç å™¨ä»å‰ä¸€ä¸ªç¼–ç å™¨æ¥æ”¶å®ƒä»¬çš„è¾“å…¥ã€‚
  - å½“å‰ç¼–ç å™¨æ¥å—ä¸Šä¸€ä¸ªç¼–ç å™¨çš„è¾“å…¥ï¼Œå¹¶å°†å…¶ä¼ å…¥å½“å‰ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›å±‚ã€‚å½“å‰è‡ªæ³¨æ„åŠ›å±‚çš„è¾“å‡ºè¢«ä¼ å…¥å‰é¦ˆå±‚ï¼Œç„¶åå°†å…¶è¾“å‡ºè‡³ä¸‹ä¸€ä¸ªç¼–ç å™¨ã€‚
  - è‡ªæ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œéƒ½ä¼šæ¥å…¥ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œä¹‹åå†é€å…¥æ­£åˆ™åŒ–å±‚ã€‚æ³¨æ„ï¼Œä¸Šä¸€ä¸ªè§£ç å™¨çš„è¾“å…¥è¿›å…¥å½“å‰è§£ç å™¨æ—¶ï¼Œä¹Ÿæœ‰ä¸€ä¸ªæ®‹å·®è¿æ¥ã€‚
  - ç¼–ç å™¨å †æ ˆä¸­çš„æœ€åä¸€ä¸ªç¼–ç å™¨çš„è¾“å‡ºï¼Œä¼šé€å…¥è§£ç å™¨å †æ ˆä¸­çš„æ¯ä¸€ä¸ªè§£ç å™¨ä¸­ã€‚
  - ![](https://pic3.zhimg.com/80/v2-4ee351389eef7f2ff34dc39a9df63aca_1440w.webp)
- è§£ç å™¨ï¼ˆDecoderï¼‰
  - è§£ç å™¨ç»“æ„ä¸ç¼–ç å™¨ç±»ä¼¼ï¼Œä½†æœ‰ä¸€äº›åŒºåˆ«ã€‚
    - åƒç¼–ç å™¨ä¸€æ ·ï¼Œå †æ ˆä¸­çš„ç¬¬ä¸€ä¸ªè§£ç å™¨ä»åµŒå…¥å±‚ï¼ˆè¯åµŒå…¥+ä½ç½®ç¼–ç ï¼‰ä¸­æ¥å—è¾“å…¥ï¼›å †æ ˆä¸­çš„å…¶ä»–è§£ç å™¨ä»ä¸Šä¸€ä¸ªè§£ç å™¨æ¥å—è¾“å…¥ã€‚
    - åœ¨ä¸€ä¸ªè§£ç å™¨å†…éƒ¨ï¼Œè¾“å…¥é¦–å…ˆè¿›å…¥è‡ªæ³¨æ„åŠ›å±‚ï¼Œè¿™ä¸€å±‚çš„è¿è¡Œæ–¹å¼ä¸ç¼–ç å™¨ç›¸åº”å±‚çš„åŒºåˆ«åœ¨äºï¼š
      - è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ï¼Œæ˜¯ç›´åˆ°å½“å‰æ—¶é—´æ­¥æ‰€å¯¹åº”çš„ç›®æ ‡åºåˆ—ï¼Œè€Œä¸ä»…æ˜¯å‰ä¸€ä¸ªæ—¶é—´æ­¥å¯¹åº”çš„ç›®æ ‡åºåˆ—(å³è¾“å…¥çš„æ˜¯step0-stepT-1ï¼Œè€Œéä»…ä»…stepT-1ï¼‰ã€‚
      - æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ï¼Œæ˜¯ç›´åˆ°å½“å‰æ—¶é—´æ­¥æ‰€äº§ç”Ÿçš„æ•´ä¸ªè¾“å‡ºåºåˆ—ã€‚
      - è§£ç å™¨çš„ä¸Šè¿°åŠŸèƒ½ä¸»è¦æ˜¯é€šè¿‡ mask æ–¹æ³•è¿›è¡Œå®ç°ã€‚
    - è§£ç å™¨ä¸ç¼–ç å™¨çš„å¦ä¸€ä¸ªä¸åŒï¼šè§£ç å™¨æœ‰ç¬¬äºŒä¸ªæ³¨æ„å±‚å±‚ï¼Œå³**ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›å±‚** Encoder-Decoder-attention å±‚ã€‚å…¶å·¥ä½œæ–¹å¼ä¸è‡ªæ³¨æ„åŠ›å±‚ç±»ä¼¼ï¼Œåªæ˜¯å…¶è¾“å…¥æ¥æºæœ‰ä¸¤å¤„ï¼šä½äºå…¶å‰çš„è‡ªæ³¨æ„åŠ›å±‚åŠ Eè§£ç å™¨å †æ ˆçš„è¾“å‡ºã€‚
    - Encoder-Decoder attention çš„è¾“å‡ºè¢«ä¼ å…¥å‰é¦ˆå±‚ï¼Œç„¶åå°†å…¶è¾“å‡ºå‘ä¸Šé€è‡³ä¸‹ä¸€ä¸ªDecoderã€‚
    - Decoder ä¸­çš„æ¯ä¸€ä¸ªå­å±‚ï¼Œå³ Multi-Head-Self-Attentionã€Encoder-Decoder-attention å’Œ Feed-forwardå±‚ï¼Œå‡ç”±ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œå¹¶è¿›è¡Œå±‚è§„èŒƒåŒ–ã€‚
    - ![](https://pic2.zhimg.com/80/v2-9a88fdd6495c8fe04e84ea9dd69f3d15_1440w.webp)
- æ³¨æ„åŠ›ï¼ˆAttentionï¼‰
  - æ³¨æ„åŠ›è¢«ç”¨åœ¨ä¸‰ä¸ªåœ°æ–¹ï¼š
    - Encoder ä¸­çš„ Self-attentionï¼šè¾“å…¥åºåˆ—å¯¹è‡ªèº«çš„æ³¨æ„åŠ›è®¡ç®—ï¼›
    - Decoder ä¸­çš„ Self-attentionï¼šç›®æ ‡åºåˆ—å¯¹è‡ªèº«çš„æ³¨æ„åŠ›è®¡ç®—ï¼›
    - Decoder ä¸­çš„Encoder-Decoder-attentionï¼šç›®æ ‡åºåˆ—å¯¹è¾“å…¥åºåˆ—çš„æ³¨æ„åŠ›è®¡ç®—ã€‚
  - æ³¨æ„åŠ›å±‚ï¼ˆSelf-attention å±‚åŠ Encoder-Decoder-attention å±‚ï¼‰ä»¥ä¸‰ä¸ªå‚æ•°çš„å½¢å¼æ¥å—å…¶è¾“å…¥ï¼Œç§°ä¸ºæŸ¥è¯¢ï¼ˆQueryï¼‰ã€é”®ï¼ˆKeyï¼‰å’Œå€¼ï¼ˆValueï¼‰
    - Decoder self-attentionï¼Œè§£ç å™¨çš„è¾“å…¥åŒæ ·è¢«ä¼ é€’ç»™æ‰€æœ‰ä¸‰ä¸ªå‚æ•°ï¼ŒQueryã€Keyå’Œ Valueã€‚
    - Encoder-Decoder-attentionï¼Œç¼–ç å™¨å †æ ˆä¸­æœ€åä¸€ä¸ªç¼–ç å™¨çš„è¾“å‡ºè¢«ä¼ é€’ç»™Valueå’ŒKeyå‚æ•°ã€‚ä½äºå…¶å‰çš„ Self-attention å’Œ Layer Norm æ¨¡å—çš„è¾“å‡ºè¢«ä¼ é€’ç»™ Query å‚æ•°ã€‚
    - ![](https://pic4.zhimg.com/80/v2-8eead7c22c8bce22e9ac2f5328bab70f_1440w.webp)
  - è‡ªæ³¨æ„åŠ›è®¡ç®—æ–¹å¼
    - ![])(https://pic3.zhimg.com/80/v2-7cda913d104961a1db0e5ea6ff3a8b86_1440w.webp)
- å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-head Attentionï¼‰
  - å¤šå¤´æ³¨æ„åŠ›--Multi-head Attention é€šè¿‡èåˆå‡ ä¸ªç›¸åŒçš„æ³¨æ„åŠ›è®¡ç®—ï¼Œä½¿æ³¨æ„åŠ›è®¡ç®—å…·æœ‰æ›´å¼ºå¤§çš„åˆ†è¾¨èƒ½åŠ›
- æ©ç 

### Transformer æ¶æ„ç†è§£

`Transformer`æ˜¯ä¸€ç§`Encoder-Decoder`æ¶æ„(Seq2Seqæ¶æ„ä¹Ÿæ˜¯)ï¼Œå…ˆæŠŠ**è¾“å…¥**æ˜ å°„åˆ°`Encoder`ï¼Œå¯ä»¥æŠŠEncoderæƒ³è±¡æˆRNNï¼ŒDecoderä¹Ÿæ˜¯ã€‚

Transformer è¿™ä¸ªæ¶æ„åŸºäº`Seq2Seq`ï¼ŒåŒæ—¶å¤„ç†`NLU`å’Œ`NLG`ä»»åŠ¡ï¼Œè€Œä¸”Self Attentionæœºåˆ¶çš„ç‰¹å¾æå–èƒ½åŠ›å¾ˆå¼ºã€‚
- ä¸åŒäºSeq2Seq, Transformer æ˜¯ä¸€ä¸ª `set-to-set` æ¨¡å‹ï¼Œä¸å†ä¾èµ–ä¸²è¡Œï¼Œè§£å†³äº†seq2seqå¹¶è¡Œèƒ½åŠ›é—®é¢˜
  - seq2seq: **åºåˆ—åˆ°åºåˆ—**æ¨¡å¼
  - transformer: **é›†åˆåˆ°é›†åˆ**æ¨¡å¼
- åªè¦æ•°æ®æ˜¯åŸºæœ¬å•ä½ç»„æˆçš„é›†åˆï¼ˆa set of unitsï¼‰ï¼Œå°±å¯ä»¥åº”ç”¨ transformerï¼›

è¿™æ ·ï¼Œå·¦è¾¹è´Ÿè´£**ç¼–ç **ï¼Œå³è¾¹åˆ™è´Ÿè´£**è§£ç **ã€‚ä¸åŒçš„æ˜¯
- (1) `ç¼–ç `æ—¶ï¼Œå› ä¸ºçŸ¥é“æ•°æ®ï¼Œæ‰€ä»¥å»ºæ¨¡æ—¶å¯ä»¥åŒæ—¶åˆ©ç”¨å½“å‰Tokençš„**å†å²Token**å’Œ**æœªæ¥Token**ï¼›
  - Encoderçš„blockåˆ†ä¸¤ä¸ªæ¨¡å—ï¼š`Multi-Head Attention`å’Œ`Feed Forward`ï¼Œ
  - â‘  `Multi-Head Attention`ç”¨åˆ°`Self Attention`ï¼Œå’ŒAttentionç±»ä¼¼ï¼Œä¸è¿‡å®ƒæ˜¯Tokenå’ŒTokençš„**é‡è¦æ€§æƒé‡**ã€‚`Multi-Head`å°†è‡ªæ³¨æ„åŠ›é‡å¤næ¬¡ï¼Œæ¯ä¸ªtokenæ³¨æ„åˆ°çš„ä¿¡æ¯ä¸ä¸€æ ·ï¼Œå¯ä»¥æ•è·åˆ°æ›´å¤šä¿¡æ¯ã€‚
    - æ¯”å¦‚ï¼šã€Œ<span style='color:blue'>æˆ‘å–œæ¬¢åœ¨æ·±å¤œçš„æ˜Ÿç©ºä¸‹ä¼´éšç€æœˆäº®è½»è½»åœ°æƒ³ä½ </span>ã€ï¼Œæœ‰çš„Headã€Œæˆ‘ã€æ³¨æ„åˆ°ã€Œ**å–œæ¬¢**ã€ï¼Œæœ‰çš„Headã€Œæˆ‘ã€æ³¨æ„åˆ°ã€Œ**æ·±å¤œ**ã€ï¼Œæœ‰çš„Headã€Œæˆ‘ã€æ³¨æ„åˆ°ã€Œ**æƒ³ä½ **ã€â€¦â€¦
  - â‘¡ `Feed Forward`ç›¸å½“äºã€Œ**è®°å¿†**å±‚ã€ï¼Œå¤§æ¨¡å‹å¤§éƒ¨åˆ†çŸ¥è¯†éƒ½å­˜åœ¨æ­¤ï¼Œ`Multi-Head Attention`æ ¹æ®ä¸åŒæƒé‡çš„æ³¨æ„æå–çŸ¥è¯†ã€‚
- (2) ä½†`è§£ç `æ—¶é€ä¸ªTokenè¾“å‡ºï¼Œæ‰€ä»¥åªèƒ½æ ¹æ®**å†å²Token**ä»¥åŠEncoderçš„**Tokenè¡¨ç¤º**è¿›è¡Œå»ºæ¨¡ï¼Œè€Œä¸èƒ½åˆ©ç”¨æœªæ¥Tokenã€‚

NLPå…¸å‹ä»»åŠ¡

|ä»»åŠ¡|ç†è§£(`NLU`)|ç”Ÿæˆ(`NLG`)|è¾“å…¥/è¾“å‡ºæ¨¡å¼|åˆ†æ|
|---|---|---|---|
|æ–‡æœ¬åˆ†ç±»|âœ…|âŒ|å¤šå¯¹ä¸€|é€‚åˆEncoder|
|æ–‡æœ¬åŒ¹é…|âœ…|âŒ|è¿‘ä¼¼å¤šå¯¹ä¸€|é€‚åˆEncoder|
|æ–‡æœ¬ç”Ÿæˆ|âŒ|âœ…|å¤šå¯¹å¤š,å˜é•¿|é€‚åˆEncoder|
|åºåˆ—æ ‡æ³¨|âœ…|âŒ|å¤šå¯¹å¤š,å®šé•¿|é€‚åˆEncoder|
|æ–‡æœ¬æ‘˜è¦|âŒ|âœ…|å¤šå¯¹å¤š,å˜é•¿,ä¸€èˆ¬å˜å°‘|é€‚åˆDecoder|
|æœºå™¨ç¿»è¯‘|âŒ|âœ…|å¤šå¯¹å¤š,å˜é•¿|é€‚åˆDecoder|
|æ”¹å†™/çº é”™|âŒ|âœ…|å¤šå¯¹å¤š,ç»´åº¦è¿‘ä¼¼|é€‚åˆDecoder|
|é—®ç­”ç³»ç»Ÿ|âŒ|âœ…|å¤šå¯¹å¤š,ç»´åº¦ä¸å®š|é€‚åˆDecoder|

ç„¶è€Œï¼Œå¤§å¤šæ•°NLPä»»åŠ¡å…¶å®å¹¶ä¸æ˜¯Seq2Seqï¼Œå…¸å‹ä»£è¡¨ï¼šå¥å­çº§åˆ«`åˆ†ç±»`ã€Tokençº§åˆ«åˆ†ç±»ï¼ˆä¹Ÿå«`åºåˆ—æ ‡æ³¨`ï¼‰ã€`ç›¸ä¼¼åº¦`åŒ¹é…å’Œç”Ÿæˆï¼›
- è€Œå‰ä¸‰ç§åº”ç”¨æœ€ä¸ºå¹¿æ³›ã€‚è¿™æ—¶å€™`Encoder`å’Œ`Decoder`å¯ä»¥æ‹†å¼€ç”¨ã€‚
  - å·¦è¾¹çš„Encoderåœ¨æŠŠå¥å­è¡¨ç¤ºæˆä¸€ä¸ªå‘é‡æ—¶ï¼Œåˆ©ç”¨**ä¸Šä¸‹æ–‡**ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯**åŒå‘**ï¼›
  - å³è¾¹çš„Decoderä¸èƒ½çœ‹åˆ°æœªæ¥çš„Tokenï¼Œä¸€èˆ¬åªåˆ©ç”¨**ä¸Šæ–‡**ï¼Œæ˜¯**å•å‘**çš„ã€‚
- è™½ç„¶éƒ½å¯ä»¥ç”¨æ¥å®Œæˆåˆšåˆšæåˆ°çš„å‡ ä¸ªä»»åŠ¡ï¼Œä½†ä»æ•ˆæœä¸Šæ¥è¯´
  - `Encoder`æ›´åŠ é€‚åˆ**éç”Ÿæˆç±»**(å³ç†è§£ç±»)ä»»åŠ¡
  - `Decoder`æ›´åŠ é€‚åˆ**ç”Ÿæˆç±»**ä»»åŠ¡ã€‚

NLPé¢†åŸŸä¸€èˆ¬åˆ†åˆ«å«åš`NLU`ï¼ˆNatural Language Understandingï¼Œè‡ªç„¶è¯­è¨€ç†è§£ï¼‰ä»»åŠ¡å’Œ`NLG`ï¼ˆNatural Language Generationï¼Œè‡ªç„¶è¯­è¨€ç”Ÿæˆï¼‰ä»»åŠ¡ã€‚
- **NLUä»»åŠ¡**ï¼šå¥å­çº§åˆ«åˆ†ç±»ï¼Œç»™å®šä¸€ä¸ªå¥å­è¾“å‡ºä¸€ä¸ªç±»åˆ«ã€‚
  - å› ä¸ºå¥å­å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ï¼Œç»è¿‡å¼ é‡è¿ç®—æ˜ å°„åˆ°æ¯ä¸ªç±»çš„æ¦‚ç‡åˆ†å¸ƒã€‚
  - è¿™å’Œä¹‹å‰çš„è¯­è¨€æ¨¡å‹æ²¡æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåªæ˜¯è¯­è¨€æ¨¡å‹çš„ç±»åˆ«æ˜¯**æ•´ä¸ªè¯è¡¨å¤§å°**ï¼Œè€Œåˆ†ç±»çš„ç±»åˆ«çœ‹å…·ä½“ä»»åŠ¡ï¼Œæœ‰`äºŒåˆ†ç±»`ã€`å¤šåˆ†ç±»`ã€`å¤šæ ‡ç­¾åˆ†ç±»`ç­‰ç­‰ã€‚
- **NLGä»»åŠ¡**: é™¤äº†ç”Ÿæˆå¤–ï¼Œå¸¸è§çš„æœ‰`æ–‡æœ¬æ‘˜è¦`ã€`æœºå™¨ç¿»è¯‘`ã€`æ”¹å†™çº é”™`ç­‰ã€‚

### self-attention ç†è§£

Self-Attention æ˜¯èƒ½åŠ›è¶…å¼ºçš„ç‰¹å¾æå–å™¨ï¼Œè·Ÿ RNNã€CNN ç›¸æ¯”
- ![](https://d2l.ai/_images/cnn-rnn-self-attention.svg)

self-attention è¿ç®—æ˜¯æ‰€æœ‰ transformer æ¶æ„çš„åŸºæœ¬è¿ç®—, è€Œ Self-attention æ˜¯ sequence-to-sequence è¿ç®—ï¼š 
- è¾“å…¥ä¸€ä¸ªå‘é‡åºåˆ—ï¼ˆx1,x2,...,xmï¼‰ï¼Œè¾“å‡ºå¦ä¸€ä¸ªå‘é‡åºåˆ— (y1,y2,...,yn)ï¼Œæ‰€æœ‰å­—ç¬¦éƒ½æ˜ å°„æˆkç»´å‘é‡ï¼›
- è¾“å‡ºå‘é‡æ˜¯xçš„åŠ æƒå¹³å‡ï¼š yi = âˆ‘ wi * xi
- è®¡ç®—æƒé‡çŸ©é˜µW æœ€ç®€å•å‡½æ•°å°±æ˜¯`ç‚¹ç§¯`ï¼ˆdot productï¼‰: $ w_ij = x_i^T * x_j $
- ç»“æœå–å€¼èŒƒå›´æ˜¯**æ­£è´Ÿæ— ç©·**ï¼Œä¸ºäº†ä½¿ç´¯åŠ å’Œï¼ˆè¡¨ç¤ºæ¦‚ç‡ï¼‰ç­‰äº 100%ï¼Œ éœ€è¦åšå½’ä¸€åŒ–, å³ softmax
- æ€»ç»“èµ·æ¥å°±æ˜¯ä¸¤ç‚¹ï¼š
  - vector-to-vector è¿ç®—ï¼šself-attention æ˜¯å¯¹ input vector åšçŸ©é˜µè¿ç®—ï¼Œå¾—åˆ°ä¸€ä¸ªåŠ æƒç»“æœä½œä¸º output vectorï¼›
  - åŠ æƒçŸ©é˜µè®¡ç®—ï¼šæƒé‡çŸ©é˜µä¸æ˜¯å¸¸é‡ï¼Œè€Œæ˜¯è·Ÿå®ƒæ‰€åœ¨çš„ä½ç½® (i,j) ç›´æ¥ç›¸å…³ï¼Œæ ¹æ®å¯¹åº”ä½ç½®çš„ input vector è®¡ç®—ã€‚
  - ![](http://arthurchiao.art/assets/img/transformers-from-scratch/self-attention.png)
  - output vector ä¸­çš„æ¯ä¸ªå…ƒç´  yj éƒ½æ˜¯å¯¹ input vector ä¸­æ‰€æœ‰å…ƒç´ çš„åŠ æƒå’Œï¼›
  - å¯¹äº yjï¼ŒåŠ æƒçŸ©é˜µç”± input å…ƒç´  xj ä¸æ¯ä¸ª input å…ƒç´ è®¡ç®—å¾—åˆ°ï¼›

self-attention æ˜¯æ•´ä¸ªæ¶æ„ä¸­å”¯ä¸€åœ¨ input & output vector ä¹‹é—´ æ‰€åšçš„è¿ç®—ï¼›
- Transformer æ¶æ„ä¸­çš„å…¶ä»–è¿ç®—éƒ½æ˜¯å•çº¯å¯¹ input vector åšè¿ç®—ã€‚

self-attention æ¨¡å‹éå¸¸ç®€å•ï¼Œæœ¬è´¨ä¸Šæ˜¯åŠ æƒå¹³å‡å…¬å¼ï¼Œä¸ºä»€ä¹ˆæ•ˆæœè¿™ä¹ˆå¥½å‘¢ï¼Ÿ

ä»¥ç”µå½±æ¨èä¸ºä¾‹

**ä¼ ç»Ÿæ¨èç³»ç»Ÿ**ï¼šç‰¹æ€§å‘é‡ç‚¹ç§¯ç”¨æˆ·åå¥½
- æ­¥éª¤ï¼š
  - äººå·¥è®¾è®¡ä¸€äº›**ç”µå½±ç‰¹å¾**ï¼Œæ¯”å¦‚ï¼šæµªæ¼«æŒ‡æ•°ã€åŠ¨ä½œæŒ‡æ•°ï¼Œ
  - äººå·¥è®¾è®¡ä¸€äº›**ç”¨æˆ·ç‰¹å¾**ï¼Œä¾‹å¦‚ï¼šå–œæ¬¢æµªæ¼«ç”µå½±æˆ–åŠ¨ä½œç‰‡çš„å¯èƒ½æ€§ï¼›
  - æœ‰äº†è¿™ä¸¤ä¸ªç»´åº¦çš„æ•°æ®ï¼ˆç‰¹å¾å‘é‡ï¼‰ä¹‹åï¼Œå¯¹äºŒè€…åš`ç‚¹ç§¯`ï¼ˆdot productï¼‰ï¼Œ å¾—åˆ°ç”µå½±å±æ€§ä¸ç”¨æˆ·å–œæ¬¢ç¨‹åº¦ä¹‹é—´çš„**åŒ¹é…ç¨‹åº¦**ï¼Œç”¨å¾—åˆ†è¡¨ç¤º
- ç”µå½±æ¨èï¼š**ç”µå½±**ç‰¹å¾å‘é‡ï¼ˆæµªæ¼«ã€åŠ¨ä½œã€å–œå‰§ï¼‰ä¸**ç”¨æˆ·**ç‰¹æ€§å‘é‡ï¼ˆå–œæ¬¢æµªæ¼«ã€åŠ¨ä½œã€å–œå‰§çš„ç¨‹åº¦ï¼‰åš**ç‚¹ç§¯è¿ç®—**
- ![](http://arthurchiao.art/assets/img/transformers-from-scratch/movie-dot-product.png)

å¾—åˆ†æ•°å€¼ï¼š
- å¦‚æœç‰¹å¾çš„ç¬¦å·ç›¸åŒï¼Œä¾‹å¦‚â€œæµªæ¼«ç”µå½± && ç”¨æˆ·å–œæ¬¢æµªæ¼«ç”µå½±â€ï¼Œ æˆ–è€…â€œä¸æ˜¯æµªæ¼«ç”µå½± && ç”¨æˆ·ä¸å–œæ¬¢æµªæ¼«ç”µå½±â€ï¼Œå¾—åˆ°çš„ç‚¹ç§¯å°±æ˜¯**æ­£æ•°**ï¼›åä¹‹å°±æ˜¯**è´Ÿæ•°**ï¼›
- ç‰¹å¾å€¼çš„å¤§å°å†³å®šè¯¥ç‰¹å¾å¯¹æ€»åˆ†çš„**è´¡çŒ®å¤§å°**ï¼š ä¸€éƒ¨ç”µå½±å¯èƒ½æœ‰ç‚¹æµªæ¼«ï¼Œä½†ä¸æ˜¯å¾ˆæ˜æ˜¾ï¼Œæˆ–è€…ç”¨æˆ·å¯èƒ½åªæ˜¯ä¸å–œæ¬¢æµªæ¼«ï¼Œä½†ä¹Ÿæ²¡åˆ°è®¨åŒçš„ç¨‹åº¦ã€‚

åˆ†æ
- ä¼˜ç‚¹ï¼šç®€å•ç›´æ¥ï¼Œå¾ˆå®¹æ˜“ä¸Šæ‰‹ï¼›
- ç¼ºç‚¹ï¼šè§„æ¨¡å¤§äº†å¾ˆéš¾æï¼Œ å› ä¸ºå¯¹å‡ ç™¾ä¸‡éƒ¨ç”µå½±æ‰“æ ‡çš„æˆæœ¬éå¸¸é«˜ï¼Œç²¾ç¡®æ ‡è®°ç”¨æˆ·å–œæ¬¢æˆ–ä¸å–œæ¬¢ä»€ä¹ˆä¹Ÿå‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚

åŸºäº **self-attention çš„æ¨èç³»ç»Ÿ**

ç”µå½±ç‰¹å¾å’Œç”¨æˆ·ç‰¹å¾ä½œä¸ºæ¨¡å‹å‚æ•°ï¼ŒåŒ¹é…å·²çŸ¥çš„ç”¨æˆ·åå¥½

ä¸¤æ­¥ï¼š
- ç”µå½±ç‰¹å¾å’Œç”¨æˆ·ç‰¹å¾ä¸å†ç›´æ¥åšç‚¹ç§¯è¿ç®—ï¼Œè€Œæ˜¯ä½œä¸º**æ¨¡å‹å‚æ•°**ï¼ˆparameters of the modelï¼‰ï¼›
- æ”¶é›†å°‘é‡çš„ç”¨æˆ·åå¥½ä½œä¸ºç›®æ ‡ï¼Œç„¶åé€šè¿‡ä¼˜åŒ–ç”¨æˆ·ç‰¹å¾å’Œç”µå½±ç‰¹å¾ï¼ˆæ¨¡å‹å‚æ•°ï¼‰ï¼Œ ä½¿äºŒè€…çš„ç‚¹ç§¯åŒ¹é…å·²çŸ¥çš„ç”¨æˆ·å–œå¥½ã€‚

è¿™å°±æ˜¯ self-attention çš„åŸºæœ¬åŸç†ã€‚

ä»¥ä¸€ä¸²å•è¯ä½œä¸ºè¾“å…¥ï¼ŒåŸç†ä¸Šåªè¦å°†å…¶ä½œä¸º input vector é€åˆ° self-attention æ¨¡å‹ã€‚
- ä½†å®é™…ä¸Šè¦å¯¹ input vector åšé¢„å¤„ç†ï¼Œç”Ÿæˆä¸€ä¸ª**ä¸­é—´è¡¨ç¤º**ï¼Œå³åºåˆ—å»ºæ¨¡ä¸­çš„åµŒå…¥å±‚ã€‚ä¸ºæ¯ä¸ªå•è¯ t åˆ†é…ä¸€ä¸ª`åµŒå…¥å‘é‡`ï¼ˆembedding vectorï¼‰ ğ¯tï¼ˆæˆ‘ä»¬åé¢å°†å­¦ä¹ åˆ°è¿™ä¸ªå€¼ï¼‰ã€‚
-  input vector -> embedding vector -> self-attention -> output vector
- (the, cat) -> (V_the, V_cat) -> åŠ æƒæ±‚å’Œ -> y_the, y_cat

ä¸åŒäºä¸€èˆ¬çš„ sequence-to-sequence è¿ç®—ï¼š
- self-attention å°†è¾“å…¥å½“åšä¸€ä¸ª**é›†åˆ**ï¼ˆsetï¼‰è€Œä¸æ˜¯**åºåˆ—**ï¼ˆsequenceï¼‰ã€‚
- å¦‚æœå¯¹è¾“å…¥åºåˆ—è¿›è¡Œ**é‡æ’**ï¼ˆpermuteï¼‰ï¼Œè¾“å‡ºåºåˆ—é™¤äº†ä¹Ÿè·Ÿç€é‡æ’ï¼Œå…¶ä»–æ–¹é¢å°†å®Œå…¨ç›¸åŒï¼Œself-attention æ˜¯**æ’åˆ—ç­‰å˜**çš„ï¼ˆpermutation equivariantï¼‰ã€‚
- æ„å»ºå®Œæ•´çš„ transformer æ—¶ï¼Œè¿˜æ˜¯ä¼šå¼•å…¥ä¸€äº›ä¸œè¥¿æ¥ä¿æŒè¾“å…¥çš„é¡ºåºä¿¡æ¯ï¼Œä½†è¦æ˜ç™½ <span style='color:red'>self-attention æœ¬èº«æ˜¯ä¸å…³å¿ƒè¾“å…¥çš„é¡ºåºå±æ€§çš„ï¼ˆsequential natureï¼‰</span>ã€‚

æœ€åŸºç¡€çš„ self-attention æ¨¡å‹å®ç°ï¼š
- 2æ¬¡ çŸ©é˜µä¹˜æ³• å’Œ 1æ¬¡ å½’ä¸€åŒ–ï¼ˆsoftmaxï¼‰ã€‚

```py
import torch
import torch.nn.functional as F

# å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº› tensor x ä½œä¸ºè¾“å…¥ï¼Œå®ƒæ˜¯ (b, t, k) ç»´çŸ©é˜µ
x = ...

# torch.bmm() æ˜¯æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼ˆbatched matrix multiplicationï¼‰å‡½æ•°ï¼Œå¯¹ä¸€æ‰¹çŸ©é˜µæ‰§è¡Œä¹˜æ³•æ“ä½œ
raw_weights = torch.bmm(x, x.transpose(1, 2))
# æ­£å€¼åŒ–ã€å½’ä¸€åŒ–
weights = F.softmax(raw_weights, dim=2)
# è®¡ç®—è¾“å‡º
y = torch.bmm(weights, x)
```

ç°ä»£ transformer å¯¹ self-attention çš„æ‰©å±•
- å¼•å…¥æ§åˆ¶å‚æ•°ï¼ˆqueries, keys and valuesï¼‰
- å¯¹ç‚¹ç§¯åšç¼©æ”¾å¤„ç†ï¼ˆscaling the dot productï¼‰
  - softmax å‡½æ•°å¯¹éå¸¸å¤§çš„è¾“å…¥å€¼æ•æ„Ÿã€‚è¿™äº› input ä¼šæ¢¯åº¦æ¶ˆå¤±ï¼Œå­¦ä¹ å˜æ…¢ç”šè‡³å®Œå…¨åœæ­¢ã€‚ 
  - ç”±äºç‚¹ç§¯çš„**å¹³å‡å€¼**éšç€åµŒå…¥ç»´åº¦ k çš„å¢åŠ è€Œå¢å¤§ï¼Œå› æ­¤ç‚¹ç§¯é€åˆ° softmax ä¹‹å‰è¿›è¡Œç¼©æ”¾æœ‰åŠ©äºç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚
  - $ w_ij = q_i^T k_j$ -> $ w_ij = \frac{q_i^T k_j}{\sqrt{k}}$
- å¼•å…¥ multi-head attention
  - åŒä¸€ä¸ªå•è¯éšç€ç›¸é‚»å•è¯ä»¬çš„ä¸åŒè¡¨ç¤ºçš„æ„æ€ä¹Ÿå¯èƒ½ä¸åŒ, <span style='color:red'>åŸºæœ¬çš„ self-attention æ¬ ç¼ºäº†å¾ˆå¤šçµæ´»æ€§</span>ã€‚
    - å¦‚ä½•ç†è§£ï¼Ÿ
  - è®©æ¨¡å‹æœ‰æ›´å¼ºçš„è¾¨è¯†åŠ›ï¼Œä¸€ç§è§£æ³•ï¼šç»„åˆå¤šä¸ª self-attentionï¼ˆç”¨ r ç´¢å¼•ï¼‰ï¼Œ æ¯ä¸ªå¯¹åº”ä¸åŒçš„ query/key/value å‚æ•°çŸ©é˜µ $ ğ–^r_q$ , $ ğ–^r_k $, $ ğ–^r_v $ï¼Œ ç§°ä¸º attention headsï¼ˆæ³¨æ„åŠ›å¤´ï¼‰ã€‚
  - å¯¹äº input ğ±iï¼Œæ¯ä¸ª attention head äº§ç”Ÿä¸åŒçš„ output vector $ ğ²^r_i $ï¼ˆä¸€éƒ¨åˆ†è¾“å‡ºï¼‰ã€‚ æœ€åå†å°†è¿™äº›éƒ¨åˆ†è¾“å‡ºè¿æ¥èµ·æ¥ï¼Œé€šè¿‡çº¿æ€§å˜æ¢æ¥é™ç»´å› kã€‚

multi-head self-attention ææ•ˆï¼šquery/key/value é™ç»´
- multi-head self-attention çœ‹ä½œ**å¤šä¸ªå¹¶è¡Œ**çš„ self-attention æœºåˆ¶ï¼Œæ¯ä¸ªéƒ½æœ‰è‡ªå·±çš„é”®ã€å€¼å’ŒæŸ¥è¯¢è½¬æ¢ã€‚
- Multi-head self-attention çš„ç¼ºç‚¹: æ…¢ï¼Œå¯¹äº R å¤´ï¼Œæ…¢ R å€ã€‚ 

ä¼˜åŒ–åŠæ³•ï¼š
- å®ç°è¿™æ ·çš„ multi-head self-attentionï¼Œæ—¢èƒ½åˆ©ç”¨å¤šä¸ª self-attention æå‡è¾¨è¯†åŠ›ï¼Œ åˆä¸ single-head self-attention åŸºæœ¬ä¸€æ ·å¿«ã€‚
- æ¯ä¸ª head å¯¹ query/key/value é™ç»´ã€‚ 

å¦‚æœè¾“å…¥å‘é‡æœ‰ k=256 ç»´ï¼Œæ¨¡å‹æœ‰ h=4 ä¸ª attention headï¼Œåˆ™é™ç»´æ“ä½œåŒ…æ‹¬ï¼š
- å°†è¾“å…¥å‘é‡ä¹˜ä»¥ä¸€ä¸ª 256Ã—64 çŸ©é˜µï¼Œè¿™ä¼šå°† input vector ä» 256 ç»´é™åˆ° 64 ç»´ï¼›
- å¯¹äºæ¯ä¸ª head éœ€è¦æ‰§è¡Œ 3 æ¬¡é™ç»´ï¼šåˆ†åˆ«é’ˆå¯¹ query/key/value çš„è®¡ç®—ã€‚

ç”šè‡³åªç”¨ä¸‰æ¬¡ kÃ—k çŸ©é˜µä¹˜æ³•å°±èƒ½å®ç° multi-head åŠŸèƒ½ï¼Œ å”¯ä¸€éœ€è¦çš„é¢å¤–æ“ä½œæ˜¯å°†ç”Ÿæˆçš„ output vector é‡æ–°æŒ‰å—æ’åº

multi-head self-attention å®Œæ•´æµç¨‹
- ![](http://arthurchiao.art/assets/img/transformers-from-scratch/multi-head.png)

4-head self-attention çš„ç›´è§‚è§£é‡Šã€‚å¯¹è¾“å…¥è¿›è¡Œé™ç»´ï¼Œé’ˆå¯¹ key/value/query åˆ†åˆ«è¿›è¡ŒçŸ©é˜µè¿ç®—æ¥å®ç°ã€‚

ä»å·¦åˆ°å³åˆ†ä¸º 5 åˆ—ï¼š
- åŸå§‹ 256-ç»´ input vectorï¼›
- è¾“å…¥é™ç»´ï¼šå°† input vector ä¹˜ä»¥ 256x64 çŸ©é˜µï¼Œé™ç»´åˆ° 64 ç»´ï¼›(256/4=64)
  - æ³¨æ„ï¼šå¯¹æ¯ä¸ª input vector éœ€è¦åˆ†åˆ«é’ˆå¯¹ query/key/value é™ç»´ï¼Œæ€»å…±æ˜¯ 3 éï¼›
- å°†é™ç»´åçš„ input åˆ†åˆ«è¾“å…¥å¤šä¸ªå¹¶è¡Œçš„ self-attentionï¼›
- è®¡ç®—å¾—åˆ°å¤šä¸ªé™ç»´ä¹‹åçš„ output vectorï¼›
- å¯¹ä½ç»´åº¦ output vectors è¿›è¡Œæ‹¼æ¥ï¼Œ**é‡æ–°**å›åˆ°ä¸ input vectors ä¸€æ ·çš„ç»´åº¦ã€‚

å‚æ•°è§„æ¨¡
- `single-head`: æ€»å‚æ•°æ•°é‡æ˜¯ $3k^2$ã€‚
- `multi-head`: å‚æ•°ä¸ªæ•° $ 3hk\frac{k}{h}=3k^2 $
  - ä¸ single-head self-attention çš„å‚æ•°æ•°é‡ç›¸åŒã€‚
- å”¯ä¸€åŒºåˆ«: 
  - multi-head self-attention æœ€åæ‹¼æ¥ output vector æ—¶å¤šäº†ä¸€ä¸ªçŸ©é˜µ Wo

- å‚è€ƒï¼š[Transformer æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š600 è¡Œ Python ä»£ç å®ç°ä¸¤ä¸ªï¼ˆæ–‡æœ¬åˆ†ç±»+æ–‡æœ¬ç”Ÿæˆï¼‰Transformer](http://arthurchiao.art/blog/transformers-from-scratch-zh/)

### transformerè§£å†³ä»€ä¹ˆé—®é¢˜

é’ˆå¯¹rnnå’Œcnnçš„ç¼ºé™·ï¼ŒTransformeræ€ä¹ˆè§£å†³è¿™äº›é—®é¢˜ï¼Ÿ
- å¹¶è¡ŒåŒ–
- é•¿ç¨‹ä¾èµ–å­¦ä¹ 
- å±‚æ¬¡åŒ–å»ºæ¨¡

[Transformerè§†é¢‘æé€Ÿè®²è§£](https://vdn6.vzuu.com/SD/8e617f0a-18b6-11ed-a515-caa2f7fe3b8b.mp4)


## Transformeræ¨¡å‹

- ![img](https://picb.zhimg.com/80/v2-6c292e2a4ed43894fc954ee625372c67_720w.jpg)

ä¸Šå›¾ä¸‹é¢éƒ¨åˆ†ï¼Œè®­ç»ƒç”¨çš„è¾“å…¥å’Œè¾“å‡ºæ•°æ®çš„ embeddingï¼Œéƒ½ä¼šå…ˆåŠ ä¸Šä¸€ä¸ªposition encodingæ¥è¡¥å……ä¸€ä¸‹ä½ç½®ä¿¡æ¯ã€‚
- `Encoder`
  - é€”ä¸­å·¦ä¾§éƒ¨åˆ†æ˜¯encoderå—ï¼Œencoderä¸­6å±‚ç›¸åŒç»“æ„å †å è€Œæˆï¼Œåœ¨æ¯å±‚ä¸­åˆå¯ä»¥åˆ†ä¸º2ä¸ªå­å±‚ï¼Œåº•ä¸‹ä¸€å±‚æ˜¯multihead self-attentionå±‚ï¼Œä¸Šé¢æ˜¯ä¸€ä¸ªFC feed-forwardå±‚ï¼Œæ¯ä¸€ä¸ªå­å±‚éƒ½æœ‰residual connectionï¼Œï¼Œç„¶ååœ¨è¿›è¡ŒLayer Normalization. ä¸ºäº†å¼•å…¥redisual connenctionç®€åŒ–è®¡ç®—ï¼Œæ¯ä¸ªå±‚çš„è¾“å…¥ç»´æ•°å’Œembeddingå±‚ä¿æŒä¸€è‡´ã€‚
- `Decoder`
  - åŒæ ·æ˜¯ä¸€ä¸ª6å±‚çš„å †å ï¼Œæ¯å±‚æœ‰ä¸‰ä¸ªå­å±‚ï¼Œå…¶ä¸­åº•ä¸‹ä¸¤å±‚éƒ½æ˜¯multihead self-attentionå±‚ï¼Œæœ€åº•ä¸‹ä¸€å±‚æ˜¯æœ‰maskçš„ï¼Œåªæœ‰å½“å‰ä½ç½®ä¹‹å‰çš„è¾“å…¥æœ‰æ•ˆï¼Œä¸­é—´å±‚æ˜¯encodeå’Œdecodeçš„è¿æ¥å±‚ï¼Œè¾“å‡ºçš„self-attentionå±‚å’Œè¾“å…¥çš„encoderè¾“å‡ºåŒæ—¶ä½œä¸ºMSAçš„è¾“å…¥ï¼Œå®ç°encoderå’Œdecoderçš„è¿æ¥ï¼Œæœ€ä¸Šå±‚å’Œencoderçš„æœ€ä¸Šå±‚æ˜¯ä¸€æ ·çš„ï¼Œä¸åœ¨å•è¯´ï¼Œæ¯ä¸ªå­å±‚éƒ½æœ‰æœ‰residual connectionï¼Œå’ŒLayer Normalization

ã€2021-8-25ã€‘Transformerç»“æ„ä¸­ï¼Œå·¦è¾¹å«åš**ç¼–ç ç«¯**(Encoder)ï¼Œå³è¾¹å«åš**è§£ç ç«¯**(Decoder)ã€‚ä¸è¦å°çœ‹è¿™ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå…¶ä¸­å·¦è¾¹çš„ç¼–ç ç«¯æœ€åæ¼”åŒ–æˆäº†æœ€åé¼é¼å¤§åçš„**Bert**ï¼Œå³è¾¹çš„è§£ç ç«¯åœ¨æœ€è¿‘å˜æˆäº†æ— äººä¸çŸ¥çš„**GPT**æ¨¡å‹ã€‚

ã€2023-2-15ã€‘transformer å‡ºç°åï¼Œè¿…é€Ÿå–ä»£äº† RNNç³»åˆ— å˜ç§ï¼Œè·»èº«ä¸»æµæ¨¡å‹æ¶æ„åŸºç¡€ã€‚

transformer ç»“æ„åˆ†æˆï¼š
- ï¼ˆ1ï¼‰è‡ªå›å½’ç³»åˆ—ï¼šåå¥½ æ–‡æœ¬ç”Ÿæˆï¼Œç¤ºä¾‹ï¼šGPT-3ï¼›
- ï¼ˆ2ï¼‰åŒå‘è‡ªç¼–ç ç³»åˆ—ï¼šåå¥½ è‡ªç„¶è¯­è¨€ç†è§£ï¼Œç¤ºä¾‹ï¼šBERTï¼ŒåŒå‘transformer+Maskè‡ªç¼–ç ç³»åˆ—
- ï¼ˆ3ï¼‰encoder-decoderç³»åˆ—ï¼šåå¥½ æ¡ä»¶æ–‡æœ¬ç”Ÿæˆï¼Œç¤ºä¾‹ï¼šT5ï¼ŒåŒå‘/å•å‘attention

### RNNç³»åˆ—

è¯¦è§ç«™å†…ä¸“é¢˜ï¼š[RNNå’Œseq2seqæ¼”å˜](text-generation)

### äº®ç‚¹

- `Self Attention`
  - ä¼ ç»Ÿçš„ç¼–è§£ç ç»“æ„ä¸­ï¼Œå°†è¾“å…¥è¾“å…¥ç¼–ç ä¸ºä¸€ä¸ªå®šé•¿è¯­ä¹‰ç¼–ç ï¼Œç„¶åé€šè¿‡è¿™ä¸ªç¼–ç åœ¨ç”Ÿæˆå¯¹åº”çš„è¾“å‡ºåºåˆ—ã€‚å®ƒå­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜åœ¨äºï¼šè¾“å…¥åºåˆ—ä¸è®ºé•¿çŸ­éƒ½ä¼šè¢«ç¼–ç æˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºï¼Œè€Œè§£ç åˆ™å—é™äºè¯¥å›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤º
  - attentionæœºåˆ¶: encoderçš„è¾“å‡ºä¸æ˜¯ä¸€ä¸ªè¯­ä¹‰å‘é‡ï¼Œæ˜¯ä¸€ä¸ªè¯­ä¹‰å‘é‡çš„åºåˆ—
   ![](https://upload-images.jianshu.io/upload_images/14911967-cadfa37d31342857.png?imageMogr2/auto-orient/strip|imageView2/2/w/568/format/webp)
  - Transformerçš„Attenionå‡½æ•°ç§°ä¸ºscaled dot-Product Attention
   ![](https://upload-images.jianshu.io/upload_images/14911967-9fb3d576399e53e5.png?imageMogr2/auto-orient/strip|imageView2/2/w/455/format/webp)
- `MultiHead Attention`
  - self attentionè®¡ç®—æ—¶ä¼šåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€ä¸ªé˜¶æ®µè®¡ç®—å‡ºsoftmaxéƒ¨åˆ†,ç¬¬äºŒéƒ¨åˆ†æ˜¯åœ¨ä¹˜ä»¥ Valueéƒ¨åˆ†ï¼Œè¿™æ ·è¿˜æ˜¯ä¸²è¡ŒåŒ–çš„ï¼Œå¹¶è¡ŒåŒ–ä¸å¤Ÿã€‚
  - MultiHeadAttentionï¼Œå¯¹queryï¼Œkeyï¼Œvalueå„è‡ªè¿›è¡Œä¸€æ¬¡ä¸åŒçš„çº¿æ€§å˜æ¢ï¼Œç„¶ååœ¨æ‰§è¡Œä¸€æ¬¡softmaxæ“ä½œï¼Œè¿™æ ·å¯ä»¥æå‡å¹¶è¡Œåº¦ï¼Œè®ºæ–‡ä¸­çš„headæ•°æ˜¯8ä¸ª

![img](https://upload-images.jianshu.io/upload_images/14911967-b31aa04d8628b8da.png?imageMogr2/auto-orient/strip|imageView2/2/w/600/format/webp)
- position Encoding
  - è¯­è¨€æ˜¯æœ‰åºçš„ï¼Œåœ¨cnnä¸­ï¼Œå·ç§¯çš„å½¢çŠ¶åŒ…å«äº†ä½ç½®ä¿¡æ¯ï¼Œåœ¨rnnä¸­ï¼Œä½ç½®çš„å…ˆåé¡ºåºå…¶å®æ˜¯é€šè¿‡é€å…¥æ¨¡å‹çš„å…ˆåæ¥ä¿è¯ã€‚transformeræŠ›å¼ƒäº†cnnå’Œrnnï¼Œé‚£ä¹ˆæ•°æ®çš„ä½ç½®ä¿¡æ¯æ€ä¹ˆæä¾›å‘¢ï¼Ÿ
  - Transformeré€šè¿‡position Encodingæ¥é¢å¤–çš„æä¾›ä½ç½®ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ªä½ç½®å¯¹åº”ä¸€ä¸ªå‘é‡ï¼Œè¿™ä¸ªå‘é‡å’Œword embeddingæ±‚å’Œåä½œä¸º encoderå’Œdecoderçš„è¾“å…¥ã€‚è¿™æ ·ï¼Œå¯¹äºåŒä¸€ä¸ªè¯è¯­æ¥è¯´ï¼Œåœ¨ä¸åŒçš„ä½ç½®ï¼Œä»–ä»¬é€å…¥encoderå’Œdecoderçš„å‘é‡ä¸åŒã€‚


### æ€»ç»“

- ç»“æ„
![](https://upload-images.jianshu.io/upload_images/14911967-dec395c8d1d19f18.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)
- è®­ç»ƒè¿‡ç¨‹
![](https://upload-images.jianshu.io/upload_images/14911967-ca45ad4ea6c91e77.gif?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)

ä½œè€…ï¼š[Transformeræ¨¡å‹å­¦ä¹ ](https://www.jianshu.com/p/04b6dd396d62)

### å›¾è§£Transformer

- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/),ä¸­æ–‡ç¿»è¯‘ï¼š[BERTå¤§ç«å´ä¸æ‡‚Transformerï¼Ÿ](https://zhuanlan.zhihu.com/p/54523019)
- [jalammar github repo](https://github.com/jalammar/jalammar.github.io/blob/master/_posts/2018-06-27-illustrated-transformer.md)
- ![](https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png)
- ![](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)
- ![](https://jalammar.github.io/images/t/transformer_decoding_2.gif)


## Transformeræ¶æ„

- transformer ç»“æ„å›¾ï¼š  
- ![transformer_architecture](http://blog.stupidme.me/wp-content/uploads/2018/09/transformer.jpg)  

é¦–å…ˆï¼Œ**Transformer**æ¨¡å‹ä½¿ç”¨ç»å…¸çš„**encoer-decoder**æ¶æ„ï¼Œç”±encoderå’Œdecoderä¸¤éƒ¨åˆ†ç»„æˆã€‚
- ä¸Šå›¾çš„å·¦åŠè¾¹ç”¨`Nx`æ¡†å‡ºæ¥çš„ï¼Œencoderçš„ä¸€å±‚ã€‚encoderä¸€å…±æœ‰6å±‚è¿™æ ·çš„ç»“æ„ã€‚
- ä¸Šå›¾çš„å³åŠè¾¹ç”¨`Nx`æ¡†å‡ºæ¥çš„ï¼Œdecoderçš„ä¸€å±‚ã€‚decoderä¸€å…±æœ‰6å±‚è¿™æ ·çš„ç»“æ„ã€‚
- è¾“å…¥åºåˆ—ç»è¿‡**word embedding**å’Œ**positional encoding**ç›¸åŠ åï¼Œè¾“å…¥åˆ°encoderã€‚
- è¾“å‡ºåºåˆ—ç»è¿‡**word embedding**å’Œ**positional encoding**ç›¸åŠ åï¼Œè¾“å…¥åˆ°decoderã€‚
- æœ€åï¼Œdecoderè¾“å‡ºçš„ç»“æœï¼Œç»è¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼Œç„¶åè®¡ç®—softmaxã€‚

**word embedding**å’Œ**positional encoding**åé¢ä¼šè§£é‡Šã€‚é¦–å…ˆè¯¦ç»†åœ°åˆ†æä¸€ä¸‹encoderå’Œdecoderçš„æ¯ä¸€å±‚æ˜¯æ€ä¹ˆæ ·çš„ã€‚


## åºåˆ—åŒ–

æ¨¡å‹åªè®¤è¯†æ•°å­—ï¼Œå› æ­¤ï¼Œè¾“å…¥å‰éœ€è¦å°†å„ç§æ¨¡æ€çš„æ•°æ®åºåˆ—åŒ–æˆæ•°ç»„/å‘é‡

æ•°æ®æ¨¡æ€
- æ–‡æœ¬
- è¯­éŸ³
- å›¾åƒ

å‚è€ƒ[çŸ¥ä¹](https://www.zhihu.com/question/362131975/answer/3360076979?utm_psn=1732160182669500416)

### æ–‡æœ¬åºåˆ—åŒ–

- æ–‡å­—åºåˆ—æ ¹æ® BPE æˆ–è€…å…¶å®ƒç¼–ç æ–¹æ³•å¾—åˆ° Token
  - æ–‡å­—ç¼–ç æ–¹å¼ï¼šä¸€ä¸ªè‹±æ–‡å•è¯ç¼–ç åœ¨ 1ï½2 ä¸ª tokenï¼Œ ä¸€ä¸ªæ±‰å­—ç¼–ç æ˜¯ 1ï½3 ä¸ª tokenï¼Œæ¯ä¸ª token éƒ½æ˜¯ä¸€ä¸ªæ•°å­—
- Token é€šè¿‡æŸ¥è¡¨ç›´æ¥å¾—åˆ° EmbedingçŸ©é˜µ
  - è¿™ä¸ªè¡¨é€šå¸¸éå¸¸å¤§ ï¼Œæ¯”å¦‚ GPT3 å¯èƒ½æ˜¯ 12288x4096ï¼Œ 12288æ˜¯ token ä¸ªæ•°ï¼Œ4096 æ˜¯ç»´åº¦ï¼Œæ¯ä¸ª token æŸ¥è¡¨åæœ‰ 4096 ç»´ï¼Œè¿™ä¸ªæ˜¯è®­ç»ƒå‡ºæ¥çš„
- Token é€šè¿‡ Postion è®¡ç®— Positional Encodingï¼ˆæ ‡å‡†ç®—æ³•å…¬å¼ï¼‰
- å°† Embedding ä¸ Positional Encoding ç›¸åŠ å¾—åˆ° Transformerçš„è¾“å…¥

Token æŸ¥è¡¨ç¤ºæ„å›¾
- ![è®¡ç®—å…¬å¼](https://pic1.zhimg.com/80/v2-7adff3d727accdb4666bb4c660c36920_1440w.webp?source=2c26e567)
- æ¯ä¸ªtokençš„ä½ç½®embeddingå—å¤šä¸ªå› ç´ å½±å“ï¼šè¯åº“æ€»æ•°n, embeddingç»´åº¦d, tokenå¯¹åº”çš„è¯åº“id(k), å¥å­ä¸­çš„ç¬¬å‡ ä¸ª(i), sinè¿˜æ˜¯cos
- ![ç¤ºæ„å›¾](https://picx.zhimg.com/80/v2-e527b6da0c2a2b70ff944bedc2ef93df_1440w.webp?source=2c26e567)


### å›¾åƒåºåˆ—åŒ–

å›¾åƒçš„ token åŒ–
- ç›´æ¥æŠŠå›¾åƒçŸ©é˜µåˆ†å‰²æˆå°å—(å¦‚ 16x16)
- å†æŒ‰é¡ºåºæ’å¥½
- ç„¶ååŠ ä½ç½®ç¼–ç 

ç¤ºä¾‹
- ![](https://picx.zhimg.com/80/v2-f2948cab056293658e4077daa1cc0510_1440w.webp?source=2c26e567)

å›¾ç‰‡è¢«åˆ‡å‰²æ‹‰å¹³åï¼Œç›´æ¥æ‰”åˆ°ä¸€ä¸ª CNN ç½‘ç»œé‡Œå˜æˆ Transformer çš„è¾“å…¥éƒ¨åˆ†

### è¯­éŸ³åºåˆ—åŒ–

å£°éŸ³çš„ token åŒ–æœ€ç®€å•ï¼Œå› ä¸ºå¤©ç”Ÿå°±æœ‰äºŒç»´ç‰¹å¾: mel è°±æ•°æ®

ä»¥ openai çš„ whisper é¡¹ç›®ä¸ºä¾‹
- å£°éŸ³è¾“å…¥çš„ token æ¯ 30ms ä¸€ä¸ªï¼Œ80 ä¸ªlog mel è°±æ•°æ®ã€‚
- è¿™æ ·åªè¦ä¸æ–­åˆ‡æ®µï¼Œè¿™ä¸ªå£°éŸ³å°±ç›´æ¥å˜æˆäº†äºŒç»´çŸ©é˜µ
- ![](https://picx.zhimg.com/80/v2-08ad9aaaa6295e24cb10a82bbab7f1a2_1440w.webp?source=2c26e567)

å£°éŸ³è¾“å…¥ä¹Ÿæœ‰ position embedding

## Encoder

Encoder ç”±6å±‚ç›¸åŒçš„å±‚ç»„æˆï¼Œæ¯ä¸€å±‚åˆ†åˆ«ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
- * ç¬¬ä¸€éƒ¨åˆ†æ˜¯ä¸€ä¸ª**multi-head self-attention mechanism**
- * ç¬¬äºŒéƒ¨åˆ†æ˜¯ä¸€ä¸ª**position-wise feed-forward network**ï¼Œæ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚

ä¸¤ä¸ªéƒ¨åˆ†ï¼Œéƒ½æœ‰ä¸€ä¸ªã€€**æ®‹å·®è¿æ¥(residual connection)**ï¼Œç„¶åæ¥ç€ä¸€ä¸ª**Layer Normalization**ã€‚
- ![ENCODER](https://jalammar.github.io/images/xlnet/transformer-encoder-block-2.png)
- An encoder block from the original transformer paper can take inputs up until a certain max sequence length (e.g. 512 tokens). It's okay if an input sequence is shorter than this limit, we can just pad the rest of the sequence.

æ–°æ‰‹å¯èƒ½ä¼šé—®ï¼š
- * multi-head self-attention æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
- * å‚å·®ç»“æ„æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
- * Layer Normalizationåˆæ˜¯ä»€ä¹ˆï¼Ÿ

## Decoder

å’Œ encoder ç±»ä¼¼ï¼Œdecoderç”±6ä¸ªç›¸åŒçš„å±‚ç»„æˆï¼Œæ¯å±‚åŒ…æ‹¬3ä¸ªéƒ¨åˆ†ï¼š
* ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ˜¯**multi-head self-attention mechanism**
* ç¬¬äºŒéƒ¨åˆ†æ˜¯**multi-head context-attention mechanism**
* ç¬¬ä¸‰éƒ¨åˆ†æ˜¯ä¸€ä¸ª**position-wise feed-forward network**
- ![DECODER](https://jalammar.github.io/images/xlnet/transformer-decoder-block-2.png)

ä¸‰ä¸ªéƒ¨åˆ†éƒ½æœ‰ä¸€ä¸ª**æ®‹å·®è¿æ¥**ï¼Œåæ¥ä¸€ä¸ª**Layer Normalization**ã€‚

ç›¸åŒ
- éƒ½æœ‰ è‡ªæ³¨æ„åŠ›å±‚ï¼ˆself-attentionï¼‰
- éƒ½æœ‰ å‰å‘å…¨è¿æ¥å±‚ï¼ˆfeed forward neural networkï¼‰

ä¸åŒäº encoderï¼š
- `è‡ªæ³¨æ„åŠ›å±‚`å°†å¾…é¢„æµ‹çš„tokenå±è”½æ‰ï¼ˆmaskï¼‰ï¼Œæ‰€ä»¥æ˜¯ masked self-attentionã€‚æ©ç æ–¹æ³•ä¸åŒäºBERTçš„ç½®ä¸º \[MASK\]ï¼Œè€Œæ˜¯ç»§æ‰¿åˆ°è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸­ã€‚
  - ![img](https://jalammar.github.io/images/gpt2/self-attention-and-masked-self-attention.png)
- æ–°å¢ `ç¼–ç å™¨-è§£ç å™¨è‡ªæ³¨æ„åŠ›å±‚`ï¼ˆencoder-decoder self-attentionï¼‰

ä½†æ˜¯ï¼Œdecoderå‡ºç°äº†ä¸€ä¸ªæ–°çš„ä¸œè¥¿**multi-head context-attention mechanism**ã€‚è¿™ä¸ªä¸œè¥¿å…¶å®ä¹Ÿä¸å¤æ‚ï¼Œç†è§£äº†**multi-head self-attention** å¯ä»¥ç†è§£**multi-head context-attention**ã€‚

GPT-2 ç”¨çš„ Decoder ç»“æ„
- ![decoder](https://jalammar.github.io/images/xlnet/transformer-decoder-intro.png)
- å»æ‰ transformer decoderç»“æ„é‡Œçš„ `ç¼–ç å™¨-è§£ç å™¨è‡ªæ³¨æ„åŠ›å±‚`

## Attentionæœºåˆ¶

è¯­è¨€çš„å«ä¹‰æåº¦ä¾èµ–ä¸Šä¸‹æ–‡ï¼Œæ¯”å¦‚ï¼Œæœºå™¨äººç¬¬äºŒæ³•åˆ™ï¼š
- <span style='color:blue'>æœºå™¨äººç¬¬äºŒæ³•åˆ™æœºå™¨äººå¿…é¡»éµå®ˆäººç±»ç»™**å®ƒ**çš„**å‘½ä»¤**ï¼Œé™¤éè¯¥å‘½ä»¤è¿èƒŒäº†**ç¬¬ä¸€æ³•åˆ™**</span>ã€‚

è¿™å¥è¯ä¸­é«˜äº®äº†ä¸‰ä¸ªåœ°æ–¹ï¼ŒæŒ‡ä»£å…¶å®ƒå•è¯ã€‚éœ€è¦æŠŠè¿™äº›è¯æŒ‡ä»£çš„ä¸Šä¸‹æ–‡è”ç³»èµ·æ¥ï¼Œæ‰èƒ½ç†è§£æˆ–å¤„ç†è¿™äº›è¯è¯­ã€‚æ¨¡å‹å¤„ç†è¿™å¥è¯æ—¶ï¼Œå¿…é¡»çŸ¥é“ï¼š
>- ã€Œå®ƒã€æŒ‡ä»£æœºå™¨äºº
>- ã€Œå‘½ä»¤ã€æŒ‡ä»£å‰åŠå¥è¯ä¸­äººç±»ç»™æœºå™¨äººä¸‹çš„å‘½ä»¤ï¼Œå³ã€Œäººç±»ç»™å®ƒçš„å‘½ä»¤ã€
>- ã€Œç¬¬ä¸€æ³•åˆ™ã€æŒ‡æœºå™¨äººç¬¬ä¸€æ³•åˆ™çš„å®Œæ•´å†…å®¹

è‡ªæ³¨æ„åŠ›æœºåˆ¶
- å¤„ç†æ¯ä¸ªå•è¯ï¼ˆå°†å…¶ä¼ å…¥ç¥ç»ç½‘ç»œï¼‰ä¹‹å‰ï¼Œèå…¥äº†æ¨¡å‹è§£é‡ŠæŸä¸ªå•è¯çš„ä¸Šä¸‹æ–‡çš„ç›¸å…³å•è¯çš„ç†è§£ã€‚
- ç»™åºåˆ—ä¸­æ¯ä¸€ä¸ªå•è¯éƒ½èµ‹äºˆä¸€ä¸ª**ç›¸å…³åº¦å¾—åˆ†**ï¼Œä¹‹åå¯¹å‘é‡è¡¨å¾æ±‚å’Œã€‚

**Attention**æ˜¯æŒ‡å¯¹äºæŸä¸ªæ—¶åˆ»çš„è¾“å‡º`y`ï¼Œå®ƒåœ¨è¾“å…¥`x`ä¸Šå„ä¸ªéƒ¨åˆ†çš„æ³¨æ„åŠ›ã€‚è¿™ä¸ªæ³¨æ„åŠ›å®é™…ä¸Šå¯ä»¥ç†è§£ä¸º**æƒé‡**ã€‚

Attention æœºåˆ¶ä¹Ÿå¯ä»¥åˆ†æˆå¾ˆå¤šç§ã€‚[Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html) ä¸€æ–‡æœ‰ä¸€å¼ æ¯”è¾ƒå…¨é¢çš„è¡¨æ ¼ï¼š  
- ![attention_mechanism](http://blog.stupidme.me/wp-content/uploads/2018/09/attention_mechanism_table.png)  
- *Figure 2. a summary table of several popular attention mechanisms.*  

ä¸Šé¢ç¬¬ä¸€ç§**additive attention**æ˜¯ä»¥å‰seq2seqæ¨¡å‹é‡Œé¢ï¼Œä½¿ç”¨attentionæœºåˆ¶ï¼Œè¿™ç§**åŠ æ€§æ³¨æ„åŠ›(additive attention)**ç”¨çš„å¾ˆå¤šã€‚Googleçš„é¡¹ç›® [tensorflow/nmt](https://github.com/tensorflow/nmt) é‡Œé¢è¿™ä¸¤ç§attentionæœºåˆ¶éƒ½æœ‰å®ç°ã€‚

ä¸ºä»€ä¹ˆè¿™ç§attentionå«åš**additive attention**å‘¢ï¼Ÿ
- å¯¹äºè¾“å…¥åºåˆ—éšçŠ¶æ€ $h_i$ å’Œè¾“å‡ºåºåˆ—çš„éšçŠ¶æ€ $s_t$ ï¼Œå®ƒçš„å¤„ç†æ–¹å¼å¾ˆç®€å•ï¼Œç›´æ¥**åˆå¹¶**ï¼Œå˜æˆ$[s_t;h_i]$

ä½†æ˜¯ transformeræ¨¡å‹ç”¨çš„ä¸æ˜¯è¿™ç§attentionæœºåˆ¶ï¼Œä½¿ç”¨çš„æ˜¯å¦ä¸€ç§ï¼Œå«åš**ä¹˜æ€§æ³¨æ„åŠ›(multiplicative attention)**ã€‚

é‚£ä¹ˆè¿™ç§**ä¹˜æ€§æ³¨æ„åŠ›æœºåˆ¶**æ˜¯æ€ä¹ˆæ ·çš„å‘¢ï¼Ÿä»ä¸Šè¡¨ä¸­çš„å…¬å¼ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥ï¼š**ä¸¤ä¸ªéšçŠ¶æ€è¿›è¡Œç‚¹ç§¯**ï¼

### Self-attentionæ˜¯ä»€ä¹ˆï¼Ÿ

ä»€ä¹ˆæ˜¯**self-attention**

self-attention ç»“æ„å›¾ã€‚[åŸæ–‡](https://zhuanlan.zhihu.com/p/636889198)
- ä¸€ä¸ªè¾“å…¥åºåˆ—çš„å‘é‡é›†åˆï¼ˆçŸ©é˜µï¼‰ï¼Œç»è¿‡Wqã€Wkã€Wvä¸‰ä¸ªæƒé‡çŸ©é˜µè®¡ç®—ä¹‹åï¼Œç”Ÿæˆäº†Qã€Kã€Vä¸‰ä¸ªçŸ©é˜µï¼Œç»è¿‡FFç½‘ç»œï¼Œæœ€åç”Ÿæˆäº†æ–°çš„å‘é‡é›†åˆã€‚
- ![img](https://pic1.zhimg.com/80/v2-545cd59a1accb86ab17cc739a029de34_1440w.webp)
- [img](https://pic1.zhimg.com/80/v2-545cd59a1accb86ab17cc739a029de34_1440w.webp)

attentionæœºåˆ¶æ¶‰åŠä¸¤ä¸ªéšçŠ¶æ€ï¼š $ h_i $ å’Œ $s_t$ï¼Œå‰è€…æ˜¯è¾“å…¥åºåˆ—ç¬¬iä¸ªä½ç½®äº§ç”Ÿçš„éšçŠ¶æ€ï¼Œåè€…æ˜¯è¾“å‡ºåºåˆ—åœ¨ç¬¬tä¸ªä½ç½®äº§ç”Ÿçš„éšçŠ¶æ€ã€‚

**self-attention**å®é™…æ˜¯ï¼š**è¾“å‡ºåºåˆ—**å°±æ˜¯**è¾“å…¥åºåˆ—**ï¼å› æ­¤ï¼Œè®¡ç®—è‡ªå·±çš„attentionå¾—åˆ†ï¼Œå°±å«åš**self-attention**ï¼

æœ€ä¸Šå±‚çš„ transformer æ¨¡å—åœ¨å¤„ç†å•è¯ã€Œitã€çš„æ—¶å€™ä¼šå…³æ³¨ã€Œa robotã€ï¼Œæ‰€ä»¥ã€Œaã€ã€ã€Œrobotã€ã€ã€Œitã€è¿™ä¸‰ä¸ªå•è¯ä¸å…¶å¾—åˆ†ç›¸ä¹˜åŠ æƒæ±‚å’Œåçš„ç‰¹å¾å‘é‡ä¼šè¢«é€å…¥ä¹‹åçš„ç¥ç»ç½‘ç»œå±‚ã€‚
- ![](https://pic4.zhimg.com/80/v2-e748fe9dc233efd6210ef79852371407_1440w.webp)

è‡ªæ³¨æ„åŠ›æœºåˆ¶æ²¿ç€åºåˆ—ä¸­æ¯ä¸€ä¸ªå•è¯çš„è·¯å¾„è¿›è¡Œå¤„ç†ï¼Œä¸»è¦ç”± 3 ä¸ªå‘é‡ç»„æˆï¼š
- **æŸ¥è¯¢å‘é‡**ï¼ˆQuery å‘é‡ï¼‰ï¼šå½“å‰å•è¯çš„æŸ¥è¯¢å‘é‡å’Œå…¶å®ƒå•è¯çš„é”®å‘é‡ç›¸ä¹˜ï¼Œå¾—åˆ°å…¶å®ƒè¯ç›¸å¯¹äºå½“å‰è¯çš„æ³¨æ„åŠ›å¾—åˆ†ã€‚åªå…³å¿ƒç›®å‰æ­£åœ¨å¤„ç†çš„å•è¯çš„æŸ¥è¯¢å‘é‡ã€‚
- `é”®å‘é‡` ï¼ˆKey å‘é‡ï¼‰ï¼šé”®å‘é‡å°±åƒæ˜¯åºåˆ—ä¸­æ¯ä¸ªå•è¯çš„**æ ‡ç­¾**ï¼Œæœç´¢ç›¸å…³å•è¯æ—¶ç”¨æ¥åŒ¹é…çš„å¯¹è±¡ã€‚
- `å€¼å‘é‡` ï¼ˆValue å‘é‡ï¼‰ï¼šå€¼å‘é‡æ˜¯å•è¯çœŸæ­£çš„**è¡¨å¾**ï¼Œå½“ç®—å‡ºæ³¨æ„åŠ›å¾—åˆ†åï¼Œä½¿ç”¨å€¼å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œå¾—åˆ°èƒ½ä»£è¡¨å½“å‰ä½ç½®ä¸Šä¸‹æ–‡çš„å‘é‡ã€‚
- ![](https://pic4.zhimg.com/80/v2-773eec2cc3564bef9f99d97513b2af27_1440w.webp)

æ¯”å–»: æ¡£æ¡ˆæŸœä¸­æ‰¾æ–‡ä»¶ã€‚
>- æŸ¥è¯¢å‘é‡å°±åƒä¸€å¼ **ä¾¿åˆ©è´´**ï¼Œä¸Šé¢å†™ç€æ­£åœ¨ç ”ç©¶çš„è¯¾é¢˜ã€‚
>- é”®å‘é‡åƒæ˜¯æ¡£æ¡ˆæŸœä¸­æ–‡ä»¶å¤¹ä¸Šè´´çš„**æ ‡ç­¾**ã€‚å½“ä½ æ‰¾åˆ°å’Œä¾¿åˆ©è´´ä¸Šæ‰€å†™ç›¸åŒ¹é…çš„æ–‡ä»¶å¤¹æ—¶ï¼Œæ‹¿å‡ºå®ƒï¼Œæ–‡ä»¶å¤¹é‡Œçš„ä¸œè¥¿ä¾¿æ˜¯å€¼å‘é‡ã€‚åªä¸è¿‡æœ€åæ‰¾çš„å¹¶ä¸æ˜¯å•ä¸€çš„å€¼å‘é‡ï¼Œè€Œæ˜¯å¾ˆå¤šæ–‡ä»¶å¤¹å€¼å‘é‡çš„æ··åˆã€‚

å°†å•è¯æŸ¥è¯¢å‘é‡åˆ†åˆ«ä¹˜ä»¥æ¯ä¸ªæ–‡ä»¶å¤¹çš„**é”®å‘é‡**ï¼Œå¾—åˆ°å„ä¸ªæ–‡ä»¶å¤¹å¯¹åº”çš„**æ³¨æ„åŠ›å¾—åˆ†**
- ä¹˜æŒ‡çš„æ˜¯**å‘é‡ç‚¹ä¹˜**ï¼Œä¹˜ç§¯ä¼šé€šè¿‡ softmax å‡½æ•°å¤„ç†ã€‚

å°†å€¼å‘é‡**åŠ æƒæ··åˆ**å¾—åˆ°ä¸€ä¸ªå‘é‡
>- å°†å…¶ **50%** çš„ã€Œæ³¨æ„åŠ›ã€æ”¾åœ¨äº†å•è¯ã€Œrobotã€ä¸Šï¼Œ**30%** çš„æ³¨æ„åŠ›æ”¾åœ¨äº†ã€Œaã€ä¸Šï¼Œè¿˜æœ‰ **19%** çš„æ³¨æ„åŠ›æ”¾åœ¨ã€Œitã€ä¸Š

- ![](https://pic4.zhimg.com/80/v2-62813b22b6fdbad01c155228f4298967_1440w.webp)

åµŒå…¥çŸ©é˜µçš„æ¯è¡Œéƒ½å¯¹åº”æ¨¡å‹è¯æ±‡è¡¨ä¸­ä¸€ä¸ªå•è¯çš„åµŒå…¥å‘é‡ã€‚**ä¹˜æ³•æ“ä½œ**å¾—åˆ°è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯å¯¹åº”çš„**æ³¨æ„åŠ›å¾—åˆ†**ã€‚
- ![](https://pic4.zhimg.com/80/v2-0871db72d018b09d71d90b31c2d1362f_1440w.webp)



### Context-attentionæ˜¯ä»€ä¹ˆï¼Ÿ

çŸ¥é“äº†**self-attention**ï¼Œé‚£ä½ è‚¯å®šçŒœåˆ°äº†**context-attention**æ˜¯ä»€ä¹ˆäº†ï¼š**å®ƒæ˜¯encoderå’Œdecoderä¹‹é—´çš„attention**ï¼æ‰€ä»¥ï¼Œä½ ä¹Ÿå¯ä»¥ç§°ä¹‹ä¸º**encoder-decoder attention**!

**context-attention**ä¸€è¯å¹¶ä¸æ˜¯æœ¬äººåŸåˆ›ï¼Œæœ‰äº›æ–‡ç« æˆ–è€…ä»£ç ä¼šè¿™æ ·æè¿°ï¼Œæˆ‘è§‰å¾—æŒºå½¢è±¡çš„ï¼Œæ‰€ä»¥åœ¨æ­¤æ²¿ç”¨è¿™ä¸ªç§°å‘¼ã€‚å…¶ä»–æ–‡ç« å¯èƒ½ä¼šæœ‰å…¶ä»–åç§°ï¼Œä½†æ˜¯ä¸è¦ç´§ï¼Œæˆ‘ä»¬æŠ“ä½äº†é‡ç‚¹å³å¯ï¼Œé‚£å°±æ˜¯**ä¸¤ä¸ªä¸åŒåºåˆ—ä¹‹é—´çš„attention**ï¼Œä¸**self-attention**ç›¸åŒºåˆ«ã€‚

ä¸ç®¡æ˜¯**self-attention**è¿˜æ˜¯**context-attention**ï¼Œå®ƒä»¬è®¡ç®—attentionåˆ†æ•°çš„æ—¶å€™ï¼Œå¯ä»¥é€‰æ‹©å¾ˆå¤šæ–¹å¼ï¼Œæ¯”å¦‚ä¸Šé¢è¡¨ä¸­æåˆ°çš„ï¼š
* additive attention
* local-base
* general
* dot-product
* scaled dot-product

é‚£ä¹ˆTransformeræ¨¡å‹é‡‡ç”¨çš„æ˜¯å“ªç§å‘¢ï¼Ÿç­”æ¡ˆæ˜¯ï¼š**scaled dot-product attention**ã€‚

### Scaled dot-product attentionæ˜¯ä»€ä¹ˆï¼Ÿ

è®ºæ–‡[Attention is all you need](https://arxiv.org/abs/1706.03762)é‡Œé¢å¯¹äºattentionæœºåˆ¶çš„æè¿°æ˜¯è¿™æ ·çš„ï¼š
> An attention function can be described as a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility of the query with the corresponding key.

è¿™å¥è¯æè¿°å¾—å¾ˆæ¸…æ¥šäº†ã€‚ç¿»è¯‘è¿‡æ¥å°±æ˜¯ï¼š**é€šè¿‡ç¡®å®šQå’ŒKä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦æ¥é€‰æ‹©V**ï¼

ç”¨å…¬å¼æ¥æè¿°æ›´åŠ æ¸…æ™°ï¼š

$$ \text{Attention}(Q,K,V)=softmax(\frac{QK^T}{\sqrt d_k})V $$

**scaled dot-product attention**å’Œ**dot-product attention**å”¯ä¸€çš„åŒºåˆ«å°±æ˜¯ï¼Œ**scaled dot-product attention**æœ‰ä¸€ä¸ªç¼©æ”¾å› å­ $ \frac{1}{\sqrt d_k} $ã€‚

ä¸Šé¢å…¬å¼ä¸­çš„$d_k$è¡¨ç¤ºçš„æ˜¯Kçš„ç»´åº¦ï¼Œåœ¨è®ºæ–‡é‡Œé¢ï¼Œé»˜è®¤æ˜¯`64`ã€‚

é‚£ä¹ˆä¸ºä»€ä¹ˆéœ€è¦åŠ ä¸Šè¿™ä¸ªç¼©æ”¾å› å­å‘¢ï¼Ÿè®ºæ–‡é‡Œç»™å‡ºäº†è§£é‡Šï¼šå¯¹äº$d_k$å¾ˆå¤§çš„æ—¶å€™ï¼Œç‚¹ç§¯å¾—åˆ°çš„ç»“æœç»´åº¦å¾ˆå¤§ï¼Œä½¿å¾—ç»“æœå¤„äºsoftmaxå‡½æ•°æ¢¯åº¦å¾ˆå°çš„åŒºåŸŸã€‚

æ¢¯åº¦å¾ˆå°çš„æƒ…å†µï¼Œè¿™å¯¹åå‘ä¼ æ’­ä¸åˆ©ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªè´Ÿé¢å½±å“ï¼Œé™¤ä»¥ä¸€ä¸ªç¼©æ”¾å› å­ï¼Œå¯ä»¥ä¸€å®šç¨‹åº¦ä¸Šå‡ç¼“è¿™ç§æƒ…å†µã€‚

ä¸ºä»€ä¹ˆæ˜¯$\frac{1}{\sqrt d_k}$å‘¢ï¼Ÿè®ºæ–‡æ²¡æœ‰è¿›ä¸€æ­¥è¯´æ˜ã€‚ä¸ªäººè§‰å¾—ä½ å¯ä»¥ä½¿ç”¨å…¶ä»–ç¼©æ”¾å› å­ï¼Œçœ‹çœ‹æ¨¡å‹æ•ˆæœæœ‰æ²¡æœ‰æå‡ã€‚

è®ºæ–‡ä¹Ÿæä¾›äº†ä¸€å¼ å¾ˆæ¸…æ™°çš„ç»“æ„å›¾ï¼Œä¾›å¤§å®¶å‚è€ƒï¼š  
- ![scaled_dot_product_attention_arch](http://blog.stupidme.me/wp-content/uploads/2018/09/scaled_dot_product_attention_arch.png)  
*Figure 3. Scaled dot-product attention architecture.*  

é¦–å…ˆè¯´æ˜ä¸€ä¸‹æˆ‘ä»¬çš„Kã€Qã€Væ˜¯ä»€ä¹ˆï¼š
* åœ¨encoderçš„self-attentionä¸­ï¼ŒQã€Kã€Véƒ½æ¥è‡ªåŒä¸€ä¸ªåœ°æ–¹ï¼ˆç›¸ç­‰ï¼‰ï¼Œä»–ä»¬æ˜¯ä¸Šä¸€å±‚encoderçš„è¾“å‡ºã€‚å¯¹äºç¬¬ä¸€å±‚encoderï¼Œå®ƒä»¬å°±æ˜¯word embeddingå’Œpositional encodingç›¸åŠ å¾—åˆ°çš„è¾“å…¥ã€‚
* åœ¨decoderçš„self-attentionä¸­ï¼ŒQã€Kã€Véƒ½æ¥è‡ªäºåŒä¸€ä¸ªåœ°æ–¹ï¼ˆç›¸ç­‰ï¼‰ï¼Œå®ƒä»¬æ˜¯ä¸Šä¸€å±‚decoderçš„è¾“å‡ºã€‚å¯¹äºç¬¬ä¸€å±‚decoderï¼Œå®ƒä»¬å°±æ˜¯word embeddingå’Œpositional encodingç›¸åŠ å¾—åˆ°çš„è¾“å…¥ã€‚ä½†æ˜¯å¯¹äºdecoderï¼Œæˆ‘ä»¬ä¸å¸Œæœ›å®ƒèƒ½è·å¾—ä¸‹ä¸€ä¸ªtime stepï¼ˆå³å°†æ¥çš„ä¿¡æ¯ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è¿›è¡Œ**sequence masking**ã€‚
* åœ¨encoder-decoder attentionä¸­ï¼ŒQæ¥è‡ªäºdecoderçš„ä¸Šä¸€å±‚çš„è¾“å‡ºï¼ŒKå’ŒVæ¥è‡ªäºencoderçš„è¾“å‡ºï¼ŒKå’ŒVæ˜¯ä¸€æ ·çš„ã€‚
* Qã€Kã€Vä¸‰è€…çš„ç»´åº¦ä¸€æ ·ï¼Œå³ $d_q=d_k=d_v$ã€‚

ä¸Šé¢scaled dot-product attentionå’Œdecoderçš„self-attentionéƒ½å‡ºç°äº†**masking**è¿™æ ·ä¸€ä¸ªä¸œè¥¿ã€‚é‚£ä¹ˆè¿™ä¸ªmaskåˆ°åº•æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿè¿™ä¸¤å¤„çš„maskæ“ä½œæ˜¯ä¸€æ ·çš„å—ï¼Ÿè¿™ä¸ªé—®é¢˜åœ¨åé¢ä¼šæœ‰è¯¦ç»†è§£é‡Šã€‚

### Scaled dot-product attentionçš„å®ç°

å…ˆæŠŠscaled dot-product attentionå®ç°äº†å§ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn

class ScaledDotProductAttention(nn.Module):
    """Scaled dot-product attention mechanism."""

    def __init__(self, attention_dropout=0.0):
        super(ScaledDotProductAttention, self).__init__()
        self.dropout = nn.Dropout(attention_dropout)
        self.softmax = nn.Softmax(dim=2)

    def forward(self, q, k, v, scale=None, attn_mask=None):
        """å‰å‘ä¼ æ’­.

        Args:
        	q: Querieså¼ é‡ï¼Œå½¢çŠ¶ä¸º[B, L_q, D_q]
        	k: Keyså¼ é‡ï¼Œå½¢çŠ¶ä¸º[B, L_k, D_k]
        	v: Valueså¼ é‡ï¼Œå½¢çŠ¶ä¸º[B, L_v, D_v]ï¼Œä¸€èˆ¬æ¥è¯´å°±æ˜¯k
        	scale: ç¼©æ”¾å› å­ï¼Œä¸€ä¸ªæµ®ç‚¹æ ‡é‡
        	attn_mask: Maskingå¼ é‡ï¼Œå½¢çŠ¶ä¸º[B, L_q, L_k]

        Returns:
        	ä¸Šä¸‹æ–‡å¼ é‡å’Œattetentionå¼ é‡
        """
        attention = torch.bmm(q, k.transpose(1, 2))
        if scale:
        	attention = attention * scale
        if attn_mask:
        	# ç»™éœ€è¦maskçš„åœ°æ–¹è®¾ç½®ä¸€ä¸ªè´Ÿæ— ç©·
        	attention = attention.masked_fill_(attn_mask, -np.inf)
		# è®¡ç®—softmax
        attention = self.softmax(attention)
		# æ·»åŠ dropout
        attention = self.dropout(attention)
		# å’ŒVåšç‚¹ç§¯
        context = torch.bmm(attention, v)
        return context, attention
```

### Multi-head attentionåˆæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

ç†è§£äº†Scaled dot-product attentionï¼ŒMulti-head attentionä¹Ÿå¾ˆç®€å•äº†ã€‚è®ºæ–‡æåˆ°ï¼Œå°†Qã€Kã€Vé€šè¿‡ä¸€ä¸ªçº¿æ€§æ˜ å°„ä¹‹åï¼Œåˆ†æˆ $h$ ä»½ï¼Œå¯¹æ¯ä¸€ä»½è¿›è¡Œ**scaled dot-product attention**æ•ˆæœæ›´å¥½ã€‚ç„¶åï¼ŒæŠŠå„ä¸ªéƒ¨åˆ†çš„ç»“æœåˆå¹¶èµ·æ¥ï¼Œå†æ¬¡ç»è¿‡çº¿æ€§æ˜ å°„ï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚è¿™å°±æ˜¯æ‰€è°“çš„**multi-head attention**ã€‚ä¸Šé¢çš„è¶…å‚æ•° $$h$$ å°±æ˜¯**heads**æ•°é‡ã€‚è®ºæ–‡é»˜è®¤æ˜¯`8`ã€‚

ä¸‹é¢æ˜¯multi-head attentionçš„ç»“æ„å›¾ï¼š  
- ![multi-head attention_architecture](http://blog.stupidme.me/wp-content/uploads/2018/09/multi_head_attention_arch.png) 

*Figure 4: Multi-head attention architecture.*  

æ³¨æ„ï¼šä¸Šé¢æ‰€è¯´çš„**åˆ†æˆ $h$ ä»½**æ˜¯åœ¨ $d_kã€d_qã€d_v$ ç»´åº¦ä¸Šé¢è¿›è¡Œåˆ‡åˆ†çš„ã€‚å› æ­¤ï¼Œè¿›å…¥åˆ°scaled dot-product attentionçš„ $d_k$ å®é™…ä¸Šç­‰äºæœªè¿›å…¥ä¹‹å‰çš„ $D_K/h$ ã€‚

Multi-head attentionå…è®¸æ¨¡å‹åŠ å…¥ä¸åŒä½ç½®çš„è¡¨ç¤ºå­ç©ºé—´çš„ä¿¡æ¯ã€‚

Multi-head attentionçš„å…¬å¼å¦‚ä¸‹ï¼š
- $$\text{MultiHead}(Q,K,V) = \text{Concat}(\text{head}_ 1,\dots,\text{head}_ h)W^O$$

å…¶ä¸­ï¼Œ$\text{head}_ i = \text{Attention}(QW_i^Q,KW_i^K,VW_i^V)$

è®ºæ–‡é‡Œé¢ï¼Œ$d_{model}=512$ï¼Œ$h=8$ã€‚æ‰€ä»¥åœ¨scaled dot-product attentioné‡Œé¢çš„ $d_q = d_k = d_v = d_{model}/h = 512/8 = 64$

### Multi-head attentionçš„å®ç°

multi-head attention å®ç°ä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn

class MultiHeadAttention(nn.Module):

    def __init__(self, model_dim=512, num_heads=8, dropout=0.0):
        super(MultiHeadAttention, self).__init__()

        self.dim_per_head = model_dim // num_heads
        self.num_heads = num_heads
        self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads)
        self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads)
        self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads)

        self.dot_product_attention = ScaledDotProductAttention(dropout)
        self.linear_final = nn.Linear(model_dim, model_dim)
        self.dropout = nn.Dropout(dropout)
		# multi-head attentionä¹‹åéœ€è¦åšlayer norm
        self.layer_norm = nn.LayerNorm(model_dim)

    def forward(self, key, value, query, attn_mask=None):
		# æ®‹å·®è¿æ¥
        residual = query

        dim_per_head = self.dim_per_head
        num_heads = self.num_heads
        batch_size = key.size(0)

        # linear projection
        key = self.linear_k(key)
        value = self.linear_v(value)
        query = self.linear_q(query)

        # split by heads
        key = key.view(batch_size * num_heads, -1, dim_per_head)
        value = value.view(batch_size * num_heads, -1, dim_per_head)
        query = query.view(batch_size * num_heads, -1, dim_per_head)

        if attn_mask:
            attn_mask = attn_mask.repeat(num_heads, 1, 1)
        # scaled dot product attention
        scale = (key.size(-1) // num_heads) ** -0.5
        context, attention = self.dot_product_attention(
          query, key, value, scale, attn_mask)

        # concat heads
        context = context.view(batch_size, -1, dim_per_head * num_heads)

        # final linear projection
        output = self.linear_final(context)

        # dropout
        output = self.dropout(output)

        # add residual and norm layer
        output = self.layer_norm(residual + output)

        return output, attention

```

ç»ˆäºå‡ºç°äº†**Residual connection**å’Œ**Layer normalization**ã€‚ç°åœ¨æ¥è§£é‡Šå®ƒä»¬ã€‚

Attention ç»†èŠ‚
 
### 2.1. ç‚¹ç§¯attention
 
ä»‹ç»ä¸€ä¸‹attentionçš„å…·ä½“è®¡ç®—æ–¹å¼ã€‚attention å¾ˆå¤šç§è®¡ç®—æ–¹å¼: 
- åŠ æ€§ attention
- ç‚¹ç§¯ attention
- å¸¦å‚æ•°çš„è®¡ç®—æ–¹å¼

ç€é‡ä»‹ç»ä¸€ä¸‹ç‚¹ç§¯attentionçš„å…¬å¼:
- ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Ctext+%7B+Attention+%7D%28Q%2C+K%2C+V%29%3D%5Coperatorname%7Bsoftmax%7D%5Cleft%28%5Cfrac%7BQ+K%5E%7BT%7D%7D%7B%5Csqrt%7Bd_%7Bk%7D%7D%7D%5Cright%29+V)
- ![](https://pic2.zhimg.com/80/v2-dc8921bfabcdf2515472b88a0808d046_720w.jpg)

- Attentionä¸­(Q^T)*KçŸ©é˜µè®¡ç®—ï¼Œqueryå’Œkeyçš„ç»´åº¦è¦ä¿æŒä¸€è‡´
 
å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=Q_%7BM%5Ctimes+d%7D) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=K_%7BN%5Ctimes+d%7D) åˆ†åˆ«æ˜¯queryå’Œkeyï¼Œå…¶ä¸­ï¼Œqueryå¯ä»¥çœ‹ä½œMä¸ªç»´åº¦ä¸ºdçš„å‘é‡(é•¿åº¦ä¸ºMçš„sequenceçš„å‘é‡è¡¨è¾¾)æ‹¼æ¥è€Œæˆï¼Œkeyå¯ä»¥çœ‹ä½œNä¸ªç»´åº¦ä¸ºdçš„å‘é‡(é•¿åº¦ä¸ºNçš„sequenceçš„å‘é‡è¡¨è¾¾)æ‹¼æ¥è€Œæˆã€‚
*   ã€ä¸€ä¸ªå°é—®é¢˜ã€‘ä¸ºä»€ä¹ˆæœ‰ç¼©æ”¾å› å­ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B%5Csqrt%7Bd_k%7D%7D) ?
*   å…ˆä¸€å¥è¯å›ç­”è¿™ä¸ªé—®é¢˜: ç¼©æ”¾å› å­çš„ä½œç”¨æ˜¯å½’ä¸€åŒ–ã€‚
*   å‡è®¾![[å…¬å¼]](https://www.zhihu.com/equation?tex=Q) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=K)é‡Œçš„å…ƒç´ çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼Œé‚£ä¹ˆ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=A%5ET%3DQ%5ETK) ä¸­å…ƒç´ çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸ºd. å½“då˜å¾—å¾ˆå¤§æ—¶ï¼Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=A) ä¸­çš„å…ƒç´ çš„æ–¹å·®ä¹Ÿä¼šå˜å¾—å¾ˆå¤§ï¼Œå¦‚æœ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=A) ä¸­çš„å…ƒç´ æ–¹å·®å¾ˆå¤§ï¼Œé‚£ä¹ˆ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Coperatorname%7Bsoftmax%7D%5Cleft%28A%5Cright%29) çš„åˆ†å¸ƒä¼šè¶‹äºé™¡å³­(åˆ†å¸ƒçš„æ–¹å·®å¤§ï¼Œåˆ†å¸ƒé›†ä¸­åœ¨ç»å¯¹å€¼å¤§çš„åŒºåŸŸ)ã€‚æ€»ç»“ä¸€ä¸‹å°±æ˜¯![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Coperatorname%7Bsoftmax%7D%5Cleft%28A%5Cright%29)çš„åˆ†å¸ƒä¼šå’Œdæœ‰å…³ã€‚å› æ­¤![[å…¬å¼]](https://www.zhihu.com/equation?tex=A) ä¸­æ¯ä¸€ä¸ªå…ƒç´ ä¹˜ä¸Š ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B%5Csqrt%7Bd_k%7D%7D) åï¼Œæ–¹å·®åˆå˜ä¸º1ã€‚è¿™ä½¿å¾—![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Coperatorname%7Bsoftmax%7D%5Cleft%28A%5Cright%29) çš„åˆ†å¸ƒâ€œé™¡å³­â€ç¨‹åº¦ä¸dè§£è€¦ï¼Œä»è€Œä½¿å¾—è®­ç»ƒè¿‡ç¨‹ä¸­æ¢¯åº¦å€¼ä¿æŒç¨³å®šã€‚
    
 
### 2.2. Attentionæœºåˆ¶æ¶‰åŠåˆ°çš„å‚æ•°
 
ä¸€ä¸ªå®Œæ•´çš„attentionå±‚æ¶‰åŠåˆ°çš„å‚æ•°æœ‰:
*   æŠŠ![[å…¬å¼]](https://www.zhihu.com/equation?tex=q) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=k) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=v)åˆ†åˆ«æ˜ å°„åˆ°![[å…¬å¼]](https://www.zhihu.com/equation?tex=Q) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=K) , ![[å…¬å¼]](https://www.zhihu.com/equation?tex=V)çš„çº¿æ€§å˜æ¢çŸ©é˜µ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=W%5EQ) ( ![[å…¬å¼]](https://www.zhihu.com/equation?tex=d_%7Bmodel%7D+%5Ctimes+d_k+) ), ![[å…¬å¼]](https://www.zhihu.com/equation?tex=W%5EK)( ![[å…¬å¼]](https://www.zhihu.com/equation?tex=d_%7Bmodel%7D+%5Ctimes+d_k) ), ![[å…¬å¼]](https://www.zhihu.com/equation?tex=W%5EV) ( ![[å…¬å¼]](https://www.zhihu.com/equation?tex=d_%7Bmodel%7D+%5Ctimes+d_v) )
*   æŠŠè¾“å‡ºçš„è¡¨è¾¾ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=O) æ˜ å°„ä¸ºæœ€ç»ˆè¾“å‡º ![[å…¬å¼]](https://www.zhihu.com/equation?tex=o) çš„çº¿æ€§å˜æ¢çŸ©é˜µ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=W%5EO) ( ![[å…¬å¼]](https://www.zhihu.com/equation?tex=d_v+%5Ctimes+d_%7Bmodel%7D+) )
    

### 2.3. Query, Key, Value
 
Queryå’ŒKeyä½œç”¨å¾—åˆ°çš„attentionæƒå€¼ä½œç”¨åˆ°Valueä¸Šã€‚å› æ­¤å®ƒä»¬ä¹‹é—´çš„å…³ç³»æ˜¯:
1.  Query ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28M%5Ctimes+d_%7Bqk%7D%29) å’Œ Key![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28N%5Ctimes+d_%7Bqk%7D%29)çš„ç»´åº¦å¿…é¡»ä¸€è‡´ï¼ŒValue ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28N%5Ctimes+d_%7Bv%7D%29) å’ŒQuery/Keyçš„ç»´åº¦å¯ä»¥ä¸ä¸€è‡´ã€‚
2.  Key ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28N%5Ctimes+d_%7Bqk%7D%29)å’ŒValue ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28N%5Ctimes+d_%7Bv%7D%29)çš„é•¿åº¦å¿…é¡»ä¸€è‡´ã€‚Keyå’ŒValueæœ¬è´¨ä¸Šå¯¹åº”äº†åŒä¸€ä¸ªSequenceåœ¨ä¸åŒç©ºé—´çš„è¡¨è¾¾ã€‚
3.  Attentionå¾—åˆ°çš„Output ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28M%5Ctimes+d_%7Bv%7D%29) çš„ç»´åº¦å’ŒValueçš„ç»´åº¦ä¸€è‡´ï¼Œé•¿åº¦å’ŒQueryä¸€è‡´ã€‚
4.  Outputæ¯ä¸ªä½ç½® i æ˜¯ç”±valueçš„æ‰€æœ‰ä½ç½®çš„vectoråŠ æƒå¹³å‡ä¹‹åçš„å‘é‡ï¼›è€Œå…¶æƒå€¼æ˜¯ç”±ä½ç½®ä¸ºi çš„queryå’Œkeyçš„æ‰€æœ‰ä½ç½®ç»è¿‡attentionè®¡ç®—å¾—åˆ°çš„ ï¼Œæƒå€¼çš„ä¸ªæ•°ç­‰äºkey/valueçš„é•¿åº¦ã€‚
 
![](https://pic4.zhimg.com/80/v2-7e7fcf5895d3cfc3f9f97b5c19069bbb_720w.jpg)
 
- Attentionç¤ºæ„å›¾
 
åœ¨ç»å…¸çš„Transformerç»“æ„ä¸­ï¼Œæˆ‘ä»¬è®°çº¿æ€§æ˜ å°„ä¹‹å‰çš„Query, Key, Valueä¸ºq, k, vï¼Œæ˜ å°„ä¹‹åä¸ºQ, K, Vã€‚é‚£ä¹ˆ:
1.  self-attentionçš„q, k, véƒ½æ˜¯åŒä¸€ä¸ªè¾“å…¥, å³å½“å‰åºåˆ—ç”±ä¸Šä¸€å±‚è¾“å‡ºçš„é«˜ç»´è¡¨è¾¾ã€‚
2.  cross-attentionçš„qä»£è¡¨å½“å‰åºåˆ—ï¼Œk,væ˜¯åŒä¸€ä¸ªè¾“å…¥ï¼Œå¯¹åº”çš„æ˜¯encoderæœ€åä¸€å±‚çš„è¾“å‡ºç»“æœ(å¯¹decoderç«¯çš„æ¯ä¸€å±‚æ¥è¯´ï¼Œä¿æŒä¸å˜)

è€Œæ¯ä¸€å±‚çº¿æ€§æ˜ å°„å‚æ•°çŸ©é˜µéƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥ç»è¿‡æ˜ å°„åçš„Q, K, Vå„ä¸ç›¸åŒï¼Œæ¨¡å‹å‚æ•°ä¼˜åŒ–çš„ç›®æ ‡åœ¨äºå°†q, k, vè¢«æ˜ å°„åˆ°æ–°çš„é«˜ç»´ç©ºé—´ï¼Œä½¿å¾—æ¯å±‚çš„Q, K, Våœ¨ä¸åŒæŠ½è±¡å±‚é¢ä¸Šæ•è·åˆ°q, k, vä¹‹é—´çš„å…³ç³»ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œåº•å±‚layeræ•è·åˆ°çš„æ›´å¤šæ˜¯lexical-levelçš„å…³ç³»ï¼Œè€Œé«˜å±‚layeræ•è·åˆ°çš„æ›´å¤šæ˜¯semantic-levelçš„å…³ç³»ã€‚
 
### 2.4. Attentionçš„ä½œç”¨
 
ä¸‹é¢è¿™æ®µæˆ‘ä¼šä»¥æœºå™¨ç¿»è¯‘ä¸ºä¾‹ï¼Œç”¨é€šä¿—çš„è¯­è¨€é˜é‡Šä¸€ä¸‹attentionçš„ä½œç”¨ï¼Œä»¥åŠquery, key, valueçš„å«ä¹‰ã€‚
- ![](https://pic4.zhimg.com/80/v2-cca6e1f0dd02f08cc554d731362a08af_720w.jpg)
 
Transformeræ¨¡å‹Encoder, Decoderçš„ç»†èŠ‚å›¾ï¼ˆçœå»äº†FFNéƒ¨åˆ†ï¼‰
 
queryå¯¹åº”çš„æ˜¯éœ€è¦è¢«è¡¨è¾¾çš„åºåˆ—(ç§°ä¸ºåºåˆ—A)ï¼Œkeyå’Œvalueå¯¹åº”çš„æ˜¯ç”¨æ¥è¡¨è¾¾Açš„åºåˆ—(ç§°ä¸ºåºåˆ—B)ã€‚å…¶ä¸­keyå’Œqueryæ˜¯åœ¨åŒä¸€é«˜ç»´ç©ºé—´ä¸­çš„(å¦åˆ™æ— æ³•ç”¨æ¥è®¡ç®—ç›¸ä¼¼ç¨‹åº¦)ï¼Œvalueä¸å¿…åœ¨åŒä¸€é«˜ç»´ç©ºé—´ä¸­ï¼Œæœ€ç»ˆç”Ÿæˆçš„outputå’Œvalueåœ¨åŒä¸€é«˜ç»´ç©ºé—´ä¸­ã€‚ä¸Šé¢è¿™æ®µå·¨ç»•çš„è¯ç”¨ä¸€å¥æ›´ç»•çš„è¯æ¥æè¿°ä¸€ä¸‹å°±æ˜¯:
 
> åºåˆ—Aå’Œåºåˆ—Båœ¨é«˜ç»´ç©ºé—´ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Calpha) ä¸­çš„é«˜ç»´è¡¨è¾¾ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=A_%7B%5Calpha%7D) çš„æ¯ä¸ªä½ç½®åˆ†åˆ«å’Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=B_%7B%5Calpha%7D) è®¡ç®—ç›¸ä¼¼åº¦ï¼Œäº§ç”Ÿçš„æƒé‡ä½œç”¨äºåºåˆ—Båœ¨é«˜ç»´ç©ºé—´ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Cbeta) ä¸­çš„é«˜ç»´è¡¨è¾¾ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=B_%7B%5Cbeta%7D) ï¼Œè·å¾—åºåˆ—Aåœ¨é«˜ç»´ç©ºé—´ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Cbeta) ä¸­çš„é«˜ç»´è¡¨è¾¾ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=A_%7B%5Cbeta%7D)
 
Encoderéƒ¨åˆ†ä¸­åªå­˜åœ¨self-attentionï¼Œè€ŒDecoderéƒ¨åˆ†ä¸­å­˜åœ¨self-attentionå’Œcross-attention
- ã€self-attentionã€‘encoderä¸­çš„self-attentionçš„query, key, valueéƒ½å¯¹åº”äº†æºç«¯åºåˆ—(å³Aå’ŒBæ˜¯åŒä¸€åºåˆ—)ï¼Œdecoderä¸­çš„self-attentionçš„query, key, valueéƒ½å¯¹åº”äº†ç›®æ ‡ç«¯åºåˆ—ã€‚
- ã€cross-attentionã€‘decoderä¸­çš„cross-attentionçš„queryå¯¹åº”äº†ç›®æ ‡ç«¯åºåˆ—ï¼Œkey, valueå¯¹åº”äº†æºç«¯åºåˆ—(æ¯ä¸€å±‚ä¸­çš„cross-attentionç”¨çš„éƒ½æ˜¯encoderçš„æœ€ç»ˆè¾“å‡º)
 
### 2.5. Decoderç«¯çš„Mask
 
Transformeræ¨¡å‹å±äºè‡ªå›å½’æ¨¡å‹ï¼ˆp.s. éè‡ªå›å½’çš„ç¿»è¯‘æ¨¡å‹æˆ‘ä¼šä¸“é—¨å†™ä¸€ç¯‡æ–‡ç« æ¥ä»‹ç»ï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´åé¢çš„tokençš„æ¨æ–­æ˜¯åŸºäºå‰é¢çš„tokençš„ã€‚Decoderç«¯çš„Maskçš„åŠŸèƒ½æ˜¯ä¸ºäº†ä¿è¯è®­ç»ƒé˜¶æ®µå’Œæ¨ç†é˜¶æ®µçš„ä¸€è‡´æ€§ã€‚
 
è®ºæ–‡åŸæ–‡ä¸­å…³äºè¿™ä¸€ç‚¹çš„æ®µè½å¦‚ä¸‹ï¼š
 
> We also modify the self-attention sub-layer in the decoder stack to prevent from attending to subsequent positions. This masking, combined with the fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.
 
åœ¨æ¨ç†é˜¶æ®µï¼Œtokenæ˜¯æŒ‰ç…§ä»å·¦å¾€å³çš„é¡ºåºæ¨ç†çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨æ¨ç†timestep=Tçš„tokenæ—¶ï¼Œdecoderåªèƒ½â€œçœ‹åˆ°â€timestep < Tçš„ T-1 ä¸ªToken, ä¸èƒ½å’Œtimestepå¤§äºå®ƒè‡ªèº«çš„tokenåšattentionï¼ˆå› ä¸ºæ ¹æœ¬è¿˜ä¸çŸ¥é“åé¢çš„tokenæ˜¯ä»€ä¹ˆï¼‰ã€‚ä¸ºäº†ä¿è¯è®­ç»ƒæ—¶å’Œæ¨ç†æ—¶çš„ä¸€è‡´æ€§ï¼Œæ‰€ä»¥ï¼Œè®­ç»ƒæ—¶è¦åŒæ ·é˜²æ­¢tokenä¸å®ƒä¹‹åçš„tokenå»åšattentionã€‚
 
### 2.6. å¤šå¤´Attention (Multi-head Attention)
 
Attentionæ˜¯å°†queryå’Œkeyæ˜ å°„åˆ°åŒä¸€é«˜ç»´ç©ºé—´ä¸­å»è®¡ç®—ç›¸ä¼¼åº¦ï¼Œè€Œå¯¹åº”çš„multi-head attentionæŠŠqueryå’Œkeyæ˜ å°„åˆ°é«˜ç»´ç©ºé—´ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%5Calpha) çš„ä¸åŒå­ç©ºé—´ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=%28%5Calpha_1%2C+%5Calpha_2%2C+...%2C%5Calpha_h%29) ä¸­å»è®¡ç®—ç›¸ä¼¼åº¦ã€‚
 
ä¸ºä»€ä¹ˆè¦åšmulti-head attentionï¼Ÿè®ºæ–‡åŸæ–‡é‡Œæ˜¯è¿™ä¹ˆè¯´çš„:
 
> Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.
 
ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™æ ·å¯ä»¥åœ¨ä¸æ”¹å˜å‚æ•°é‡çš„æƒ…å†µä¸‹å¢å¼ºæ¯ä¸€å±‚attentionçš„è¡¨ç°åŠ›ã€‚
- ![](https://pic3.zhimg.com/80/v2-3f8c3c102404c9b61398b63e06ffd80b_720w.jpg)
 
Multi-head Attentionç¤ºæ„å›¾

Multi-head Attentionçš„æœ¬è´¨æ˜¯ï¼Œåœ¨å‚æ•°æ€»é‡ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ï¼Œå°†åŒæ ·çš„query, key, valueæ˜ å°„åˆ°åŸæ¥çš„é«˜ç»´ç©ºé—´çš„ä¸åŒå­ç©ºé—´ä¸­è¿›è¡Œattentionçš„è®¡ç®—ï¼Œåœ¨æœ€åä¸€æ­¥å†åˆå¹¶ä¸åŒå­ç©ºé—´ä¸­çš„attentionä¿¡æ¯ã€‚è¿™æ ·é™ä½äº†è®¡ç®—æ¯ä¸ªheadçš„attentionæ—¶æ¯ä¸ªå‘é‡çš„ç»´åº¦ï¼Œåœ¨æŸç§æ„ä¹‰ä¸Šé˜²æ­¢äº†è¿‡æ‹Ÿåˆï¼›ç”±äºAttentionåœ¨ä¸åŒå­ç©ºé—´ä¸­æœ‰ä¸åŒçš„åˆ†å¸ƒï¼ŒMulti-head Attentionå®é™…ä¸Šæ˜¯å¯»æ‰¾äº†åºåˆ—ä¹‹é—´ä¸åŒè§’åº¦çš„å…³è”å…³ç³»ï¼Œå¹¶åœ¨æœ€åconcatè¿™ä¸€æ­¥éª¤ä¸­ï¼Œå°†ä¸åŒå­ç©ºé—´ä¸­æ•è·åˆ°çš„å…³è”å…³ç³»å†ç»¼åˆèµ·æ¥ã€‚
 
ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=q_i) å’Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=k_j) ä¹‹é—´çš„attention scoreä»1ä¸ªå˜æˆäº†hä¸ªï¼Œè¿™å°±å¯¹åº”äº†hä¸ªå­ç©ºé—´ä¸­å®ƒä»¬çš„å…³è”åº¦ã€‚
 
3. Transformeræ¨¡å‹æ¶æ„ä¸­çš„å…¶ä»–éƒ¨åˆ†
 
### 3.1. Feed Forward Network
 
æ¯ä¸€å±‚ç»è¿‡attentionä¹‹åï¼Œè¿˜ä¼šæœ‰ä¸€ä¸ªFFNï¼Œè¿™ä¸ªFFNçš„ä½œç”¨å°±æ˜¯ç©ºé—´å˜æ¢ã€‚FFNåŒ…å«äº†2å±‚linear transformationå±‚ï¼Œä¸­é—´çš„æ¿€æ´»å‡½æ•°æ˜¯ReLuã€‚
 
æ›¾ç»æˆ‘åœ¨è¿™é‡Œæœ‰ä¸€ä¸ªç™¾æ€ä¸å¾—å…¶è§£çš„é—®é¢˜ï¼šattentionå±‚çš„outputæœ€åä¼šå’Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=W_O) ç›¸ä¹˜ï¼Œä¸ºä»€ä¹ˆè¿™é‡Œåˆè¦å¢åŠ ä¸€ä¸ª2å±‚çš„FFNç½‘ç»œï¼Ÿ
 
å…¶å®ï¼ŒFFNçš„åŠ å…¥å¼•å…¥äº†éçº¿æ€§(ReLuæ¿€æ´»å‡½æ•°)ï¼Œå˜æ¢äº†attention outputçš„ç©ºé—´, ä»è€Œå¢åŠ äº†æ¨¡å‹çš„è¡¨ç°èƒ½åŠ›ã€‚æŠŠFFNå»æ‰æ¨¡å‹ä¹Ÿæ˜¯å¯ä»¥ç”¨çš„ï¼Œä½†æ˜¯æ•ˆæœå·®äº†å¾ˆå¤šã€‚
 
### 3.2. Positional Encoding
 
ä½ç½®ç¼–ç å±‚åªåœ¨encoderç«¯å’Œdecoderç«¯çš„embeddingä¹‹åï¼Œç¬¬ä¸€ä¸ªblockä¹‹å‰å‡ºç°ï¼Œå®ƒéå¸¸é‡è¦ï¼Œæ²¡æœ‰è¿™éƒ¨åˆ†ï¼ŒTransformeræ¨¡å‹å°±æ— æ³•ç”¨ã€‚ä½ç½®ç¼–ç æ˜¯Transformeræ¡†æ¶ä¸­ç‰¹æœ‰çš„ç»„æˆéƒ¨åˆ†ï¼Œè¡¥å……äº†Attentionæœºåˆ¶æœ¬èº«ä¸èƒ½æ•æ‰ä½ç½®ä¿¡æ¯çš„ç¼ºé™·ã€‚
- ![](https://pic4.zhimg.com/80/v2-42d5035562aca2c6136a2c8abaafc565_720w.jpg)

- position encoding
 
Positional Embeddingçš„æˆåˆ†ç›´æ¥å åŠ äºEmbeddingä¹‹ä¸Šï¼Œä½¿å¾—æ¯ä¸ªtokençš„ä½ç½®ä¿¡æ¯å’Œå®ƒçš„è¯­ä¹‰ä¿¡æ¯(embedding)å……åˆ†èåˆï¼Œå¹¶è¢«ä¼ é€’åˆ°åç»­æ‰€æœ‰ç»è¿‡å¤æ‚å˜æ¢çš„åºåˆ—è¡¨è¾¾ä¸­å»ã€‚
 
è®ºæ–‡ä¸­ä½¿ç”¨çš„Positional Encoding(PE)æ˜¯æ­£ä½™å¼¦å‡½æ•°ï¼Œä½ç½®(pos)è¶Šå°ï¼Œæ³¢é•¿è¶Šé•¿ï¼Œæ¯ä¸€ä¸ªä½ç½®å¯¹åº”çš„PEéƒ½æ˜¯å”¯ä¸€çš„ã€‚åŒæ—¶ä½œè€…ä¹Ÿæåˆ°ï¼Œä¹‹æ‰€ä»¥é€‰ç”¨æ­£ä½™å¼¦å‡½æ•°ä½œä¸ºPEï¼Œæ˜¯å› ä¸ºè¿™å¯ä»¥ä½¿å¾—æ¨¡å‹å­¦ä¹ åˆ°tokenä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼šå› ä¸ºå¯¹äºä»»æ„çš„åç§»é‡kï¼Œ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7Bpos%2Bk%7D) å¯ä»¥ç”± ![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7Bpos%7D) çš„çº¿æ€§è¡¨ç¤ºï¼š
- ![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7B%28pos%2Bk%2C2i%29%7D%3Dsin%5B%28pos%2Bk%29%2F10000%5E%7B2i%2Fd_%7Bmodel%7D%7D%5D)
- ![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7B%28pos%2Bk%2C2i%2B1%29%7D%3Dcos%5B%28pos%2Bk%29%2F10000%5E%7B2i%2Fd_%7Bmodel%7D%7D%5D)

ä¸Šé¢ä¸¤ä¸ªå…¬å¼å¯ä»¥ç”± ![[å…¬å¼]](https://www.zhihu.com/equation?tex=sin%5B%28pos%29%2F10000%5E%7B2i%2Fd_%7Bmodel%7D%7D%5D) å’Œ![[å…¬å¼]](https://www.zhihu.com/equation?tex=cos%5B%28pos%29%2F10000%5E%7B2i%2Fd_%7Bmodel%7D%7D%5D)çš„çº¿æ€§ç»„åˆå¾—åˆ°ã€‚ä¹Ÿå°±æ˜¯ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7Bpos%7D)ä¹˜ä¸ŠæŸä¸ªçº¿æ€§å˜æ¢çŸ©é˜µå°±å¾—åˆ°äº†![[å…¬å¼]](https://www.zhihu.com/equation?tex=PE_%7Bpos%2Bk%7D)
 
p.s. åç»­æœ‰ä¸€ä¸ªå·¥ä½œåœ¨attentionä¸­ä½¿ç”¨äº†â€œç›¸å¯¹ä½ç½®è¡¨ç¤ºâ€ ([Self-Attention with Relative Position Representations](https://link.zhihu.com/?target=https%3A//www.aclweb.org/anthology/N18-2074.pdf)) ï¼Œæœ‰å…´è¶£å¯ä»¥çœ‹çœ‹ã€‚
 
### 3.3. Layer Normalization
 
åœ¨æ¯ä¸ªblockä¸­ï¼Œæœ€åå‡ºç°çš„æ˜¯Layer Normalizationã€‚Layer Normalizationæ˜¯ä¸€ä¸ªé€šç”¨çš„æŠ€æœ¯ï¼Œå…¶æœ¬è´¨æ˜¯è§„èŒƒä¼˜åŒ–ç©ºé—´ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚
 
å½“æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•åšä¼˜åŒ–æ—¶ï¼Œéšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œæ•°æ®çš„åˆ†å¸ƒä¼šä¸æ–­å‘ç”Ÿå˜åŒ–ï¼Œå‡è®¾featureåªæœ‰äºŒç»´ï¼Œé‚£ä¹ˆç”¨ç¤ºæ„å›¾æ¥è¡¨ç¤ºä¸€ä¸‹å°±æ˜¯ï¼š
- ![](https://pic3.zhimg.com/80/v2-59e1dc490d55d7b908f4e12c38cb80f8_720w.jpg)
 
æ•°æ®çš„åˆ†å¸ƒå‘ç”Ÿå˜åŒ–ï¼Œå·¦å›¾æ¯”è¾ƒè§„èŒƒï¼Œå³å›¾å˜å¾—ä¸è§„èŒƒ
 
ä¸ºäº†ä¿è¯æ•°æ®ç‰¹å¾åˆ†å¸ƒçš„ç¨³å®šæ€§ï¼ˆå¦‚å·¦å›¾ï¼‰ï¼Œæˆ‘ä»¬åŠ å…¥Layer Normalizationï¼Œè¿™æ ·å¯ä»¥åŠ é€Ÿæ¨¡å‹çš„ä¼˜åŒ–é€Ÿåº¦ã€‚
- ä»¥ä¸Šå†…å®¹æ‘˜è‡ªï¼š[Transformeræ¨¡å‹æ·±åº¦è§£è¯»](https://zhuanlan.zhihu.com/p/104393915)


## Residual connectionæ˜¯ä»€ä¹ˆï¼Ÿ

æ®‹å·®è¿æ¥å…¶å®å¾ˆç®€å•ï¼ç»™ä½ çœ‹ä¸€å¼ ç¤ºæ„å›¾ä½ å°±æ˜ç™½äº†ï¼š  
- ![residual_conn](http://blog.stupidme.me/wp-content/uploads/2018/09/residual_connection.png)  
*Figure 5. Residual connection.*  

å‡è®¾ç½‘ç»œä¸­æŸä¸ªå±‚å¯¹è¾“å…¥`x`ä½œç”¨åçš„è¾“å‡ºæ˜¯$F(x)$ï¼Œé‚£ä¹ˆå¢åŠ **residual connection**ä¹‹åï¼Œå°±å˜æˆäº†ï¼š$F(x)+x$

è¿™ä¸ª`+x`æ“ä½œå°±æ˜¯ä¸€ä¸ª**shortcut**ã€‚é‚£ä¹ˆ**æ®‹å·®ç»“æ„**æœ‰ä»€ä¹ˆå¥½å¤„å‘¢ï¼Ÿæ˜¾è€Œæ˜“è§ï¼šå› ä¸ºå¢åŠ äº†ä¸€é¡¹$x$ï¼Œé‚£ä¹ˆè¯¥å±‚ç½‘ç»œå¯¹xæ±‚åå¯¼çš„æ—¶å€™ï¼Œå¤šäº†ä¸€ä¸ªå¸¸æ•°é¡¹$1$ï¼æ‰€ä»¥åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦è¿ä¹˜ï¼Œä¹Ÿä¸ä¼šé€ æˆ**æ¢¯åº¦æ¶ˆå¤±**ï¼

æ‰€ä»¥ï¼Œä»£ç å®ç°residual connectionå¾ˆéå¸¸ç®€å•ï¼š

```python
def residual(sublayer_fn,x):
	return sublayer_fn(x)+x
```

æ–‡ç« å¼€å§‹çš„transformeræ¶æ„å›¾ä¸­çš„`Add & Norm`ä¸­çš„`Add`ä¹Ÿå°±æ˜¯æŒ‡çš„è¿™ä¸ª**shortcut**ã€‚

è‡³æ­¤ï¼Œ**residual connection**çš„é—®é¢˜ç†æ¸…æ¥šäº†ã€‚æ›´å¤šå…³äºæ®‹å·®ç½‘ç»œçš„ä»‹ç»å¯ä»¥çœ‹æ–‡æœ«çš„å‚è€ƒæ–‡çŒ®ã€‚

### Pre-LN VS Post-LN

ã€2023-6-14ã€‘[æ­¤ã€Œé”™ã€å¹¶éçœŸçš„é”™ï¼šä»å››ç¯‡ç»å…¸è®ºæ–‡å…¥æ‰‹ï¼Œç†è§£Transformeræ¶æ„å›¾ã€Œé”™ã€åœ¨ä½•å¤„](https://www.jiqizhixin.com/articles/2023-06-13-4)
- Sebastian: æŒ‡å‡ºè°·æ­Œå¤§è„‘å›¢é˜Ÿè®ºæ–‡ã€ŠAttention Is All You Needã€‹ä¸­ Transformer æ„æ¶å›¾ä¸ä»£ç ä¸ä¸€è‡´
- æœ€åˆçš„ Transformer æ„æ¶å›¾ç¡®å®ä¸ä»£ç ä¸ä¸€è‡´, ä½† 2017 å¹´æäº¤çš„ä»£ç ç‰ˆæœ¬è¿›è¡Œäº†ä¿®æ”¹ï¼Œä½†åŒæ—¶æ²¡æœ‰æ›´æ–°æ¶æ„å›¾ã€‚è¿™ä¹Ÿæ˜¯é€ æˆã€Œä¸ä¸€è‡´ã€è®¨è®ºçš„æ ¹æœ¬åŸå› ã€‚

Layer Norm ä½ç½® -- è¯¦ç»†è§£ç­”è§[ä¸ºä»€ä¹ˆPre Normçš„æ•ˆæœä¸å¦‚Post Normï¼Ÿ](https://spaces.ac.cn/archives/9009)
- `Pre-LN`: LN åœ¨ self-attention ä¹‹å‰, æ”¾æ®‹å·®è¿æ¥é‡Œ
  - æ•ˆæœï¼šæ¢¯åº¦æ›´å¥½, å¯è§£å†³æ¢¯åº¦é—®é¢˜, æ›´å®¹æ˜“è®­ç»ƒ, ä½†å¯èƒ½å¯¼è‡´è¡¨å¾å´©æºƒ
  - åˆ†æ: 
    - å®¹æ˜“è®­ç»ƒ: å› ä¸º æ’ç­‰è·¯å¾„æ›´çªå‡º
    - æ•ˆæœä¸å¥½: Pre Normç»“æ„æ— å½¢åœ°å¢åŠ äº†**æ¨¡å‹å®½åº¦**è€Œé™ä½äº†**æ¨¡å‹æ·±åº¦**ï¼Œè€Œæ·±åº¦é€šå¸¸æ¯”å®½åº¦æ›´é‡è¦ï¼Œæ‰€ä»¥é™ä½æ·±åº¦å¯¼è‡´æœ€ç»ˆæ•ˆæœå˜å·®äº†
- `Post-LN`: LN åœ¨ self-attention å’Œ FFN ä¹‹å
  - æ•ˆæœ: é¢„æœŸçš„æ¢¯åº¦è¢«æ”¾å¤§, æœ€ç»ˆæ•ˆæœæ›´å¥½
  - åˆ†æ: æ¯Normä¸€æ¬¡å°±å‰Šå¼±ä¸€æ¬¡æ’ç­‰åˆ†æ”¯çš„æƒé‡ï¼Œæ‰€ä»¥Post Normåè€Œæ˜¯æ›´çªå‡ºæ®‹å·®åˆ†æ”¯çš„ï¼Œå› æ­¤Post Normä¸­çš„å±‚æ•°æ›´åŠ â€œè¶³ç§¤â€ï¼Œä¸€æ—¦è®­ç»ƒå¥½ä¹‹åæ•ˆæœæ›´ä¼˜ã€‚
- Deep-LN: æœªçŸ¥

ç»“è®º:
> åŒä¸€è®¾ç½®ä¹‹ä¸‹ï¼ŒPre Norm ç»“æ„å¾€å¾€æ›´å®¹æ˜“**è®­ç»ƒ**ï¼Œä½†æœ€ç»ˆ**æ•ˆæœ**é€šå¸¸ä¸å¦‚Post Normã€‚

2020å¹´çš„è®ºæ–‡: [On Layer Normalization in the Transformer Architecture](https://zhuanlan.zhihu.com/p/633358080)

Transformer æ¶æ„è®ºæ–‡ä¸­çš„**å±‚å½’ä¸€åŒ–**è¡¨æ˜ï¼Œ`Pre-LN` å·¥ä½œå¾—æ›´å¥½ï¼Œå¯è§£å†³æ¢¯åº¦é—®é¢˜ã€‚
- è®¸å¤šä½“ç³»æ¶æ„é‡‡ç”¨äº†è¿™ç§æ–¹æ³•ï¼Œä½†å¯èƒ½å¯¼è‡´**è¡¨å¾å´©æºƒ**ã€‚æœ‰è®ºæ–‡å°†pre å’Œ postç»“åˆ
- ![img](https://image.jiqizhixin.com/uploads/editor/85586261-eff5-475e-9d0c-952985984a4b/640.png)
- å°† Post-LN å’Œ Pre-LN ä¸€èµ·ç”¨ï¼Œã€Š [ResiDual: Transformer with Dual Residual Connections](https://arxiv.org/abs/2304.14802)ã€‹ï¼Œæ˜¯å¦æœ‰ç”¨è¿˜æœ‰å¾…è§‚å¯Ÿã€‚

æ³¨
- é¢è¯•é¢˜ç›®ï¼š ä¸ºä»€ä¹ˆ Trans/GPT-1 é‡‡ç”¨ Post-LN è€Œ GPT-2 é‡‡ç”¨ Pre-LN ï¼Ÿ

## Layer normalizationæ˜¯ä»€ä¹ˆï¼Ÿ

[GRADIENTS, BATCH NORMALIZATION AND LAYER NORMALIZATION](https://theneuralperspective.com/2016/10/27/gradient-topics/)ä¸€æ–‡å¯¹normalizationæœ‰å¾ˆå¥½çš„è§£é‡Šï¼š
> Normalizationæœ‰å¾ˆå¤šç§ï¼Œä½†æ˜¯å®ƒä»¬éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„ç›®çš„ï¼Œé‚£å°±æ˜¯æŠŠè¾“å…¥è½¬åŒ–æˆå‡å€¼ä¸º0æ–¹å·®ä¸º1çš„æ•°æ®ã€‚æˆ‘ä»¬åœ¨æŠŠæ•°æ®é€å…¥æ¿€æ´»å‡½æ•°ä¹‹å‰è¿›è¡Œnormalizationï¼ˆå½’ä¸€åŒ–ï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›è¾“å…¥æ•°æ®è½åœ¨æ¿€æ´»å‡½æ•°çš„é¥±å’ŒåŒºã€‚

è¯´åˆ°normalizationï¼Œé‚£å°±è‚¯å®šå¾—æåˆ°**Batch Normalization**ã€‚BNåœ¨CNNç­‰åœ°æ–¹ç”¨å¾—å¾ˆå¤šã€‚

BNçš„ä¸»è¦æ€æƒ³å°±æ˜¯ï¼šåœ¨æ¯ä¸€å±‚çš„æ¯ä¸€æ‰¹æ•°æ®ä¸Šè¿›è¡Œå½’ä¸€åŒ–ã€‚

æˆ‘ä»¬å¯èƒ½ä¼šå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†æ˜¯ç»è¿‡è¯¥ç½‘ç»œå±‚çš„ä½œç”¨åï¼Œæˆ‘ä»¬çš„çš„æ•°æ®å·²ç»ä¸å†æ˜¯å½’ä¸€åŒ–çš„äº†ã€‚éšç€è¿™ç§æƒ…å†µçš„å‘å±•ï¼Œæ•°æ®çš„åå·®è¶Šæ¥è¶Šå¤§ï¼Œæˆ‘çš„åå‘ä¼ æ’­éœ€è¦è€ƒè™‘åˆ°è¿™äº›å¤§çš„åå·®ï¼Œè¿™å°±è¿«ä½¿æˆ‘ä»¬åªèƒ½ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡æ¥é˜²æ­¢æ¢¯åº¦æ¶ˆå¤±æˆ–è€…æ¢¯åº¦çˆ†ç‚¸ã€‚

BNçš„å…·ä½“åšæ³•å°±æ˜¯å¯¹æ¯ä¸€å°æ‰¹æ•°æ®ï¼Œåœ¨æ‰¹è¿™ä¸ªæ–¹å‘ä¸Šåšå½’ä¸€åŒ–ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š  
- ![batch_normalization](http://blog.stupidme.me/wp-content/uploads/2018/09/batch_normalization.png)  
*Figure 6. Batch normalization example.(From [theneuralperspective.com](https://theneuralperspective.com/2016/10/27/gradient-topics/))*  

å¯ä»¥çœ‹åˆ°ï¼Œå³åŠè¾¹æ±‚å‡å€¼æ˜¯**æ²¿ç€æ•°æ®æ‰¹é‡Nçš„æ–¹å‘è¿›è¡Œçš„**ï¼

Batch normalizationçš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š
- $$BN(x_i)=\alpha\times\frac{x_i-u_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta$$

å…·ä½“çš„å®ç°å¯ä»¥æŸ¥çœ‹ä¸Šå›¾çš„é“¾æ¥æ–‡ç« ã€‚

è¯´å®ŒBatch normalizationï¼Œå°±è¯¥è¯´è¯´å’±ä»¬ä»Šå¤©çš„ä¸»è§’**Layer normalization**ã€‚

é‚£ä¹ˆä»€ä¹ˆæ˜¯Layer normalizationå‘¢ï¼Ÿ:å®ƒä¹Ÿæ˜¯å½’ä¸€åŒ–æ•°æ®çš„ä¸€ç§æ–¹å¼ï¼Œä¸è¿‡LNæ˜¯**åœ¨æ¯ä¸€ä¸ªæ ·æœ¬ä¸Šè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œè€Œä¸æ˜¯BNé‚£ç§åœ¨æ‰¹æ–¹å‘è®¡ç®—å‡å€¼å’Œæ–¹å·®**ï¼

ä¸‹é¢æ˜¯LNçš„ç¤ºæ„å›¾ï¼š  
- ![layer_normalization](http://blog.stupidme.me/wp-content/uploads/2018/09/layer_normalization.png)  
*Figure 7. Layer normalization example.*  

å’Œä¸Šé¢çš„BNç¤ºæ„å›¾ä¸€æ¯”è¾ƒå°±å¯ä»¥çœ‹å‡ºäºŒè€…çš„åŒºåˆ«å•¦ï¼

ä¸‹é¢çœ‹ä¸€ä¸‹LNçš„å…¬å¼ï¼Œä¹ŸBNååˆ†ç›¸ä¼¼ï¼š
- $$LN(x_i)=\alpha\times\frac{x_i-u_L}{\sqrt{\sigma_L^2+\epsilon}}+\beta$$

### Layer normalizationçš„å®ç°

ä¸Šè¿°ä¸¤ä¸ªå‚æ•°$\alpha$å’Œ$\beta$éƒ½æ˜¯å¯å­¦ä¹ å‚æ•°ã€‚ä¸‹é¢æˆ‘ä»¬è‡ªå·±æ¥å®ç°Layer normalization(PyTorchå·²ç»å®ç°å•¦ï¼)ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn


class LayerNorm(nn.Module):
    """å®ç°LayerNormã€‚å…¶å®PyTorchå·²ç»å®ç°å•¦ï¼Œè§nn.LayerNormã€‚"""

    def __init__(self, features, epsilon=1e-6):
        """Init.

        Args:
            features: å°±æ˜¯æ¨¡å‹çš„ç»´åº¦ã€‚è®ºæ–‡é»˜è®¤512
            epsilon: ä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Œé˜²æ­¢æ•°å€¼è®¡ç®—çš„é™¤0é”™è¯¯
        """
        super(LayerNorm, self).__init__()
        # alpha
        self.gamma = nn.Parameter(torch.ones(features))
        # beta
        self.beta = nn.Parameter(torch.zeros(features))
        self.epsilon = epsilon

    def forward(self, x):
        """å‰å‘ä¼ æ’­.

        Args:
            x: è¾“å…¥åºåˆ—å¼ é‡ï¼Œå½¢çŠ¶ä¸º[B, L, D]
        """
        # æ ¹æ®å…¬å¼è¿›è¡Œå½’ä¸€åŒ–
        # åœ¨Xçš„æœ€åä¸€ä¸ªç»´åº¦æ±‚å‡å€¼ï¼Œæœ€åä¸€ä¸ªç»´åº¦å°±æ˜¯æ¨¡å‹çš„ç»´åº¦
        mean = x.mean(-1, keepdim=True)
        # åœ¨Xçš„æœ€åä¸€ä¸ªç»´åº¦æ±‚æ–¹å·®ï¼Œæœ€åä¸€ä¸ªç»´åº¦å°±æ˜¯æ¨¡å‹çš„ç»´åº¦
        std = x.std(-1, keepdim=True)
        return self.gamma * (x - mean) / (std + self.epsilon) + self.beta
```

é¡ºä¾¿æä¸€å¥ï¼Œ**Layer normalization**å¤šç”¨äºRNNè¿™ç§ç»“æ„ã€‚

## Maskæ˜¯ä»€ä¹ˆï¼Ÿ

ç°åœ¨ç»ˆäºè½®åˆ°è®²è§£maskäº†!maské¡¾åæ€ä¹‰å°±æ˜¯**æ©ç **ï¼Œåœ¨æˆ‘ä»¬è¿™é‡Œçš„æ„æ€å¤§æ¦‚å°±æ˜¯**å¯¹æŸäº›å€¼è¿›è¡Œæ©ç›–ï¼Œä½¿å…¶ä¸äº§ç”Ÿæ•ˆæœ**ã€‚

éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œæˆ‘ä»¬çš„Transformeræ¨¡å‹é‡Œé¢æ¶‰åŠä¸¤ç§maskã€‚åˆ†åˆ«æ˜¯**padding mask**å’Œ**sequence mask**ã€‚å…¶ä¸­åè€…æˆ‘ä»¬å·²ç»åœ¨decoderçš„self-attentioné‡Œé¢è§è¿‡å•¦ï¼
- **padding mask**åœ¨æ‰€æœ‰çš„scaled dot-product attentioné‡Œé¢éƒ½éœ€è¦ç”¨åˆ°
- **sequence mask**åªæœ‰åœ¨decoderçš„self-attentioné‡Œé¢ç”¨åˆ°ã€‚

æ‰€ä»¥ï¼Œæˆ‘ä»¬ä¹‹å‰**ScaledDotProductAttention**çš„`forward`æ–¹æ³•é‡Œé¢çš„å‚æ•°`attn_mask`åœ¨ä¸åŒçš„åœ°æ–¹ä¼šæœ‰ä¸åŒçš„å«ä¹‰ã€‚è¿™ä¸€ç‚¹æˆ‘ä»¬ä¼šåœ¨åé¢è¯´æ˜ã€‚

### Padding mask

ä»€ä¹ˆæ˜¯**padding mask**å‘¢ï¼Ÿå›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬çš„æ¯ä¸ªæ‰¹æ¬¡è¾“å…¥åºåˆ—é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ï¼ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è¦å¯¹è¾“å…¥åºåˆ—è¿›è¡Œ**å¯¹é½**ï¼å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯ç»™åœ¨è¾ƒçŸ­çš„åºåˆ—åé¢å¡«å……`0`ã€‚å› ä¸ºè¿™äº›å¡«å……çš„ä½ç½®ï¼Œå…¶å®æ˜¯æ²¡ä»€ä¹ˆæ„ä¹‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„attentionæœºåˆ¶**ä¸åº”è¯¥æŠŠæ³¨æ„åŠ›æ”¾åœ¨è¿™äº›ä½ç½®ä¸Š**ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›å¤„ç†ã€‚

å…·ä½“çš„åšæ³•æ˜¯ï¼Œ**æŠŠè¿™äº›ä½ç½®çš„å€¼åŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°(å¯ä»¥æ˜¯è´Ÿæ— ç©·)ï¼Œè¿™æ ·çš„è¯ï¼Œç»è¿‡softmaxï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šæ¥è¿‘0**ï¼

è€Œæˆ‘ä»¬çš„padding maskå®é™…ä¸Šæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯ä¸€ä¸ª**Boolen**ï¼Œå€¼ä¸º`False`çš„åœ°æ–¹å°±æ˜¯æˆ‘ä»¬è¦è¿›è¡Œå¤„ç†çš„åœ°æ–¹ã€‚

ä¸‹é¢æ˜¯å®ç°ï¼š

```python
def padding_mask(seq_k, seq_q):
	# seq_kå’Œseq_qçš„å½¢çŠ¶éƒ½æ˜¯[B,L]
    len_q = seq_q.size(1)
    # `PAD` is 0
    pad_mask = seq_k.eq(0)
    pad_mask = pad_mask.unsqueeze(1).expand(-1, len_q, -1)  # shape [B, L_q, L_k]
    return pad_mask
```

### Sequence mask

æ–‡ç« å‰é¢ä¹Ÿæåˆ°ï¼Œsequence maskæ˜¯ä¸ºäº†ä½¿å¾—decoderä¸èƒ½çœ‹è§æœªæ¥çš„ä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯å¯¹äºä¸€ä¸ªåºåˆ—ï¼Œåœ¨time_stepä¸ºtçš„æ—¶åˆ»ï¼Œæˆ‘ä»¬çš„è§£ç è¾“å‡ºåº”è¯¥åªèƒ½ä¾èµ–äºtæ—¶åˆ»ä¹‹å‰çš„è¾“å‡ºï¼Œè€Œä¸èƒ½ä¾èµ–tä¹‹åçš„è¾“å‡ºã€‚å› æ­¤æˆ‘ä»¬éœ€è¦æƒ³ä¸€ä¸ªåŠæ³•ï¼ŒæŠŠtä¹‹åçš„ä¿¡æ¯ç»™éšè—èµ·æ¥ã€‚

é‚£ä¹ˆå…·ä½“æ€ä¹ˆåšå‘¢ï¼Ÿä¹Ÿå¾ˆç®€å•ï¼š**äº§ç”Ÿä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µï¼Œä¸Šä¸‰è§’çš„å€¼å…¨ä¸º1ï¼Œä¸‹ä¸‰è§’çš„å€¼æƒå¨0ï¼Œå¯¹è§’çº¿ä¹Ÿæ˜¯0**ã€‚æŠŠè¿™ä¸ªçŸ©é˜µä½œç”¨åœ¨æ¯ä¸€ä¸ªåºåˆ—ä¸Šï¼Œå°±å¯ä»¥è¾¾åˆ°æˆ‘ä»¬çš„ç›®çš„å•¦ã€‚

å…·ä½“çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š

```python
def sequence_mask(seq):
    batch_size, seq_len = seq.size()
    mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8),
                    diagonal=1)
    mask = mask.unsqueeze(0).expand(batch_size, -1, -1)  # [B, L, L]
    return mask
```

å“ˆä½›å¤§å­¦çš„æ–‡ç« [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)æœ‰ä¸€å¼ æ•ˆæœå›¾:
- ![sequence_mask](http://blog.stupidme.me/wp-content/uploads/2018/09/sequence_mask.png)  
*Figure 8. Sequence mask.*

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ¬æ¥maskåªéœ€è¦äºŒç»´çš„çŸ©é˜µå³å¯ï¼Œä½†æ˜¯è€ƒè™‘åˆ°æˆ‘ä»¬çš„è¾“å…¥åºåˆ—éƒ½æ˜¯æ‰¹é‡çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æŠŠåŸæœ¬äºŒç»´çš„çŸ©é˜µæ‰©å¼ æˆ3ç»´çš„å¼ é‡ã€‚ä¸Šé¢çš„ä»£ç å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬å·²ç»è¿›è¡Œäº†å¤„ç†ã€‚

å›åˆ°æœ¬å°ç»“å¼€å§‹çš„é—®é¢˜ï¼Œ`attn_mask`å‚æ•°æœ‰å‡ ç§æƒ…å†µï¼Ÿåˆ†åˆ«æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
* å¯¹äºdecoderçš„self-attentionï¼Œé‡Œé¢ä½¿ç”¨åˆ°çš„scaled dot-product attentionï¼ŒåŒæ—¶éœ€è¦`padding mask`å’Œ`sequence mask`ä½œä¸º`attn_mask`ï¼Œå…·ä½“å®ç°å°±æ˜¯ä¸¤ä¸ªmaskç›¸åŠ ä½œä¸ºattn_maskã€‚
* å…¶ä»–æƒ…å†µï¼Œ`attn_mask`ä¸€å¾‹ç­‰äº`padding mask`ã€‚

è‡³æ­¤ï¼Œmaskç›¸å…³çš„é—®é¢˜è§£å†³äº†ã€‚

## Positional encoding æ˜¯ä»€ä¹ˆï¼Ÿ

ã€2021-8-25ã€‘[é¢ç»ï¼šä»€ä¹ˆæ˜¯Transformerä½ç½®ç¼–ç ï¼Ÿ](https://blog.csdn.net/Datawhale/article/details/119582757)

**ä½ç½®ç¼–ç **æ˜¯ç»“æ„å›¾é‡Œçš„**Positional encoding**ã€‚

åºåˆ—é¡ºåºæ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„ä¿¡æ¯ï¼Œå¦‚æœç¼ºå¤±ï¼Œç»“æœå°±æ˜¯ï¼šæ‰€æœ‰è¯è¯­éƒ½å¯¹äº†ï¼Œä½†æ˜¯æ— æ³•ç»„æˆæœ‰æ„ä¹‰çš„è¯­å¥

Self-attention ä¸€æ¬¡æ€§å°†æ‰€æœ‰å­—éƒ½å½“åšè¾“å…¥ï¼Œæ„ŸçŸ¥ä¸åˆ°æ–¹å‘ã€ä½ç½®ã€é—´è·ã€‚

ä½†æ˜¯NLPè¾“å…¥çš„æ–‡æœ¬è¦æŒ‰ç…§ä¸€å®šçš„é¡ºåºæ‰å¯ä»¥ã€‚ä¸åŒè¯­åºå°±æœ‰ä¸åŒè¯­ä¹‰ã€‚
- å¥å­1ï¼šæˆ‘å–œæ¬¢åƒæ´‹è‘±
- å¥å­2ï¼šæ´‹è‘±å–œæ¬¢åƒæˆ‘

Transformerç»“æ„ä¸ºäº†æ›´å¥½çš„å‘æŒ¥å¹¶è¡Œè¾“å…¥çš„ç‰¹ç‚¹ï¼Œé¦–å…ˆè¦è®©è¾“å…¥å†…å®¹å…·æœ‰ä¸€å®šä½ç½®ä¿¡æ¯ã€‚

äºæ˜¯ï¼Œè®ºæ–‡æå‡ºäº†**Positional encoding**ã€‚
- **å¯¹åºåˆ—ä¸­çš„è¯è¯­å‡ºç°çš„ä½ç½®è¿›è¡Œç¼–ç **ï¼Œå¦‚æœå¯¹ä½ç½®è¿›è¡Œç¼–ç ï¼Œé‚£æ¨¡å‹å°±å¯ä»¥æ•æ‰é¡ºåºä¿¡æ¯


### ä¸ºä»€ä¹ˆç”¨ä½ç½®ç¼–ç 

ã€2023-6-13ã€‘[å¦‚ä½•ç†è§£Transformerè®ºæ–‡ä¸­çš„positional encodingï¼Œå’Œä¸‰è§’å‡½æ•°æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ](https://www.zhihu.com/question/347678607/answer/2301693596)

ä¸ºä»€ä¹ˆè€ƒè™‘é¡ºåº?
- æ•æ‰åºåˆ—**é¡ºåº**ï¼Œäº¤æ¢å•è¯ä½ç½®å attention map çš„å¯¹åº”ä½ç½®æ•°å€¼ä¹Ÿä¼šäº¤æ¢ï¼Œäº§ç”Ÿæ•°å€¼å˜åŒ–ï¼Œè¡¥å……è¯åºä¿¡æ¯ã€‚
- ä¸åŒ**è·ç¦»**çš„å•è¯å½±å“ç¨‹åº¦ä¸åŒ

ä¸ºä»€ä¹ˆç”¨ç›¸å¯¹ä½ç½®ï¼Ÿ

tokens ä½ç½®ä¿¡æ¯æœ‰ï¼š
- ï¼ˆ1ï¼‰**ç»å¯¹**ä½ç½®ä¿¡æ¯ã€‚a1æ˜¯ç¬¬ä¸€ä¸ªtokenï¼Œa2æ˜¯ç¬¬äºŒä¸ªtoken...... 
- ï¼ˆ2ï¼‰**ç›¸å¯¹**ä½ç½®ä¿¡æ¯ã€‚a2åœ¨a1çš„åé¢ä¸€ä½ï¼Œa4åœ¨a2çš„åé¢ä¸¤ä½...... 
- ï¼ˆ3ï¼‰ä¸åŒä½ç½®**é—´è·**ã€‚a1å’Œa3å·®ä¸¤ä¸ªä½ç½®ï¼Œa1å’Œa4å·®ä¸‰ä¸ªä½ç½®.... 

ä½†æ˜¯è¿™äº›ä¿¡æ¯ self-attention éƒ½æ— æ³•åˆ†è¾©
- å› ä¸ºself-attentionçš„è¿ç®—æ˜¯**æ— å‘**çš„ã€‚
- éœ€è¦æƒ³åŠæ³•æŠŠtokensçš„ä½ç½®ä¿¡æ¯å–‚ç»™æ¨¡å‹ã€‚

åˆ†æ
- é¡ºåºç¼–ç : æ— ç•Œä¸”ä¸åˆ©äºæ¨¡å‹æ³›åŒ–
- ç›¸å¯¹ç¼–ç : ç›¸å¯¹è·ç¦»ä¸åŒï¼Œæ— æ³•ååº”é—´è·ä¿¡æ¯
  - å¦‚å°†ä½ç½®ç¼–å·å½’ä¸€åŒ–åˆ° `[0,1]` åŒºé—´
  - åŒæ ·æ˜¯é—´éš”3ä¸ªä½ç½®ï¼Œç›¸å¯¹è·ç¦»å¯èƒ½æ˜¯ 0.33, 0.5, ...
- ç†æƒ³çš„ç¼–ç æ–¹å¼æ»¡è¶³ï¼š
  - ï¼ˆ1ï¼‰èƒ½è¡¨ç¤ºtokenåœ¨åºåˆ—ä¸­çš„**ç»å¯¹**ä½ç½®ï¼Œä¸”**è¿ç»­æœ‰ç•Œ**
  - ï¼ˆ2ï¼‰åºåˆ—é•¿åº¦ä¸åŒæ—¶ï¼Œtokençš„**ç›¸å¯¹**ä½ç½®/è·ç¦»ä¹Ÿè¦ä¿æŒä¸€è‡´
  - ï¼ˆ3ï¼‰æ”¯æŒè®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰çš„å¥å­é•¿åº¦ã€‚
  - ï¼ˆ4ï¼‰ä¸åŒä½ç½®å‘é‡å¯ä»¥é€šè¿‡çº¿æ€§å˜åŒ–å¾—åˆ°

äºŒè¿›åˆ¶å‡½æ•°ä¸è¡Œï¼Ÿ
- 0/1 ç¦»æ•£ç©ºé—´ï¼Œone-hotè¡¨ç¤ºå­—ç¬¦ï¼Œæ˜¾ç¤ºä¸å‡ºå·®è·

ä¸ºä»€ä¹ˆç”¨sinå‡½æ•°ï¼Ÿ
- è¯åºä¿¡æ¯è¡¨ç¤ºæ–¹æ³•å¾ˆä¸°å¯Œï¼Œä½†éƒ½éœ€è¦å¯¹ä¸åŒç»´åº¦çš„ä¸åŒä½ç½®ç”Ÿæˆåˆç†çš„æ•°å€¼è¡¨ç¤ºã€‚
  - åˆç†ï¼šä¸åŒä½ç½®çš„åŒä¸€ç»´åº¦çš„ä½ç½®å‘é‡ä¹‹é—´ï¼Œå«æœ‰**ç›¸å¯¹ä½ç½®ä¿¡æ¯**ï¼Œè€Œç›¸å¯¹ä½ç½®ä¿¡æ¯å¯ä»¥é€šè¿‡å‡½æ•°**å‘¨æœŸæ€§**å®ç°ã€‚
  - è®ºæ–‡è§£é‡Šï¼šå¯¹ä¸åŒç»´åº¦ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£/ä½™å¼¦å…¬å¼è¿›è€Œç”Ÿæˆä¸åŒä½ç½®çš„é«˜ç»´ä½ç½®å‘é‡ã€‚
- çŒœæµ‹
  - å‘¨æœŸæ€§é¢‘ç‡é‡‡æ ·ï¼ˆOFDMã€FFTç­‰ï¼‰ï¼Œå¯èƒ½ç¡®å®è¿åˆäº†è¯­è¨€çš„æŸç§å±æ€§ã€‚æ¯”å¦‚ï¼Œè¯—æ­Œå°±æ˜¯ä¸€ç±»é¢‘ç‡ä½“ç°å¾ˆæ˜æ˜¾çš„å¥å­ã€‚

ä¸ºä»€ä¹ˆå¥‡å¶ç»´åº¦ä¹‹é—´éœ€è¦ä½œå‡ºåŒºåˆ†ï¼Œåˆ†åˆ«ä½¿ç”¨ sin å’Œ cos å‘¢ï¼Ÿ
- ä¸‰è§’å‡½æ•°çš„**ç§¯åŒ–å’Œå·®**å…¬å¼
- å¥‡å¶åŒºåˆ†å¯ä»¥é€šè¿‡å…¨è¿æ¥å±‚å¸®åŠ©é‡æ’åæ ‡ï¼Œæ‰€ä»¥ç›´æ¥ç®€å•åœ°åˆ†ä¸ºä¸¤æ®µ(å‰ 256 ç»´ä½¿ç”¨ sinï¼Œå 256 ç»´ä½¿ç”¨ cos)ã€‚

å³æ»¡è¶³ï¼ˆ4ï¼‰**ä¸åŒä½ç½®å‘é‡å¯ä»¥é€šè¿‡çº¿æ€§å˜åŒ–å¾—åˆ°**
- sin(a+b)=sin(a)

$$ 
\left(\begin{array}{c}
\cos (\theta+\phi) \\
\sin (\theta+\phi)
\end{array}\right)=\left(\begin{array}{cc}
\cos \phi & -\sin \phi \\
\sin \phi & \cos \phi
\end{array}\right)\left(\begin{array}{c}
\cos \theta \\
\sin \theta
\end{array}\right)
$$

Transformerä½ç½®ç¼–ç å¯è§†åŒ–
- ä¸€ä¸²åºåˆ—é•¿åº¦ä¸º50ï¼Œä½ç½®ç¼–ç ç»´åº¦ä¸º128çš„ä½ç½®ç¼–ç å¯è§†åŒ–ç»“æœ
- ![](https://pic1.zhimg.com/80/v2-b6c64586260ebed24339052adec7bca8_1440w.webp?source=1940ef5c)
- ç”±äºsin/coså‡½æ•°çš„æ€§è´¨ï¼Œä½ç½®å‘é‡æ¯ä¸ªå€¼éƒ½ä½äº\[-1, 1\]ä¹‹é—´ã€‚
- åŒæ—¶ï¼Œçºµå‘æ¥çœ‹ï¼Œå›¾çš„å³åŠè¾¹å‡ ä¹éƒ½æ˜¯è“è‰²çš„ï¼Œå› ä¸ºè¶Šå¾€åçš„ä½ç½®ï¼Œé¢‘ç‡è¶Šå°ï¼Œæ³¢é•¿è¶Šé•¿ï¼Œæ‰€ä»¥ä¸åŒçš„tå¯¹æœ€ç»ˆç»“æœå½±å“ä¸å¤§ã€‚è€Œè¶Šå¾€å·¦è¾¹èµ°ï¼Œé¢œè‰²äº¤æ›¿çš„é¢‘ç‡è¶Šé¢‘ç¹ã€‚

### ä½ç½®ç¼–ç åˆ†ç±»

***ä½ç½®ç¼–ç åˆ†ç±»***

ä½ç½®ç¼–ç åˆ†ä¸ºä¸¤ä¸ªç±»å‹ï¼š`å‡½æ•°å‹`å’Œ`è¡¨æ ¼å‹`
- `å‡½æ•°å‹`ï¼šé€šè¿‡è¾“å…¥tokenä½ç½®ä¿¡æ¯å¾—åˆ°ç›¸åº”çš„ä½ç½®ç¼–ç ï¼›
  - æ–¹æ³•â‘ ï¼šä½¿ç”¨`[0, 1]`èŒƒå›´åˆ†é…ã€‚ç¬¬ä¸€ä¸ªtokenåˆ†é…0ï¼Œæœ€åä¸€ä¸ªtokenåˆ†é…å»1ï¼Œå…¶ä½™tokenæŒ‰ç…§æ–‡ç« é•¿åº¦å¹³å‡åˆ†é…ã€‚
    - ç¤ºä¾‹ï¼š
        - æˆ‘å–œæ¬¢åƒæ´‹è‘± `ã€0 0.16 0.32.....1ã€‘`
        - æˆ‘çœŸçš„ä¸å–œæ¬¢åƒæ´‹è‘±`ã€0 0.125 0.25.....1ã€‘`
    - é—®é¢˜ï¼šå¦‚æœå¥å­é•¿åº¦ä¸åŒï¼Œé‚£ä¹ˆä½ç½®ç¼–ç æ˜¯ä¸ä¸€æ ·ï¼Œæ‰€ä»¥, <span style='color:red'>æ— æ³•è¡¨ç¤ºå¥å­ä¹‹é—´æœ‰ä»€ä¹ˆç›¸ä¼¼æ€§</span>ã€‚
  - æ–¹æ³•â‘¡ï¼š1-n**æ­£æ•´æ•°**èŒƒå›´åˆ†é…
    - ç›´è§‚ï¼ŒæŒ‰ç…§è¾“å…¥é¡ºåºï¼Œä¸€æ¬¡åˆ†é…ç»™tokenæ‰€åœ¨çš„ç´¢å¼•ä½ç½®ã€‚å…·ä½“å½¢å¼å¦‚ä¸‹ï¼š
      - æˆ‘å–œæ¬¢åƒæ´‹è‘± `ã€1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ã€‘`
      - æˆ‘çœŸçš„ä¸å–œæ¬¢åƒæ´‹è‘±`ã€1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ã€‘`
    - é—®é¢˜ï¼šå¥å­è¶Šé•¿ï¼Œåé¢å€¼è¶Šå¤§ï¼Œæ•°å­—è¶Šå¤§è¯´æ˜è¿™ä¸ªä½ç½®å çš„æƒé‡ä¹Ÿè¶Šå¤§,<span style='color:red'>æ— æ³•å‡¸æ˜¾æ¯ä¸ªä½ç½®çš„çœŸå®æƒé‡</span>ã€‚
  - æ€»ç»“ï¼š
    - è¿‡å»çš„æ–¹æ³•æœ‰å„ç§ä¸è¶³ï¼Œæ‰€ä»¥Transformerå¯¹äºä½ç½®ä¿¡æ¯ç¼–ç åšäº†æ”¹è¿›
- `è¡¨æ ¼å‹`ï¼šå»ºé•¿åº¦ä¸ºLçš„è¯è¡¨ï¼ŒæŒ‰è¯è¡¨é•¿åº¦æ¥åˆ†é…ä½ç½®id
  - **ç›¸å¯¹ä½ç½®ç¼–ç **å…³æ³¨tokenä¸tokenè·ç¦»çš„**ç›¸å¯¹ä½ç½®**(è·ç¦»å·®å‡ ä¸ªtoken)ã€‚ä½ç½®1å’Œä½ç½®2çš„è·ç¦»æ¯”ä½ç½®3å’Œä½ç½®10çš„è·ç¦»æ›´è¿‘ï¼Œä½ç½®1å’Œä½ç½®2ä¸ä½ç½®3å’Œä½ç½®4éƒ½åªç›¸å·®1ã€‚è¿™ç§æ–¹æ³•å¯ä»¥çŸ¥é“å•è¯ä¹‹é—´çš„**è·ç¦»è¿œè¿‘**å…³ç³»ã€‚
  - ![å›¾ç¤º](https://img-blog.csdnimg.cn/img_convert/ef2c7618ee3451e8c16c2e7fa21fbd71.png)
  - é—®é¢˜ï¼šè™½è¯´å¯ä»¥è¡¨ç¤ºå‡ºç›¸å¯¹çš„è·ç¦»å…³ç³»ï¼Œä½†æ˜¯ä¹Ÿæœ‰å±€é™ã€‚
    - åªèƒ½çš„åˆ°**ç›¸å¯¹**å…³ç³»ï¼Œæ— æ³•å¾—åˆ°**æ–¹å‘å…³ç³»**ã€‚å¯¹äºä¸¤ä¸ªtokenè°åœ¨è°çš„å‰é¢/åé¢ï¼Œæ— æ³•åˆ¤æ–­ã€‚

Transformerä½ç½®ç¼–ç é‡‡ç”¨`å‡½æ•°å‹`ï¼ŒGPT-3è®ºæ–‡ç»™å‡ºå…¬å¼ï¼š
- ![å…¬å¼](https://img-blog.csdnimg.cn/img_convert/0eed794d556ddb9a75bb2e39cf2791b7.png)
- æ³¨æ„ï¼šæ¯ä¸€ä¸ªTokençš„ä½ç½®ä¿¡æ¯ç¼–ç ä¸æ˜¯æ•°å­—ï¼Œè€Œæ˜¯ä¸€ä¸ªä¸åŒé¢‘ç‡åˆ†å‰²å‡ºæ¥ï¼Œå’Œæ–‡æœ¬ä¸€æ ·ç»´åº¦çš„å‘é‡ã€‚ä¸åŒé¢‘ç‡æ˜¯é€šè¿‡Wnæ¥è¡¨ç¤ºã€‚
- å¾—åˆ°ä½ç½®å‘é‡Pä¹‹åï¼Œå°†å’Œæ¨¡å‹çš„embeddingå‘é‡ç›¸åŠ ï¼Œå¾—åˆ°è¿›å…¥Transformeræ¨¡å‹çš„æœ€ç»ˆè¡¨ç¤º ![å…¬å¼](https://img-blog.csdnimg.cn/img_convert/c096e564bb2b7b833c96769511a704a5.png), å…¶ä¸­ï¼Œ$w_i=1/10000^{2i/d_{model}}$,  tæ˜¯æ¯ä¸ªtokençš„ä½ç½®ï¼Œæ¯”å¦‚è¯´æ˜¯ä½ç½®1ï¼Œä½ç½®2ï¼Œä»¥åŠä½ç½®n

transformeræ€ä¹ˆåšå‘¢ï¼Ÿè®ºæ–‡çš„å®ç°å¾ˆæœ‰æ„æ€ï¼Œä½¿ç”¨æ­£ä½™å¼¦å‡½æ•°ã€‚å…¬å¼å¦‚ä¸‹ï¼š
- $$PE(pos,2i) = sin(pos/10000^{2i/d_{model}}) $$
- $$PE(pos,2i+1) = cos(pos/10000^{2i/d_{model}})$$

å…¶ä¸­ï¼Œ`pos`æ˜¯æŒ‡è¯è¯­åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚å¯ä»¥çœ‹å‡ºï¼Œåœ¨**å¶æ•°ä½ç½®ï¼Œä½¿ç”¨æ­£å¼¦ç¼–ç ï¼Œåœ¨å¥‡æ•°ä½ç½®ï¼Œä½¿ç”¨ä½™å¼¦ç¼–ç **ã€‚

ä¸Šé¢å…¬å¼ä¸­çš„$d_{model}$æ˜¯æ¨¡å‹çš„ç»´åº¦ï¼Œè®ºæ–‡é»˜è®¤æ˜¯`512`ã€‚

è¿™ä¸ªç¼–ç å…¬å¼çš„æ„æ€å°±æ˜¯ï¼šç»™å®šè¯è¯­çš„ä½ç½®$\text{pos}$ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒç¼–ç æˆ$d_{model}$ç»´çš„å‘é‡ï¼ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ç½®ç¼–ç çš„æ¯ä¸€ä¸ªç»´åº¦å¯¹åº”æ­£å¼¦æ›²çº¿ï¼Œæ³¢é•¿æ„æˆäº†ä»$2\pi$$åˆ°$$10000*2\pi$çš„ç­‰æ¯”åºåˆ—ã€‚

ä¸Šé¢çš„ä½ç½®ç¼–ç æ˜¯**ç»å¯¹ä½ç½®ç¼–ç **ã€‚ä½†æ˜¯è¯è¯­çš„**ç›¸å¯¹ä½ç½®**ä¹Ÿéå¸¸é‡è¦ã€‚è¿™å°±æ˜¯è®ºæ–‡ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ä¸‰è§’å‡½æ•°çš„åŸå› ï¼

æ­£å¼¦å‡½æ•°èƒ½å¤Ÿè¡¨è¾¾ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚ä¸»è¦æ•°å­¦ä¾æ®æ˜¯ä»¥ä¸‹ä¸¤ä¸ªå…¬å¼ï¼š
- $$sin(\alpha+\beta) = sin\alpha cos\beta + cos\alpha sin\beta$$
- $$cos(\alpha+\beta) = cos\alpha cos\beta - sin\alpha sin\beta$$

ä¸Šé¢çš„å…¬å¼è¯´æ˜ï¼Œå¯¹äºè¯æ±‡ä¹‹é—´çš„ä½ç½®åç§»`k`ï¼Œ$PE(pos+k)$å¯ä»¥è¡¨ç¤ºæˆ$PE(pos)$å’Œ$PE(k)$çš„ç»„åˆå½¢å¼ï¼Œè¿™å°±æ˜¯è¡¨è¾¾ç›¸å¯¹ä½ç½®çš„èƒ½åŠ›ï¼

ä»¥ä¸Šå°±æ˜¯$PE$çš„æ‰€æœ‰ç§˜å¯†ã€‚è¯´å®Œäº†positional encodingï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªä¸ä¹‹å¤„äºåŒä¸€åœ°ä½çš„**word embedding**ã€‚

**Word embedding**å¤§å®¶éƒ½å¾ˆç†Ÿæ‚‰äº†ï¼Œå®ƒæ˜¯å¯¹åºåˆ—ä¸­çš„è¯æ±‡çš„ç¼–ç ï¼ŒæŠŠæ¯ä¸€ä¸ªè¯æ±‡ç¼–ç æˆ$d_{model}$ç»´çš„å‘é‡ï¼çœ‹åˆ°æ²¡æœ‰ï¼Œ**Postional encodingæ˜¯å¯¹è¯æ±‡çš„ä½ç½®ç¼–ç ï¼Œword embeddingæ˜¯å¯¹è¯æ±‡æœ¬èº«ç¼–ç **

æ‰€ä»¥ï¼Œæˆ‘æ›´å–œæ¬¢positional encodingçš„å¦å¤–ä¸€ä¸ªåå­—**Positional embedding**

### å›¾è§£ä½ç½®ç¼–ç 

è¾“å…¥ attention ç»“æ„ä¹‹å‰ï¼Œæ¯ä¸ªå­—åš word embedding å’Œ positional embeddingã€‚
- åŠ ä½ç½® embeddingæ˜¯ä¸ºäº†æœåŠ¡äº self-attention çš„ç›®æ ‡ï¼Œå³å¾—åˆ°ä¸€ä¸ª word åºåˆ—ä¸­æ¯ä¸¤ä¸ªword ä¹‹é—´çš„ç›¸å…³æ€§ã€‚
- wordä¹‹é—´çš„ç›¸å…³æ€§ï¼Œåªè·Ÿ**ç›¸å¯¹ä½ç½®**æœ‰å…³ã€è€Œä¸ç»å¯¹ä½ç½®æ— å…³ã€‚[img](https://pic4.zhimg.com/80/v2-84165bd9ee3ef5cdf52ec6be63bd7dab_1440w.webp)
- ![img](https://pic4.zhimg.com/80/v2-84165bd9ee3ef5cdf52ec6be63bd7dab_1440w.webp)




### Positional encoding å®ç°

PEçš„å®ç°ä¹Ÿä¸éš¾ï¼ŒæŒ‰ç…§è®ºæ–‡çš„å…¬å¼å³å¯ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn

class PositionalEncoding(nn.Module):
    
    def __init__(self, d_model, max_seq_len):
        """åˆå§‹åŒ–ã€‚
        Args:
            d_model: ä¸€ä¸ªæ ‡é‡ã€‚æ¨¡å‹çš„ç»´åº¦ï¼Œè®ºæ–‡é»˜è®¤æ˜¯512
            max_seq_len: ä¸€ä¸ªæ ‡é‡ã€‚æ–‡æœ¬åºåˆ—çš„æœ€å¤§é•¿åº¦
        """
        super(PositionalEncoding, self).__init__()
        
        # æ ¹æ®è®ºæ–‡ç»™çš„å…¬å¼ï¼Œæ„é€ å‡ºPEçŸ©é˜µ
        position_encoding = np.array([
          [pos / np.pow(10000, 2.0 * (j // 2) / d_model) for j in range(d_model)]
          for pos in range(max_seq_len)])
        # å¶æ•°åˆ—ä½¿ç”¨sinï¼Œå¥‡æ•°åˆ—ä½¿ç”¨cos
        position_encoding[:, 0::2] = np.sin(position_encoding[:, 0::2])
        position_encoding[:, 1::2] = np.cos(position_encoding[:, 1::2])

        # åœ¨PEçŸ©é˜µçš„ç¬¬ä¸€è¡Œï¼ŒåŠ ä¸Šä¸€è¡Œå…¨æ˜¯0çš„å‘é‡ï¼Œä»£è¡¨è¿™`PAD`çš„positional encoding
        # åœ¨word embeddingä¸­ä¹Ÿç»å¸¸ä¼šåŠ ä¸Š`UNK`ï¼Œä»£è¡¨ä½ç½®å•è¯çš„word embeddingï¼Œä¸¤è€…ååˆ†ç±»ä¼¼
        # é‚£ä¹ˆä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªé¢å¤–çš„PADçš„ç¼–ç å‘¢ï¼Ÿå¾ˆç®€å•ï¼Œå› ä¸ºæ–‡æœ¬åºåˆ—çš„é•¿åº¦ä¸ä¸€ï¼Œæˆ‘ä»¬éœ€è¦å¯¹é½ï¼Œ
        # çŸ­çš„åºåˆ—æˆ‘ä»¬ä½¿ç”¨0åœ¨ç»“å°¾è¡¥å…¨ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦è¿™äº›è¡¥å…¨ä½ç½®çš„ç¼–ç ï¼Œä¹Ÿå°±æ˜¯`PAD`å¯¹åº”çš„ä½ç½®ç¼–ç 
        pad_row = torch.zeros([1, d_model])
        position_encoding = torch.cat((pad_row, position_encoding))
        
        # åµŒå…¥æ“ä½œï¼Œ+1æ˜¯å› ä¸ºå¢åŠ äº†`PAD`è¿™ä¸ªè¡¥å…¨ä½ç½®çš„ç¼–ç ï¼Œ
        # Word embeddingä¸­å¦‚æœè¯å…¸å¢åŠ `UNK`ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦+1ã€‚çœ‹å§ï¼Œä¸¤è€…ååˆ†ç›¸ä¼¼
        self.position_encoding = nn.Embedding(max_seq_len + 1, d_model)
        self.position_encoding.weight = nn.Parameter(position_encoding,
                                                     requires_grad=False)
    def forward(self, input_len):
        """ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­ã€‚
        Args:
          input_len: ä¸€ä¸ªå¼ é‡ï¼Œå½¢çŠ¶ä¸º[BATCH_SIZE, 1]ã€‚æ¯ä¸€ä¸ªå¼ é‡çš„å€¼ä»£è¡¨è¿™ä¸€æ‰¹æ–‡æœ¬åºåˆ—ä¸­å¯¹åº”çš„é•¿åº¦ã€‚

        Returns:
          è¿”å›è¿™ä¸€æ‰¹åºåˆ—çš„ä½ç½®ç¼–ç ï¼Œè¿›è¡Œäº†å¯¹é½ã€‚
        """
        # æ‰¾å‡ºè¿™ä¸€æ‰¹åºåˆ—çš„æœ€å¤§é•¿åº¦
        max_len = torch.max(input_len)
        tensor = torch.cuda.LongTensor if input_len.is_cuda else torch.LongTensor
        # å¯¹æ¯ä¸€ä¸ªåºåˆ—çš„ä½ç½®è¿›è¡Œå¯¹é½ï¼Œåœ¨åŸåºåˆ—ä½ç½®çš„åé¢è¡¥ä¸Š0
        # è¿™é‡Œrangeä»1å¼€å§‹ä¹Ÿæ˜¯å› ä¸ºè¦é¿å¼€PAD(0)çš„ä½ç½®
        input_pos = tensor(
          [list(range(1, len + 1)) + [0] * (max_len - len) for len in input_len])
        return self.position_encoding(input_pos)
```

### Word embeddingçš„å®ç°

Word embeddingåº”è¯¥æ˜¯è€ç”Ÿå¸¸è°ˆäº†ï¼Œå®ƒå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªäºŒç»´æµ®ç‚¹çŸ©é˜µï¼Œé‡Œé¢çš„æƒé‡æ˜¯å¯è®­ç»ƒå‚æ•°ï¼Œæˆ‘ä»¬åªéœ€è¦æŠŠè¿™ä¸ªçŸ©é˜µæ„å»ºå‡ºæ¥å°±å®Œæˆäº†word embeddingçš„å·¥ä½œã€‚

æ‰€ä»¥ï¼Œå…·ä½“çš„å®ç°å¾ˆç®€å•ï¼š

```python
import torch.nn as nn


embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)
# è·å¾—è¾“å…¥çš„è¯åµŒå…¥ç¼–ç 
seq_embedding = seq_embedding(inputs)*np.sqrt(d_model)
```

ä¸Šé¢`vocab_size`å°±æ˜¯è¯å…¸çš„å¤§å°ï¼Œ`embedding_size`å°±æ˜¯è¯åµŒå…¥çš„ç»´åº¦å¤§å°ï¼Œè®ºæ–‡é‡Œé¢å°±æ˜¯ç­‰äº$d_{model}=512$ã€‚æ‰€ä»¥word embeddingçŸ©é˜µå°±æ˜¯ä¸€ä¸ª`vocab_size`*`embedding_size`çš„äºŒç»´å¼ é‡ã€‚

å¦‚æœä½ æƒ³è·å–æ›´è¯¦ç»†çš„å…³äºword embeddingçš„ä¿¡æ¯ï¼Œå¯ä»¥çœ‹æˆ‘çš„å¦å¤–ä¸€ä¸ªæ–‡ç« [word2vecçš„ç¬”è®°å’Œå®ç°](https://github.com/luozhouyang/machine-learning-notes/blob/master/word2vec.ipynb)ã€‚

### ä½ç½®ç¼–ç : BERT vs Trans

å„ä¸ªæ¨¡å‹çš„ä½ç½®ç¼–ç å·®å¼‚
- Word2Vec æ²¡æœ‰ä½ç½®ç¼–ç 
- Trans ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªsinå’Œcoså‡½æ•°ç®—å‡ºæ¥çš„å›ºå®šå€¼ï¼Œåªèƒ½æ ‡è®°è¿™æ˜¯æŸä¸€ä¸ªä½ç½®ï¼Œå¹¶ä¸èƒ½æ ‡è®°è¿™ä¸ªä½ç½®æœ‰å•¥ç”¨ã€‚
  - æ»¡è¶³æ¡ä»¶ï¼šç»å¯¹ä½ç½®ã€ç›¸å¯¹ä½ç½®ã€è€ƒè™‘è¿œè¿‘ã€ä¾¿äºçº¿æ€§å˜æ¢
- BERT ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªå¯å­¦ä¹ çš„embeddingï¼Œæ‰€ä»¥ä¸ä»…å¯ä»¥æ ‡æ³¨è¿™ä¸€ä¸ªä½ç½®ï¼Œè¿˜èƒ½å­¦ä¹ <span style='color:blue'>è¿™ä¸ªä½ç½®æœ‰ä»€ä¹ˆä½œç”¨</span>ã€‚
  - ç»´æŠ¤3ä¸ªembeddingçŸ©é˜µï¼Œè¯ã€æ®µã€ä½ç½®ã€‚è¯æ˜¯æ€ä¹ˆå–embeddingçš„ï¼Œæ®µå’Œä½ç½®å°±æ€ä¹ˆå–embedding
  - ![img](https://zh-v2.d2l.ai/_images/bert-input.svg)

[BERT](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert.html#subsec-bert-input-rep)

ä¸ TransformerEncoderä¸åŒï¼Œ BERTEncoder ä½¿ç”¨**ç‰‡æ®µåµŒå…¥**å’Œå¯å­¦ä¹ çš„**ä½ç½®åµŒå…¥**ã€‚
- nn.Parameter ä¼ å…¥çš„æ˜¯ä¸€ä¸ª**éšæœºæ•°**

```py
#@save
class BERTEncoder(nn.Module):
    """BERTç¼–ç å™¨"""
    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,
                 ffn_num_hiddens, num_heads, num_layers, dropout,
                 max_len=1000, key_size=768, query_size=768, value_size=768,
                 **kwargs):
        super(BERTEncoder, self).__init__(**kwargs)
        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)
        self.segment_embedding = nn.Embedding(2, num_hiddens)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module(f"{i}", d2l.EncoderBlock(
                key_size, query_size, value_size, num_hiddens, norm_shape,
                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))
        # åœ¨BERTä¸­ï¼Œä½ç½®åµŒå…¥æ˜¯å¯å­¦ä¹ çš„ï¼Œå› æ­¤æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„ä½ç½®åµŒå…¥å‚æ•°
        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, num_hiddens))

    def forward(self, tokens, segments, valid_lens):
        # åœ¨ä»¥ä¸‹ä»£ç æ®µä¸­ï¼ŒXçš„å½¢çŠ¶ä¿æŒä¸å˜ï¼šï¼ˆæ‰¹é‡å¤§å°ï¼Œæœ€å¤§åºåˆ—é•¿åº¦ï¼Œnum_hiddensï¼‰
        X = self.token_embedding(tokens) + self.segment_embedding(segments)
        X = X + self.pos_embedding.data[:, :X.shape[1], :]
        for blk in self.blks:
            X = blk(X, valid_lens)
        return X
```

è¯¦è§ï¼šBERT

## Position-wise Feed-Forward networkæ˜¯ä»€ä¹ˆï¼Ÿ

è¿™å°±æ˜¯ä¸€ä¸ªå…¨è¿æ¥ç½‘ç»œï¼ŒåŒ…å«ä¸¤ä¸ªçº¿æ€§å˜æ¢å’Œä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼ˆå®é™…ä¸Šå°±æ˜¯ReLUï¼‰ã€‚å…¬å¼å¦‚ä¸‹ï¼š

$$FFN(x)=max(0,xW_1+b_1)W_2+b_2$$

è¿™ä¸ªçº¿æ€§å˜æ¢åœ¨ä¸åŒçš„ä½ç½®éƒ½è¡¨ç°åœ°ä¸€æ ·ï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„å±‚ä¹‹é—´ä½¿ç”¨ä¸åŒçš„å‚æ•°ã€‚

è®ºæ–‡æåˆ°ï¼Œè¿™ä¸ªå…¬å¼è¿˜å¯ä»¥ç”¨ä¸¤ä¸ªæ ¸å¤§å°ä¸º1çš„ä¸€ç»´å·ç§¯æ¥è§£é‡Šï¼Œå·ç§¯çš„è¾“å…¥è¾“å‡ºéƒ½æ˜¯$d_{model}=512$ï¼Œä¸­é—´å±‚çš„ç»´åº¦æ˜¯$d_{ff}=2048$ã€‚

å®ç°å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn


class PositionalWiseFeedForward(nn.Module):

    def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):
        super(PositionalWiseFeedForward, self).__init__()
        self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)
        self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(model_dim)

    def forward(self, x):
        output = x.transpose(1, 2)
        output = self.w2(F.relu(self.w1(output)))
        output = self.dropout(output.transpose(1, 2))

        # add residual and norm layer
        output = self.layer_norm(x + output)
        return output
```

## Transformer å®ç°


### pytorch ç‰ˆæœ¬

[Transformeræ¨¡å‹çš„PyTorchå®ç°](https://luozhouyang.github.io/transformer/)
- Google 2017å¹´çš„è®ºæ–‡ [Attention is all you need](https://arxiv.org/abs/1706.03762) é˜é‡Šäº†ä»€ä¹ˆå«åšå¤§é“è‡³ç®€ï¼è¯¥è®ºæ–‡æå‡ºäº†**Transformer**æ¨¡å‹ï¼Œå®Œå…¨åŸºäº**Attention mechanism**ï¼ŒæŠ›å¼ƒäº†ä¼ ç»Ÿçš„**RNN**å’Œ**CNN**ã€‚
- æ ¹æ®è®ºæ–‡çš„ç»“æ„å›¾ï¼Œä¸€æ­¥ä¸€æ­¥ä½¿ç”¨ [PyTorch](https://github.com/pytoch/pytorch) å®ç°è¿™ä¸ª**Transformer**æ¨¡å‹ã€‚


#### è‡ªæ³¨æ„åŠ›å®ç°

Self-Attentionçš„ä»£ç å®ç°


```py
# Self-Attention æœºåˆ¶çš„å®ç°
from math import sqrt
import torch
import torch.nn as nn

class Self_Attention(nn.Module):
    # input : batch_size * seq_len * input_dim
    # q : batch_size * input_dim * dim_k
    # k : batch_size * input_dim * dim_k
    # v : batch_size * input_dim * dim_v
    def __init__(self,input_dim, dim_k, dim_v):
        super(Self_Attention,self).__init__()
        self.q = nn.Linear(input_dim,dim_k)
        self.k = nn.Linear(input_dim,dim_k)
        self.v = nn.Linear(input_dim,dim_v)
        self._norm_fact = 1 / sqrt(dim_k)
        
    def forward(self,x):
        Q = self.q(x) # Q: batch_size * seq_len * dim_k
        K = self.k(x) # K: batch_size * seq_len * dim_k
        V = self.v(x) # V: batch_size * seq_len * dim_v
         
        atten = nn.Softmax(dim=-1)(torch.bmm(Q,K.permute(0,2,1))) * self._norm_fact # Q * K.T() # batch_size * seq_len * seq_len
        
        output = torch.bmm(atten,V) # Q * K.T() * V # batch_size * seq_len * dim_v
        
        return output


if __name__ == '__main__':

    X = torch.randn(4,3,2)
    print(X.size(), X)
    sa = Self_Attention(2,4,5)
    res = sa(X)
    print(res)

```


#### å¤šå¤´æ³¨æ„åŠ›å®ç°


```py
# Muti-head Attention æœºåˆ¶çš„å®ç°
from math import sqrt
import torch
import torch.nn as nn

class Self_Attention_Muti_Head(nn.Module):
    # input : batch_size * seq_len * input_dim
    # q : batch_size * input_dim * dim_k
    # k : batch_size * input_dim * dim_k
    # v : batch_size * input_dim * dim_v
    def __init__(self,input_dim,dim_k,dim_v,nums_head):
        super(Self_Attention_Muti_Head,self).__init__()
        assert dim_k % nums_head == 0
        assert dim_v % nums_head == 0
        self.q = nn.Linear(input_dim,dim_k)
        self.k = nn.Linear(input_dim,dim_k)
        self.v = nn.Linear(input_dim,dim_v)
        
        self.nums_head = nums_head
        self.dim_k = dim_k
        self.dim_v = dim_v
        self._norm_fact = 1 / sqrt(dim_k)
    
    def forward(self,x):
        Q = self.q(x).reshape(-1,x.shape[0],x.shape[1],self.dim_k // self.nums_head) 
        K = self.k(x).reshape(-1,x.shape[0],x.shape[1],self.dim_k // self.nums_head) 
        V = self.v(x).reshape(-1,x.shape[0],x.shape[1],self.dim_v // self.nums_head)
        print(x.shape)
        print(Q.size())
        atten = nn.Softmax(dim=-1)(torch.matmul(Q,K.permute(0,1,3,2))) # Q * K.T() # batch_size * seq_len * seq_len
        output = torch.matmul(atten,V).reshape(x.shape[0],x.shape[1],-1) # Q * K.T() * V # batch_size * seq_len * dim_v
        return output
```


ã€2023-5-10ã€‘ç‚¹çš„selfã€crossæ³¨æ„åŠ›æœºåˆ¶[å®ç°](https://www.cnblogs.com/hellcat/p/15260145.html)

```py
def attention(query, key, value):
    dim = query.shape[1]
    scores = torch.einsum('bdhn,bdhm->bhnm', query, key) / dim**.5
    prob = torch.nn.functional.softmax(scores, dim=-1)
    return torch.einsum('bhnm,bdhm->bdhn', prob, value), prob

class MultiHeadedAttention(nn.Module):
    """ 
      Multi-head attention to increase model expressivitiy 
    """
    def __init__(self, num_heads: int, d_model: int):
        super().__init__()
        assert d_model % num_heads == 0
        self.dim = d_model // num_heads
        self.num_heads = num_heads
        self.merge = nn.Conv1d(d_model, d_model, kernel_size=1)
        self.proj = nn.ModuleList([deepcopy(self.merge) for _ in range(3)])

    def forward(self, query, key, value):
        batch_dim = query.size(0)
        query, key, value = [l(x).view(batch_dim, self.dim, self.num_heads, -1)
                             for l, x in zip(self.proj, (query, key, value))]
        x, prob = attention(query, key, value)
        self.prob.append(prob)
        return self.merge(x.contiguous().view(batch_dim, self.dim*self.num_heads, -1))
```

éœ€è¦å®ç°6å±‚ encoderå’Œdecoderã€‚

encoderä»£ç å®ç°å¦‚ä¸‹ï¼š

```py
import torch
import torch.nn as nn

class EncoderLayer(nn.Module):
	"""Encoderçš„ä¸€å±‚ã€‚"""

    def __init__(self, model_dim=512, num_heads=8, ffn_dim=2018, dropout=0.0):
        super(EncoderLayer, self).__init__()

        self.attention = MultiHeadAttention(model_dim, num_heads, dropout)
        self.feed_forward = PositionalWiseFeedForward(model_dim, ffn_dim, dropout)

    def forward(self, inputs, attn_mask=None):
        # self attention
        context, attention = self.attention(inputs, inputs, inputs, padding_mask)
        # feed forward network
        output = self.feed_forward(context)
        return output, attention

class Encoder(nn.Module):
	"""å¤šå±‚EncoderLayerç»„æˆEncoderã€‚"""

    def __init__(self,
               vocab_size,
               max_seq_len,
               num_layers=6,
               model_dim=512,
               num_heads=8,
               ffn_dim=2048,
               dropout=0.0):
        super(Encoder, self).__init__()

        self.encoder_layers = nn.ModuleList(
          [EncoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in
           range(num_layers)])

        self.seq_embedding = nn.Embedding(vocab_size + 1, model_dim, padding_idx=0)
        self.pos_embedding = PositionalEncoding(model_dim, max_seq_len)

    def forward(self, inputs, inputs_len):
        output = self.seq_embedding(inputs)
        output += self.pos_embedding(inputs_len)

        self_attention_mask = padding_mask(inputs, inputs)

        attentions = []
        for encoder in self.encoder_layers:
            output, attention = encoder(output, self_attention_mask)
            attentions.append(attention)

        return output, attentions

```

é€šè¿‡æ–‡ç« å‰é¢çš„åˆ†æï¼Œä»£ç ä¸éœ€è¦æ›´å¤šè§£é‡Šäº†ã€‚åŒæ ·çš„ï¼Œæˆ‘ä»¬çš„decoderä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn


class DecoderLayer(nn.Module):

    def __init__(self, model_dim, num_heads=8, ffn_dim=2048, dropout=0.0):
        super(DecoderLayer, self).__init__()

        self.attention = MultiHeadAttention(model_dim, num_heads, dropout)
        self.feed_forward = PositionalWiseFeedForward(model_dim, ffn_dim, dropout)

    def forward(self,
              dec_inputs,
              enc_outputs,
              self_attn_mask=None,
              context_attn_mask=None):
        # self attention, all inputs are decoder inputs
        dec_output, self_attention = self.attention(
          dec_inputs, dec_inputs, dec_inputs, self_attn_mask)

        # context attention
        # query is decoder's outputs, key and value are encoder's inputs
        dec_output, context_attention = self.attention(
          enc_outputs, enc_outputs, dec_output, context_attn_mask)

        # decoder's output, or context
        dec_output = self.feed_forward(dec_output)

        return dec_output, self_attention, context_attention


class Decoder(nn.Module):

    def __init__(self,
               vocab_size,
               max_seq_len,
               num_layers=6,
               model_dim=512,
               num_heads=8,
               ffn_dim=2048,
               dropout=0.0):
        super(Decoder, self).__init__()

        self.num_layers = num_layers

        self.decoder_layers = nn.ModuleList(
          [DecoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in
           range(num_layers)])

        self.seq_embedding = nn.Embedding(vocab_size + 1, model_dim, padding_idx=0)
        self.pos_embedding = PositionalEncoding(model_dim, max_seq_len)

    def forward(self, inputs, inputs_len, enc_output, context_attn_mask=None):
        output = self.seq_embedding(inputs)
        output += self.pos_embedding(inputs_len)

        self_attention_padding_mask = padding_mask(inputs, inputs)
        seq_mask = sequence_mask(inputs)
        self_attn_mask = torch.gt((self_attention_padding_mask + seq_mask), 0)

        self_attentions = []
        context_attentions = []
        for decoder in self.decoder_layers:
            output, self_attn, context_attn = decoder(
            output, enc_output, self_attn_mask, context_attn_mask)
            self_attentions.append(self_attn)
            context_attentions.append(context_attn)

        return output, self_attentions, context_attentions
```

æœ€åï¼ŒæŠŠencoderå’Œdecoderç»„æˆTransformeræ¨¡å‹ï¼

ä»£ç å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn


class Transformer(nn.Module):

    def __init__(self,
               src_vocab_size,
               src_max_len,
               tgt_vocab_size,
               tgt_max_len,
               num_layers=6,
               model_dim=512,
               num_heads=8,
               ffn_dim=2048,
               dropout=0.2):
        super(Transformer, self).__init__()
        self.encoder = Encoder(src_vocab_size, src_max_len, num_layers, model_dim,
                               num_heads, ffn_dim, dropout)
        self.decoder = Decoder(tgt_vocab_size, tgt_max_len, num_layers, model_dim,
                               num_heads, ffn_dim, dropout)
        self.linear = nn.Linear(model_dim, tgt_vocab_size, bias=False)
        self.softmax = nn.Softmax(dim=2)

    def forward(self, src_seq, src_len, tgt_seq, tgt_len):
        context_attn_mask = padding_mask(tgt_seq, src_seq)
        output, enc_self_attn = self.encoder(src_seq, src_len)
        output, dec_self_attn, ctx_attn = self.decoder(
          tgt_seq, tgt_len, output, context_attn_mask)
        output = self.linear(output)
        output = self.softmax(output)
        return output, enc_self_attn, dec_self_attn, ctx_attn

```

è‡³æ­¤ï¼ŒTransformeræ¨¡å‹å·²ç»å®ç°äº†ï¼

### pytorchä»£ç 

ã€2021-11-1ã€‘
- [ç†¬äº†ä¸€æ™šä¸Šï¼Œæˆ‘ä»é›¶å®ç°äº†Transformeræ¨¡å‹ï¼ŒæŠŠä»£ç è®²ç»™ä½ å¬](https://zhuanlan.zhihu.com/p/411311520)
- ç†è®ºè®²è§£ï¼š[Transformer - Attention is all you need](https://zhuanlan.zhihu.com/p/311156298)
- æ¨¡å‹ç»“æ„å›¾
  - ![](https://pic1.zhimg.com/80/v2-dad8a00603dc120dee165c06ae8b44d0_720w.jpg)

å®Œæ•´ä»£ç 

```python
# @Author:Yifx
# @Contact: Xxuyifan1999@163.com
# @Time:2021/9/16 20:02
# @Software: PyCharm

"""
æ–‡ä»¶è¯´æ˜ï¼š
"""

import torch
import torch.nn as nn
import numpy as np
import math

class Config(object):
    # æ¨¡å‹è¶…å‚ç±»
    def __init__(self):
        self.vocab_size = 6

        self.d_model = 20
        self.n_heads = 2

        assert self.d_model % self.n_heads == 0
        dim_k  = self.d_model // self.n_heads
        dim_v = self.d_model // self.n_heads

        self.padding_size = 30
        self.UNK = 5
        self.PAD = 4

        self.N = 6
        self.p = 0.1

config = Config()

class Embedding(nn.Module):
    def __init__(self,vocab_size):
        super(Embedding, self).__init__()
        # ä¸€ä¸ªæ™®é€šçš„ embeddingå±‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½®padding_idx=config.PAD æ¥å®ç°è®ºæ–‡ä¸­çš„ padding_mask
        self.embedding = nn.Embedding(vocab_size,config.d_model,padding_idx=config.PAD)


    def forward(self,x):
        # æ ¹æ®æ¯ä¸ªå¥å­çš„é•¿åº¦ï¼Œè¿›è¡Œpaddingï¼ŒçŸ­è¡¥é•¿æˆª
        for i in range(len(x)):
            if len(x[i]) < config.padding_size:
                x[i].extend([config.UNK] * (config.padding_size - len(x[i]))) # æ³¨æ„ UNKæ˜¯ä½ è¯è¡¨ä¸­ç”¨æ¥è¡¨ç¤ºoovçš„tokenç´¢å¼•ï¼Œè¿™é‡Œè¿›è¡Œäº†ç®€åŒ–ï¼Œç›´æ¥å‡è®¾ä¸º6
            else:
                x[i] = x[i][:config.padding_size]
        x = self.embedding(torch.tensor(x)) # batch_size * seq_len * d_model
        return x

class Positional_Encoding(nn.Module):

    def __init__(self,d_model):
        super(Positional_Encoding,self).__init__()
        self.d_model = d_model

    def forward(self,seq_len,embedding_dim):
        positional_encoding = np.zeros((seq_len,embedding_dim))
        for pos in range(positional_encoding.shape[0]):
            for i in range(positional_encoding.shape[1]):
                positional_encoding[pos][i] = math.sin(pos/(10000**(2*i/self.d_model))) if i % 2 == 0 else math.cos(pos/(10000**(2*i/self.d_model)))
        return torch.from_numpy(positional_encoding)

class Mutihead_Attention(nn.Module):
    def __init__(self,d_model,dim_k,dim_v,n_heads):
        super(Mutihead_Attention, self).__init__()
        self.dim_v = dim_v
        self.dim_k = dim_k
        self.n_heads = n_heads

        self.q = nn.Linear(d_model,dim_k)
        self.k = nn.Linear(d_model,dim_k)
        self.v = nn.Linear(d_model,dim_v)

        self.o = nn.Linear(dim_v,d_model)
        self.norm_fact = 1 / math.sqrt(d_model)

    def generate_mask(self,dim):
        # æ­¤å¤„æ˜¯ sequence mask ï¼Œé˜²æ­¢ decoderçª¥è§†åé¢æ—¶é—´æ­¥çš„ä¿¡æ¯ã€‚
        # padding mask åœ¨æ•°æ®è¾“å…¥æ¨¡å‹ä¹‹å‰å®Œæˆã€‚
        matirx = np.ones((dim,dim))
        mask = torch.Tensor(np.tril(matirx))

        return mask==1

    def forward(self,x,y,requires_mask=False):
        assert self.dim_k % self.n_heads == 0 and self.dim_v % self.n_heads == 0
        # size of x : [batch_size * seq_len * batch_size]
        # å¯¹ x è¿›è¡Œè‡ªæ³¨æ„åŠ›
        Q = self.q(x).reshape(-1,x.shape[0],x.shape[1],self.dim_k // self.n_heads) # n_heads * batch_size * seq_len * dim_k
        K = self.k(x).reshape(-1,x.shape[0],x.shape[1],self.dim_k // self.n_heads) # n_heads * batch_size * seq_len * dim_k
        V = self.v(y).reshape(-1,y.shape[0],y.shape[1],self.dim_v // self.n_heads) # n_heads * batch_size * seq_len * dim_v
        # print("Attention V shape : {}".format(V.shape))
        attention_score = torch.matmul(Q,K.permute(0,1,3,2)) * self.norm_fact
        if requires_mask:
            mask = self.generate_mask(x.shape[1])
            # masked_fill å‡½æ•°ä¸­ï¼Œå¯¹Maskä½ç½®ä¸ºTrueçš„éƒ¨åˆ†è¿›è¡ŒMask
            attention_score.masked_fill(mask,value=float("-inf")) # æ³¨æ„è¿™é‡Œçš„å°Trickï¼Œä¸éœ€è¦å°†Q,K,V åˆ†åˆ«MASK,åªMASKSoftmaxä¹‹å‰çš„ç»“æœå°±å¥½äº†
        output = torch.matmul(attention_score,V).reshape(y.shape[0],y.shape[1],-1)
        # print("Attention output shape : {}".format(output.shape))

        output = self.o(output)
        return output

class Feed_Forward(nn.Module):
    def __init__(self,input_dim,hidden_dim=2048):
        super(Feed_Forward, self).__init__()
        self.L1 = nn.Linear(input_dim,hidden_dim)
        self.L2 = nn.Linear(hidden_dim,input_dim)

    def forward(self,x):
        output = nn.ReLU()(self.L1(x))
        output = self.L2(output)
        return output

class Add_Norm(nn.Module):
    def __init__(self):
        self.dropout = nn.Dropout(config.p)
        super(Add_Norm, self).__init__()

    def forward(self,x,sub_layer,**kwargs):
        sub_output = sub_layer(x,**kwargs)
        # print("{} output : {}".format(sub_layer,sub_output.size()))
        x = self.dropout(x + sub_output)

        layer_norm = nn.LayerNorm(x.size()[1:])
        out = layer_norm(x)
        return out


class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.positional_encoding = Positional_Encoding(config.d_model)
        self.muti_atten = Mutihead_Attention(config.d_model,config.dim_k,config.dim_v,config.n_heads)
        self.feed_forward = Feed_Forward(config.d_model)

        self.add_norm = Add_Norm()


    def forward(self,x): # batch_size * seq_len å¹¶ä¸” x çš„ç±»å‹ä¸æ˜¯tensorï¼Œæ˜¯æ™®é€šlist

        x += self.positional_encoding(x.shape[1],config.d_model)
        # print("After positional_encoding: {}".format(x.size()))
        output = self.add_norm(x,self.muti_atten,y=x)
        output = self.add_norm(output,self.feed_forward)

        return output

# åœ¨ Decoder ä¸­ï¼ŒEncoderçš„è¾“å‡ºä½œä¸ºQueryå’ŒKEyè¾“å‡ºçš„é‚£ä¸ªä¸œè¥¿ã€‚å³ Decoderçš„Inputä½œä¸ºVã€‚æ­¤æ—¶æ˜¯å¯è¡Œçš„
# å› ä¸ºåœ¨è¾“å…¥è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªpaddingæ“ä½œï¼Œå°†Inputså’ŒOutputsçš„seq_lenè¿™ä¸ªç»´åº¦éƒ½æ‹‰æˆä¸€æ ·çš„äº†
# æˆ‘ä»¬çŸ¥é“ï¼ŒQKé‚£ä¸ªè¿‡ç¨‹å¾—åˆ°çš„ç»“æœæ˜¯ batch_size * seq_len * seq_len .æ—¢ç„¶ seq_len ä¸€æ ·ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¿™æ ·æ“ä½œ
# è¿™æ ·æ“ä½œçš„æ„ä¹‰æ˜¯ï¼ŒOutputs ä¸­çš„ token åˆ†åˆ«å¯¹äº Inputs ä¸­çš„æ¯ä¸ªtokenä½œæ³¨æ„åŠ›

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.positional_encoding = Positional_Encoding(config.d_model)
        self.muti_atten = Mutihead_Attention(config.d_model,config.dim_k,config.dim_v,config.n_heads)
        self.feed_forward = Feed_Forward(config.d_model)
        self.add_norm = Add_Norm()

    def forward(self,x,encoder_output): # batch_size * seq_len å¹¶ä¸” x çš„ç±»å‹ä¸æ˜¯tensorï¼Œæ˜¯æ™®é€šlist
        # print(x.size())
        x += self.positional_encoding(x.shape[1],config.d_model)
        # print(x.size())
        # ç¬¬ä¸€ä¸ª sub_layer
        output = self.add_norm(x,self.muti_atten,y=x,requires_mask=True)
        # ç¬¬äºŒä¸ª sub_layer
        output = self.add_norm(x,self.muti_atten,y=encoder_output,requires_mask=True)
        # ç¬¬ä¸‰ä¸ª sub_layer
        output = self.add_norm(output,self.feed_forward)
        return output

class Transformer_layer(nn.Module):
    def __init__(self):
        super(Transformer_layer, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

    def forward(self,x):
        x_input,x_output = x
        encoder_output = self.encoder(x_input)
        decoder_output = self.decoder(x_output,encoder_output)
        return (encoder_output,decoder_output)

class Transformer(nn.Module):
    def __init__(self,N,vocab_size,output_dim):
        super(Transformer, self).__init__()
        self.embedding_input = Embedding(vocab_size=vocab_size)
        self.embedding_output = Embedding(vocab_size=vocab_size)

        self.output_dim = output_dim
        self.linear = nn.Linear(config.d_model,output_dim)
        self.softmax = nn.Softmax(dim=-1)
        self.model = nn.Sequential(*[Transformer_layer() for _ in range(N)])


    def forward(self,x):
        x_input , x_output = x
        x_input = self.embedding_input(x_input)
        x_output = self.embedding_output(x_output)

        _ , output = self.model((x_input,x_output))

        output = self.linear(output)
        output = self.softmax(output)

        return output
```


# Transformer æ”¹è¿›


## Transformer é—®é¢˜


ã€2023-9-18ã€‘[RetNetï¼šä¸‡ä¼—æœŸå¾…çš„ Transformers æ€æ‰‹](https://mp.weixin.qq.com/s/HhRtxONjzkoOmSRqixX50g), [å¤´æ¡](https://www.toutiao.com/article/7304956621552501285/)

Transformer å·²æˆä¸ºå¤§è¯­è¨€æ¨¡å‹ä¸Šçš„æ¶æ„ï¼Œå› ä¸ºå®ƒæœ‰æ•ˆåœ°å…‹æœäº†å¾ªç¯ç¥ç»ç½‘ç»œ (RNN) çš„é¡ºåºè®­ç»ƒé—®é¢˜ã€‚

ç„¶è€Œï¼ŒTransformer å¹¶ä¸å®Œç¾ï¼Œå› ä¸ºä»…è§£å†³äº†æ‰€è°“â€œ`impossible triangle`â€çš„**ä¸¤**æ¡è‡‚ã€‚

â€œä¸å¯èƒ½ä¸‰è§’â€ä»£è¡¨å½“å‰åºåˆ—æ¨¡å‹æ— æ³•åŒæ—¶å®ç°**è®­ç»ƒå¹¶è¡Œæ€§**ã€**ä½æˆæœ¬æ¨ç†**ä»¥åŠ**å¼ºå¤§æ€§èƒ½**çš„æ‰€æœ‰3ä¸ªæœŸæœ›ç»´åº¦ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-axegupay5k/e154053c06d24a3a8c24253b5185346e~noop.image?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1701422819&x-signature=oxc1OeNc6B1%2BDAdIQ%2BaOw8jw%2BA0%3D)

ä¸‰è§’ä¸Šçš„æ–¹æ³•è¡¨ç¤ºå®ç°çš„ä¸¤ä¸ªç»´åº¦ï¼Œä½†ç¼ºå°‘ç¬¬ä¸‰ä¸ªé¡¶ç‚¹çš„æ‰€éœ€å±æ€§ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7c1f587ebec642bf9332284352e4a64d~noop.image?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1701422819&x-signature=nYJb%2B%2FFDdkA1f%2F5FLtlAkG5XEVY%3D)


## å¯è§£é‡Šæ€§


### ç™½ç›’ transformer -- CRATE

ã€2023-11-30ã€‘[ã€ŒGPT-4åªæ˜¯åœ¨å‹ç¼©æ•°æ®ã€ï¼Œé©¬æ¯…å›¢é˜Ÿé€ å‡ºç™½ç›’Transformerï¼Œå¯è§£é‡Šçš„å¤§æ¨¡å‹è¦æ¥äº†å—ï¼Ÿ](https://mp.weixin.qq.com/s/ErrCWbz8zDqSYkC9DH79Mg)

ä¼¯å…‹åˆ©å’Œé¦™æ¸¯å¤§å­¦çš„`é©¬æ¯…`æ•™æˆé¢†å¯¼çš„ä¸€ä¸ªç ”ç©¶å›¢é˜Ÿç»™å‡ºäº†è‡ªå·±çš„æœ€æ–°ç ”ç©¶ç»“æœï¼š
> åŒ…æ‹¬ GPT-4 åœ¨å†…çš„å½“å‰ AI ç³»ç»Ÿæ‰€åšçš„æ­£æ˜¯å‹ç¼©ã€‚

æå‡ºçš„æ–°æ·±åº¦ç½‘ç»œæ¶æ„ CRATEï¼Œé€šè¿‡æ•°å­¦æ–¹å¼éªŒè¯äº†è¿™ä¸€ç‚¹ã€‚
- CRATE æ˜¯ä¸€ç§**ç™½ç›’ Transformer**ï¼Œå…¶ä¸ä»…èƒ½åœ¨å‡ ä¹æ‰€æœ‰ä»»åŠ¡ä¸Šä¸**é»‘ç›’ Transformer** ç›¸åª²ç¾ï¼Œè€Œä¸”è¿˜å…·å¤‡éå¸¸å‡ºè‰²çš„**å¯è§£é‡Šæ€§**ã€‚

åŸºäºæ­¤ï¼Œé©¬æ¯…æ•™æˆè¿˜åœ¨ Twitter ä¸Šåˆ†äº«äº†ä¸€ä¸ªæœ‰è¶£çš„è§è§£ï¼š
- æ—¢ç„¶å½“å‰çš„ AI åªæ˜¯åœ¨å‹ç¼©æ•°æ®ï¼Œé‚£ä¹ˆå°±åªèƒ½å­¦ä¹ åˆ°æ•°æ®ä¸­çš„**ç›¸å…³æ€§ / åˆ†å¸ƒ**ï¼Œæ‰€ä»¥å°±å¹¶ä¸çœŸæ­£å…·å¤‡**å› æœæˆ–é€»è¾‘æ¨ç†**æˆ–æŠ½è±¡æ€è€ƒèƒ½åŠ›ã€‚

å› æ­¤ï¼Œå½“ä»Šçš„ AI è¿˜ç®—ä¸æ˜¯ AGIï¼Œå³ä¾¿è¿‘å¹´æ¥åœ¨å¤„ç†å’Œå»ºæ¨¡å¤§é‡é«˜ç»´å’Œå¤šæ¨¡æ€æ•°æ®æ–¹é¢ï¼Œæ·±åº¦å­¦ä¹ åœ¨å®éªŒä¸­å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚

è¿™ç§æˆåŠŸå½’åŠŸäºæ·±åº¦ç½‘ç»œèƒ½æœ‰æ•ˆå­¦ä¹ æ•°æ®åˆ†å¸ƒä¸­**å¯å‹ç¼©çš„ä½ç»´ç»“æ„**ï¼Œå¹¶å°†è¯¥åˆ†å¸ƒè½¬æ¢ä¸ºç®€çº¦ï¼ˆå³ç´§å‡‘ä¸”ç»“æ„åŒ–çš„ï¼‰è¡¨å¾ã€‚è¿™æ ·çš„è¡¨å¾å¯ç”¨äºå¸®åŠ©è®¸å¤šä¸‹æ¸¸ä»»åŠ¡ï¼Œæ¯”å¦‚è§†è§‰ã€åˆ†ç±»ã€è¯†åˆ«å’Œåˆ†å‰²ã€ç”Ÿæˆã€‚

è¡¨å¾å­¦ä¹ æ˜¯é€šè¿‡å‹ç¼©å¼ç¼–ç å’Œè§£ç å®ç°çš„

ç™½ç›’æ·±åº¦ç½‘ç»œç†è®ºã€‚ä¸ºå­¦ä¹ ç´§å‡‘å’Œç»“æ„åŒ–çš„è¡¨å¾æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€ç›®æ ‡ï¼Œæœ‰åŸç†ä¿è¯çš„ä¼˜è‰¯åº¦åº¦é‡ã€‚å¯¹äºå­¦ä¹ åˆ°çš„è¡¨å¾ï¼Œè¯¥ç›®æ ‡æ—¨åœ¨æ—¢ä¼˜åŒ–å…¶åœ¨ç¼–ç ç‡ä¸‹é™æ–¹é¢çš„å†…åœ¨å¤æ‚æ€§ï¼Œä¹Ÿä¼˜åŒ–å…¶åœ¨ç¨€ç–æ€§æ–¹é¢çš„å¤–åœ¨å¤æ‚æ€§ã€‚è¯¥ç›®æ ‡ç§°ä¸º `ç¨€ç–ç‡ä¸‹é™`ï¼ˆsparse rate reductionï¼‰ã€‚

ä¸ºäº†ä¼˜åŒ–è¿™ä¸ªç›®æ ‡ï¼Œæå‡ºå­¦ä¹ ä¸€ä¸ª**å¢é‡æ˜ å°„åºåˆ—**ï¼Œæ¨¡æ‹Ÿå±•å¼€ç›®æ ‡å‡½æ•°çš„æŸäº›ç±»ä¼¼æ¢¯åº¦ä¸‹é™çš„è¿­ä»£ä¼˜åŒ–æ–¹æ¡ˆã€‚è¿™å¾—åˆ°ä¸€ä¸ªç±»ä¼¼ Transformer çš„æ·±åº¦ç½‘ç»œæ¶æ„ï¼Œå¹¶ä¸”å®ƒå®Œå…¨æ˜¯ä¸€ä¸ªã€Œç™½ç›’ã€â€”â€” å…¶ä¼˜åŒ–ç›®æ ‡ã€ç½‘ç»œç®—å­å’Œå­¦ä¹ åˆ°çš„è¡¨å¾åœ¨æ•°å­¦ä¸Šæ˜¯å®Œå…¨å¯è§£é‡Šçš„ã€‚

è¿™ä¸ªç™½ç›’æ·±åº¦æ¶æ„å‘½åä¸º `CRATE` æˆ– `CRATE-Transformer`ï¼Œè¿™æ˜¯ `Coding-RATE transformer` çš„ç¼©å†™ã€‚è¿˜é€šè¿‡æ•°å­¦æ–¹å¼è¯æ˜è¿™äº›å¢é‡æ˜ å°„åœ¨åˆ†å¸ƒçš„æ„ä¹‰ä¸Šæ˜¯å¯é€†çš„ï¼Œå¹¶ä¸”å®ƒä»¬çš„é€†æ˜ å°„æœ¬è´¨ä¸Šç”±åŒä¸€ç±»æ•°å­¦ç®—å­æ„æˆã€‚

å› æ­¤ï¼Œå¯ä»¥å°†å‡ ä¹å®Œå…¨ä¸€æ ·çš„ CRATE æ¶æ„ç”¨äºç¼–ç å™¨ã€è§£ç å™¨æˆ–è‡ªåŠ¨ç¼–ç å™¨ã€‚

## æ¨¡å‹ç»“æ„

å¦‚æœè¯´ RetNet æ˜¯ä»**å¹³è¡Œæ¨ç†æ•ˆèƒ½**çš„è§’åº¦é©æ–°äº†ç½‘ç»œæ¶æ„ï¼Œé‚£ä¹ˆ BitNet åˆ™ä»æ­£äº¤è§’åº¦æå‡äº†æ¨ç†æ•ˆç‡ã€‚

è¿™ä¸¤è€…çš„ç»“åˆï¼Œä»¥åŠèåˆå…¶ä»–æå‡æ¨¡å‹æ•ˆç‡çš„æŠ€æœ¯æ¯”å¦‚æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å’Œç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSparse Attentionï¼‰ï¼Œå°†æˆä¸ºæœªæ¥åŸºç¡€æ¨¡å‹ç½‘ç»œæ¶æ„çš„åŸºç¡€ã€‚


### RetNet

ã€2023-9-18ã€‘[RetNetï¼šä¸‡ä¼—æœŸå¾…çš„ Transformers æ€æ‰‹](https://mp.weixin.qq.com/s/HhRtxONjzkoOmSRqixX50g), [å¤´æ¡](https://www.toutiao.com/article/7304956621552501285/)

å¾®è½¯çš„ RetNet ä½äºè¿™ä¸ªâ€œ`impossible triangle`â€çš„æ­£ä¸­å¿ƒï¼Œèƒœè¿‡äº†æ‰€æœ‰å°è¯•è¿‡ä½†æœªèƒ½å®ç°è¿™ä¸€å£®ä¸¾çš„æ–¹æ³•ã€‚RetNet è®¾æ³•åœ¨å•ä¸ªæ¡†æ¶ä¸‹å®ç°æ‰€æœ‰å±æ€§ã€‚

çªç ´ï¼š
- RetNet å…·æœ‰æ›´å¥½çš„è¯­è¨€å»ºæ¨¡æ€§èƒ½
- RetNet å†…å­˜æ¶ˆè€—é™ä½äº† 3.4 å€
- â€¦.8.4 å€æ›´é«˜çš„ååé‡
- â€¦å»¶è¿Ÿé™ä½ 15.6 å€

è¿™é€Ÿåº¦æ¯”å½“å‰çš„ SOTA å¿«**å‡ ä¸ªæ•°é‡çº§**ï¼ŒåŒæ—¶è¿˜æä¾›æ›´å¥½çš„æ€§èƒ½ï¼å¦‚æœå…¶ä»–å›¢é˜Ÿèƒ½å¤Ÿå¤åˆ¶è¿™ä¸€ç‚¹å¹¶ä¸”è¿›å…¥å¼€æºé¢†åŸŸï¼Œè¿™å°†æ˜¯å·¨å¤§çš„è¿›æ­¥ï¼Œä½†ç›®å‰å¾®è½¯ç»å¯¹æ˜¯ã€Œé¥é¥é¢†å…ˆã€

RetNetçš„ä¸»è¦è´¡çŒ®å¯ä»¥æ¦‚æ‹¬ä¸ºä¸¤å¤§ç‚¹
- RetNetå¼•å…¥**å¤šå°ºåº¦ä¿ç•™æœºåˆ¶**æ¥æ›¿ä»£**å¤šå¤´æ³¨æ„åŠ›**ã€‚è¿™æ˜¯æ¶ˆé™¤è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„é­”é¬¼è¿™ä¸€ç»„æˆéƒ¨åˆ†çš„å…³é”®ã€‚å°½ç®¡å¦‚æ­¤ï¼Œè¿™ç§ä¿ç•™æœºåˆ¶æœ‰ä¸€ä¸ªå°å°çš„ç†è®ºä¸Šçš„ç¼ºç‚¹ã€‚
- RetNet é€‚ç”¨äºä¸‰ç§è®¡ç®—èŒƒå¼ï¼Œè€Œåªæœ‰ä¸€ç§ Transformer åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨ç›¸åŒçš„åºåˆ—å¤„ç†èŒƒå¼ã€‚
  - A. **å¹¶è¡Œ**è¡¨ç¤ºä½¿è®­ç»ƒå¹¶è¡Œæ€§èƒ½å¤Ÿå……åˆ†åˆ©ç”¨ GPU è®¾å¤‡ã€‚
  - B. **å¾ªç¯**è¡¨ç¤ºåœ¨å†…å­˜å’Œè®¡ç®—æ–¹é¢å¯å®ç°é«˜æ•ˆçš„ O(1) æ¨ç†ã€‚å¯ä»¥æ˜¾ç€é™ä½éƒ¨ç½²æˆæœ¬å’Œå»¶è¿Ÿã€‚æ­¤å¤–ï¼Œåœ¨æ²¡æœ‰é”®å€¼ç¼“å­˜æŠ€å·§çš„æƒ…å†µä¸‹ï¼Œå®ç°ä¹Ÿå¾—åˆ°äº†æå¤§çš„ç®€åŒ–ã€‚
  - C. **åˆ†å—å¾ªç¯**è¡¨ç¤ºå¯ä»¥æ‰§è¡Œæœ‰æ•ˆçš„é•¿åºåˆ—å»ºæ¨¡ã€‚å¯¹æ¯ä¸ªæœ¬åœ°å—è¿›è¡Œå¹¶è¡Œç¼–ç ä»¥æé«˜è®¡ç®—é€Ÿåº¦ï¼ŒåŒæ—¶å¯¹å…¨å±€å—è¿›è¡Œå¾ªç¯ç¼–ç ä»¥èŠ‚çœ GPU å†…å­˜ã€‚

æ–°å‹åŸºç¡€ç½‘ç»œæ¶æ„ Retentive Networkï¼ˆ`RetNet`ï¼‰æˆåŠŸçªç ´äº†æ‰€è°“çš„â€œ`ä¸å¯èƒ½ä¸‰è§’`â€éš¾é¢˜ï¼Œå®ç°äº†`å¸•ç´¯æ‰˜`ï¼ˆParetoï¼‰ä¼˜åŒ–ã€‚
- RetNet åœ¨ä¿æŒè‰¯å¥½çš„æ‰©å±•æ€§èƒ½å’Œå¹¶è¡Œè®­ç»ƒçš„åŒæ—¶ï¼Œå®ç°äº†ä½æˆæœ¬éƒ¨ç½²å’Œé«˜æ•ˆç‡æ¨ç†ã€‚

RetNet æ¨ç†æˆæœ¬ä¸æ¨¡å‹åºåˆ—é•¿åº¦æ— å…³ï¼Œè¿™è¡¨ç¤ºæ— è®ºæ˜¯å¤„ç†é•¿æ–‡æœ¬åºåˆ—ï¼Œè¿˜æ˜¯é•¿å›¾åƒåºåˆ—ï¼Œäº¦æˆ–æ˜¯æœªæ¥æ›´é•¿çš„éŸ³è§†é¢‘åºåˆ—ï¼ŒRetNet éƒ½å¯ä»¥ä¿æŒç¨³å®šçš„é«˜æ•ˆæ¨ç†ã€‚


### å¾®è½¯ BitNet

ã€2024-2-29ã€‘[BitNet b1.58ï¼šå¼€å¯1-bitå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£](https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649498640&idx=1&sn=a860101ceee6bc3a777f465bdd1586da&chksm=82c7cd94b5b0448231f0017d2694e59f6e41369ea14a38a3a19a32a9ba18c3fe0f934e214bee&scene=21#wechat_redirect)

å¾®è½¯äºšæ´²ç ”ç©¶é™¢æ¨å‡ºäº† 1-bit LLM æ–°å˜ä½“ï¼š`BitNet b1.58`ã€‚
- è®ºæ–‡æ ‡é¢˜ï¼š[The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764.pdf)

è¯¥æ¨¡å‹æ¯ä¸ªå‚æ•°ä»…ä½¿ç”¨ä¸‰å€¼è¡¨ç¤ºï¼Œå³-1, 0 æˆ– 1ã€‚å› æ­¤ï¼Œåœ¨ LLM çš„çŸ©é˜µä¹˜æ³•æ“ä½œä¸­åªéœ€è¦æ•´æ•°åŠ æ³•ï¼Œè€Œä¸éœ€è¦ä»»ä½•æµ®ç‚¹æ•°ä¹˜æ³•æˆ–åŠ æ³•ã€‚åœ¨è¯­è¨€æ¨¡å‹å›°æƒ‘åº¦å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„è¯„ä¼°ä¸­
- BitNet b1.58 èƒ½å¤Ÿä¸å…·æœ‰ç›¸åŒå‚æ•°é‡å’Œè®­ç»ƒæ•°æ®é‡çš„å…¨ç²¾åº¦ï¼ˆå³FP16æˆ–BF16ï¼‰Transformer LLM ç›¸åŒ¹æ•Œã€‚
- ä¸æ­¤åŒæ—¶ï¼Œå®ƒåœ¨é€Ÿåº¦ã€å†…å­˜ä½¿ç”¨ã€ååé‡å’Œèƒ½è€—ç­‰æ–¹é¢å…·æœ‰å¤§å¹…ä¼˜åŠ¿ã€‚

BitNet b1.58 ä¸ºè®­ç»ƒæ–°ä¸€ä»£é«˜æ€§èƒ½é«˜æ•ˆç‡çš„ LLMs ç¡®ç«‹äº†æ–°çš„**æ‰©å±•å®šå¾‹**ï¼ˆscaling lawï¼‰å’Œæ–¹æ³•ã€‚æ­¤å¤–å¼•é¢†äº†ä¸€ç§å…¨æ–°çš„è®¡ç®—èŒƒå¼ï¼Œå¹¶ä¸ºå¼€å‘ä¸“ä¸º 1-bit LLMs ä¼˜åŒ–çš„ç¡¬ä»¶è®¾å¤‡é“ºå¹³äº†é“è·¯ã€‚

BitNet æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒè®­ç»ƒ1æ¯”ç‰¹å¤§è¯­è¨€æ¨¡å‹çš„æ–°å‹ç½‘ç»œç»“æ„ï¼Œå…·æœ‰å¼ºå¤§çš„å¯æ‰©å±•æ€§å’Œç¨³å®šæ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—å‡å°‘å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æˆæœ¬ã€‚

ä¸æœ€å…ˆè¿›çš„8æ¯”ç‰¹é‡åŒ–æ–¹æ³•å’Œå…¨ç²¾åº¦ Transformer åŸºçº¿ç›¸æ¯”ï¼ŒBitNet åœ¨å¤§å¹…é™ä½å†…å­˜å ç”¨å’Œè®¡ç®—èƒ½è€—çš„åŒæ—¶ï¼Œè¡¨ç°å‡ºäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚

æ­¤å¤–ï¼ŒBitNet æ‹¥æœ‰ä¸å…¨ç²¾åº¦ Transformer ç›¸ä¼¼çš„**è§„æ¨¡æ³•åˆ™**ï¼ˆScaling Lawï¼‰ï¼Œåœ¨ä¿æŒæ•ˆç‡å’Œæ€§èƒ½ä¼˜åŠ¿çš„åŒæ—¶ï¼Œè¿˜å¯ä»¥æ›´åŠ é«˜æ•ˆåœ°å°†å…¶èƒ½åŠ›æ‰©å±•åˆ°æ›´å¤§çš„è¯­è¨€æ¨¡å‹ä¸Šï¼Œä»è€Œè®©1æ¯”ç‰¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆ1-bit LLMï¼‰æˆä¸ºå¯èƒ½ã€‚

### å¾®è½¯ YOCO

ã€2024-5-13ã€‘[YOCOï¼šæ‰“ç ´ä¼ ç»ŸDecoder-onlyæ¶æ„ï¼Œå†…å­˜æ¶ˆè€—ä»…ä¸ºTransformerçš„å…­åˆ†ä¹‹ä¸€](https://mp.weixin.qq.com/s/X4HSyEreN4L4xTizC-_mow)

æ¨¡å‹æ¶æ„è¿˜åªæœ‰ä¸‰å¤§ç±»ï¼šDecoder-Onlyã€Encoder-Onlyã€Encoder-Decoderã€‚

å¾®è½¯äºšæ´²ç ”ç©¶é™¢æ¨å‡ºäº†ä¸€ç§åˆ›æ–°æ€§çš„ Decoder-Decoder æ¶æ„ `YOCO`ï¼ˆYou Only Cache Onceï¼‰ã€‚é€šè¿‡**è‡ªè§£ç å™¨**å’Œ**äº¤å‰è§£ç å™¨**çš„ç‹¬ç‰¹æ¶æ„ï¼ŒYOCO ä»…éœ€ç¼“å­˜ä¸€æ¬¡é”®å€¼å¯¹ï¼Œä»è€Œæ˜¾è‘—é™ä½ GPU å†…å­˜çš„ä½¿ç”¨ã€‚
- è®ºæ–‡ [You Only Cache Once: Decoder-Decoder Architectures for Language Models](https://arxiv.org/abs/2405.05254)

æ¨¡å‹è¯„ä¼°ä¸­ï¼ŒYOCO å±•ç°å‡ºä¸åŒè§„æ¨¡ Transformer æ¨¡å‹ç›¸åª²ç¾çš„æ€§èƒ½ï¼Œå¹¶åœ¨è¯­è¨€å»ºæ¨¡è¯„ä¼°ã€æ¨¡å‹å¤§å°æ‰©å±•ä»¥åŠé•¿ä¸Šä¸‹æ–‡å¤„ç†æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ç‰¹åˆ«æ˜¯åœ¨é™ä½ GPU å†…å­˜å ç”¨å’Œç¼©çŸ­é¢„å¡«å……å»¶è¿Ÿæ–¹é¢ï¼Œ

YOCO æ•´ä½“æ¶æ„è®¾è®¡å¦‚ä¸‹ï¼Œåˆ†ä¸º`è‡ªè§£ç å™¨`ï¼ˆSelf-Decoderï¼‰å’Œ`äº¤å‰è§£ç å™¨`ï¼ˆCross-Decoderï¼‰ä¸¤éƒ¨åˆ†ã€‚

YOCO å®ç°äº†â€œ**æ¨¡å‹è¶Šå¤§ï¼Œå†…å­˜è¶Šçœ**â€ï¼Œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå¸¦æ¥äº†å…¨æ–°çš„ç ”ç©¶å’Œåº”ç”¨èŒƒå¼ã€‚
- YOCO ä»…ç¼“å­˜ä¸€æ¬¡é”®å€¼å¯¹ï¼Œå¯å¤§å¹…é™ä½ GPU å†…å­˜éœ€æ±‚ï¼Œä¸”ä¿ç•™å…¨å±€æ³¨æ„åŠ›èƒ½åŠ›ã€‚

æ‰“ç ´ GPT ç³»åˆ—å¼€åˆ›çš„ `Decoder-Only` æ¶æ„â€”â€”æå‡º `Decoder-Decoder` æ–°å‹æ¶æ„ï¼Œåä¸º `YOCO` (You Only Cache Once)ã€‚
- åœ¨å¤„ç† 512K ä¸Šä¸‹æ–‡é•¿åº¦æ—¶ï¼Œæ ‡å‡† Transformer å†…å­˜ä½¿ç”¨æ˜¯ YOCO çš„6.4å€ï¼Œé¢„å¡«å……å»¶è¿Ÿæ˜¯ YOCO çš„30.3å€ï¼Œè€Œ YOCO çš„ååé‡æå‡åˆ°æ ‡å‡† Transformer çš„9.6å€ã€‚


## ä½ç½®ç¼–ç æ–¹å¼



### 2021.3.23 Roformer

ã€2021-3-23ã€‘Rotary Transformerï¼Œç®€ç§° `RoFormer`ï¼Œæ˜¯è¿½ä¸€ç§‘æŠ€`è‹å‰‘æ—`è‡ªç ”çš„è¯­è¨€æ¨¡å‹ä¹‹ä¸€ï¼Œä¸»è¦æ˜¯ä¸ºTransformerç»“æ„è®¾è®¡äº†æ–°çš„`æ—‹è½¬å¼ä½ç½®ç¼–ç `ï¼ˆRotary Position Embeddingï¼Œ`RoPE`ï¼‰ã€‚
- `RoPE`å…·æœ‰è‰¯å¥½çš„ç†è®ºæ€§è´¨ï¼Œä¸”æ˜¯ç›®å‰**å”¯ä¸€**ä¸€ç§ç”¨åˆ°çº¿æ€§Attentionçš„ç»å¯¹ä½ç½®ç¼–ç ï¼Œç›®å‰æ¥çœ‹å®éªŒç»“æœä¹Ÿé¢‡ä¸ºä¸é”™ã€‚
- å‚è€ƒé…ç½®ï¼šåœ¨24Gæ˜¾å­˜çš„3090ä¸Šï¼Œè·‘maxlen=1024ï¼Œbatch_sizeèƒ½è·‘åˆ°8ä»¥ä¸Šã€‚

è¯¦ç»†ä»‹ç»ï¼š
- [Transformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç ](https://kexue.fm/archives/8265)

ä½¿ç”¨

- [pytorchç‰ˆæœ¬](https://github.com/JunnYu/RoFormer_pytorch)
- huggingface [roformer](https://huggingface.co/docs/transformers/model_doc/roformer)

```py
from transformers import RoFormerTokenizerFast

tokenizer = RoFormerTokenizerFast.from_pretrained("junnyu/roformer_chinese_base")
tokenizer.tokenize("ä»Šå¤©å¤©æ°”éå¸¸å¥½ã€‚")
```


## æ£€ç´¢å¢å¼º

å¢å¤§æ¨¡å‹å¹¶ä¸æ˜¯æå‡æ€§èƒ½çš„å”¯ä¸€è·¯å¾„ï¼Œç”¨ä¸€ç§æœç´¢/æŸ¥è¯¢ä¿¡æ¯çš„æ–¹å¼æ¥å¢å¼ºæ¨¡å‹ï¼Œå°çš„ç”Ÿæˆè¯­è¨€æ¨¡å‹ä¹Ÿèƒ½è¾¾åˆ°ä¹‹å‰å¤§æ¨¡å‹æ‰èƒ½è¾¾åˆ°çš„æ€§èƒ½ã€‚

è¯­è¨€æ¨¡å‹çš„ä»»åŠ¡æ˜¯åš**å¡«ç©ºé¢˜**ï¼Œè¿™å¯¹äºè¯­è¨€ä¿¡æ¯æœ‰æ„ä¹‰ï¼Œä½†æ˜¯å¯¹äºäº‹å®ä¿¡æ¯å’Œä¸–ç•ŒçŸ¥è¯†ä¿¡æ¯æ˜¯æ— æ•ˆçš„ã€‚
- æœ‰æ—¶éœ€è¦ä¸äº‹å®æœ‰å…³çš„ä¿¡æ¯

ä»£è¡¨
- DeepMind çš„ RETRO Transformer
  - DeepMind çš„ RETROï¼ˆRetrieval-Enhanced TRansfOrmerï¼‰æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä¸ GPT-3 æ€§èƒ½ç›¸å½“ï¼Œä½†å‚æ•°é‡ä»…ä¸º GPT-3 çš„ 4%ã€‚
- OpenAI çš„ WebGPT


### 2021.12.16 WebGPT

OpenAI æ¨å‡º WebGPT, è§£å†³ long-form quesion-answering (LFQA) çš„æ–¹æ¡ˆ, å¼€æ”¾åŸŸQAå›å¤æ›´é•¿æ›´å¯é ã€‚
- [WebGPT: Improving the factual accuracy of language models through web browsing](https://openai.com/research/webgpt)
- [WebGPTç®€è¯»](https://zhuanlan.zhihu.com/p/591565418)
- æ¯” InstructGPT æå‡ºç¨æ—©ä¸€äº›

WebGPT æ€è·¯ç±»ä¼¼ Knowledge-Grounded Conversationï¼Œåˆ©ç”¨æœç´¢å¼•æ“åšç›¸å…³æ–‡æ¡£æ£€ç´¢ï¼Œä»è€Œç”Ÿæˆæ›´é•¿çš„ç­”æ¡ˆã€‚ä¸»è¦çš„ä¸¤ä¸ªè´¡çŒ®ï¼š
- å¾®è°ƒçš„è¯­è¨€æ¨¡å‹å¯ä»¥ä¸ä¸€ä¸ªåŸºäºæ–‡æœ¬çš„Webæµè§ˆç¯å¢ƒäº¤äº’ï¼Œä»è€Œå¯ä»¥ç«¯åˆ°ç«¯åœ°ä½¿ç”¨æ¨¡ä»¿å’Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ£€ç´¢å’Œèšåˆæ•ˆæœã€‚
- å‚è€ƒWebæ£€ç´¢å‡ºæ¥çš„ä¿¡æ¯ç”Ÿæˆå›å¤ã€‚labelerå¯ä»¥æ ¹æ®æ£€ç´¢å‡ºæ¥çš„ä¿¡æ¯åˆ¤æ–­factualå‡†ç¡®ç‡ï¼Œé™ä½äº†ç‹¬ç«‹è°ƒç ”é—®é¢˜æ­£ç¡®æ€§çš„éš¾åº¦ã€‚

è¿™ä¸ªæƒ³æ³•å¹¶é WebGPTé¦–æ¬¡æå‡º
- 2021å¹´åˆ, Facebook (FAIR) å°±æå‡ºä½¿ç”¨æœç´¢å¼•æ“æ¥æå‡å¯¹è¯å›å¤çš„è´¨é‡ï¼šACL2022 [Internet-Augmented Dialogue Generation](https://aclanthology.org/2022.acl-long.579/)

WebGPT æ€è·¯æ›´è¿›ä¸€æ­¥ï¼Œå®Œå…¨æ¨¡æ‹Ÿäº†äººä½¿ç”¨æœç´¢å¼•æ“çš„æ–¹æ³•(æœ‰æ›´å¤šaction: æœç´¢ã€ç‚¹å‡»ã€ç¿»é¡µã€å›é€€ç­‰ç­‰)ï¼Œè€Œéä»…ç”Ÿæˆsearch queryå¹¶ä½¿ç”¨å…¶ç»“æœã€‚

### 2022.2.7 RETRO

DeepMind æ¨å‡º RETRO, æ•´åˆäº†ä»æ•°æ®åº“ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œå°†å…¶å‚æ•°ä»æ˜‚è´µçš„äº‹å®å’Œä¸–ç•ŒçŸ¥è¯†å­˜å‚¨ä¸­è§£æ”¾å‡ºæ¥ã€‚
- è®ºæ–‡: [Improving language models by retrieving from trillions of tokens](https://arxiv.org/pdf/2112.04426.pdf)
- [illustrated-retrieval-transformer](http://jalammar.github.io/illustrated-retrieval-transformer)
- ã€2022-1-4ã€‘[å‚æ•°é‡ä»…ä¸º4%ï¼Œæ€§èƒ½åª²ç¾GPT-3ï¼šå¼€å‘è€…å›¾è§£DeepMindçš„RETRO](https://www.jiqizhixin.com/articles/2022-01-04-8)

åŠ å…¥æ£€ç´¢æ–¹æ³•ä¹‹åï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥ç¼©å°å¾ˆå¤šã€‚
- ç¥ç»æ•°æ®åº“å¯ä»¥å¸®åŠ©æ¨¡å‹æ£€ç´¢å®ƒéœ€è¦çš„äº‹å®ä¿¡æ¯ã€‚
- ![](https://image.jiqizhixin.com/uploads/editor/ffbea1f3-54eb-411d-a9a9-3c0912dfef3c/1641280248346.png)

#### æ¨¡å‹ç»“æ„

ç»“æ„
- RETRO æ˜¯ **ç¼–ç å™¨ - è§£ç å™¨**æ¨¡å‹ï¼ŒåƒåŸå§‹çš„ Transformerã€‚
- ç„¶è€Œåœ¨æ£€ç´¢æ•°æ®åº“çš„å¸®åŠ©ä¸‹å¢åŠ äº†**è¾“å…¥åºåˆ—**ã€‚
- è¯¥æ¨¡å‹åœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°æœ€å¯èƒ½çš„åºåˆ—ï¼Œå¹¶æ·»åŠ åˆ°è¾“å…¥ä¸­ã€‚
- RETRO åˆ©ç”¨å®ƒçš„é­”åŠ›ç”Ÿæˆè¾“å‡ºé¢„æµ‹ã€‚
- ![](https://image.jiqizhixin.com/uploads/editor/96d18172-b521-4ed5-a913-a00440b05625/1641280241153.png)


#### RETRO æ£€ç´¢æ•°æ®åº“

è¿™é‡Œçš„æ•°æ®åº“æ˜¯ä¸€ä¸ª**é”®å€¼å­˜å‚¨**ï¼ˆkey-value storeï¼‰æ•°æ®åº“ã€‚
- key æ˜¯æ ‡å‡†çš„ **BERT å¥å­åµŒå…¥**ï¼Œvalue æ˜¯ç”±ä¸¤éƒ¨åˆ†ç»„æˆçš„**æ–‡æœ¬**ï¼š
- Neighborï¼Œç”¨äºè®¡ç®— keyï¼›
- Completionï¼ŒåŸæ–‡ä»¶ä¸­æ–‡æœ¬çš„å»¶ç»­ã€‚

RETRO æ•°æ®åº“åŒ…å«åŸºäº MassiveText æ•°æ®é›†çš„ 2 ä¸‡äº¿ä¸ªå¤šè¯­è¨€ tokenã€‚neighbor chunk å’Œ completion chunk çš„é•¿åº¦æœ€å¤šä¸º 64 ä¸ª tokenã€‚
- ![](https://image.jiqizhixin.com/uploads/editor/713760aa-cf75-4bc7-8116-e308ce3b8b83/1641280228557.png)

#### æ•°æ®åº“æŸ¥æ‰¾

è¿›å…¥ RETRO å‰
- è¾“å…¥æç¤ºè¿›å…¥ BERTã€‚å¯¹è¾“å‡ºçš„ä¸Šä¸‹æ–‡å‘é‡è¿›è¡Œ**å¹³å‡**ä»¥æ„å»ºå¥å­åµŒå…¥å‘é‡ã€‚
  - ![](https://image.jiqizhixin.com/uploads/editor/3e8b9491-570a-4280-b36a-e68a6d0fff7c/1641280220663.png)
- ç„¶åï¼Œä½¿ç”¨è¯¥å‘é‡æŸ¥è¯¢æ•°æ®åº“ã€‚è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ã€‚æ£€ç´¢ä¸¤ä¸ªæœ€è¿‘é‚»
  - ![](https://image.jiqizhixin.com/uploads/editor/aac2a845-a303-415b-b582-7b55402db078/1641280209906.png)
- å°†è¿™äº›æ·»åŠ åˆ°è¯­è¨€æ¨¡å‹çš„è¾“å…¥ä¸­
  - æ£€ç´¢å‡ºçš„æ–‡æœ¬æˆä¸º RETRO è¾“å…¥çš„ä¸€éƒ¨åˆ†ï¼ŒTransformer å’Œ RETRO å—å°†ä¿¡æ¯åˆå¹¶åˆ°å®ƒä»¬çš„å¤„ç†ä¸­
  - ![](https://image.jiqizhixin.com/uploads/editor/ff98762d-0d34-4771-8753-56d6b7762648/1641280203796.png)


#### é«˜å±‚æ¬¡çš„ RETRO æ¶æ„

RETRO æ¶æ„ç”±ä¸€ä¸ª**ç¼–ç å™¨**å †æ ˆå’Œä¸€ä¸ª**è§£ç å™¨**å †æ ˆç»„æˆã€‚
- ç¼–ç å™¨ç”±æ ‡å‡†çš„ Transformer ç¼–ç å™¨å—ï¼ˆself-attention + FFNNï¼‰ç»„æˆã€‚Retro ä½¿ç”¨ç”±ä¸¤ä¸ª Transformer ç¼–ç å™¨å—ç»„æˆçš„ç¼–ç å™¨ã€‚
  - ç¼–ç å™¨å †æ ˆä¼šå¤„ç†æ£€ç´¢åˆ°çš„è¿‘é‚»ï¼Œç”Ÿæˆåç»­å°†ç”¨äºæ³¨æ„åŠ›çš„ KEYS å’Œ VALUES çŸ©é˜µ
- è§£ç å™¨å †æ ˆåŒ…å«äº†ä¸¤ç§è§£ç å™¨ blockï¼š
  - æ ‡å‡† Transformer è§£ç å™¨å—ï¼ˆATTN + FFNNï¼‰
  - RETRO è§£ç å™¨å—ï¼ˆATTN + Chunked cross attention (CCA) + FFNNï¼‰
- è§£ç å™¨ block åƒ GPT ä¸€æ ·å¤„ç†è¾“å…¥æ–‡æœ¬ã€‚å¯¹æç¤º token åº”ç”¨è‡ªæ³¨æ„åŠ›ï¼ˆå› æ­¤åªå…³æ³¨ä¹‹å‰çš„ tokenï¼‰ï¼Œç„¶åé€šè¿‡ FFNN å±‚ã€‚åªæœ‰åˆ°è¾¾ RETRO è§£ç å™¨æ—¶ï¼Œå®ƒæ‰å¼€å§‹åˆå¹¶æ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚ä» 9 å¼€å§‹çš„æ¯ä¸ªç¬¬ä¸‰ä¸ª block æ˜¯ä¸€ä¸ª RETRO blockï¼ˆå…è®¸å…¶è¾“å…¥å…³æ³¨è¿‘é‚»ï¼‰ã€‚æ‰€ä»¥ç¬¬ 9ã€12ã€15â€¦32 å±‚æ˜¯ RETRO blockã€‚
- ![](https://image.jiqizhixin.com/uploads/editor/5103886f-035d-4506-9e03-32b9ec93259b/1641280193608.png)
- ![](https://image.jiqizhixin.com/uploads/editor/305626c2-7918-419a-9e4c-5c8d7eaf0e60/1641280182910.png)




## è¾“å…¥è¾“å‡º æ”¹è¿›


è¾“å…¥é•¿åº¦æ”¹è¿›

### 2023.7.8 LongNet

ã€2023-7-8ã€‘[1000000000ï¼å¾®è½¯æ”¹è¿›Transformerä¸€æ¬¡èƒ½è®°ä½è¿™ä¹ˆå¤štokenäº†](https://mp.weixin.qq.com/s/PKKC4lMdSTg-ButNnZHLlw)
- æœ€å¼ºçš„GPT-4ä¹Ÿæ‰æœ€å¤§æ”¯æŒä¸€æ¬¡å¤„ç†32k tokenï¼Œç›¸å½“äº50é¡µæ–‡å­—ã€‚
- è€Œèƒ½å¤Ÿåªç”¨1åˆ†é’Ÿçœ‹å®Œä¸€æœ¬æ•°ä¸‡å­—å°è¯´çš„Claudeï¼Œå…¶tokenæ•°ä¹Ÿä¸è¿‡â€œæ‰â€100kï¼ˆ10ä¸‡ï¼‰ã€‚

ä¸€æ¬¡æ€§æ‰©å±•åˆ°10äº¿ï¼Œå¹¶ä¸”è¿™ä¸ªæ•°å­—ç†è®ºä¸Šå…¶å®è¿˜æ˜¯æ— é™çš„ï¼Œè¿™ä¸å°±æ„å‘³ç€ï¼šä¸ä¹…çš„å°†æ¥ï¼Œæ•´ä¸ªè¯­æ–™åº“ç”šè‡³äº’è”ç½‘éƒ½èƒ½è§†ä¸ºä¸€ä¸ªåºåˆ—ï¼Ÿ

ä½œè€…æå‡ºä¸€ä¸ªTransformerå˜ä½“ï¼š`LongNet`ï¼Œå®ƒåº”ç”¨äº†ä¸€ç§å«åšâ€œ**è†¨èƒ€æ³¨æ„åŠ›**ï¼ˆdilated attentionï¼‰â€çš„æœºåˆ¶ï¼Œå¯ä»¥éšç€è·ç¦»çš„å¢é•¿ï¼Œè®©æ³¨æ„åŠ›åœºï¼ˆæ¨¡å‹æ„ŸçŸ¥èŒƒå›´ï¼‰å‘ˆæŒ‡æ•°çº§æ‰©å±•ã€‚

å…·ä½“è€Œè¨€ï¼Œdilated attentionæ›¿ä»£äº†æ™®é€šTransformerä¸­çš„æ³¨æ„åŠ›æœºåˆ¶çš„ï¼Œå…¶ä¸€èˆ¬çš„è®¾è®¡åŸåˆ™æ˜¯ï¼š
> è®©æ³¨æ„åŠ›çš„åˆ†é…éšç€tokenä¹‹é—´è·ç¦»çš„å¢é•¿ï¼Œå‘ˆæŒ‡æ•°çº§ä¸‹é™ã€‚

dilated attentionèƒ½å¤Ÿäº§ç”Ÿçº¿æ€§è®¡ç®—å¤æ‚åº¦å’Œtokenä¹‹é—´çš„å¯¹æ•°ä¾èµ–æ€§ï¼Œä»è€Œè§£å†³äº†æ³¨æ„åŠ›èµ„æºæœ‰é™ï¼Œä½†æ¯ä¸€ä¸ªtokenéƒ½å¯è®¿é—®çš„çŸ›ç›¾ã€‚

## Attention æ”¹è¿›

### ç»„æ³¨æ„åŠ› Grouped-Query Attention

Grouped-Query Attention ï¼šå¯¹äºæ›´å¤§å‚æ•°é‡ã€æ›´å¤§çš„ context lengthã€æ›´å¤§çš„ batchsize æ¥è¯´ï¼ŒåŸå§‹çš„MHAï¼ˆmulti-head attentionï¼‰çš„å†…å­˜å ç”¨ä¼šæ›´é«˜ï¼ˆå› ä¸ºåœ¨è®¡ç®—æ—¶è¦ç¼“å­˜pre tokençš„Kã€VçŸ©é˜µï¼‰ã€‚
- MQAï¼ˆmulti-query attentionï¼‰è®©æ‰€æœ‰çš„ head å…±äº« 1 ä¸ª KV projection çŸ©é˜µï¼›
- GQAï¼ˆgrouped-query attention ï¼‰ä½¿ç”¨ 8 ä¸ª KV projectionsï¼ˆé€‰æ‹©8æ˜¯å› ä¸ºA100 8GPUsï¼‰ æ¥å‡å°‘å†…å­˜å ç”¨ã€‚

åœ¨ 30B æ¨¡å‹ä¸Šè®­ç»ƒ 150B tokensï¼Œå‘ç° GQA æ•ˆæœå’Œ MHA å·®ä¸å¤šï¼Œæ¯” MQA è¦å¥½ï¼›åœ¨ 1 ä¸ªnodeçš„ 8 ä¸ª A100 GPUs ä¸Šæ¨ç†é€Ÿåº¦ GQA å’Œ MQAå·®ä¸å¤šï¼Œæ¯” MHA è¦å¥½ï¼ˆMQA åœ¨æ¨ç†çš„æ—¶å€™ï¼Œè¦æŠŠ KV projections å¤åˆ¶åˆ°8å¼ å¡ä¸Šï¼‰ã€‚



### æ¨ç†åŠ é€Ÿ


#### èŠ¯ç‰‡

ã€2023-12-19ã€‘ç¾å›½èŠ¯ç‰‡åˆåˆ›å…¬å¸ [Etched AI](https://www.etched.ai/) å®£ç§°å¼€åˆ›äº†ä¸€é¡¹æ–°çš„æŠ€æœ¯ï¼Œå°† Transformer æ¶æ„ç›´æ¥â€œçƒ§å½•â€åˆ°äº†èŠ¯ç‰‡ä¸­ğŸ˜‚ï¼Œåˆ›é€ å‡ºäº†ä¸–ç•Œä¸Šæœ€å¼ºå¤§çš„ä¸“é—¨ç”¨äºTransformeræ¨ç†çš„æœåŠ¡å™¨ã€‚å¯ä»¥è¿è¡Œä¸‡äº¿å‚æ•°çš„æ¨¡å‹ï¼ğŸ¤” ç”©è‹±ä¼Ÿè¾¾iconå‡ ç™¾æ¡è¡—ğŸ¤“
- ![](https://assets-global.website-files.com/6570a6bdf377183fb173431e/6570b5e6b0cd5f0189cf79b8_hero.webp)

å°† Transformeræ¶æ„ç›´æ¥â€œçƒ§å½•â€åˆ°èŠ¯ç‰‡ä¸­ï¼Œè¿™æ„å‘³ç€Transformeræ¨¡å‹çš„æ¨ç†å¯ä»¥åœ¨ä¸“é—¨çš„ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œè€Œä¸éœ€è¦ä¾èµ–ä¼ ç»Ÿçš„CPUæˆ–GPUã€‚è¿™å°†å¤§å¤§æé«˜æ¨ç†é€Ÿåº¦ï¼Œé™ä½åŠŸè€—ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
- è§£ç é€Ÿåº¦è¿œè¶… A100, H100: NVIDIA A100(1x) < NVIDIA H100(5x) < Etched Sohu(15+x)

åŠŸèƒ½ï¼š
- â€¢ **å®æ—¶**è¯­éŸ³ä»£ç†ï¼šèƒ½å¤Ÿåœ¨æ¯«ç§’å†…å¤„ç†æˆåƒä¸Šä¸‡çš„è¯ã€‚
- â€¢ æ›´å¥½çš„ç¼–ç ä¸**æ ‘æœç´¢**ï¼šå¯ä»¥å¹¶è¡Œæ¯”è¾ƒæ•°ç™¾ä¸ªå“åº”ã€‚
- â€¢ å¤šæ’­æ¨æµ‹è§£ç ï¼šå®æ—¶ç”Ÿæˆæ–°å†…å®¹ã€‚
- â€¢ è¿è¡Œæœªæ¥çš„ä¸‡äº¿å‚æ•°æ¨¡å‹ï¼šåªéœ€ä¸€ä¸ªæ ¸å¿ƒï¼Œæ”¯æŒå…¨å¼€æºè½¯ä»¶æ ˆï¼Œå¯æ‰©å±•è‡³100Tå‚æ•°æ¨¡å‹ã€‚
- â€¢ é«˜çº§è§£ç æŠ€æœ¯ï¼šåŒ…æ‹¬å…‰æŸæœç´¢å’ŒMCTSè§£ç ã€‚
- â€¢ æ¯ä¸ªèŠ¯ç‰‡144 GB HBM3Eï¼šæ”¯æŒMoEå’Œè½¬æ¢å™¨å˜ä½“ã€‚

è¿™å¯¹äºè‹±ä¼Ÿè¾¾æ¥è¯´æ˜¯å·¨å¤§çš„æŒ‘æˆ˜ã€‚è‹±ä¼Ÿè¾¾ä¸€ç›´æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é¢†å¯¼è€…ä¹‹ä¸€ï¼Œå…¶GPUè¢«å¹¿æ³›åº”ç”¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†ã€‚ç„¶è€Œï¼ŒEtched AIçš„æŠ€æœ¯å¯èƒ½æ”¹å˜è¿™ä¸€æ ¼å±€ã€‚

è¯¦ç»†ï¼šiconetched.ai


### è®¡ç®—æ•ˆç‡

attention å­˜åœ¨ $n^2$ çš„è®¡ç®—å¤æ‚åº¦ï¼Œå¦‚ä½•å®ç°æ›´é•¿æ–‡æœ¬çš„è®¡ç®—ï¼Ÿ
- åŸºäºçŠ¶æ€è¿­ä»£: TransformerXL RMT
- åŸºäºä½ç½®ç¼–ç å¤–æ¨èƒ½åŠ›: ALiBi xPos Unlimiformer
- åŸºäºå·¥ç¨‹ä¼˜åŒ–: FlashAttention
- åŸºäºé«˜æ•ˆAttention: Reformer LinFormer Flash
- å…¶ä»–ï¼› S4, FLASH
- ![](https://pic3.zhimg.com/80/v2-fae510edc3aff2863cca31bc0dcd2046_1440w.webp)

#### 2023.6.14 FlashAttention

ã€2023-6-14ã€‘[FlashAttention: æ›´å¿«è®­ç»ƒæ›´é•¿ä¸Šä¸‹æ–‡çš„GPT](https://www.bilibili.com/video/BV1SW4y1X7kh)
- å°† transformer çš„ qkv è®¡ç®—åŠ é€Ÿï¼Œæ–¹æ³•ï¼šå‘é‡åˆ†å—å¹¶è¡Œ
- è§†é¢‘æœ‰ç‰¹æ•ˆã€‚
- [é£ä¹¦åˆé›†æ–‡æ¡£](https://bytedance.feishu.cn/docx/doxcn3zm448MK9sK6pHuPsqtH8f)
- [FlashAttention](https://readpaper.feishu.cn/docx/AC7JdtLrhoKpgxxSRM8cfUounsh)
- [GitHub CodeRepo](https://github.com/cauyxy/bilivideos/tree/master/flash-attn)

<iframe src="//player.bilibili.com/player.html?aid=954566955&bvid=BV1SW4y1X7kh&cid=1158494106&page=1&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"  height="600" width="100%" > </iframe>


#### 2023.6.24 PageAttention -- ç®¡ç†qkvç¼“å­˜

ã€2023-6-24ã€‘UC Berkeley å›¢é˜Ÿæ¨å‡ºä¸€ä¸ªç”¨äºåŠ é€ŸLLMæ¨ç†çš„å¼€æºåº“`vLLM`ï¼ŒVicunaåœ¨çº¿æ¨ç†æœåŠ¡çš„å¹•åè‹±é›„ã€‚
- åˆ©ç”¨PagedAttentionæŠ€æœ¯ï¼Œé€šè¿‡æœ‰æ•ˆåœ°ç®¡ç†Attentionæ¨¡å—ä¸­çš„Keyå’ŒValueçš„Cacheï¼Œé‡æ–°å®šä¹‰äº†LLMçš„æ¨ç†æœåŠ¡ã€‚æ— éœ€æ›´æ”¹ä»»ä½•æ¨¡å‹æ¶æ„ï¼Œå®ƒçš„ååé‡æ¯”åŸç”ŸHF Transformersé«˜å‡º**24å€**ã€‚

ç°æœ‰çš„Cacheä»å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œ
- Largeï¼šå¯¹äºLLaMA-13Bä¸­çš„å•ä¸ªåºåˆ—ï¼Œå®ƒå ç”¨é«˜è¾¾1.7GBçš„å†…å­˜ã€‚
- Dynamicï¼šå®ƒçš„å¤§å°å–å†³äºåºåˆ—é•¿åº¦ï¼Œè€Œåºåˆ—é•¿åº¦å…·æœ‰é«˜åº¦å¯å˜å’Œä¸å¯é¢„æµ‹çš„ç‰¹ç‚¹ã€‚

å› æ­¤ï¼Œé«˜æ•ˆåœ°ç®¡ç†KV Cacheæ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚
- ç°æœ‰ç³»ç»Ÿï¼ˆHuggingFace é»˜è®¤å®ç°æ˜¯pytorchçš„å†…å­˜åˆ†é…ç­–ç•¥ï¼‰ç”±äºå†…å­˜ç¢ç‰‡åŒ–å’Œè¿‡åº¦é¢„ç•™è€Œæµªè´¹äº†60%è‡³80%çš„å†…å­˜ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†PagedAttentionï¼Œä¸€ç§å—ä¼ ç»Ÿæ“ä½œç³»ç»Ÿ**è™šæ‹Ÿå†…å­˜**å’Œ**åˆ†é¡µ**æ¦‚å¿µå¯å‘çš„æ³¨æ„åŠ›ç®—æ³•ã€‚
- ä¸ä¼ ç»Ÿçš„æ³¨æ„åŠ›ç®—æ³•ä¸åŒï¼ŒPagedAttentionå…è®¸å°†**è¿ç»­çš„é”®å’Œå€¼å­˜å‚¨åœ¨éè¿ç»­çš„å†…å­˜ç©ºé—´**ä¸­ã€‚
- å…·ä½“è€Œè¨€ï¼ŒPagedAttentionå°†æ¯ä¸ªåºåˆ—çš„KVç¼“å­˜åˆ†æˆå¤šä¸ªå—ï¼Œæ¯ä¸ªå—åŒ…å«å›ºå®šæ•°é‡çš„æ ‡è®°çš„é”®å’Œå€¼ã€‚
- åœ¨æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹ä¸­ï¼ŒPagedAttention Kernelé«˜æ•ˆåœ°è¯†åˆ«å’Œè·å–è¿™äº›å—ï¼Œé‡‡ç”¨å¹¶è¡Œçš„æ–¹å¼åŠ é€Ÿè®¡ç®—ã€‚ï¼ˆå’ŒByteTransformerçš„æ€æƒ³æœ‰ç‚¹åƒï¼‰


#### 2023.7.4 FasterTransfomer

ã€2023-7-4ã€‘[FasterTransfomer](https://github.com/NVIDIA/FasterTransformer) æ˜¯ NVIDIA é«˜åº¦ä¼˜åŒ–çš„ Transformer æ¨¡å‹åº“ï¼Œåœ¨ç”Ÿæˆæ—¶è¾¾åˆ° **2.5å€**çš„é€Ÿåº¦ï¼Œè¯¦è§ [Inference with FasterTransformer](https://github.com/THUDM/GLM-130B/blob/main/docs/inference-with-fastertransformer.md) 



### Decoder æ•ˆç‡

#### Muti Query Attention (MQA)

MQA æ˜¯ 2019 å¹´æå‡ºçš„ä¸€ç§æ–°çš„ Attention æœºåˆ¶ï¼Œå…¶èƒ½å¤Ÿåœ¨ä¿è¯æ¨¡å‹æ•ˆæœçš„åŒæ—¶åŠ å¿« decoder ç”Ÿæˆ token çš„é€Ÿåº¦ã€‚
- è®ºæ–‡ï¼š [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/pdf/1911.02150.pdf)
- æ‰€æœ‰ head ä¹‹é—´å…±äº«ä¸€ä»½ key å’Œ value çš„å‚æ•°

MQA åœ¨ encoder ä¸Šçš„æé€Ÿæ²¡æœ‰éå¸¸æ˜æ˜¾ï¼Œä½†åœ¨ decoder ä¸Šçš„æé€Ÿæ˜¯å¾ˆæ˜¾è‘—çš„
- ![](https://pic1.zhimg.com/80/v2-150a48c2eadeacd0aca50408ea391710_1440w.webp)

Multi Query Attentionï¼ˆMQAï¼‰ å’Œ Multi Head Attentionï¼ˆMHAï¼‰åªå·®äº†ä¸€ä¸ªå•è¯ï¼Œä»ã€ŒHeadã€å˜æˆäº†ã€ŒQueryã€ã€‚

MQA è®©**æ‰€æœ‰çš„å¤´ä¹‹é—´ å…±äº« åŒä¸€ä»½ Key å’Œ Value çŸ©é˜µ**ï¼Œæ¯ä¸ªå¤´åªå•ç‹¬ä¿ç•™äº†ä¸€ä»½ Query å‚æ•°ï¼Œä»è€Œå¤§å¤§å‡å°‘ Key å’Œ Value çŸ©é˜µçš„å‚æ•°é‡ã€‚
- ã€Œå‚æ•°å…±äº«ã€å¹¶ä¸æ˜¯æ–°å¥‡æ€è·¯ï¼ŒAlbert é€šè¿‡ä½¿ç”¨**è·¨å±‚å…±äº«å‚æ•°**ï¼ˆCross-layer parameter sharingï¼‰æ–¹å¼æ¥å¤§å¤§å‡å°‘ bert çš„å‚æ•°é‡
- MQA å®é™…ä¸Šæ˜¯å°† head ä¸­çš„ key å’Œ value çŸ©é˜µæŠ½å‡ºæ¥å•ç‹¬å­˜ä¸ºä¸€ä»½å…±äº«å‚æ•°ï¼Œè€Œ query åˆ™æ˜¯ä¾æ—§ä¿ç•™åœ¨åŸæ¥çš„ head ä¸­ï¼Œæ¯ä¸ª head æœ‰ä¸€ä»½è‡ªå·±ç‹¬æœ‰çš„ query å‚æ•°ã€‚

ä»£ç è§[åŸæ–‡](https://zhuanlan.zhihu.com/p/634236135)

### é•¿åº¦é™åˆ¶

æ–‡æœ¬é•¿åº¦ä¸€ç›´æ˜¯ transformer çš„ç¡¬ä¼¤ã€‚
- ä¸åŒäº RNNï¼Œtransformer åœ¨è®­ç»ƒæ—¶å¿…é¡»å¡åœ¨ä¸€ä¸ª**æœ€å¤§é•¿åº¦**ä¸Šï¼Œè¿™å°†å¯¼è‡´è®­ç»ƒå¥½çš„æ¨¡å‹æ— æ³•åœ¨ä¸€ä¸ªä¸è®­ç»ƒæ—¶çš„é•¿åº¦ç›¸å·®è¾ƒè¿œçš„å¥å­ä¸Šå–å¾—è¾ƒå¥½çš„æ¨ç†ç»“æœã€‚

Transformer ä¸­ï¼Œç”±äº token å’Œ token ä¹‹é—´æ˜¯æ²¡æœ‰é¡ºåºä¹‹åˆ†çš„. å› æ­¤ï¼Œé€šå¸¸åœ¨è¾“å…¥æ·»åŠ  Position Embedding æ¥è¡¨å¾æ¯ä¸€ä¸ª token åœ¨å¥å­ä¸­çš„ä½ç½®ã€‚

Position Embedding çš„å¦‚ä½•é€‰æ‹©å®åœ¨æ˜¯ä¸€ä¸ªéš¾é¢˜ï¼Œé€šå¸¸æœ‰ä»¥ä¸‹å‡ ç§ï¼š
- å¯å­¦ä¹ çš„å‚æ•°ï¼šè¿™ç§æ¯”è¾ƒå¸¸è§ï¼ŒBRET ä¸­å°±æ˜¯è¿™ä¹ˆåšçš„ï¼Œä½†è¿™ç§æ–¹å¼å¼Šç«¯å¾ˆæ˜æ˜¾ï¼Œå› ä¸ºä½ç½®ä¿¡æ¯æ˜¯å­¦ä¹ å‡ºæ¥çš„ï¼Œæ‰€ä»¥å¦‚æœè®­ç»ƒé›†é‡Œé¢æ²¡æœ‰è§è¿‡è¦†ç›–æŸä¸ªé•¿åº¦ï¼Œæ¨ç†çš„æ•ˆæœå°±æ— æ³•å¾—åˆ°ä¿è¯ã€‚
- æ­£å¼¦ä½ç½®ç¼–ç ï¼šè¿™æ˜¯æ—©æœŸ transformer ä½¿ç”¨çš„ä½ç½®ç¼–ç ï¼Œè®ºæ–‡ä¸­æœ‰å°è¯•åšå®éªŒï¼Œè¿™ç§ç¼–ç ä¼šéšç€è®­ç»ƒ/é¢„æµ‹æ—¶çš„æ–‡æœ¬é•¿åº¦å·®å¼‚å¢å¤§ï¼Œï¼ˆè¶…è¿‡ 50 ä¸ªtoken åï¼‰æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚
- æ—‹è½¬ç¼–ç ï¼šè®ºæ–‡ä¸­æåˆ°è¿™ç§æ–¹å¼æ˜¯æ¯”è¾ƒä¸é”™çš„ï¼Œåªä¸è¿‡å› å…¶åœ¨æ¯ä¸€å±‚éƒ½è¦åšä¸€æ¬¡å‘é‡æ—‹è½¬ï¼Œä»è€Œé™ä½è®­ç»ƒå’Œæ¨ç†çš„é€Ÿåº¦ã€‚

transformer è¿™ç±»æ¨¡å‹çš„ æ—¶é—´å¤æ‚åº¦ã€å†…å­˜ä½¿ç”¨å¤æ‚åº¦éƒ½æ˜¯ n^2ï¼ˆnä¸ºåºåˆ—é•¿åº¦ï¼‰
- å½“åºåˆ—é•¿åº¦è¶…è¿‡ 512 æ—¶ï¼Œæ¨¡å‹å¯¹ç®—åŠ›çš„è¦æ±‚å°†ä¼šå¤§å¹…æé«˜ã€‚

æœ€è¿‘ä¸€äº›æ–‡ç«  Longformer, Performer, Reformer, Clustered attention éƒ½è¯•å›¾é€šè¿‡è¿‘ä¼¼å…¨æ³¨æ„åŠ›æœºåˆ¶æ”¹å–„è¯¥é—®é¢˜ã€‚

å‡†BERTæ³¨æ„åŠ›æœºåˆ¶æ—¶ï¼Œé—®é¢˜å¯èƒ½æœ‰ï¼š
- æ¯ä¸ªè¯ä¸å…¶ä»–æ‰€æœ‰è¯éƒ½æœ‰å…³ç³»å—ï¼Ÿ
- ä¸ºä»€ä¹ˆæ¯ä¸ªè¯çš„æ³¨æ„åŠ›ä¸ä»…ä»…é›†ä¸­åœ¨æœ€é‡è¦çš„è¯
- å¦‚ä½•çŸ¥é“å“ªäº›è¯æ˜¯é‡è¦çš„
- å¦‚ä½•æœ‰æ•ˆçš„è®©æ³¨æ„åŠ›ä»…è€ƒè™‘ä¸ªåˆ«ä¸€äº›è¯



#### ã€2020-12-2ã€‘AllenAI Longformer

ã€2020-12-2ã€‘Allen AI æ¨å‡º Longformer
- ä»‹ç» [Longformer: Transformer æ”¹è¿›ç‰ˆï¼Œå¯å¤„ç†è¾ƒé•¿çš„åºåˆ—](https://ai-scholar.tech/zh/articles/bert/longformer)
- è®ºæ–‡: [Longformer: The Long-Document Transformer](https://arxiv.org/pdf/2004.05150.pdf)
- huggingface [longformer](https://huggingface.co/docs/transformers/model_doc/longformer)

Transformer è®¡ç®—å¤æ‚åº¦éšè¾“å…¥åºåˆ—çš„å¢åŠ è€Œå‘ˆäºŒæ¬¡æ›²çº¿å¢åŠ , æ—¶é—´å’Œå†…å­˜å ç”¨éå¸¸å¤§
- åŸå› ï¼šTransformer ä¸»è¦éƒ¨åˆ† -- **ç¼©æ”¾ç‚¹ç§¯è‡ªæ³¨æ„åŠ›**ï¼ˆScaled Dot-Product Self-Attentionï¼‰
- è‡ªæ³¨æ„åŠ›çš„è®¡ç®—å¤æ‚åº¦ä¸º `O(N^2)` ï¼Œå½“åŒ…å«é•¿å¥æ—¶ï¼Œå†…å­˜ä½¿ç”¨é‡ä¼šéšç€è¾“å…¥é‡çš„å¢åŠ è€Œå‘ˆ4å€å¢é•¿ã€‚

Longformer æ˜¯åŸºäº Transformer çš„å¯æ‰©å±•æ¨¡å‹ï¼Œç”¨äºå¤„ç†**é•¿æ–‡æ¡£**ï¼Œå¯è½»æ¾æ‰§è¡Œå„ç§æ–‡æ¡£çº§ NLP ä»»åŠ¡ï¼Œè€Œæ— éœ€å¯¹é•¿è¾“å…¥è¿›è¡Œåˆ†å—æˆ–ç¼©çŸ­ï¼Œä¹Ÿæ— éœ€ä½¿ç”¨å¤æ‚çš„æ¶æ„æ¥ç»„åˆå„å—ä¿¡æ¯ã€‚

Longformer ç»“åˆæœ¬åœ°å’Œå…¨å±€ä¿¡æ¯ï¼Œä»¥åŠä¸‰ç§æ³¨æ„åŠ›ï¼ˆæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ã€æ”¾å¤§æ»‘åŠ¨çª—å£æ³¨æ„åŠ›å’Œå…¨å±€æ³¨æ„åŠ›ï¼‰ã€‚çª—å£æ³¨æ„å’Œå…¨å±€æ³¨æ„ï¼‰ã€‚
- ![](https://aisholar.s3.ap-northeast-1.amazonaws.com/media/August2023/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-08-05_7.16.49.png)

æ•ˆæœ
- Longformer è¿˜åœ¨ text8 å’Œ enwik8 ä»»åŠ¡ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚
- Longformer åœ¨é•¿æ–‡æ¡£è¡¨ç°ä¸€ç›´ä¼˜äº RoBERTaï¼Œå¹¶ä¸”åœ¨é¢„è®­ç»ƒåçš„ WikiHop å’Œ TriviaQA ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ã€‚

RoBERTa åªæœ‰ 512 ä¸ªä½ç½®åµŒå…¥ï¼Œå› æ­¤éœ€è¦å¤åˆ¶ 8 ä¸ªä½ç½®åµŒå…¥æ¥å®¹çº³ 4096 ä¸ªå­—ã€‚å°½ç®¡å®ƒå¾ˆç®€å•ï¼Œä½†æ®ç§°å´éå¸¸æœ‰æ•ˆï¼Œè¿™æ˜¾ç„¶æ˜¯å› ä¸ºå¤åˆ¶æ¶ˆé™¤äº†åˆ†åŒºè¾¹ç•Œã€‚

#### ã€2021-1-8ã€‘è°·æ­Œ BigBird


ã€2021-1-8ã€‘è°·æ­Œæ¨å‡º BigBird, åŸºäº**ç¨€ç–æ³¨æ„åŠ›**çš„Transformerï¼Œå°†åŸºäºTransformerçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ BERTï¼‰æ‰©å±•åˆ°æ›´é•¿çš„åºåˆ—ã€‚
- å¹³æ–¹çº§åˆ«çš„ä¾èµ–é™æˆçº¿æ€§
- åŒç­‰ç¡¬ä»¶æ¡ä»¶ä¸‹ï¼Œé•¿åº¦æ‰©å……8å€
- è®ºæ–‡ï¼š[Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)
- ä»£ç ï¼š[bigbird](https://github.com/google-research/bigbird)

å¼€æºä¸­æ–‡ bigbird é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»tinyè‡³baseå…±5ä¸ªçº§åˆ«é¢„è®­ç»ƒæ¨¡å‹ã€‚å¯ä»[huggingface hub](https://huggingface.co/models?language=zh&sort=downloads&search=bigbird)ç›´æ¥ä¸‹è½½ä½¿ç”¨

BigBird æ¨¡å‹å®ç°äº†ä¸‰ç§æ³¨æ„åŠ›æœºåˆ¶ï¼š**éšæœºæ³¨æ„åŠ›**ã€**çª—å£æ³¨æ„åŠ›**å’Œ**å…¨å±€æ³¨æ„åŠ›**ï¼Œè¿™ä¸LongFormerå‡ ä¹ç›¸ä¼¼

ä¸BERTåŒç­‰è®¡ç®—åŠ›ä¸‹ï¼Œå¯å¤„ç†åºåˆ—é•¿åº¦è¾¾åˆ°4096ã€‚
- å¾ˆå¤šé•¿æ–‡æœ¬åºåˆ—çš„ä»»åŠ¡ä¸Šè¾¾åˆ°SOTAæ•ˆæœï¼Œä¾‹å¦‚ï¼šé•¿æ–‡æœ¬æ‘˜è¦ã€é•¿æ–‡æœ¬é—®ç­”ã€‚ 
- BigBird RoBERTa æ¨¡å‹åœ¨Transformersä»“åº“ä¸­ä½¿ç”¨ã€‚

BigBirdçš„æ³¨æ„åŠ›æœºåˆ¶æ˜¯ä¸€ä¸ªè¿‘ä¼¼BERTçš„**å…¨æ³¨æ„åŠ›æœºåˆ¶**ï¼Œå› æ­¤ä¸æ˜¯æ¯”BERTçš„æ³¨æ„åŠ›æœºåˆ¶æ•ˆæœæ›´å¥½ï¼Œè€Œæ˜¯**è¿è¡Œæ•ˆç‡æ›´é«˜**ã€‚
- BERTçš„æ³¨æ„åŠ›æœºåˆ¶å­˜å‚¨ä¸åºåˆ—é•¿åº¦æ˜¯äºŒæ¬¡æ–¹å…³ç³»ï¼Œåœ¨é•¿æ–‡æœ¬æƒ…å†µä¸‹çš„å­˜å‚¨éœ€æ±‚å°±å·²ç»å¼€å§‹ä»¤äººéš¾ä»¥å¿å—
- è€Œ BigBird çš„ block sparse attention å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ— é™é•¿é•¿åº¦åºåˆ—ä¸Šï¼Œè®¡ç®—æ— ç©·æ¬¡ æ¬¡æ—¶ï¼ŒæŠŠBERTçš„å…¨æ³¨æ„åŠ›æœºåˆ¶æ¢æˆ block sparse attentionã€‚ 


BigBirdæœ‰ä¸¤ç§é•¿ç¨‹æ³¨æ„åŠ›æ–¹å¼ï¼Œå¯ä»¥è®©è®¡ç®—å˜çš„æ›´æœ‰æ•ˆï¼š
- å…¨å±€è¯ï¼ˆGlobal tokenï¼‰ï¼šæœ‰ä¸€äº›è¯ï¼Œéœ€è¦è€ƒè™‘å…¶ä»–æ‰€æœ‰è¯ï¼Œå…¶ä»–æ‰€æœ‰è¯ä¹Ÿéœ€è¦è€ƒè™‘å®ƒã€‚ä¾‹å¦‚â€HuggingFace is building nice libraries for easy NLPâ€œã€‚å¦‚æœâ€buildingâ€œæ˜¯ä¸€ä¸ªå…¨å±€è¯ï¼Œæ¨¡å‹åœ¨æœ‰çš„äººç‰©ä¸­éœ€è¦çŸ¥é“è¯â€NLPâ€œå’Œè¯â€HuggingFaceâ€œçš„å…³ç³»ï¼ˆè¿™ä¸¤ä¸ªè¯åœ¨æœ€å·¦è¾¹å’Œæœ€å³è¾¹ï¼‰ï¼Œé‚£ä¹ˆè¯â€buildingâ€œéœ€è¦è¢«è®¾ç½®æˆå…¨å±€è¯ï¼Œä»è€Œå¤„ç†ä¸â€NLPâ€œå’Œâ€HuggingFaceâ€œçš„å…³ç³»ã€‚
- éšæœºè¯ï¼ˆRandom tokensï¼‰ï¼šéšæœºé€‰æ‹©ä¸€äº›è¯ï¼ŒæŠŠä¿¡æ¯ä¼ é€’ç»™å…¶ä»–è¯ï¼Œè¿™å¯ä»¥é™ä½è¯ä¸è¯ä¹‹é—´çš„ä¿¡æ¯äº¤äº’éš¾åº¦ã€‚

```py
# ä¾‹å¦‚ç¬¬ä¸€ä¸ªè¯å’Œæœ€åä¸€ä¸ªè¯æ˜¯å…¨å±€çš„
global_tokens = ["BigBird", "answering"]
# å°†å…¨å±€è¯åŠ å…¥è‡³key_tokensé›†åˆä¸­
key_tokens.append(global_tokens)
# ç°åœ¨ç”¨è¯â€isâ€œåšéšæœºè¯
random_tokens = ["is"]
key_tokens.append(random_tokens)
key_tokens # {'now', 'is', 'in', 'answering', 'available', 'BigBird'}
# ç°åœ¨ï¼Œè¯â€availableâ€œå¯ä»¥åªä¸è¿™äº›è¯åšæ³¨æ„åŠ›è®¡ç®—ï¼Œè€Œä¸æ˜¯æ‰€æœ‰è¯
```

å‚è€ƒ
- [bigbirdé•¿æ–‡æœ¬é¢„è®­ç»ƒæ¨¡å‹ä»‹ç»](https://zhuanlan.zhihu.com/p/444333724)
- [BigBirdï¼šå¤§é¸Ÿæ¨¡å‹ä¸­æ–‡ç”Ÿæˆå¼é•¿æ–‡æœ¬æ‘˜è¦å®è·µ](https://blog.csdn.net/yjh_SE007/article/details/129244755)

#### 2022.*.* Attention with Linear Biasï¼ˆALiBiï¼‰

ALiBi æ˜¯ 2022 å¹´æå‡ºçš„ä¸€ç§æ–¹æ³•ï¼Œè§£å†³ transformer **è®­ç»ƒå’Œæ¨ç†æ—¶æ–‡æœ¬é•¿åº¦ä¸ä¸€è‡´**çš„éš¾é¢˜ï¼Œ
- è®ºæ–‡ä¸­åœ¨è®­ç»ƒæ—¶å€™ä½¿ç”¨ 1024 çš„æœ€å¤§é•¿åº¦ï¼Œä½†åœ¨æ¨ç†æ—¶ç”¨ 2048 çš„æœ€å¤§é•¿åº¦æ¨ç†ï¼Œå¹¶ä¸”åœ¨ PPL æŒ‡æ ‡æŒå¹³ã€‚
- ALiBi éƒ½æ˜¯åœ¨æµ‹è¯•é›†çš„å¥å­æœ€å¤§é•¿åº¦çš„ã€Œä¸€åŠé•¿åº¦ã€ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œ Sinusoidal åˆ™æ˜¯æ­£å¸¸åœ¨ã€Œæµ‹è¯•é›†é•¿åº¦ã€ä¸Šè¿›è¡Œè®­ç»ƒï¼Œ
- [TRAIN SHORT, TEST LONG: ATTENTION WITH LINEAR BIASES ENABLES INPUT LENGTH EXTRAPOLATION](https://arxiv.org/pdf/2108.12409.pdf)

å¦‚ä½•å®ç°ï¼Ÿ
- ALiBi å®ç°æ€è·¯å¾ˆç›´è§‰ï¼Œæ¨¡å‹åœ¨æ¥æ”¶è¾“å…¥æ—¶ç›´æ¥å»æ‰ Position Embedding å‘é‡ï¼Œè€Œæ˜¯åœ¨ Attention ä¸­è®¡ç®— queryÂ·Key çš„å€¼åé¢åŠ å…¥ä¸€ä¸ªåç½®å¸¸é‡ï¼ˆéè®­ç»ƒå˜é‡ï¼‰ï¼Œæ¥è¾¾åˆ°æ³¨å…¥ä½ç½®ä¿¡æ¯çš„æ•ˆæœã€‚è¿™ä¸ªå¸¸é‡æ˜¯ä¸€ä¸ª äº‹å…ˆè®¡ç®—å¥½ çš„æ•°å€¼ï¼Œå¹¶ä¸”æ¯ä¸ªå¤´ï¼ˆheadï¼‰çš„å€¼éƒ½æœ‰æ‰€ä¸åŒã€‚
- é€šè¿‡ã€Œç›¸å¯¹ä½ç½®ä¿¡æ¯ã€å°±èƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£ã€Œç»å¯¹ä½ç½®ä¿¡æ¯ã€é€ æˆçš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­é•¿åº¦ç¼–ç ä¸ä¸€è‡´çš„é—®é¢˜

ä»£ç è§[åŸæ–‡](https://zhuanlan.zhihu.com/p/634236135)


#### 2024.4.10 Infini-Transformer

ã€2024-4-11ã€‘[Google æå‡ºInfini-Transformeræ¶æ„ï¼Œå¯è®©LLMså¤„ç†æ— é™é•¿ä¸Šä¸‹æ–‡ï¼Œå†…å­˜èŠ‚çº¦114å€](https://mp.weixin.qq.com/s/factToEEJdWcs5WJG1Ljfg)
- [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/pdf/2404.07143.pdf)

å¯¹äºæ‰¹é‡å¤§å°ä¸º 512ã€ä¸Šä¸‹æ–‡é•¿åº¦ä¸º 2048 çš„ 500B æ¨¡å‹ï¼Œæ³¨æ„åŠ›é”®å€¼ (KV) çŠ¶æ€çš„å†…å­˜å ç”¨ä¸º 3TB

é¢å¯¹è¶…é•¿åºåˆ—ï¼Œç›¸æ¯”æ³¨æ„åŠ›æœºåˆ¶ï¼Œå†…å­˜å‹ç¼©æŠ€æœ¯æ›´å…·æ‰©å±•æ€§ã€‚
- å†…å­˜å‹ç¼©ä¸ä½¿ç”¨éšè¾“å…¥åºåˆ—é•¿åº¦è€Œå¢é•¿çš„æ•°ç»„ï¼Œè€Œæ˜¯åœ¨æœ‰é™çš„å†…å­˜èµ„æºä¸Šï¼Œç»´æŠ¤å›ºå®šæ•°é‡çš„å‚æ•°æ¥è¿›è¡Œä¿¡æ¯çš„å­˜å‚¨å’Œå›è°ƒã€‚
- ç„¶è€Œï¼Œç›®å‰çš„LLMså°šæœªæœ‰ä¸€ç§æœ‰æ•ˆã€å®ç”¨çš„å†…å­˜å‹ç¼©æŠ€æœ¯ï¼Œå¯ä»¥åœ¨ç®€å•æ€§ä¸è´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

åŸºäºä»¥ä¸ŠèƒŒæ™¯ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°æ¶æ„ï¼šInfini-Transformerï¼Œèƒ½å¤Ÿè®©åŸºäºTransformerçš„å¤§æ¨¡å‹åœ¨æœ‰é™å†…å­˜ã€è®¡ç®—èµ„æºçš„æ¡ä»¶ä¸‹ï¼Œå¤„ç†æ— é™é•¿çš„ä¸Šä¸‹æ–‡è¾“å…¥ã€‚

Infini-Transformer å¯åœ¨æœ‰é™å†…å­˜æ¡ä»¶ä¸‹ï¼Œè®©åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é«˜æ•ˆå¤„ç†æ— é™é•¿çš„è¾“å…¥åºåˆ—ã€‚

ä¸Transformer-XLç±»ä¼¼ï¼ŒInfini-Transformerå¤„ç†çš„æ˜¯ä¸€ç³»åˆ—ç‰‡æ®µã€‚
- æ¯ä¸ªç‰‡æ®µå†… è®¡ç®— standard causal ç‚¹ç§¯attention contextï¼ˆæ³¨æ„åŠ›ä¸Šä¸‹æ–‡ï¼‰ã€‚å› æ­¤ï¼Œç‚¹ç§¯æ³¨æ„åŠ›è®¡ç®—åœ¨æŸç§æ„ä¹‰ä¸Šæ˜¯**å±€éƒ¨**çš„ï¼Œè¦†ç›–äº†ç´¢å¼•ä¸º S çš„å½“å‰ç‰‡æ®µçš„æ€»å…± N ä¸ªæ ‡è®°ã€‚
- ç„¶è€Œï¼Œå±€éƒ¨æ³¨æ„åŠ›åœ¨å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µæ—¶ä¼šä¸¢å¼ƒå‰ä¸€ä¸ªç‰‡æ®µçš„æ³¨æ„åŠ›çŠ¶æ€ã€‚åœ¨Infini-Transformerä¸­ï¼Œå¹¶æ²¡æœ‰å¿½ç•¥æ—§çš„é”®å€¼ï¼ˆKVï¼‰æ³¨æ„åŠ›çŠ¶æ€ï¼Œè€Œæ˜¯é€šè¿‡å†…å­˜å‹ç¼©æŠ€æœ¯é‡æ–°ä½¿ç”¨å®ƒä»¬æ¥ä¿æŒæ•´ä¸ªä¸Šä¸‹æ–‡å†å²ã€‚
- å› æ­¤ï¼ŒInfini-Transformerçš„æ¯ä¸ªæ³¨æ„åŠ›å±‚éƒ½å…·æœ‰**å…¨å±€**å‹ç¼©å’Œ**å±€éƒ¨**ç»†ç²’åº¦çŠ¶æ€ï¼Œè¿™å°±æ˜¯å‰é¢æåˆ°çš„æ— é™æ³¨æ„åŠ›ï¼ˆInfini-attentionï¼‰ã€‚

å®éªŒç»“æœè¡¨æ˜ï¼š
- Infini-Transformeråœ¨é•¿ä¸Šä¸‹æ–‡è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šè¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œå†…å­˜æœ€é«˜å¯èŠ‚çº¦114å€ã€‚



## ç¨€ç–Attention

### èµ·å› 

transformerèƒ½æ•æ‰è¾“å…¥åºåˆ—tokenä¹‹é—´çš„å…³ç³»ï¼Œå³ä½¿æ˜¯é•¿è·ç¦»ã€‚

é•¿åºåˆ—è¾“å…¥å—åˆ°æ³¨æ„åŠ›è®¡ç®—å’Œå†…å­˜èµ„æºé™åˆ¶ï¼Œéšç€åºåˆ—é•¿åº¦näºŒæ¬¡å¢é•¿ã€‚
- DeepSpeedæä¾›äº† **ç¨€ç– attention kernel** â€”â€” æ”¯æŒ**é•¿åºåˆ—**æ¨¡å‹è¾“å…¥ï¼ŒåŒ…æ‹¬æ–‡æœ¬è¾“å…¥ï¼Œå›¾åƒè¾“å…¥å’Œè¯­éŸ³è¾“å…¥ã€‚
- é€šè¿‡å—ç¨€ç–è®¡ç®—å°†æ³¨æ„åŠ›çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚é™ä½å‡ ä¸ªæ•°é‡çº§ã€‚

è¯¥æ–¹æ³•ä¸ä»…ç¼“è§£äº†æ³¨æ„åŠ›è®¡ç®—çš„å†…å­˜ç“¶é¢ˆï¼Œè€Œä¸”å¯ä»¥æœ‰æ•ˆåœ°æ‰§è¡Œç¨€ç–è®¡ç®—ã€‚

é™¤äº†æä¾›å¹¿æ³›çš„ç¨€ç–æ€§ç»“æ„å¤–ï¼Œè¿˜å…·æœ‰å¤„ç†ä»»ä½•ç”¨æˆ·å®šä¹‰çš„å—ç¨€ç–ç»“æ„çš„çµæ´»æ€§ã€‚

### æ€»ç»“

ç¨€ç–Attention
- `Atrous Self Attention` ç©ºæ´è‡ªæ³¨æ„åŠ›ï¼Œåªè®¡ç®—ç¬¬k,2k,3k,4k...å…ƒç´ 
- `Local Self Attention`
- `Sparse Self Attention`: OpenAIåœ¨image transformerä¸­å¼•å…¥äº†Sparse self-attentionï¼ŒæŠŠä¸¤è€…ç»“åˆåœ¨ä¸€å—ï¼Œæ—¢å¯ä»¥å­¦ä¹ åˆ°å±€éƒ¨çš„ç‰¹æ€§ï¼Œåˆå¯ä»¥å­¦ä¹ åˆ°è¿œç¨‹ç¨€ç–çš„ç›¸å…³æ€§

|ç¨€ç–Attention|åç§°|è¯´æ˜||
|---|---|---|---|
|`Atrous Self Attention`|ç©ºæ´è‡ªæ³¨æ„åŠ›|![](https://pic2.zhimg.com/80/v2-a39db55945b1ae7c413572b22fbe4cd1_1440w.webp)||
|`Local Self Attention`|å±€éƒ¨è‡ªæ³¨æ„åŠ›|![](https://pic4.zhimg.com/80/v2-c2b46a79fb998e2030ecd8cea99100fb_1440w.webp)||
|`Sparse Self Attention`|ç¨€ç–è‡ªæ³¨æ„åŠ›|![](https://pic4.zhimg.com/80/v2-a2f4cfa836abe8a6fc537048be262ab3_1440w.webp)|ç»¼åˆä»¥ä¸Šä¼˜ç‚¹|

ã€2019-7-27ã€‘è‹å‰‘æ—ï¼Œ[èŠ‚çº¦è€Œç”Ÿï¼šä»æ ‡å‡†Attentionåˆ°ç¨€ç–Attention](https://spaces.ac.cn/archives/6853) èŠ‚çº¦æ—¶é—´ã€æ˜¾å­˜ã€‚

Attentionçš„æ ¸å¿ƒåœ¨äºQ,K,V ä¸‰ä¸ªå‘é‡åºåˆ—çš„äº¤äº’å’Œèåˆï¼Œå…¶ä¸­Q,K çš„äº¤äº’ç»™å‡ºäº†ä¸¤ä¸¤å‘é‡ä¹‹é—´çš„æŸç§ç›¸å…³åº¦ï¼ˆæƒé‡ï¼‰ï¼Œè€Œæœ€åçš„è¾“å‡ºåºåˆ—åˆ™æ˜¯æŠŠVæŒ‰ç…§æƒé‡æ±‚å’Œå¾—åˆ°çš„

ç†è®ºä¸Šï¼ŒSelf Attention **è®¡ç®—æ—¶é—´**å’Œ**æ˜¾å­˜å ç”¨é‡**éƒ½æ˜¯ ğ’ª(n^2) çº§åˆ«çš„ï¼ˆnæ˜¯åºåˆ—é•¿åº¦ï¼‰
- å¦‚æœåºåˆ—é•¿åº¦å˜æˆåŸæ¥çš„**2å€**ï¼Œæ˜¾å­˜å ç”¨é‡å°±æ˜¯åŸæ¥çš„**4å€**ï¼Œè®¡ç®—æ—¶é—´ä¹Ÿæ˜¯åŸæ¥çš„**4å€**ã€‚
- å½“ç„¶ï¼Œå‡è®¾å¹¶è¡Œæ ¸å¿ƒæ•°è¶³å¤Ÿå¤šçš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æ—¶é—´æœªå¿…ä¼šå¢åŠ åˆ°åŸæ¥çš„4å€ï¼Œä½†æ˜¯æ˜¾å­˜çš„4å€å´æ˜¯å®å®åœ¨åœ¨çš„ï¼Œæ— å¯é¿å…ï¼Œè¿™ä¹Ÿæ˜¯å¾®è°ƒBertæ—¶OOMçš„åŸå› ã€‚

ä¸ºä»€ä¹ˆæ˜¯ ğ’ª(n^2)ï¼Ÿ
- è¦å¯¹åºåˆ—ä¸­çš„ä»»æ„ä¸¤ä¸ªå‘é‡éƒ½è¦è®¡ç®—ç›¸å…³åº¦ï¼Œå¾—åˆ°ä¸€ä¸ª$n^2$å¤§å°çš„ç›¸å…³åº¦çŸ©é˜µ
- ![](https://spaces.ac.cn/usr/uploads/2019/07/775103900.png)
- å·¦è¾¹æ˜¾ç¤ºäº†**æ³¨æ„åŠ›çŸ©é˜µ**ï¼Œå³å˜æ˜¾ç¤ºäº†**å…³è”æ€§**ï¼Œè¿™è¡¨æ˜æ¯ä¸ªå…ƒç´ éƒ½è·Ÿåºåˆ—å†…æ‰€æœ‰å…ƒç´ æœ‰å…³è”ã€‚

æ‰€ä»¥ï¼ŒèŠ‚çœæ˜¾å­˜ï¼ŒåŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œä¸€ä¸ªè§£æ³•æ˜¯**å‡å°‘å…³è”æ€§è®¡ç®—**
- æ¯ä¸ªå…ƒç´ åªè·Ÿåºåˆ—å†…çš„**éƒ¨åˆ†å…ƒç´ **ç›¸å…³ï¼Œè¿™å°±æ˜¯ç¨€ç–Attentionçš„åŸºæœ¬åŸç†ã€‚
- æºäºOpenAIçš„è®ºæ–‡ã€Š[Generating Long Sequences with Sparse Transformers](https://arxiv.org/abs/1904.10509)ã€‹


### Atrous Self Attention è†¨èƒ€æ³¨æ„åŠ›

Atrous Self Attentionï¼Œâ€œ**è†¨èƒ€**è‡ªæ³¨æ„åŠ›â€ã€â€œ**ç©ºæ´**è‡ªæ³¨æ„åŠ›â€ã€â€œ**å¸¦å­”**è‡ªæ³¨æ„åŠ›â€ç­‰ã€‚
- åç§°æ˜¯è‡ªå®šä¹‰, åŸè®ºæ–‡ã€ŠGenerating Long Sequences with Sparse Transformersã€‹æ²¡æœ‰å‡ºç°è¿‡è¿™ä¸¤ä¸ªæ¦‚å¿µ

Atrous Self Attention å¯å‘äºâ€œ**è†¨èƒ€å·ç§¯**ï¼ˆAtrous Convolutionï¼‰â€ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå®ƒå¯¹ç›¸å…³æ€§è¿›è¡Œäº†çº¦æŸï¼Œå¼ºè¡Œè¦æ±‚æ¯ä¸ªå…ƒç´ åªè·Ÿå®ƒç›¸å¯¹è·ç¦»ä¸ºk,2k,3k,â€¦ çš„å…ƒç´ å…³è”ï¼Œå…¶ä¸­k>1æ˜¯é¢„å…ˆè®¾å®šçš„è¶…å‚æ•°ã€‚ä»ä¸‹å·¦çš„æ³¨æ„åŠ›çŸ©é˜µçœ‹ï¼Œå°±æ˜¯å¼ºè¡Œè¦æ±‚ç›¸å¯¹è·ç¦»ä¸æ˜¯k
çš„å€æ•°çš„æ³¨æ„åŠ›ä¸º0ï¼ˆç™½è‰²ä»£è¡¨0ï¼‰ï¼š
- ![](https://spaces.ac.cn/usr/uploads/2019/07/4107095412.png)
- Atrous Self Attentionçš„æ³¨æ„åŠ›çŸ©é˜µï¼ˆå·¦ï¼‰å’Œå…³è”å›¾ç¤ºï¼ˆå³ï¼‰

ç”±äºç°åœ¨è®¡ç®—æ³¨æ„åŠ›æ˜¯â€œè·³ç€â€æ¥äº†ï¼Œæ‰€ä»¥å®é™…ä¸Šæ¯ä¸ªå…ƒç´ åªè·Ÿå¤§çº¦n/kä¸ªå…ƒç´ ç®—ç›¸å…³æ€§ï¼Œè¿™æ ·ç†æƒ³æƒ…å†µä¸‹è¿è¡Œæ•ˆç‡å’Œæ˜¾å­˜å ç”¨éƒ½å˜æˆäº†ğ’ª(n^2/k)ï¼Œä¹Ÿå°±æ˜¯è¯´èƒ½ç›´æ¥é™ä½åˆ°åŸæ¥çš„1/kã€‚


### Local Self Attention å±€éƒ¨è‡ªæ³¨æ„åŠ›

Local Self Attentionï¼Œä¸­æ–‡ç§°â€œå±€éƒ¨è‡ªæ³¨æ„åŠ›â€ã€‚
- **è‡ªæ³¨æ„åŠ›**æœºåˆ¶åœ¨CVé¢†åŸŸç»Ÿç§°ä¸ºâ€œNon Localâ€
- è€ŒLocal Self Attentionåˆ™è¦æ”¾å¼ƒå…¨å±€å…³è”ï¼Œé‡æ–°å¼•å…¥**å±€éƒ¨å…³è”**ã€‚çº¦æŸæ¯ä¸ªå…ƒç´ åªä¸å‰åkä¸ªå…ƒç´ ä»¥åŠè‡ªèº«æœ‰å…³è”ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
- ![](https://spaces.ac.cn/usr/uploads/2019/07/713126535.png)
- Local Self Attentionçš„æ³¨æ„åŠ›çŸ©é˜µï¼ˆå·¦ï¼‰å’Œå…³è”å›¾ç¤ºï¼ˆå³ï¼‰
- ä»æ³¨æ„åŠ›çŸ©é˜µæ¥çœ‹ï¼Œå°±æ˜¯ç›¸å¯¹è·ç¦»è¶…è¿‡kçš„æ³¨æ„åŠ›éƒ½ç›´æ¥è®¾ä¸º0ã€‚

å…¶å® Local Self Attention è·Ÿæ™®é€šå·ç§¯å¾ˆåƒäº†ï¼Œéƒ½æ˜¯ä¿ç•™äº†ä¸€ä¸ª 2k+1 å¤§å°çš„çª—å£ï¼Œç„¶ååœ¨çª—å£å†…è¿›è¡Œä¸€äº›è¿ç®—ï¼Œä¸åŒçš„æ˜¯æ™®é€šå·ç§¯æ˜¯æŠŠçª—å£å±•å¹³ç„¶åæ¥ä¸€ä¸ªå…¨è¿æ¥å±‚å¾—åˆ°è¾“å‡ºï¼Œè€Œç°åœ¨æ˜¯çª—å£å†…é€šè¿‡æ³¨æ„åŠ›æ¥åŠ æƒå¹³å‡å¾—åˆ°è¾“å‡ºã€‚å¯¹äºLocal Self Attentionæ¥è¯´ï¼Œæ¯ä¸ªå…ƒç´ åªè·Ÿ 2k+1 ä¸ªå…ƒç´ ç®—ç›¸å…³æ€§ï¼Œè¿™æ ·ä¸€æ¥ç†æƒ³æƒ…å†µä¸‹è¿è¡Œæ•ˆç‡å’Œæ˜¾å­˜å ç”¨éƒ½å˜æˆäº† ğ’ª((2k+1)n)âˆ¼ğ’ª(kn) äº†ï¼Œä¹Ÿå°±æ˜¯è¯´éšç€n è€Œçº¿æ€§å¢é•¿ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆç†æƒ³çš„æ€§è´¨â€”â€”å½“ç„¶ä¹Ÿç›´æ¥ç‰ºç‰²äº†é•¿ç¨‹å…³è”æ€§ã€‚

### Sparse Self Attention -- OpenAIæ”¹è¿›ï¼Œç»¼åˆä»¥ä¸Šä¸¤ç§

ç°åœ¨å¯ä»¥å¾ˆè‡ªç„¶åœ°å¼•å…¥OpenAIçš„ Sparse Self Attentionäº†ã€‚
- Atrous Self Attention æœ‰ä¸€äº›æ´ï¼Œè€Œ Local Self Attentionæ­£å¥½å¡«è¡¥äº†è¿™äº›æ´ï¼Œæ‰€ä»¥ä¸€ä¸ªç®€å•æ–¹å¼å°±æ˜¯å°†Local Self Attentionå’ŒAtrous Self Attention äº¤æ›¿ä½¿ç”¨ï¼Œä¸¤è€…ç´¯ç§¯èµ·æ¥ï¼Œç†è®ºä¸Šä¹Ÿå¯ä»¥å­¦ä¹ åˆ°å…¨å±€å…³è”æ€§ï¼Œä¹Ÿçœäº†æ˜¾å­˜ã€‚
- æ€è·¯ï¼šç¬¬ä¸€å±‚ç”¨Local Self Attentionï¼Œè¾“å‡ºçš„æ¯ä¸ªå‘é‡éƒ½èåˆäº†å±€éƒ¨å‡ ä¸ªè¾“å…¥å‘é‡ï¼Œç„¶åç¬¬äºŒå±‚ç”¨Atrous Self Attentionï¼Œè™½ç„¶è·³ç€æ¥ï¼Œä½†æ˜¯å› ä¸ºç¬¬ä¸€å±‚çš„è¾“å‡ºèåˆäº†å±€éƒ¨çš„è¾“å…¥å‘é‡ï¼Œæ‰€ä»¥ç¬¬äºŒå±‚çš„è¾“å‡ºç†è®ºä¸Šå¯ä»¥è·Ÿä»»æ„çš„è¾“å…¥å‘é‡ç›¸å…³ï¼Œä¹Ÿå°±æ˜¯è¯´å®ç°äº†**é•¿ç¨‹å…³è”**ã€‚
- ä½†æ˜¯OpenAIç›´æ¥å°†ä¸¤ä¸ªAtrous Self Attentionå’ŒLocal Self Attentionåˆå¹¶ä¸ºä¸€ä¸ªï¼Œå¦‚ä¸‹å›¾ï¼š
- ![](https://spaces.ac.cn/usr/uploads/2019/07/1199615308.png)
- Sparse Self Attentionçš„æ³¨æ„åŠ›çŸ©é˜µï¼ˆå·¦ï¼‰å’Œå…³è”å›¾ç¤ºï¼ˆå³ï¼‰

ä»æ³¨æ„åŠ›çŸ©é˜µä¸Šçœ‹å°±å¾ˆå®¹æ˜“ç†è§£äº†ï¼Œå°±æ˜¯é™¤äº†ç›¸å¯¹è·ç¦»ä¸è¶…è¿‡kçš„ã€ç›¸å¯¹è·ç¦»ä¸ºk,2k,3k,â€¦ çš„æ³¨æ„åŠ›éƒ½è®¾ä¸º0ï¼Œè¿™æ ·ä¸€æ¥Attentionå°±å…·æœ‰â€œå±€éƒ¨ç´§å¯†ç›¸å…³å’Œè¿œç¨‹ç¨€ç–ç›¸å…³â€çš„ç‰¹æ€§ï¼Œè¿™å¯¹å¾ˆå¤šä»»åŠ¡æ¥è¯´å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„å…ˆéªŒï¼Œå› ä¸ºçœŸæ­£éœ€è¦å¯†é›†çš„é•¿ç¨‹å…³è”çš„ä»»åŠ¡äº‹å®ä¸Šæ˜¯å¾ˆå°‘çš„ã€‚

OpenAI å¼€æºäº†å®˜æ–¹å®ç° [sparse_attention](https://github.com/openai/sparse_attention)

## Transformer-Decoder

ã€2021-4-19ã€‘[https://zhuanlan.zhihu.com/p/179959751](https://zhuanlan.zhihu.com/p/79714797)

Transformer åŸå§‹è®ºæ–‡å‘è¡¨ä¹‹åï¼Œã€ŒGenerating Wikipedia by Summarizing Long Sequencesã€æå‡ºç”¨å¦ä¸€ç§ transformer æ¨¡å—çš„**æ’åˆ—æ–¹å¼**æ¥è¿›è¡Œè¯­è¨€å»ºæ¨¡
- ç›´æ¥æ‰”æ‰äº†æ‰€æœ‰çš„ transformer ç¼–ç å™¨æ¨¡å—â€¦â€¦ã€ŒTransformer-Decoderã€æ¨¡å‹ã€‚

æ—©æœŸçš„åŸºäº transformer çš„æ¨¡å‹ç”± 6 ä¸ª transformer è§£ç å™¨æ¨¡å—å †å è€Œæˆï¼š
- ![](https://pic3.zhimg.com/80/v2-19720b1c70a294558dc9456477156b06_1440w.webp)

è§£ç å™¨æ¨¡å—
- å’Œ transformer åŸå§‹è§£ç å™¨æ¨¡å—ç›¸æ¯”ï¼Œå»æ‰äº†ç¬¬äºŒä¸ªè‡ªæ³¨æ„åŠ›å±‚ã€‚

ä¸€ä¸ªç›¸ä¼¼çš„æ¶æ„åœ¨**å­—ç¬¦**çº§åˆ«çš„è¯­è¨€å»ºæ¨¡ä¸­ä¹Ÿè¢«éªŒè¯æœ‰æ•ˆï¼Œä½¿ç”¨æ›´æ·±çš„è‡ªæ³¨æ„åŠ›å±‚æ„å»ºè¯­è¨€æ¨¡å‹ï¼Œä¸€æ¬¡é¢„æµ‹ä¸€ä¸ªå­—æ¯/å­—ç¬¦ã€‚

æ‰€æœ‰è§£ç å™¨æ¨¡å—éƒ½ä¸€æ ·ã€‚ä½¿ç”¨å¸¦æ©æ¨¡çš„è‡ªæ³¨æ„åŠ›å±‚ã€‚
- è¯¥æ¨¡å‹åœ¨æŸä¸ªç‰‡æ®µä¸­å¯ä»¥æ”¯æŒæœ€é•¿ **4000** ä¸ªå•è¯çš„åºåˆ—ï¼Œç›¸è¾ƒäº transformer åŸå§‹è®ºæ–‡ä¸­æœ€é•¿ **512** å•è¯çš„é™åˆ¶æœ‰äº†å¾ˆå¤§çš„æå‡ã€‚

## GPT-2 

OpenAI çš„ GPT-2 æ¨¡å‹å°±ç”¨äº†è¿™ç§åªåŒ…å«`ç¼–ç å™¨`ï¼ˆdecoder-onlyï¼‰æ¨¡å—

GPT-2 å¯ä»¥å¤„ç†æœ€é•¿ 1024 ä¸ªå•è¯çš„åºåˆ—ã€‚æ¯ä¸ªå•è¯éƒ½ä¼šå’Œå‰ç»­è·¯å¾„ä¸€èµ·ã€Œæµè¿‡ã€æ‰€æœ‰çš„è§£ç å™¨æ¨¡å—ã€‚

è®­ç»ƒ GPT-2 æ¨¡å‹ï¼Œæœ€ç®€å•çš„æ–¹æ³•
- è‡ªå·±éšæœºå·¥ä½œï¼ˆç”Ÿæˆ**æ— æ¡ä»¶**æ ·æœ¬ï¼‰ã€‚
- ç»™å®ƒä¸€ç‚¹æç¤ºï¼Œè¯´ä¸€äº›å…³äºç‰¹å®šä¸»é¢˜çš„è¯ï¼ˆå³ç”Ÿæˆ**äº¤äº’å¼**æ¡ä»¶æ ·æœ¬ï¼‰ã€‚

åœ¨éšæœºæƒ…å†µä¸‹ï¼Œåªç®€å•åœ°æä¾›ä¸€ä¸ªé¢„å…ˆå®šä¹‰å¥½çš„**èµ·å§‹å•è¯**ï¼Œç„¶åè‡ªå·±ç”Ÿæˆæ–‡å­—ã€‚
- è®­ç»ƒå¥½çš„æ¨¡å‹ä½¿ç”¨ã€Œ\|endoftext\|ã€ä½œä¸ºèµ·å§‹å•è¯ï¼Œä¸å¦¨å°†å…¶ç§°ä¸º\<s\>

- æ¨¡å‹çš„è¾“å…¥åªæœ‰ä¸€ä¸ªå•è¯ï¼Œæ‰€ä»¥åªæœ‰è¿™ä¸ªå•è¯çš„è·¯å¾„æ˜¯æ´»è·ƒçš„ã€‚
- å•è¯ç»è¿‡å±‚å±‚å¤„ç†ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå‘é‡ã€‚å‘é‡å¯¹äºè¯æ±‡è¡¨çš„æ¯ä¸ªå•è¯è®¡ç®—ä¸€ä¸ªæ¦‚ç‡
  - è¯æ±‡è¡¨æ˜¯æ¨¡å‹èƒ½ã€Œè¯´å‡ºã€çš„æ‰€æœ‰å•è¯ï¼ŒGPT-2 çš„è¯æ±‡è¡¨ä¸­æœ‰ 50000 ä¸ªå•è¯
- é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„å•è¯ã€ŒTheã€ä½œä¸ºä¸‹ä¸€ä¸ªå•è¯ã€‚
- å°†è¾“å‡ºçš„å•è¯æ·»åŠ åœ¨è¾“å…¥åºåˆ—çš„å°¾éƒ¨æ„å»ºæ–°çš„è¾“å…¥åºåˆ—ï¼Œè®©æ¨¡å‹è¿›è¡Œä¸‹ä¸€æ­¥çš„é¢„æµ‹
- ![](https://pic3.zhimg.com/80/v2-dc958d69c301d00cf1b2ea17e8ae005a_1440w.webp)

é—®é¢˜ï¼šé‡å¤
- é™·å…¥æ¨èåŒä¸€ä¸ªè¯çš„å¾ªç¯ä¸­ï¼Œé™¤éé‡‡ç”¨å…¶ä»–å•è¯æ‰èƒ½è·³å‡º

GPT-2 æœ‰ä¸ªã€Œtop-kã€çš„å‚æ•°
- æ¨¡å‹ä¼šä»æ¦‚ç‡å‰ k å¤§çš„å•è¯ä¸­**éšæœºæŠ½æ ·**é€‰å–ä¸‹ä¸€ä¸ªå•è¯ã€‚
- ä¹‹å‰æƒ…å†µä¸‹ï¼Œtop-k = 1

GPT-2 ä»åµŒå…¥ï¼ˆEmbeddingï¼‰çŸ©é˜µä¸­æ‰¾å•è¯å¯¹åº”çš„åµŒå…¥å‘é‡ï¼Œè¯¥çŸ©é˜µä¹Ÿæ˜¯æ¨¡å‹è®­ç»ƒç»“æœçš„ä¸€éƒ¨åˆ†ã€‚
- ![](https://pic2.zhimg.com/80/v2-5e67529ff0a194c39a45aaa6acec70bd_1440w.webp)
- åµŒå…¥çŸ©é˜µçš„æ¯ä¸€è¡Œéƒ½å¯¹åº”æ¨¡å‹è¯æ±‡è¡¨ä¸­ä¸€ä¸ªå•è¯çš„åµŒå…¥å‘é‡ã€‚
- embedding size
  - small : 768ä¸ªå­—ç¬¦ï¼Œ117m
  - medium : 1024ï¼Œ345m
  - large : 1280ï¼Œ762m
  - extra large : 1600ï¼Œ 1542m

æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªè¯åµŒå…¥å‘é‡ï¼šä¸€ä¸ªèƒ½å¤Ÿè¡¨å¾æŸä¸ªå•è¯ï¼Œå¹¶æ•è·å…¶æ•°å­—åˆ—è¡¨ã€‚
- åµŒå…¥å‘é‡çš„**é•¿åº¦**å’Œ GPT-2 æ¨¡å‹çš„å¤§å°æœ‰å…³ï¼Œæœ€å°çš„æ¨¡å‹ä½¿ç”¨äº†é•¿ä¸º 768 çš„åµŒå…¥å‘é‡æ¥è¡¨å¾ä¸€ä¸ªå•è¯ã€‚

åœ¨åµŒå…¥çŸ©é˜µä¸­æŸ¥æ‰¾èµ·å§‹å•è¯\<s\>å¯¹åº”çš„åµŒå…¥å‘é‡ã€‚
- ä½†åœ¨å°†å…¶è¾“å…¥ç»™æ¨¡å‹ä¹‹å‰ï¼Œå¼•å…¥`ä½ç½®ç¼–ç `â€”â€” ä¸€äº›å‘ transformer æ¨¡å—æŒ‡å‡ºåºåˆ—ä¸­çš„**å•è¯é¡ºåº**çš„ä¿¡å·ã€‚
- 1024 ä¸ªè¾“å…¥åºåˆ—ä½ç½®ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯¹åº”ä¸€ä¸ªä½ç½®ç¼–ç ï¼Œç¼–ç çŸ©é˜µä¹Ÿæ˜¯è®­ç»ƒæ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚

GPT-2 æ¨¡å‹è®­ç»ƒååŒ…å«ä¸¤ä¸ªæƒå€¼çŸ©é˜µï¼š`åµŒå…¥çŸ©é˜µ`å’Œ`ä½ç½®ç¼–ç çŸ©é˜µ`ã€‚

å•è¯è¾“å…¥ç¬¬ä¸€ä¸ª transformer æ¨¡å—ä¹‹å‰, æŸ¥åˆ°å¯¹åº”çš„åµŒå…¥å‘é‡ï¼ŒåŠ ä¸Š 1å·ä½ç½®å¯¹åº”çš„**ä½ç½®å‘é‡**ã€‚

å †æ ˆä¹‹æ—…: ç¬¬ä¸€ä¸ª transformer æ¨¡å—å¤„ç†å•è¯çš„æ­¥éª¤ï¼š
- é€šè¿‡è‡ªæ³¨æ„åŠ›å±‚å¤„ç†ï¼Œä¼ ç»™ç¥ç»ç½‘ç»œå±‚ã€‚ç¬¬ä¸€ä¸ª transformer æ¨¡å—å¤„ç†å®Œä½†æ­¤åï¼Œä¼šå°†ç»“æœå‘é‡è¢«ä¼ å…¥å †æ ˆä¸­çš„ä¸‹ä¸€ä¸ª transformer æ¨¡å—ï¼Œç»§ç»­è¿›è¡Œè®¡ç®—ã€‚æ¯ä¸€ä¸ª transformer æ¨¡å—çš„å¤„ç†æ–¹å¼éƒ½æ˜¯ä¸€æ ·çš„ï¼Œä½†æ¯ä¸ªæ¨¡å—éƒ½ä¼šç»´æŠ¤è‡ªå·±çš„è‡ªæ³¨æ„åŠ›å±‚å’Œç¥ç»ç½‘ç»œå±‚ä¸­çš„æƒé‡ã€‚
- ![](https://pic3.zhimg.com/80/v2-ec9e62183466343b547da05f34ad289e_1440w.webp)

æœ€ä¸Šå±‚çš„ transformer æ¨¡å—åœ¨å¤„ç†å•è¯ã€Œitã€çš„æ—¶å€™ä¼šå…³æ³¨ã€Œa robotã€ï¼Œæ‰€ä»¥ã€Œaã€ã€ã€Œrobotã€ã€ã€Œitã€è¿™ä¸‰ä¸ªå•è¯ä¸å…¶å¾—åˆ†ç›¸ä¹˜åŠ æƒæ±‚å’Œåçš„ç‰¹å¾å‘é‡ä¼šè¢«é€å…¥ä¹‹åçš„ç¥ç»ç½‘ç»œå±‚ã€‚



## Lite Transformer (è¾¹ç¼˜è®¾å¤‡)

ã€2020-6-7ã€‘[æ¨¡å‹å‹ç¼©95%ï¼ŒMITéŸ©æ¾ç­‰äººæå‡ºæ–°å‹Lite Transformer](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650789244&idx=3&sn=498864894b6e1d584a45017911ce233c&chksm=871a1102b06d98144d851133ead6bd4c69f90843d6ed5ef4ef46f56bfc3256d46f43f463b419&mpshare=1&scene=23&srcid&sharer_sharetime=1591760786074&sharer_shareid=b8d409494a5439418f4a89712efcd92a%23rd)
- MIT æœ€è¿‘çš„ç ”ç©¶ã€Š[Lite Transformer with Long-Short Range Attention](https://arxiv.org/abs/2004.11886v1)ã€‹ä¸­ï¼ŒMIT ä¸ä¸Šæµ·äº¤å¤§çš„ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ç§»åŠ¨ç«¯ NLP æ¶æ„ `Lite Transformer`ï¼Œå‘åœ¨**è¾¹ç¼˜è®¾å¤‡**ä¸Šéƒ¨ç½²ç§»åŠ¨çº§ NLP åº”ç”¨è¿ˆè¿›äº†ä¸€å¤§æ­¥ã€‚è¯¥è®ºæ–‡å·²è¢«äººå·¥æ™ºèƒ½é¡¶ä¼š ICLR 2020 æ”¶å½•ã€‚[ä»£ç ](https://github.com/mit-han-lab/lite-transformer)
- æ ¸å¿ƒæ˜¯é•¿çŸ­è·ç¦»æ³¨æ„åŠ›ï¼ˆLong-Short Range Attentionï¼ŒLSRAï¼‰ï¼Œå…¶ä¸­ä¸€ç»„æ³¨æ„åŠ›å¤´ï¼ˆé€šè¿‡å·ç§¯ï¼‰è´Ÿè´£å±€éƒ¨ä¸Šä¸‹æ–‡å»ºæ¨¡ï¼Œè€Œå¦ä¸€ç»„åˆ™ï¼ˆä¾é æ³¨æ„åŠ›ï¼‰æ‰§è¡Œé•¿è·ç¦»å…³ç³»å»ºæ¨¡ã€‚
- å¯¹äºç§»åŠ¨ NLP è®¾ç½®ï¼ŒLite Transformer çš„ BLEU å€¼æ¯”åŸºäº AutoML çš„ [Evolved Transformer](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756694&idx=4&sn=9de8bdbe79a5f4c45833f87418642111&chksm=871a9228b06d1b3e886f549543f8ba742ee120e4ca8f1780996fb241b6b6d05ca97882d5290b&scene=21#wechat_redirect) é«˜ 0.5ï¼Œè€Œä¸”å®ƒä¸éœ€è¦ä½¿ç”¨æˆæœ¬é«˜æ˜‚çš„æ¶æ„æœç´¢ã€‚
- ä» Lite Transformer ä¸ Evolved Transformerã€åŸç‰ˆ transformer çš„æ¯”è¾ƒç»“æœä¸­å¯ä»¥çœ‹å‡ºï¼ŒLite Transformer çš„æ€§èƒ½æ›´ä½³ï¼Œæœç´¢æˆæœ¬ç›¸æ¯” Evolved Transformer å¤§å¤§å‡å°‘


## Transformer-XL å’Œ XLNet

XLNetå¼•å…¥äº†è‡ªå›å½’è¯­è¨€æ¨¡å‹ä»¥åŠè‡ªç¼–ç è¯­è¨€æ¨¡å‹

### æ¨æ¤éºŸä»‹ç»

[å¾ªç¯æ™ºèƒ½ï¼ˆRecurrentï¼‰ï¼šç”¨AIé‡å¡‘æ²Ÿé€š](https://www.cyzone.cn/article/557072.html)

ã€2022-1-17ã€‘æ¨æ¤éºŸåšå£«ï¼Œ**å¾ªç¯æ™ºèƒ½**ï¼ˆRecurrent AIï¼‰è”åˆåˆ›å§‹äººï¼Œæ¸…åå¤§å­¦äº¤å‰ä¿¡æ¯é™¢åŠ©ç†æ•™æˆï¼Œæ™ºæºé’å¹´ç§‘å­¦å®¶ã€‚

2016å¹´5æœˆè”åˆåˆ›åŠçš„Recurrent AIï¼Œæ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬è‡ªç„¶è¯­è¨€ç†è§£ã€è¯­éŸ³è¯†åˆ«ã€è¯­æ°”è¯†åˆ«ã€å£°çº¹è¯†åˆ«å’Œæ¨èç³»ç»Ÿã€‚å…¶ä¸­ï¼Œè‡ªç„¶è¯­è¨€ç†è§£æ¥è‡ªå…¬å¸çš„æ ¸å¿ƒåŸåˆ›ç®—æ³•XLNetï¼Œè¿™å¥—ç®—æ³•åˆ·æ–°äº†18é¡¹NLPï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰ä»»åŠ¡ã€‚å¦‚ä»Šç´¯è®¡èèµ„4äº¿å…ƒï¼Œè¿ç»­ä¸‰å¹´è¥æ”¶å¢é•¿è¶…200%ï¼ŒæœåŠ¡é“¶è¡Œä¿é™©ç­‰è¡Œä¸šçš„å¤´éƒ¨å®¢æˆ·ï¼Œæ—¥å‡å¤„ç†å¯¹è¯ä¸€äº¿æ¡ã€è¦†ç›–æ•°ç™¾ä¸‡ç»ˆç«¯ç”¨æˆ·ã€‚
- ![](https://oss.cyzone.cn/2019/0926/631f26ab025a8c33d218a4a09424bbb4.png?x-oss-process=image/format,png)
- å¾ªç¯æ™ºèƒ½åˆ›å§‹å›¢é˜Ÿï¼Œä»å·¦åˆ°å³ï¼šCOOæ­å‘ã€CTOå¼ å®‡éŸ¬ã€CEOé™ˆéº’èªä»¥åŠAIå’Œäº§å“è´Ÿè´£äººæ¨æ¤éºŸ

å…¶ç ”ç©¶æˆæœç´¯è®¡Google Scholarå¼•ç”¨10,000ä½™æ¬¡ï¼›ä½œä¸ºç¬¬ä¸€ä½œè€…å‘è¡¨Transformer-XL å’Œ XLNet ï¼Œå¯¹NLPé¢†åŸŸäº§ç”Ÿé‡å¤§å½±å“ï¼Œåˆ†åˆ«æ˜¯ACL 2019å’ŒNeurIPS 2019æœ€é«˜å¼•è®ºæ–‡ä¹‹ä¸€ï¼›ä¸»å¯¼å¼€å‘çš„ç›˜å¤NLPå¤§æ¨¡å‹è·2021å¹´ä¸–ç•Œäººå·¥æ™ºèƒ½å¤§ä¼šâ€œå“è¶Šäººå·¥æ™ºèƒ½å¼•é¢†è€…ä¹‹æ˜Ÿå¥–â€ã€‚æ›¾å…¥é€‰2021å¹´ç¦å¸ƒæ–¯äºšæ´²30 under 30ï¼›æ›¾æ•ˆåŠ›äºGoogle Brainå’ŒFacebook AIã€‚åšå£«æ¯•ä¸šäºç¾å›½å¡å†…åŸºæ¢…éš†å¤§å­¦ï¼Œæœ¬ç§‘æ¯•ä¸šäºæ¸…åå¤§å­¦
 
### 1. ä»€ä¹ˆæ˜¯XLNet

- [XLNeté¢„è®­ç»ƒæ¨¡å‹ï¼Œçœ‹è¿™ç¯‡å°±å¤Ÿäº†ï¼(ä»£ç å®ç°)](https://www.cnblogs.com/mantch/p/11611554.html)
 
XLNet æ˜¯ä¸€ä¸ªç±»ä¼¼ BERT çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯å®Œå…¨ä¸åŒçš„æ¨¡å‹ã€‚æ€»ä¹‹ï¼Œ**XLNetæ˜¯ä¸€ç§é€šç”¨çš„è‡ªå›å½’é¢„è®­ç»ƒæ–¹æ³•**ã€‚å®ƒæ˜¯CMUå’ŒGoogle Brainå›¢é˜Ÿåœ¨2019å¹´6æœˆä»½å‘å¸ƒçš„æ¨¡å‹ï¼Œæœ€ç»ˆï¼ŒXLNet åœ¨ 20 ä¸ªä»»åŠ¡ä¸Šè¶…è¿‡äº† BERT çš„è¡¨ç°ï¼Œå¹¶åœ¨ 18 ä¸ªä»»åŠ¡ä¸Šå–å¾—äº†å½“å‰æœ€ä½³æ•ˆæœï¼ˆstate-of-the-artï¼‰ï¼ŒåŒ…æ‹¬æœºå™¨é—®ç­”ã€è‡ªç„¶è¯­è¨€æ¨æ–­ã€æƒ…æ„Ÿåˆ†æå’Œæ–‡æ¡£æ’åºã€‚

BERT è¿™æ ·åŸºäºå»å™ªè‡ªç¼–ç å™¨çš„é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥å¾ˆå¥½åœ°å»ºæ¨¡åŒå‘è¯­å¢ƒä¿¡æ¯ï¼Œæ€§èƒ½ä¼˜äºåŸºäºè‡ªå›å½’è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äºéœ€è¦ mask ä¸€éƒ¨åˆ†è¾“å…¥ï¼ŒBERT å¿½ç•¥äº†è¢« mask ä½ç½®ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œå› æ­¤å‡ºç°é¢„è®­ç»ƒå’Œå¾®è°ƒæ•ˆæœçš„å·®å¼‚ï¼ˆpretrain-finetune discrepancyï¼‰ã€‚

åŸºäºè¿™äº›ä¼˜ç¼ºç‚¹ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ³›åŒ–çš„è‡ªå›å½’é¢„è®­ç»ƒæ¨¡å‹ XLNetã€‚XLNet å¯ä»¥ï¼š
1.  é€šè¿‡æœ€å¤§åŒ–æ‰€æœ‰å¯èƒ½çš„å› å¼åˆ†è§£é¡ºåºçš„å¯¹æ•°ä¼¼ç„¶ï¼Œå­¦ä¹ åŒå‘è¯­å¢ƒä¿¡æ¯ï¼›
2.  ç”¨è‡ªå›å½’æœ¬èº«çš„ç‰¹ç‚¹å…‹æœ BERT çš„ç¼ºç‚¹ï¼›
3.  æ­¤å¤–ï¼ŒXLNet è¿˜èåˆäº†å½“å‰æœ€ä¼˜è‡ªå›å½’æ¨¡å‹ Transformer-XL çš„æ€è·¯ã€‚
 
### 2. è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆAutoregressive LMï¼‰

åœ¨ELMOï¼BERTå‡ºæ¥ä¹‹å‰ï¼Œå¤§å®¶é€šå¸¸è®²çš„è¯­è¨€æ¨¡å‹å…¶å®æ˜¯æ ¹æ®ä¸Šæ–‡å†…å®¹é¢„æµ‹ä¸‹ä¸€ä¸ªå¯èƒ½è·Ÿéšçš„å•è¯ï¼Œå°±æ˜¯å¸¸è¯´çš„è‡ªå·¦å‘å³çš„è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼Œæˆ–è€…åè¿‡æ¥ä¹Ÿè¡Œï¼Œå°±æ˜¯æ ¹æ®ä¸‹æ–‡é¢„æµ‹å‰é¢çš„å•è¯ï¼Œè¿™ç§ç±»å‹çš„LMè¢«ç§°ä¸ºè‡ªå›å½’è¯­è¨€æ¨¡å‹ã€‚GPT å°±æ˜¯å…¸å‹çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ã€‚ELMOå°½ç®¡çœ‹ä¸Šå»åˆ©ç”¨äº†ä¸Šæ–‡ï¼Œä¹Ÿåˆ©ç”¨äº†ä¸‹æ–‡ï¼Œä½†æ˜¯æœ¬è´¨ä¸Šä»ç„¶æ˜¯è‡ªå›å½’LMï¼Œè¿™ä¸ªè·Ÿæ¨¡å‹å…·ä½“æ€ä¹ˆå®ç°æœ‰å…³ç³»ã€‚ELMOæ˜¯åšäº†ä¸¤ä¸ªæ–¹å‘ï¼ˆä»å·¦åˆ°å³ä»¥åŠä»å³åˆ°å·¦ä¸¤ä¸ªæ–¹å‘çš„è¯­è¨€æ¨¡å‹ï¼‰ï¼Œä½†æ˜¯æ˜¯åˆ†åˆ«æœ‰ä¸¤ä¸ªæ–¹å‘çš„è‡ªå›å½’LMï¼Œç„¶åæŠŠLSTMçš„ä¸¤ä¸ªæ–¹å‘çš„éšèŠ‚ç‚¹çŠ¶æ€æ‹¼æ¥åˆ°ä¸€èµ·ï¼Œæ¥ä½“ç°åŒå‘è¯­è¨€æ¨¡å‹è¿™ä¸ªäº‹æƒ…çš„ã€‚æ‰€ä»¥å…¶å®æ˜¯ä¸¤ä¸ªè‡ªå›å½’è¯­è¨€æ¨¡å‹çš„æ‹¼æ¥ï¼Œæœ¬è´¨ä¸Šä»ç„¶æ˜¯è‡ªå›å½’è¯­è¨€æ¨¡å‹ã€‚
 
è‡ªå›å½’è¯­è¨€æ¨¡å‹æœ‰ä¼˜ç‚¹æœ‰ç¼ºç‚¹ï¼š
- **ç¼ºç‚¹**æ˜¯åªèƒ½åˆ©ç”¨ä¸Šæ–‡æˆ–è€…ä¸‹æ–‡çš„ä¿¡æ¯ï¼Œä¸èƒ½åŒæ—¶åˆ©ç”¨ä¸Šæ–‡å’Œä¸‹æ–‡çš„ä¿¡æ¯ï¼Œå½“ç„¶ï¼Œè²Œä¼¼ELMOè¿™ç§åŒå‘éƒ½åšï¼Œç„¶åæ‹¼æ¥çœ‹ä¸Šå»èƒ½å¤Ÿè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºèåˆæ¨¡å¼è¿‡äºç®€å•ï¼Œæ‰€ä»¥æ•ˆæœå…¶å®å¹¶ä¸æ˜¯å¤ªå¥½ã€‚
- **ä¼˜ç‚¹**å…¶å®è·Ÿä¸‹æ¸¸NLPä»»åŠ¡æœ‰å…³ï¼Œæ¯”å¦‚ç”Ÿæˆç±»NLPä»»åŠ¡ï¼Œæ¯”å¦‚æ–‡æœ¬æ‘˜è¦ï¼Œæœºå™¨ç¿»è¯‘ç­‰ï¼Œåœ¨å®é™…ç”Ÿæˆå†…å®¹çš„æ—¶å€™ï¼Œå°±æ˜¯ä»å·¦å‘å³çš„ï¼Œè‡ªå›å½’è¯­è¨€æ¨¡å‹å¤©ç„¶åŒ¹é…è¿™ä¸ªè¿‡ç¨‹ã€‚è€ŒBertè¿™ç§DAEæ¨¡å¼ï¼Œåœ¨ç”Ÿæˆç±»NLPä»»åŠ¡ä¸­ï¼Œå°±é¢ä¸´è®­ç»ƒè¿‡ç¨‹å’Œåº”ç”¨è¿‡ç¨‹ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå¯¼è‡´ç”Ÿæˆç±»çš„NLPä»»åŠ¡åˆ°ç›®å‰ä¸ºæ­¢éƒ½åšä¸å¤ªå¥½ã€‚
 
### 3. è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆAutoencoder LMï¼‰
 
è‡ªå›å½’è¯­è¨€æ¨¡å‹åªèƒ½æ ¹æ®ä¸Šæ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œæˆ–è€…åè¿‡æ¥ï¼Œåªèƒ½æ ¹æ®ä¸‹æ–‡é¢„æµ‹å‰é¢ä¸€ä¸ªå•è¯ã€‚ç›¸æ¯”è€Œè¨€ï¼ŒBerté€šè¿‡åœ¨è¾“å…¥Xä¸­éšæœºMaskæ‰ä¸€éƒ¨åˆ†å•è¯ï¼Œç„¶åé¢„è®­ç»ƒè¿‡ç¨‹çš„ä¸»è¦ä»»åŠ¡ä¹‹ä¸€æ˜¯æ ¹æ®ä¸Šä¸‹æ–‡å•è¯æ¥é¢„æµ‹è¿™äº›è¢«Maskæ‰çš„å•è¯ï¼Œå¦‚æœä½ å¯¹Denoising Autoencoderæ¯”è¾ƒç†Ÿæ‚‰çš„è¯ï¼Œä¼šçœ‹å‡ºï¼Œè¿™ç¡®å®æ˜¯å…¸å‹çš„DAEçš„æ€è·¯ã€‚é‚£äº›è¢«Maskæ‰çš„å•è¯å°±æ˜¯åœ¨è¾“å…¥ä¾§åŠ å…¥çš„æ‰€è°“å™ªéŸ³ã€‚ç±»ä¼¼Bertè¿™ç§é¢„è®­ç»ƒæ¨¡å¼ï¼Œè¢«ç§°ä¸ºDAE LMã€‚
 
è¿™ç§DAE LMçš„ä¼˜ç¼ºç‚¹æ­£å¥½å’Œè‡ªå›å½’LMåè¿‡æ¥ï¼Œå®ƒèƒ½æ¯”è¾ƒè‡ªç„¶åœ°èå…¥åŒå‘è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶çœ‹åˆ°è¢«é¢„æµ‹å•è¯çš„ä¸Šæ–‡å’Œä¸‹æ–‡ï¼Œè¿™æ˜¯å¥½å¤„ã€‚ç¼ºç‚¹æ˜¯å•¥å‘¢ï¼Ÿä¸»è¦åœ¨è¾“å…¥ä¾§å¼•å…¥\[Mask\]æ ‡è®°ï¼Œå¯¼è‡´é¢„è®­ç»ƒé˜¶æ®µå’ŒFine-tuningé˜¶æ®µä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå› ä¸ºFine-tuningé˜¶æ®µæ˜¯çœ‹ä¸åˆ°\[Mask\]æ ‡è®°çš„ã€‚DAEå—ï¼Œå°±è¦å¼•å…¥å™ªéŸ³ï¼Œ\[Mask\] æ ‡è®°å°±æ˜¯å¼•å…¥å™ªéŸ³çš„æ‰‹æ®µï¼Œè¿™ä¸ªæ­£å¸¸ã€‚
 
XLNetçš„å‡ºå‘ç‚¹å°±æ˜¯ï¼šèƒ½å¦èåˆè‡ªå›å½’LMå’ŒDAE LMä¸¤è€…çš„ä¼˜ç‚¹ã€‚å°±æ˜¯è¯´å¦‚æœç«™åœ¨è‡ªå›å½’LMçš„è§’åº¦ï¼Œå¦‚ä½•å¼•å…¥å’ŒåŒå‘è¯­è¨€æ¨¡å‹ç­‰ä»·çš„æ•ˆæœï¼›å¦‚æœç«™åœ¨DAE LMçš„è§’åº¦çœ‹ï¼Œå®ƒæœ¬èº«æ˜¯èå…¥åŒå‘è¯­è¨€æ¨¡å‹çš„ï¼Œå¦‚ä½•æŠ›æ‰è¡¨é¢çš„é‚£ä¸ª\[Mask\]æ ‡è®°ï¼Œè®©é¢„è®­ç»ƒå’ŒFine-tuningä¿æŒä¸€è‡´ã€‚å½“ç„¶ï¼ŒXLNetè¿˜è®²åˆ°äº†ä¸€ä¸ªBertè¢«Maskå•è¯ä¹‹é—´ç›¸äº’ç‹¬ç«‹çš„é—®é¢˜ã€‚
 
### 4. XLNetæ¨¡å‹
 
#### 4.1 æ’åˆ—è¯­è¨€å»ºæ¨¡ï¼ˆPermutation Language Modelingï¼‰
 
Bertçš„è‡ªç¼–ç è¯­è¨€æ¨¡å‹ä¹Ÿæœ‰å¯¹åº”çš„ç¼ºç‚¹ï¼Œå°±æ˜¯XLNetåœ¨æ–‡ä¸­æŒ‡å‡ºçš„ï¼š
1.  ç¬¬ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µå› ä¸ºé‡‡å–å¼•å…¥\[Mask\]æ ‡è®°æ¥Maskæ‰éƒ¨åˆ†å•è¯çš„è®­ç»ƒæ¨¡å¼ï¼Œè€ŒFine-tuningé˜¶æ®µæ˜¯çœ‹ä¸åˆ°è¿™ç§è¢«å¼ºè¡ŒåŠ å…¥çš„Maskæ ‡è®°çš„ï¼Œæ‰€ä»¥ä¸¤ä¸ªé˜¶æ®µå­˜åœ¨ä½¿ç”¨æ¨¡å¼ä¸ä¸€è‡´çš„æƒ…å½¢ï¼Œè¿™å¯èƒ½ä¼šå¸¦æ¥ä¸€å®šçš„æ€§èƒ½æŸå¤±ï¼› 
2.  å¦å¤–ä¸€ä¸ªæ˜¯ï¼ŒBertåœ¨ç¬¬ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µï¼Œå‡è®¾å¥å­ä¸­å¤šä¸ªå•è¯è¢«Maskæ‰ï¼Œè¿™äº›è¢«Maskæ‰çš„å•è¯ä¹‹é—´æ²¡æœ‰ä»»ä½•å…³ç³»ï¼Œæ˜¯æ¡ä»¶ç‹¬ç«‹çš„ï¼Œè€Œæœ‰æ—¶å€™è¿™äº›å•è¯ä¹‹é—´æ˜¯æœ‰å…³ç³»çš„ã€‚
 
ä¸Šé¢ä¸¤ç‚¹æ˜¯XLNetåœ¨ç¬¬ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µï¼Œç›¸å¯¹Bertæ¥è¯´è¦è§£å†³çš„ä¸¤ä¸ªé—®é¢˜ã€‚
 
å…¶å®æ€è·¯ä¹Ÿæ¯”è¾ƒç®€æ´ï¼Œå¯ä»¥è¿™ä¹ˆæ€è€ƒï¼šXLNetä»ç„¶éµå¾ªä¸¤é˜¶æ®µçš„è¿‡ç¨‹ï¼Œç¬¬ä¸€ä¸ªé˜¶æ®µæ˜¯è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒé˜¶æ®µï¼›ç¬¬äºŒé˜¶æ®µæ˜¯ä»»åŠ¡æ•°æ®Fine-tuningé˜¶æ®µã€‚å®ƒä¸»è¦å¸Œæœ›æ”¹åŠ¨ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œå°±æ˜¯è¯´ä¸åƒBerté‚£ç§å¸¦Maskç¬¦å·çš„Denoising-autoencoderçš„æ¨¡å¼ï¼Œè€Œæ˜¯é‡‡ç”¨è‡ªå›å½’LMçš„æ¨¡å¼ã€‚å°±æ˜¯è¯´ï¼Œçœ‹ä¸Šå»è¾“å…¥å¥å­Xä»ç„¶æ˜¯è‡ªå·¦å‘å³çš„è¾“å…¥ï¼Œçœ‹åˆ°Tiå•è¯çš„ä¸Šæ–‡Context\_beforeï¼Œæ¥é¢„æµ‹Tiè¿™ä¸ªå•è¯ã€‚ä½†æ˜¯åˆå¸Œæœ›åœ¨Context\_beforeé‡Œï¼Œä¸ä»…ä»…çœ‹åˆ°ä¸Šæ–‡å•è¯ï¼Œä¹Ÿèƒ½çœ‹åˆ°Tiå•è¯åé¢çš„ä¸‹æ–‡Context_afteré‡Œçš„ä¸‹æ–‡å•è¯ï¼Œè¿™æ ·çš„è¯ï¼ŒBerté‡Œé¢é¢„è®­ç»ƒé˜¶æ®µå¼•å…¥çš„Maskç¬¦å·å°±ä¸éœ€è¦äº†ï¼Œäºæ˜¯åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œçœ‹ä¸Šå»æ˜¯ä¸ªæ ‡å‡†çš„ä»å·¦å‘å³è¿‡ç¨‹ï¼ŒFine-tuningå½“ç„¶ä¹Ÿæ˜¯è¿™ä¸ªè¿‡ç¨‹ï¼Œäºæ˜¯ä¸¤ä¸ªç¯èŠ‚å°±ç»Ÿä¸€èµ·æ¥ã€‚å½“ç„¶ï¼Œè¿™æ˜¯ç›®æ ‡ã€‚å‰©ä¸‹æ˜¯æ€ä¹ˆåšåˆ°è¿™ä¸€ç‚¹çš„é—®é¢˜ã€‚
- ![](https://pic4.zhimg.com/80/v2-948e085be7a9a2eb7eac2d12069b1a93_hd.jpg)
 
é¦–å…ˆï¼Œéœ€è¦å¼ºè°ƒä¸€ç‚¹ï¼Œå°½ç®¡ä¸Šé¢è®²çš„æ˜¯æŠŠå¥å­Xçš„å•è¯æ’åˆ—ç»„åˆåï¼Œå†éšæœºæŠ½å–ä¾‹å­ä½œä¸ºè¾“å…¥ï¼Œä½†æ˜¯ï¼Œå®é™…ä¸Šä½ æ˜¯ä¸èƒ½è¿™ä¹ˆåšçš„ï¼Œå› ä¸ºFine-tuningé˜¶æ®µä½ ä¸å¯èƒ½ä¹Ÿå»æ’åˆ—ç»„åˆåŸå§‹è¾“å…¥ã€‚æ‰€ä»¥ï¼Œå°±å¿…é¡»è®©é¢„è®­ç»ƒé˜¶æ®µçš„è¾“å…¥éƒ¨åˆ†ï¼Œçœ‹ä¸Šå»ä»ç„¶æ˜¯x1,x2,x3,x4è¿™ä¸ªè¾“å…¥é¡ºåºï¼Œä½†æ˜¯å¯ä»¥åœ¨Transformeréƒ¨åˆ†åšäº›å·¥ä½œï¼Œæ¥è¾¾æˆæˆ‘ä»¬å¸Œæœ›çš„ç›®æ ‡ã€‚
 
å…·ä½“è€Œè¨€ï¼ŒXLNeté‡‡å–äº†Attentionæ©ç çš„æœºåˆ¶ï¼Œä½ å¯ä»¥ç†è§£ä¸ºï¼Œå½“å‰çš„è¾“å…¥å¥å­æ˜¯Xï¼Œè¦é¢„æµ‹çš„å•è¯Tiæ˜¯ç¬¬iä¸ªå•è¯ï¼Œå‰é¢1åˆ°i-1ä¸ªå•è¯ï¼Œåœ¨è¾“å…¥éƒ¨åˆ†è§‚å¯Ÿï¼Œå¹¶æ²¡å‘ç”Ÿå˜åŒ–ï¼Œè¯¥æ˜¯è°è¿˜æ˜¯è°ã€‚ä½†æ˜¯åœ¨Transformerå†…éƒ¨ï¼Œé€šè¿‡Attentionæ©ç ï¼Œä»Xçš„è¾“å…¥å•è¯é‡Œé¢ï¼Œä¹Ÿå°±æ˜¯Tiçš„ä¸Šæ–‡å’Œä¸‹æ–‡å•è¯ä¸­ï¼Œéšæœºé€‰æ‹©i-1ä¸ªï¼Œæ”¾åˆ°Tiçš„ä¸Šæ–‡ä½ç½®ä¸­ï¼ŒæŠŠå…¶å®ƒå•è¯çš„è¾“å…¥é€šè¿‡Attentionæ©ç éšè—æ‰ï¼Œäºæ˜¯å°±èƒ½å¤Ÿè¾¾æˆæˆ‘ä»¬æœŸæœ›çš„ç›®æ ‡ï¼ˆå½“ç„¶è¿™ä¸ªæ‰€è°“æ”¾åˆ°Tiçš„ä¸Šæ–‡ä½ç½®ï¼Œåªæ˜¯ä¸€ç§å½¢è±¡çš„è¯´æ³•ï¼Œå…¶å®åœ¨å†…éƒ¨ï¼Œå°±æ˜¯é€šè¿‡Attention Maskï¼ŒæŠŠå…¶å®ƒæ²¡æœ‰è¢«é€‰åˆ°çš„å•è¯Maskæ‰ï¼Œä¸è®©å®ƒä»¬åœ¨é¢„æµ‹å•è¯Tiçš„æ—¶å€™å‘ç”Ÿä½œç”¨ï¼Œå¦‚æ­¤è€Œå·²ã€‚çœ‹ç€å°±ç±»ä¼¼äºæŠŠè¿™äº›è¢«é€‰ä¸­çš„å•è¯æ”¾åˆ°äº†ä¸Šæ–‡Context_beforeçš„ä½ç½®äº†ï¼‰ã€‚
 
å…·ä½“å®ç°çš„æ—¶å€™ï¼ŒXLNetæ˜¯ç”¨â€œåŒæµè‡ªæ³¨æ„åŠ›æ¨¡å‹â€å®ç°çš„ï¼Œç»†èŠ‚å¯ä»¥å‚è€ƒè®ºæ–‡ï¼Œä½†æ˜¯åŸºæœ¬æ€æƒ³å°±å¦‚ä¸Šæ‰€è¿°ï¼ŒåŒæµè‡ªæ³¨æ„åŠ›æœºåˆ¶åªæ˜¯å®ç°è¿™ä¸ªæ€æƒ³çš„å…·ä½“æ–¹å¼ï¼Œç†è®ºä¸Šï¼Œä½ å¯ä»¥æƒ³å‡ºå…¶å®ƒå…·ä½“å®ç°æ–¹å¼æ¥å®ç°è¿™ä¸ªåŸºæœ¬æ€æƒ³ï¼Œä¹Ÿèƒ½è¾¾æˆè®©Tiçœ‹åˆ°ä¸‹æ–‡å•è¯çš„ç›®æ ‡ã€‚
 
è¿™é‡Œç®€å•è¯´ä¸‹â€œ**åŒæµè‡ªæ³¨æ„åŠ›æœºåˆ¶**â€ï¼Œä¸€ä¸ªæ˜¯å†…å®¹æµè‡ªæ³¨æ„åŠ›ï¼Œå…¶å®å°±æ˜¯æ ‡å‡†çš„Transformerçš„è®¡ç®—è¿‡ç¨‹ï¼›ä¸»è¦æ˜¯å¼•å…¥äº†Queryæµè‡ªæ³¨æ„åŠ›ï¼Œè¿™ä¸ªæ˜¯å¹²å˜›çš„å‘¢ï¼Ÿå…¶å®å°±æ˜¯ç”¨æ¥ä»£æ›¿Bertçš„é‚£ä¸ª\[Mask\]æ ‡è®°çš„ï¼Œå› ä¸ºXLNetå¸Œæœ›æŠ›æ‰\[Mask\]æ ‡è®°ç¬¦å·ï¼Œä½†æ˜¯æ¯”å¦‚çŸ¥é“ä¸Šæ–‡å•è¯x1,x2ï¼Œè¦é¢„æµ‹å•è¯x3ï¼Œæ­¤æ—¶åœ¨x3å¯¹åº”ä½ç½®çš„Transformeræœ€é«˜å±‚å»é¢„æµ‹è¿™ä¸ªå•è¯ï¼Œä½†æ˜¯è¾“å…¥ä¾§ä¸èƒ½çœ‹åˆ°è¦é¢„æµ‹çš„å•è¯x3ï¼ŒBertå…¶å®æ˜¯ç›´æ¥å¼•å…¥\[Mask\]æ ‡è®°æ¥è¦†ç›–æ‰å•è¯x3çš„å†…å®¹çš„ï¼Œç­‰äºè¯´\[Mask\]æ˜¯ä¸ªé€šç”¨çš„å ä½ç¬¦å·ã€‚è€ŒXLNetå› ä¸ºè¦æŠ›æ‰\[Mask\]æ ‡è®°ï¼Œä½†æ˜¯åˆä¸èƒ½çœ‹åˆ°x3çš„è¾“å…¥ï¼Œäºæ˜¯Queryæµï¼Œå°±ç›´æ¥å¿½ç•¥æ‰x3è¾“å…¥äº†ï¼Œåªä¿ç•™è¿™ä¸ªä½ç½®ä¿¡æ¯ï¼Œç”¨å‚æ•°wæ¥ä»£è¡¨ä½ç½®çš„embeddingç¼–ç ã€‚å…¶å®XLNetåªæ˜¯æ‰”äº†è¡¨é¢çš„\[Mask\]å ä½ç¬¦å·ï¼Œå†…éƒ¨è¿˜æ˜¯å¼•å…¥Queryæµæ¥å¿½ç•¥æ‰è¢«Maskçš„è¿™ä¸ªå•è¯ã€‚å’ŒBertæ¯”ï¼Œåªæ˜¯å®ç°æ–¹å¼ä¸åŒè€Œå·²ã€‚
- ![](https://pic1.zhimg.com/80/v2-2bb1a60af4fe2fa751647fdce48e337c_hd.jpg)

ä¸Šé¢è®²çš„Permutation Language Modelæ˜¯XLNetçš„ä¸»è¦ç†è®ºåˆ›æ–°ï¼Œæ‰€ä»¥ä»‹ç»çš„æ¯”è¾ƒå¤šï¼Œä»æ¨¡å‹è§’åº¦è®²ï¼Œè¿™ä¸ªåˆ›æ–°è¿˜æ˜¯æŒºæœ‰æ„æ€çš„ï¼Œå› ä¸ºå®ƒå¼€å¯äº†è‡ªå›å½’è¯­è¨€æ¨¡å‹å¦‚ä½•å¼•å…¥ä¸‹æ–‡çš„ä¸€ä¸ªæ€è·¯ï¼Œç›¸ä¿¡å¯¹äºåç»­å·¥ä½œä¼šæœ‰å¯å‘ã€‚å½“ç„¶ï¼ŒXLNetä¸ä»…ä»…åšäº†è¿™äº›ï¼Œå®ƒè¿˜å¼•å…¥äº†å…¶å®ƒçš„å› ç´ ï¼Œä¹Ÿç®—æ˜¯ä¸€ä¸ªå½“å‰æœ‰æ•ˆæŠ€æœ¯çš„é›†æˆä½“ã€‚æ„Ÿè§‰**XLNetå°±æ˜¯Bertã€GPT 2.0å’ŒTransformer XLçš„ç»¼åˆä½“å˜èº«**ï¼š
1.  é¦–å…ˆï¼Œå®ƒé€šè¿‡PLM(Permutation Language Model)é¢„è®­ç»ƒç›®æ ‡ï¼Œå¸æ”¶äº†Bertçš„åŒå‘è¯­è¨€æ¨¡å‹ï¼›
2.  ç„¶åï¼ŒGPT2.0çš„æ ¸å¿ƒå…¶å®æ˜¯æ›´å¤šæ›´é«˜è´¨é‡çš„é¢„è®­ç»ƒæ•°æ®ï¼Œè¿™ä¸ªæ˜æ˜¾ä¹Ÿè¢«XLNetå¸æ”¶è¿›æ¥äº†ï¼›
3.  å†ç„¶åï¼ŒTransformer XLçš„ä¸»è¦æ€æƒ³ä¹Ÿè¢«å¸æ”¶è¿›æ¥ï¼Œå®ƒçš„ä¸»è¦ç›®æ ‡æ˜¯è§£å†³Transformerå¯¹äºé•¿æ–‡æ¡£NLPåº”ç”¨ä¸å¤Ÿå‹å¥½çš„é—®é¢˜ã€‚

#### 4.2 Transformer XL
 
ç›®å‰åœ¨NLPé¢†åŸŸä¸­ï¼Œå¤„ç†è¯­è¨€å»ºæ¨¡é—®é¢˜æœ‰ä¸¤ç§æœ€å…ˆè¿›çš„æ¶æ„ï¼šRNNå’ŒTransformerã€‚RNNæŒ‰ç…§åºåˆ—é¡ºåºé€ä¸ªå­¦ä¹ è¾“å…¥çš„å•è¯æˆ–å­—ç¬¦ä¹‹é—´çš„å…³ç³»ï¼Œè€ŒTransformeråˆ™æ¥æ”¶ä¸€æ•´æ®µåºåˆ—ï¼Œç„¶åä½¿ç”¨self-attentionæœºåˆ¶æ¥å­¦ä¹ å®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™ä¸¤ç§æ¶æ„ç›®å‰æ¥çœ‹éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆå°±ï¼Œä½†å®ƒä»¬éƒ½å±€é™åœ¨æ•æ‰é•¿æœŸä¾èµ–æ€§ä¸Šã€‚

ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒCMUè”åˆGoogle Brainåœ¨2019å¹´1æœˆæ¨å‡ºçš„ä¸€ç¯‡æ–°è®ºæ–‡ã€ŠTransformer-XLï¼šAttentive Language Models beyond a Fixed-Length Contextã€‹åŒæ—¶ç»“åˆäº†RNNåºåˆ—å»ºæ¨¡å’ŒTransformerè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ä¼˜ç‚¹ï¼Œåœ¨è¾“å…¥æ•°æ®çš„æ¯ä¸ªæ®µä¸Šä½¿ç”¨Transformerçš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶ä½¿ç”¨å¾ªç¯æœºåˆ¶æ¥å­¦ä¹ è¿ç»­æ®µä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚
 
4.2.1 vanilla Transformer
 
ä¸ºä½•è¦æè¿™ä¸ªæ¨¡å‹ï¼Ÿå› ä¸ºTransformer-XLæ˜¯åŸºäºè¿™ä¸ªæ¨¡å‹è¿›è¡Œçš„æ”¹è¿›ã€‚
 
Al-Rfouç­‰äººåŸºäºTransformeræå‡ºäº†ä¸€ç§è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œæ¥æ ¹æ®ä¹‹å‰çš„å­—ç¬¦é¢„æµ‹ç‰‡æ®µä¸­çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå®ƒä½¿ç”¨ ğ‘¥1,ğ‘¥2,...,ğ‘¥ğ‘›âˆ’1x1,x2,...,xnâˆ’1 é¢„æµ‹å­—ç¬¦ ğ‘¥ğ‘›xnï¼Œè€Œåœ¨ ğ‘¥ğ‘›xn ä¹‹åçš„åºåˆ—åˆ™è¢«maskæ‰ã€‚è®ºæ–‡ä¸­ä½¿ç”¨64å±‚æ¨¡å‹ï¼Œå¹¶ä»…é™äºå¤„ç† 512ä¸ªå­—ç¬¦è¿™ç§ç›¸å¯¹è¾ƒçŸ­çš„è¾“å…¥ï¼Œå› æ­¤å®ƒå°†è¾“å…¥åˆ†æˆæ®µï¼Œå¹¶åˆ†åˆ«ä»æ¯ä¸ªæ®µä¸­è¿›è¡Œå­¦ä¹ ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ åœ¨æµ‹è¯•é˜¶æ®µå¦‚éœ€å¤„ç†è¾ƒé•¿çš„è¾“å…¥ï¼Œè¯¥æ¨¡å‹ä¼šåœ¨æ¯ä¸€æ­¥ä¸­å°†è¾“å…¥å‘å³ç§»åŠ¨ä¸€ä¸ªå­—ç¬¦ï¼Œä»¥æ­¤å®ç°å¯¹å•ä¸ªå­—ç¬¦çš„é¢„æµ‹ã€‚
- ![](https://img-blog.csdnimg.cn/20190407095512873.png)
 
è¯¥æ¨¡å‹åœ¨å¸¸ç”¨çš„æ•°æ®é›†å¦‚enwik8å’Œtext8ä¸Šçš„è¡¨ç°æ¯”RNNæ¨¡å‹è¦å¥½ï¼Œä½†å®ƒä»æœ‰ä»¥ä¸‹ç¼ºç‚¹ï¼š
*   **ä¸Šä¸‹æ–‡é•¿åº¦å—é™**ï¼šå­—ç¬¦ä¹‹é—´çš„æœ€å¤§ä¾èµ–è·ç¦»å—è¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼Œæ¨¡å‹çœ‹ä¸åˆ°å‡ºç°åœ¨å‡ ä¸ªå¥å­ä¹‹å‰çš„å•è¯ã€‚
*   **ä¸Šä¸‹æ–‡ç¢ç‰‡**ï¼šå¯¹äºé•¿åº¦è¶…è¿‡512ä¸ªå­—ç¬¦çš„æ–‡æœ¬ï¼Œéƒ½æ˜¯ä»å¤´å¼€å§‹å•ç‹¬è®­ç»ƒçš„ã€‚æ®µä¸æ®µä¹‹é—´æ²¡æœ‰ä¸Šä¸‹æ–‡ä¾èµ–æ€§ï¼Œä¼šè®©è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œä¹Ÿä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€‚
*   **æ¨ç†é€Ÿåº¦æ…¢**ï¼šåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¯æ¬¡é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œéƒ½éœ€è¦é‡æ–°æ„å»ºä¸€éä¸Šä¸‹æ–‡ï¼Œå¹¶ä»å¤´å¼€å§‹è®¡ç®—ï¼Œè¿™æ ·çš„è®¡ç®—é€Ÿåº¦éå¸¸æ…¢ã€‚
    
 4.2.2 Transformer XL
 
Transformer-XLæ¶æ„åœ¨vanilla Transformerçš„åŸºç¡€ä¸Šå¼•å…¥äº†ä¸¤ç‚¹åˆ›æ–°ï¼šå¾ªç¯æœºåˆ¶ï¼ˆRecurrence Mechanismï¼‰å’Œç›¸å¯¹ä½ç½®ç¼–ç ï¼ˆRelative Positional Encodingï¼‰ï¼Œä»¥å…‹æœvanilla Transformerçš„ç¼ºç‚¹ã€‚ä¸vanilla Transformerç›¸æ¯”ï¼ŒTransformer-XLçš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯å®ƒå¯ä»¥è¢«ç”¨äºå•è¯çº§å’Œå­—ç¬¦çº§çš„è¯­è¨€å»ºæ¨¡ã€‚
 
1.  **å¼•å…¥å¾ªç¯æœºåˆ¶**

ä¸vanilla Transformerçš„åŸºæœ¬æ€è·¯ä¸€æ ·ï¼ŒTransformer-XLä»ç„¶æ˜¯ä½¿ç”¨åˆ†æ®µçš„æ–¹å¼è¿›è¡Œå»ºæ¨¡ï¼Œä½†å…¶ä¸vanilla Transformerçš„æœ¬è´¨ä¸åŒæ˜¯åœ¨äºå¼•å…¥äº†æ®µä¸æ®µé—´çš„å¾ªç¯æœºåˆ¶ï¼Œä½¿å¾—å½“å‰æ®µåœ¨å»ºæ¨¡çš„æ—¶å€™èƒ½å¤Ÿåˆ©ç”¨ä¹‹å‰æ®µçš„ä¿¡æ¯æ¥å®ç°é•¿æœŸä¾èµ–æ€§ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
- ![](https://img-blog.csdnimg.cn/20190407095601191.png)

åœ¨è®­ç»ƒé˜¶æ®µï¼Œå¤„ç†åé¢çš„æ®µæ—¶ï¼Œæ¯ä¸ªéšè—å±‚éƒ½ä¼šæ¥æ”¶ä¸¤ä¸ªè¾“å…¥ï¼š
- è¿™ä¸¤ä¸ªè¾“å…¥ä¼šè¢«æ‹¼æ¥ï¼Œç„¶åç”¨äºè®¡ç®—å½“å‰æ®µçš„Keyå’ŒValueçŸ©é˜µã€‚
- è¯¥æ–¹æ³•å¯ä»¥åˆ©ç”¨å‰é¢æ›´å¤šæ®µçš„ä¿¡æ¯ï¼Œæµ‹è¯•é˜¶æ®µä¹Ÿå¯ä»¥è·å¾—æ›´é•¿çš„ä¾èµ–ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œä¸vanilla Transformerç›¸æ¯”ï¼Œå…¶é€Ÿåº¦ä¹Ÿä¼šæ›´å¿«ã€‚åœ¨vanilla Transformerä¸­ï¼Œä¸€æ¬¡åªèƒ½å‰è¿›ä¸€ä¸ªstepï¼Œå¹¶ä¸”éœ€è¦é‡æ–°æ„å»ºæ®µï¼Œå¹¶å…¨éƒ¨ä»å¤´å¼€å§‹è®¡ç®—ï¼›è€Œåœ¨Transformer-XLä¸­ï¼Œæ¯æ¬¡å¯ä»¥å‰è¿›ä¸€æ•´ä¸ªæ®µï¼Œå¹¶åˆ©ç”¨ä¹‹å‰æ®µçš„æ•°æ®æ¥é¢„æµ‹å½“å‰æ®µçš„è¾“å‡ºã€‚
*   è¯¥æ®µçš„å‰é¢éšè—å±‚çš„è¾“å‡ºï¼Œä¸vanilla Transformerç›¸åŒï¼ˆä¸Šå›¾çš„ç°è‰²çº¿ï¼‰ã€‚
*   å‰é¢æ®µçš„éšè—å±‚çš„è¾“å‡ºï¼ˆä¸Šå›¾çš„ç»¿è‰²çº¿ï¼‰ï¼Œå¯ä»¥ä½¿æ¨¡å‹åˆ›å»ºé•¿æœŸä¾èµ–å…³ç³»ã€‚

3.  **ç›¸å¯¹ä½ç½®ç¼–ç **
    
åœ¨Transformerä¸­ï¼Œä¸€ä¸ªé‡è¦çš„åœ°æ–¹åœ¨äºå…¶è€ƒè™‘äº†åºåˆ—çš„ä½ç½®ä¿¡æ¯ã€‚åœ¨åˆ†æ®µçš„æƒ…å†µä¸‹ï¼Œå¦‚æœä»…ä»…å¯¹äºæ¯ä¸ªæ®µä»ç›´æ¥ä½¿ç”¨Transformerä¸­çš„ä½ç½®ç¼–ç ï¼Œå³æ¯ä¸ªä¸åŒæ®µåœ¨åŒä¸€ä¸ªä½ç½®ä¸Šçš„è¡¨ç¤ºä½¿ç”¨ç›¸åŒçš„ä½ç½®ç¼–ç ï¼Œå°±ä¼šå‡ºç°é—®é¢˜ã€‚æ¯”å¦‚ï¼Œç¬¬iâˆ’2i-2iâˆ’2æ®µå’Œç¬¬iâˆ’1i-1iâˆ’1æ®µçš„ç¬¬ä¸€ä¸ªä½ç½®å°†å…·æœ‰ç›¸åŒçš„ä½ç½®ç¼–ç ï¼Œä½†å®ƒä»¬å¯¹äºç¬¬iiiæ®µçš„å»ºæ¨¡é‡è¦æ€§æ˜¾ç„¶å¹¶ä¸ç›¸åŒï¼ˆä¾‹å¦‚ç¬¬iâˆ’2i-2iâˆ’2æ®µä¸­çš„ç¬¬ä¸€ä¸ªä½ç½®é‡è¦æ€§å¯èƒ½è¦ä½ä¸€äº›ï¼‰ã€‚å› æ­¤ï¼Œéœ€è¦å¯¹è¿™ç§ä½ç½®è¿›è¡ŒåŒºåˆ†ã€‚
    
è®ºæ–‡å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ä½ç½®ç¼–ç çš„æ–¹å¼ï¼Œå³ä¼šæ ¹æ®è¯ä¹‹é—´çš„ç›¸å¯¹è·ç¦»è€ŒéåƒTransformerä¸­çš„ç»å¯¹ä½ç½®è¿›è¡Œç¼–ç ã€‚ä»å¦ä¸€ä¸ªè§’åº¦æ¥è§£è¯»å…¬å¼çš„è¯ï¼Œå¯ä»¥å°†attentionçš„è®¡ç®—åˆ†ä¸ºå¦‚ä¸‹å››ä¸ªéƒ¨åˆ†ï¼š
    
è¯¦ç»†å…¬å¼è§ï¼š[Transformer-XLè§£è¯»ï¼ˆè®ºæ–‡ + PyTorchæºç ï¼‰](https://blog.csdn.net/magical_bubble/article/details/89060213)
    
*   åŸºäºå†…å®¹çš„â€œå¯»å€â€ï¼Œå³æ²¡æœ‰æ·»åŠ åŸå§‹ä½ç½®ç¼–ç çš„åŸå§‹åˆ†æ•°ã€‚
*   åŸºäºå†…å®¹çš„ä½ç½®åç½®ï¼Œå³ç›¸å¯¹äºå½“å‰å†…å®¹çš„ä½ç½®åå·®ã€‚
*   å…¨å±€çš„å†…å®¹åç½®ï¼Œç”¨äºè¡¡é‡keyçš„é‡è¦æ€§ã€‚
*   å…¨å±€çš„ä½ç½®åç½®ï¼Œæ ¹æ®queryå’Œkeyä¹‹é—´çš„è·ç¦»è°ƒæ•´é‡è¦æ€§ã€‚
 
### 5. XLNetä¸BERTæ¯”è¾ƒ
 
å°½ç®¡çœ‹ä¸Šå»ï¼ŒXLNetåœ¨é¢„è®­ç»ƒæœºåˆ¶å¼•å…¥çš„Permutation Language Modelè¿™ç§æ–°çš„é¢„è®­ç»ƒç›®æ ‡ï¼Œå’ŒBerté‡‡ç”¨Maskæ ‡è®°è¿™ç§æ–¹å¼ï¼Œæœ‰å¾ˆå¤§ä¸åŒã€‚å…¶å®ä½ æ·±å…¥æ€è€ƒä¸€ä¸‹ï¼Œä¼šå‘ç°ï¼Œä¸¤è€…æœ¬è´¨æ˜¯ç±»ä¼¼çš„ã€‚
 
**åŒºåˆ«ä¸»è¦åœ¨äº**ï¼š
* Bertæ˜¯ç›´æ¥åœ¨è¾“å…¥ç«¯æ˜¾ç¤ºåœ°é€šè¿‡å¼•å…¥Maskæ ‡è®°ï¼Œåœ¨è¾“å…¥ä¾§éšè—æ‰ä¸€éƒ¨åˆ†å•è¯ï¼Œè®©è¿™äº›å•è¯åœ¨é¢„æµ‹çš„æ—¶å€™ä¸å‘æŒ¥ä½œç”¨ï¼Œè¦æ±‚åˆ©ç”¨ä¸Šä¸‹æ–‡ä¸­å…¶å®ƒå•è¯å»é¢„æµ‹æŸä¸ªè¢«Maskæ‰çš„å•è¯ï¼›
* è€ŒXLNetåˆ™æŠ›å¼ƒæ‰è¾“å…¥ä¾§çš„Maskæ ‡è®°ï¼Œé€šè¿‡Attention Maskæœºåˆ¶ï¼Œåœ¨Transformerå†…éƒ¨éšæœºMaskæ‰ä¸€éƒ¨åˆ†å•è¯ï¼ˆè¿™ä¸ªè¢«Maskæ‰çš„å•è¯æ¯”ä¾‹è·Ÿå½“å‰å•è¯åœ¨å¥å­ä¸­çš„ä½ç½®æœ‰å…³ç³»ï¼Œä½ç½®è¶Šé å‰ï¼Œè¢«Maskæ‰çš„æ¯”ä¾‹è¶Šé«˜ï¼Œä½ç½®è¶Šé åï¼Œè¢«Maskæ‰çš„æ¯”ä¾‹è¶Šä½ï¼‰ï¼Œè®©è¿™äº›è¢«Maskæ‰çš„å•è¯åœ¨é¢„æµ‹æŸä¸ªå•è¯çš„æ—¶å€™ä¸å‘ç”Ÿä½œç”¨ã€‚
    
 
æ‰€ä»¥ï¼Œæœ¬è´¨ä¸Šä¸¤è€…å¹¶æ²¡ä»€ä¹ˆå¤ªå¤§çš„ä¸åŒï¼Œåªæ˜¯Maskçš„ä½ç½®ï¼ŒBertæ›´è¡¨é¢åŒ–ä¸€äº›ï¼ŒXLNetåˆ™æŠŠè¿™ä¸ªè¿‡ç¨‹éšè—åœ¨äº†Transformerå†…éƒ¨è€Œå·²ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥æŠ›æ‰è¡¨é¢çš„\[Mask\]æ ‡è®°ï¼Œè§£å†³å®ƒæ‰€è¯´çš„é¢„è®­ç»ƒé‡Œå¸¦æœ‰\[Mask\]æ ‡è®°å¯¼è‡´çš„å’ŒFine-tuningè¿‡ç¨‹ä¸ä¸€è‡´çš„é—®é¢˜ã€‚è‡³äºè¯´XLNetè¯´çš„ï¼ŒBerté‡Œé¢è¢«Maskæ‰å•è¯çš„ç›¸äº’ç‹¬ç«‹é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨é¢„æµ‹æŸä¸ªè¢«Maskå•è¯çš„æ—¶å€™ï¼Œå…¶å®ƒè¢«Maskå•è¯ä¸èµ·ä½œç”¨ï¼Œè¿™ä¸ªé—®é¢˜ï¼Œä½ æ·±å…¥æ€è€ƒä¸€ä¸‹ï¼Œå…¶å®æ˜¯ä¸é‡è¦çš„ï¼Œå› ä¸ºXLNetåœ¨å†…éƒ¨Attention Maskçš„æ—¶å€™ï¼Œä¹Ÿä¼šMaskæ‰ä¸€å®šæ¯”ä¾‹çš„ä¸Šä¸‹æ–‡å•è¯ï¼Œåªè¦æœ‰ä¸€éƒ¨åˆ†è¢«Maskæ‰çš„å•è¯ï¼Œå…¶å®å°±é¢ä¸´è¿™ä¸ªé—®é¢˜ã€‚è€Œå¦‚æœè®­ç»ƒæ•°æ®è¶³å¤Ÿå¤§ï¼Œå…¶å®ä¸é å½“å‰è¿™ä¸ªä¾‹å­ï¼Œé å…¶å®ƒä¾‹å­ï¼Œä¹Ÿèƒ½å¼¥è¡¥è¢«Maskå•è¯ç›´æ¥çš„ç›¸äº’å…³ç³»é—®é¢˜ï¼Œå› ä¸ºæ€»æœ‰å…¶å®ƒä¾‹å­èƒ½å¤Ÿå­¦ä¼šè¿™äº›å•è¯çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚
 
å½“ç„¶ï¼ŒXLNetè¿™ç§æ”¹é€ ï¼Œç»´æŒäº†è¡¨é¢çœ‹ä¸Šå»çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„ä»å·¦å‘å³çš„æ¨¡å¼ï¼Œè¿™ä¸ªBertåšä¸åˆ°ï¼Œè¿™ä¸ªæœ‰æ˜æ˜¾çš„å¥½å¤„ï¼Œå°±æ˜¯å¯¹äºç”Ÿæˆç±»çš„ä»»åŠ¡ï¼Œèƒ½å¤Ÿåœ¨ç»´æŒè¡¨é¢ä»å·¦å‘å³çš„ç”Ÿæˆè¿‡ç¨‹å‰æä¸‹ï¼Œæ¨¡å‹é‡Œéšå«äº†ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ã€‚æ‰€ä»¥çœ‹ä¸Šå»ï¼ŒXLNetè²Œä¼¼åº”è¯¥å¯¹äºç”Ÿæˆç±»å‹çš„NLPä»»åŠ¡ï¼Œä¼šæ¯”Bertæœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚å¦å¤–ï¼Œå› ä¸ºXLNetè¿˜å¼•å…¥äº†Transformer XLçš„æœºåˆ¶ï¼Œæ‰€ä»¥å¯¹äºé•¿æ–‡æ¡£è¾“å…¥ç±»å‹çš„NLPä»»åŠ¡ï¼Œä¹Ÿä¼šæ¯”Bertæœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

6\. ä»£ç å®ç°
- [ä¸­æ–‡XLNeté¢„è®­ç»ƒæ¨¡å‹](https://github.com/ymcui/Chinese-PreTrained-XLNet)


## 2023.5.24 RWKV

ã€2023-5-24ã€‘[RWKVè®ºæ–‡ç‡ƒçˆ†ï¼å°†RNNå´›èµ·è¿›è¡Œåˆ°åº•ï¼å¯æ‰©ç™¾äº¿çº§å‚æ•°ï¼Œä¸Transformerè¡¨ç°ç›¸å½“](https://mp.weixin.qq.com/s/JokJttEBlXm2b8Zew4m1mw)

RWKVç»“åˆäº†RNNå’ŒTransformerçš„ä¼˜åŠ¿ï¼š
- ä¸€æ–¹é¢ï¼ŒæŠ›å¼ƒä¼ ç»Ÿçš„**ç‚¹ç§¯è‡ªæ³¨æ„åŠ›**ï¼Œä½¿ç”¨**çº¿æ€§æ³¨æ„åŠ›**ï¼Œè§£å†³transformerå†…å­˜å’Œè®¡ç®—å¤æ‚åº¦éšåºåˆ—å¢é•¿å‘ˆ**å¹³æ–¹**ç¼©æ”¾çš„ç“¶é¢ˆï¼›
- å¦ä¸€æ–¹é¢ï¼Œçªç ´äº†RNNæ¢¯åº¦æ¶ˆå¤±ã€å¹¶è¡ŒåŒ–å’Œå¯æ‰©å±•æ€§ç­‰é™åˆ¶ã€‚

å®ç° O(Td) çš„æ—¶é—´å¤æ‚åº¦å’Œ O(d) çš„ç©ºé—´å¤æ‚åº¦ï¼

- è®ºæ–‡ï¼š[RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/pdf/2305.13048.pdf)
- ä»£ç : [RWKV-LM](https://github.com/BlinkDL/RWKV-LM), [æ¨¡å‹](https://huggingface.co/BlinkDL/rwkv-4-raven)

é—®é¢˜
- RNNåˆ†è§£ä¸ºä¸¤ä¸ª**çº¿æ€§å—**ï¼ˆå’Œï¼‰å’Œä¸€ä¸ªç‰¹å®šäº**RNNå—**ï¼Œä½†å¯¹äºå…ˆå‰**æ—¶é—´æ­¥çš„æ•°æ®ä¾èµ–**é˜»æ­¢äº†RNNçš„å¹¶è¡ŒåŒ–ã€‚
- RWKVä¸QRNNå’ŒRNNï¼ˆVanillaã€LSTMã€GRUç­‰ï¼‰çš„æ¶æ„å¯¹æ¯”

RWKV æ¨¡å‹æ¶æ„
- The Receptance Weighted Key Value (RWKV) çš„åå­—æ¥è‡ªäºæ—¶é—´æ··åˆ (time-mixing) å’Œé€šé“æ··åˆ (channel-mixing) å—ä¸­ä½¿ç”¨çš„å››ä¸ªä¸»è¦å…ƒç´ ï¼š
- `R` (Receptance) ï¼šæ¥å—è¿‡å»ä¿¡æ¯çš„æ¥å—å‘é‡ï¼›
- `W` (Weight)ï¼šä½ç½®æƒé‡è¡°å‡å‘é‡ï¼ˆå¯è®­ç»ƒçš„æ¨¡å‹å‚æ•°ï¼‰ï¼›
- `K` (Key) ï¼šé”®æ˜¯ç±»ä¼¼äºä¼ ç»Ÿæ³¨æ„åŠ›ä¸­çš„å‘é‡ï¼›
- `V` (Value)ï¼šå€¼æ˜¯ç±»ä¼¼äºä¼ ç»Ÿæ³¨æ„åŠ›ä¸­çš„å‘é‡ã€‚

æ¯ä¸ªæ—¶é—´æ­¥ï¼Œä¸»è¦å…ƒç´ ä¹‹é—´é€šè¿‡ä¹˜æ³•è¿›è¡Œäº¤äº’ã€‚

RWKV æ¶æ„ç”±ä¸€ç³»åˆ—å †å çš„æ®‹å·®å—ç»„æˆï¼Œæ¯ä¸ªæ®‹å·®å—ç”±å…·æœ‰å¾ªç¯ç»“æ„çš„æ—¶é—´æ··åˆå’Œé€šé“æ··åˆå­å—ç»„æˆã€‚

æ•ˆæœ
- ä¸å…·æœ‰ç›¸åŒå‚æ•°å’Œè®­ç»ƒtokenæ•°é‡çš„ä¼ ç»Ÿtransformeræ¶æ„ï¼ˆPythiaã€OPTã€BLOOMã€GPT-Neoï¼‰ç›¸æ¯”ï¼ŒRWKVåœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ï¼ˆWinograndeã€PIQAã€ARC-Cã€ARC-Eã€LAMBADAå’ŒSciQï¼‰ä¸Šå‡å…·æœ‰ç«äº‰åŠ›ã€‚RWKVç”šè‡³åœ¨å››é¡¹ä»»åŠ¡ä¸­è¶…è¶Šäº†Pythiaå’ŒGPT-Neo.

RWKV-4å’ŒChatGPT / GPT-4çš„æ¯”è¾ƒç ”ç©¶æ˜¾ç¤ºï¼ŒRWKV-4å¯¹æç¤ºå·¥ç¨‹éå¸¸æ•æ„Ÿã€‚å½“å°†æŒ‡ä»¤é£æ ¼ä»é€‚åˆGPTè°ƒæ•´ä¸ºæ›´é€‚åˆRWKVæ—¶ï¼ŒRTEçš„F1æ€§èƒ½ç”šè‡³ä»44.2ï¼…å¢åŠ åˆ°74.8ï¼…ã€‚ä½œè€…çŒœæƒ³æ˜¯å› ä¸ºRNNä¸èƒ½å›æº¯å¤„ç† ( retrospective processing) æ¥é‡æ–°è°ƒæ•´å…ˆå‰ä¿¡æ¯çš„æƒé‡ã€‚å› æ­¤ä¸ºäº†è®©æ€§èƒ½æ›´å¥½ï¼ŒæœŸæœ›ä¿¡æ¯åº”è¯¥åœ¨é—®é¢˜ä¹‹åå±•ç¤ºã€‚

RWKVä¸Transformerè¡¨ç°ç›¸å½“ï¼Œä¸”èƒ½åœ¨è®­ç»ƒæ—¶èƒ½å¤Ÿå¹¶è¡Œã€åœ¨æ¨ç†æ—¶ä¿æŒæ’å®šçš„è®¡ç®—å’Œå†…å­˜å¤æ‚åº¦ã€‚

ä½†RWKVä¹Ÿå­˜åœ¨å±€é™ï¼š
- æ¯”èµ·æ ‡å‡†Transformerçš„å¹³æ–¹æ³¨æ„åŠ›æ‰€ç»´æŠ¤çš„å®Œæ•´ä¿¡æ¯ï¼Œ**çº¿æ€§æ³¨æ„åŠ›**å’Œ**é€’å½’æ¶æ„**ä½¿ä¿¡æ¯é€šè¿‡å•ä¸ªå‘é‡è¡¨ç¤ºåœ¨å¤šä¸ªæ—¶é—´æ­¥ä¸Šæ¼æ–—å¼ä¼ é€’ï¼Œå¯èƒ½é™åˆ¶æ¨¡å‹å›å¿†éå¸¸é•¿çš„ä¸Šä¸‹æ–‡ä¸­ç»†èŠ‚ä¿¡æ¯çš„èƒ½åŠ›ã€‚å¹¶ä¸”ï¼Œæç¤ºå·¥ç¨‹å˜å¾—æ›´åŠ é‡è¦ã€‚



# å‚è€ƒèµ„æ–™

## å‚è€ƒæ–‡ç« 

1. [ä¸ºä»€ä¹ˆResNetå’ŒDenseNetå¯ä»¥è¿™ä¹ˆæ·±ï¼Ÿä¸€æ–‡è¯¦è§£æ®‹å·®å—ä¸ºä½•æœ‰åŠ©äºè§£å†³æ¢¯åº¦å¼¥æ•£é—®é¢˜](https://zhuanlan.zhihu.com/p/28124810)  
2. [GRADIENTS, BATCH NORMALIZATION AND LAYER NORMALIZATION](https://theneuralperspective.com/2016/10/27/gradient-topics/)  
3. [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks)  
4. [Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I](https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8)  
5. [Building the Mighty Transformer for Sequence Tagging in PyTorch : Part II](https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-ii-c85bf8fd145)  
6. [Attention?Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)  

## å‚è€ƒä»£ç 

1. [jadore801120/attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch)  
2. [JayParks/transformer](https://github.com/JayParks/transformer)  


## å·ç§¯

å„ç±»å·ç§¯è®²è§£:[A Comprehensive Introduction to Different Types of Convolutions in Deep Learning](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215)
- å·ç§¯ä¸äº’ç›¸å…³ï¼ˆä¿¡å·å¤„ç†ï¼‰
- æ·±åº¦å­¦ä¹ ä¸­çš„å·ç§¯ï¼ˆå•é€šé“/å¤šé€šé“ï¼‰
- 3Då·ç§¯1 x 1å·ç§¯å·ç§¯è¿ç®—ï¼ˆConvolution Arithmeticï¼‰
- è½¬ç½®å·ç§¯ï¼ˆåå·ç§¯ï¼Œcheckerboard artifactsï¼‰
- æ‰©å¼ å·ç§¯ï¼ˆç©ºæ´å·ç§¯ï¼‰
- å¯åˆ†ç¦»å·ç§¯ï¼ˆç©ºé—´å¯åˆ†ç¦»å·ç§¯ï¼Œæ·±åº¦å·ç§¯ï¼‰
- æ‰å¹³å·ç§¯ï¼ˆFlattened Convolutionï¼‰
- åˆ†ç»„å·ç§¯ï¼ˆGrouped Convolutionï¼‰
- éšæœºåˆ†ç»„å·ç§¯ï¼ˆShuffled Grouped Convolutionï¼‰
- é€ç‚¹åˆ†ç»„å·ç§¯ï¼ˆPointwise Grouped Convolutionï¼‰

ä½œè€…ï¼š[åˆè¯†CV](https://www.zhihu.com/question/54149221/answer/1850592489)

![](https://pic1.zhimg.com/50/v2-0411ccbcb5529b2855478d619ac78d9d_hd.webp?source=1940ef5c)

ç©ºæ´å·ç§¯ diolation
- ![](https://pic1.zhimg.com/50/v2-9c531569460c694db396a7530d8e5ffc_hd.webp?source=1940ef5c)


å†…éƒ¨å·ç§¯ involution
- [CVPR 2021 Involutionï¼šè¶…è¶Š Convolution å’Œ Self-attention çš„ç¥ç»ç½‘ç»œæ–°ç®—å­](https://blog.csdn.net/BAAIBeijing/article/details/115222970), [è®ºæ–‡åœ°å€](http://arxiv.org/abs/2103.06255)
- ![img](https://img-blog.csdnimg.cn/img_convert/0f8c8ff1aa63b079025990418c20ea68.png)
- ![img](https://img-blog.csdn.net/20170730100057611?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTGVmdF9UaGluaw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
- ![img](https://img-blog.csdnimg.cn/img_convert/b670881b8e5cd7b52b4ebe69ace1654b.png)

# ç»“æŸ