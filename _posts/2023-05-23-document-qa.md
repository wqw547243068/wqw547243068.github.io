---
layout: post
title:  æ–‡æ¡£é—®ç­”åŸç†åŠå®è·µ Thoery and Implemetation of the Doucument QA
date:   2023-03-30 19:10:00
categories: æ·±åº¦å­¦ä¹  è‡ªç„¶è¯­è¨€å¤„ç†
tags: ChatGPT å¯¹è¯ç³»ç»Ÿ çŸ¥è¯†åº“ å‘é‡åŒ– milvus
excerpt: æ–‡æ¡£é—®ç­”çš„åŸç†ã€æ¡ˆä¾‹åŠå®è·µ
mathjax: true
permalink: /doc-chat
---

* content
{:toc}

# æ–‡æ¡£é—®ç­”

ã€2023-3-27ã€‘æ–‡æ¡£é—®ç­”

ä½œè€…ï¼š[å¼ºåŒ–å­¦å¾’](https://www.zhihu.com/question/589726461/answer/2961450933)

ã€2023-5-9ã€‘[å¤§è¯­è¨€æ¨¡å‹å®ç°æ™ºèƒ½å®¢æœçŸ¥è¯†åº“æ–‡æ¡£æ•°æ®æå–åŠŸèƒ½](https://www.toutiao.com/article/7231062779061502501)
- æ™ºèƒ½å®¢æœçš„çŸ¥è¯†åº“æœ‰ä¸¤ç±»ï¼š**æœºå™¨äºº**çŸ¥è¯†åº“å’Œ**åå¸­**çŸ¥è¯†åº“ï¼Œåˆ†åˆ«æ˜¯ä¸ºæœºå™¨äººå’Œåå¸­è¿›è¡ŒæœåŠ¡æ—¶ï¼Œæä¾›æ•°æ®çš„æ”¯æ’‘ã€‚
- å¦‚ä½•é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ï¼Œè®©ä¼ä¸šçš„æ–‡æ¡£å¯æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨å‘¢ï¼Ÿ

å½“å‰çš„ä¸»æµå®¢æœäº§å“
- æ™ºèƒ½å®¢æœç³»ç»Ÿä¼šæ ‡é…`çŸ¥è¯†åº“ç®¡ç†`åŠŸèƒ½ï¼Œå¸¸è§çš„å½¢å¼æ˜¯**æ ‘çŠ¶ç»“æ„**ï¼Œæä¾›åˆ†ç±»ç®¡ç†ã€çŸ¥è¯†åº“æ¡ç›®ç®¡ç†ï¼Œå¹¶æ”¯æŒçŸ¥è¯†åº“çš„æ‰¹é‡å¯¼å…¥å¯¼å‡ºæ“ä½œã€‚
- ä½¿ç”¨ä¸­ï¼Œä¼ä¸šéœ€è¦ç»å¸¸æ€§åœ°ç»´æŠ¤ç®¡ç†çŸ¥è¯†åº“å†…å®¹ï¼Œå°†ä¼ä¸šå·²æœ‰çŸ¥è¯†å†…å®¹æ–‡æ¡£ä¸Šä¼ ï¼Œä½†å¦‚æœæ˜¯å°†åŸæ–‡ä»¶ä¸Šä¼ ï¼Œåˆ™ç³»ç»Ÿæœ€å¤šèƒ½æ”¯æŒé¢„è§ˆåŠŸèƒ½ï¼Œä½¿ç”¨è€…åœ¨æ“ä½œç•Œé¢åªèƒ½ç‚¹å‡»æ‰“å¼€å…¨æ–‡æ£€ç´¢ã€‚è€Œå¦‚æœæ˜¯æœºå™¨äººçŸ¥è¯†åº“ï¼Œç›´æ¥ä¸Šä¼ æ–‡æ¡£æ˜¯ä¸å¯ç”¨çš„ï¼Œéœ€è¦æ“ä½œè€…æ‰‹å·¥æ•´ç†æ–‡æ¡£ä¸­çš„å†…å®¹ä¸ºæœºå™¨äººæ ‡å‡†é—®ç­”å¯¹ã€‚

å¤§æ¨¡å‹æ—¶ä»£
- æ‰€æœ‰ä¼ä¸šçš„æ–‡æ¡£å¯ä»¥æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥å¯è‡ªåŠ¨è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨ã€‚

## èƒŒæ™¯

### æ–‡æœ¬å‘é‡åŒ–

`åµŒå…¥`ï¼ˆEmbeddingï¼‰æ˜¯ä¸€ç§å°†**æ–‡æœ¬æˆ–å¯¹è±¡**è½¬æ¢ä¸º**å‘é‡è¡¨ç¤º**çš„æŠ€æœ¯ï¼Œå°†è¯è¯­ã€å¥å­æˆ–å…¶ä»–æ–‡æœ¬å½¢å¼è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºã€‚
- åµŒå…¥å‘é‡æ˜¯ç”±ä¸€ç³»åˆ—æµ®ç‚¹æ•°æ„æˆçš„**å‘é‡**ã€‚
- é€šè¿‡è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡ä¹‹é—´çš„è·ç¦»ï¼Œå¯ä»¥è¡¡é‡å®ƒä»¬ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è·ç¦»è¾ƒå°çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ç›¸å…³æ€§ï¼Œè€Œè·ç¦»è¾ƒå¤§çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´ç›¸å…³æ€§è¾ƒä½ã€‚

ä»¥ `Milvus` ä¸ºä»£è¡¨çš„`å‘é‡æ•°æ®åº“`åˆ©ç”¨è¯­ä¹‰æœç´¢ï¼ˆSemantic Searchï¼‰æ›´å¿«åœ°æ£€ç´¢åˆ°ç›¸å…³æ€§æ›´å¼ºçš„æ–‡æ¡£ã€‚

è¯¦è§ï¼šsklearnä¸“é¢˜é‡Œçš„[æ–‡æœ¬å‘é‡åŒ–](sklearn#%E5%90%91%E9%87%8F%E5%8C%96)

### Token

ä»€ä¹ˆæ˜¯tokenï¼Ÿ
- tokens ä¸æ˜¯æŒ‡ prompt å­—ç¬¦ä¸²çš„é•¿åº¦ï¼›
- token æŒ‡ä¸€æ®µè¯ä¸­å¯èƒ½è¢«åˆ†å‡ºæ¥çš„**è¯æ±‡**ã€‚
  - æ¯”å¦‚ï¼ši love youï¼Œå°±æ˜¯ä¸‰ä¸ªtokenï¼Œåˆ†åˆ«ä¸º ã€Œiã€ã€Œloveã€ã€Œyouã€ã€‚
- ä¸åŒè¯­è¨€tokenè®¡ç®—ä¸ä¸€æ ·ã€‚[åœ¨çº¿æµ‹è¯•](platform.openai.com/tokenizer)
  - ä¸­æ–‡çš„ã€Œæˆ‘çˆ±ä½ ã€å…¶å®æ˜¯ç®— 5ä¸ªtokenï¼Œå› ä¸ºä¼šå…ˆæŠŠå†…å®¹è½¬æˆ unicodeã€‚
  - æœ‰äº› emoji çš„tokené•¿åº¦ä¼šè¶…å‡ºæƒ³è±¡ï¼Œé•¿è¾¾11ä¸ªã€‚

ChatGPT has an upper limit of 4096

GPT-4 æ”¯æŒï¼Œè¯¦è§[å®˜ç½‘](https://platform.openai.com/docs/models/gpt-4)
- 8k context
- 32k context

| Model | Price for 1000 tokens (prompt) |
|---|---|
| Ada | 2048 |
| Babbage | 2048 | 
| Curie | 2048 |
| DaVinci | 4096 |
| ChatGPT | 4096 |
| GPT-4 8k context | 8192 |
| GPT-4 32k context | 32768 |

Remember, the sum of your prompt and maximum tokens should always be less than equal to the model's maximum token limit, OR your output is truncated.

å¤‡æ³¨
- ç¼–ç å™¨ï¼šå¯ä»¥æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚å¦‚æœåºåˆ—é•¿åº¦å°äºè¯¥é™åˆ¶ï¼Œå°±åœ¨å…¶åå¡«å…¥é¢„å…ˆå®šä¹‰çš„ç©ºç™½å•è¯ã€‚
  - å¦‚ï¼ŒåŸå§‹ transformer è®ºæ–‡ä¸­çš„ç¼–ç å™¨æ¨¡å—å¯ä»¥æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚
- è§£ç å™¨ï¼šåŒºåˆ«
  - åŠ å…¥äº†ä¸€å±‚é‡ç‚¹å…³æ³¨ç¼–ç å™¨è¾“å‡ºçš„æŸä¸€ç‰‡æ®µï¼Œ**ç¼–ç å™¨-è§£ç å™¨è‡ªæ³¨æ„åŠ›**ï¼ˆencoder-decoder self-attentionï¼‰å±‚
  - åé¢çš„å•è¯æ©ç›–æ‰äº†ã€‚ä½†å¹¶ä¸åƒ BERT ä¸€æ ·å°†å®ƒä»¬æ›¿æ¢æˆç‰¹æ®Šå®šä¹‰çš„å•è¯ < mask >ï¼Œè€Œæ˜¯åœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—çš„æ—¶å€™å±è”½äº†æ¥è‡ªå½“å‰è®¡ç®—ä½ç½®å³è¾¹æ‰€æœ‰å•è¯çš„ä¿¡æ¯ã€‚


ç»éªŒ
- è‹±æ–‡ï¼š100 tokens ~= 75 words)
- ä¸­æ–‡ï¼šä¸€ä¸ªæ±‰å­—å 2-3ä¸ªtoken
- å…¶å®ƒï¼šemojiè¡¨æƒ…ç¬¦å·ï¼Œå ç”¨æ›´å¤šï¼Œæœ‰çš„é«˜è¾¾11ä¸ª

### å¦‚ä½•å¢å¼ºLLMèƒ½åŠ›

ã€2023-5-21ã€‘[LLMè®­ç»ƒè¥è¯¾ç¨‹ç¬”è®°â€”Augmented Language Models](https://zhuanlan.zhihu.com/p/630195581)
- [è‹±æ–‡ppt](https://drive.google.com/file/d/1A5RcMETecn6Aa4nNzpVx9kTKdyeErqrI/view), [è®²ä¹‰æ€»ç»“](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)
- There are three ways to augment language models: retrieval, chains, and tools.
- Retrieval involves providing an external corpus of data for the model to search, chains use the output of one language model as input for another, and tools allow models to interact with external data sources.

LLMæ“…é•¿ä»€ä¹ˆï¼Ÿ
- â€¢ è¯­è¨€ç†è§£
- â€¢ éµå¾ªæŒ‡ä»¤
- â€¢ åŸºç¡€æ¨ç†
- â€¢ ä»£ç ç†è§£

LLMåœ¨å“ªäº›æ–¹é¢éœ€è¦å¸®åŠ©ï¼Ÿ
- â€¢ è·å–æœ€æ–°çŸ¥è¯†
- â€¢ ç”¨æˆ·æ•°æ®åŒ…å«çš„çŸ¥è¯†
- â€¢ æ›´æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†
- â€¢ ä¸å¤–ç•Œäº¤äº’

å¦‚ä½•å¢å¼ºLLMçš„èƒ½åŠ›ï¼Ÿ
- LLMæ›´åŠ æ“…é•¿**é€šç”¨æ¨ç†**ï¼Œè€Œä¸æ˜¯**ç‰¹å®šçŸ¥è¯†**ã€‚

ä¸ºäº†è®©LLMèƒ½å¤Ÿå–å¾—æ›´å¥½çš„è¡¨ç°ï¼Œæœ€å¸¸è§æ–¹æ³•å°±æ˜¯ç»™LLMæä¾›åˆé€‚çš„**ä¸Šä¸‹æ–‡ä¿¡æ¯**å¸®åŠ©LLMè¿›è¡Œæ¨ç†ã€‚

éšç€æœ€è¿‘LLMçš„ä¸æ–­å‘å±•ï¼Œå„ç±»å¤§æ¨¡å‹æ‰€èƒ½æ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡**é•¿åº¦**ä¹Ÿè¶Šæ¥è¶Šå¤§ï¼Œä½†æ˜¯åœ¨å¯é¢„è§çš„ä¸€æ®µæ—¶é—´å†…ä»ä¸å¯èƒ½åŒ…å«æ‰€æœ‰å†…å®¹ï¼Œå¹¶ä¸”è¶Šå¤šçš„ä¸Šä¸‹æ–‡æ„å‘³ç€æ›´å¤šçš„è®¡ç®—æˆæœ¬ã€‚
- ![](https://pic3.zhimg.com/80/v2-01d520894c2ada7c23aa4f450aae71ca_1440w.webp)

å¦‚ä½•å……åˆ†åˆ©ç”¨å½“å‰æ‰€èƒ½æ”¯æŒçš„æœ‰é™çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè®©LLMè¡¨ç°æ›´å¥½ï¼Œå€¼å¾—ç ”ç©¶ã€‚æœ‰é™ä¸‹æ–‡æƒ…å†µä¸‹å……åˆ†æ¿€å‘LLMçš„èƒ½åŠ›çš„æ–¹æ³•æœ‰ä¸‰ç§ï¼š
- `Retrieval`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å†…ï¼Œå¹¶è¡Œæ‰¾ç›¸å…³å†…å®¹ä½œä¸ºprompt
- `Chain`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å¤–ï¼Œä¸²è¡Œè¯·æ±‚
- `Tools`ï¼šè°ƒç”¨å¤–éƒ¨å·¥å…·

ï¼ˆ1ï¼‰é€šè¿‡**Retrievalå¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å†…</span>
 
ä¸€ä¸ªå…¸å‹çš„åœ¨æ–‡æ¡£QAåœºæ™¯ä½¿ç”¨æ£€ç´¢æ–¹å¼æ¥å¢å¼ºLLMèƒ½åŠ›çš„æ–¹å¼ï¼Œåˆ†ä¸ºå‡ ä¸ªæµç¨‹ï¼š
*   ç”¨æˆ·é—®é¢˜embedding
*   ä»æµ·é‡æ–‡æ¡£ä¸­æ£€ç´¢å‡ºTop Nä¸é—®é¢˜embeddingç›¸ä¼¼çš„å€™é€‰æ–‡æ¡£
*   åŸºäºTopNæ–‡æ¡£å†…å®¹æ„é€ Prompt
*   è°ƒç”¨LLMè·å–æœ€ç»ˆç­”æ¡ˆ
 
![](https://pic1.zhimg.com/80/v2-72a51d5f2be59ac526ea858e8fe15678_1440w.webp)
 
å¸¸ç”¨çš„RetrievalæŠ€æœ¯
 
å¯¹Retrievalçš„æŠ€æœ¯ç»†èŠ‚ä»¥åŠä¸€äº›å¸¸ç”¨çš„å·¥å…·è¿›è¡Œäº†è¯¦ç»†çš„ä»‹ç»ï¼ŒåŒ…æ‹¬**ä¼ ç»ŸRetrieval**ä»¥åŠ**åŸºäºEmbeddingçš„Retrieval**è¿™ä¸¤ç§æŠ€æœ¯è·¯çº¿ï¼Œ[åŸæ•™ç¨‹](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)å­¦ä¹ æˆ–è€…å‚è€ƒä¸€äº›å…¶ä»–çš„[ä¿¡æ¯æ£€ç´¢èµ„æ–™](https://github.com/%2520%2520sebastian-hofstaetter/teaching)ã€‚
 
ï¼ˆ2ï¼‰é€šè¿‡**Chain**å¢å¼ºLLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å¤–</span>
 
æŸäº›æƒ…å†µä¸‹ï¼Œæœ€ä½³çš„contextå¯èƒ½å¹¶**ä¸å­˜åœ¨äºç”¨æˆ·è¯­æ–™åº“**ä¸­ã€‚ä¸Šä¸€ä¸ªLLMçš„è¾“å‡ºç»“æœå¯èƒ½æ­£å¥½æ˜¯å½“å‰LLMçš„æœ€å¥½çš„è¾“å…¥contextã€‚
 
æ­¤æ—¶ï¼Œå¯ä»¥ç”¨Chainå½¢å¼å°†ä¸åŒçš„LLMè¿æ¥èµ·æ¥ï¼Œå»å¢å¼ºæœ€ç»ˆä»»åŠ¡çš„æ•ˆæœã€‚ä¾‹å¦‚ä¸‹å›¾çš„æ‘˜è¦ä»»åŠ¡ï¼š
- é¦–å…ˆå°†æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œå¯¹äºæ¯ä¸ªéƒ¨åˆ†ä½¿ç”¨LLMåšä¸€ä¸ªå±€éƒ¨æ‘˜è¦ï¼Œç„¶åå†ç”¨LLMå¯¹å„ä¸ªæ‘˜è¦è¿›è¡Œåˆå¹¶è¾“å‡ºå…¨å±€çš„æ‘˜è¦ã€‚
- ![](https://pic3.zhimg.com/80/v2-65144390d9958a95f33a316618a32092_1440w.webp)

å…¸å‹è¿›è¡Œè¿™æ ·ä»»åŠ¡ç¼–æ’çš„å·¥å…·æ˜¯[LangChain](https://github.com/hwchase17/langchain)ï¼Œå¯ä»¥åˆ©ç”¨å®ƒæ¥å¼€å‘å¾ˆå¤šæœ‰æ„æ€çš„åº”ç”¨ã€‚
 
ï¼ˆ3ï¼‰é€šè¿‡**Toolså¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>å€ŸåŠ©å¤–ç•Œå·¥å…·</span>
 
é€šè¿‡å„ç§å„æ ·çš„å·¥å…·è®©LLMä¸å¤–ç•Œè¿›è¡Œäº¤äº’ï¼Œæ¯”å¦‚ä½¿ç”¨æœç´¢å¼•æ“ã€æ‰§è¡ŒSQLè¯­å¥ç­‰ï¼Œä»è€Œå»ä¸°å¯ŒLLMçš„åŠŸèƒ½ã€‚

Toolsæ–¹å¼å¤§è‡´æœ‰ä¸¤ç§
- ä¸€ç§æ˜¯åŸºäº**Chain**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¿…é€‰é¡¹**ï¼Œå‰é¢æœ‰ä¸€ä¸ªLLMæ¥æ„é€ Toolçš„è¾“å…¥ï¼Œåé¢ä¼šæœ‰å¦ä¸€ä¸ªLLMæ¥æ€»ç»“Toolçš„è¾“å‡ºå¹¶å¾—åˆ°æœ€ç»ˆçš„ç»“æœï¼›
- ä¸€ç§æ˜¯åŸºäº**Plugin**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¯é€‰é¡¹**ï¼Œè®©LLMæ¥å†³å®šç”¨ä¸ç”¨ä»¥åŠæ€ä¹ˆç”¨Toolã€‚

![](https://pic2.zhimg.com/80/v2-2038fc84985ec24ed8831bf66f16a4b1_1440w.webp)

æ€»ç»“
- â€¢ é€šè¿‡ä¸å¤–ç•Œæ•°æ®çš„äº¤äº’ï¼ŒLLMçš„èƒ½åŠ›èƒ½å¤Ÿæ›´åŠ å¼ºå¤§ã€‚
- â€¢ é€šè¿‡ä½¿ç”¨è§„åˆ™å’Œå¯å‘å¼æ–¹æ³•ï¼Œå¯ä»¥å®ç°å„ç§å„æ ·çš„åŠŸèƒ½ã€‚

éšç€çŸ¥è¯†åº“çš„æ‰©å¤§ï¼Œåº”è¯¥å°†å…¶è§†ä¸ºä¸€ä¸ª**ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿ**ã€‚ä½¿ç”¨Chainçš„æ–¹å¼å¯ä»¥å¸®åŠ©ç¼–ç æ›´å¤æ‚çš„æ¨ç†ï¼Œå¹¶ä¸”ç»•è¿‡tokené•¿åº¦çš„é™åˆ¶ã€‚å„ç§å„æ ·çš„å¤–éƒ¨å·¥å…·å¯ä»¥è®©æ¨¡å‹è®¿é—®æ›´å¤šçš„èµ„æºã€‚


## æ–¹æ³•æ€»ç»“

[ä½œè€…](https://www.zhihu.com/question/591935281/answer/2961925796)

å¸¸è§çš„æ–¹æ³•ï¼š
- `retrieve-then-generate`ï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
  - æ ¹æ®è¾“å…¥queryæ¥æŠ½å–ç›¸å…³å¤–éƒ¨æ–‡æœ¬ï¼ŒæŠŠæŠ½å–åˆ°çš„æ–‡æœ¬å’Œqueryä¸€èµ·ä½œä¸ºpromptå†æ¥åšåç»­å­—ç¬¦çš„æ¨ç†ã€‚
  - chatpdfè¿™ç§äº§å“çš„æ–¹æ³•ä¹Ÿç±»ä¼¼ï¼Œå…ˆæŠŠä½ è¾“å…¥çš„æ–‡æ¡£åˆ†æˆå¤šä¸ªchunkåˆ†åˆ«åšembeddingæ”¾åˆ°å‘é‡æ•°æ®åº“é‡Œï¼Œç„¶åæ ¹æ®è¾“å…¥embeddingçš„å‘é‡åšåŒ¹é…ï¼Œå†æŠŠåŒ¹é…åˆ°çš„å‘é‡å¯¹åº”çš„chunkå’Œè¾“å…¥ä¸€èµ·ä½œä¸ºpromptç»™LLMã€‚
  - è®ºæ–‡ï¼šã€2020-2-10ã€‘[REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)
- `Fine-tuning`ï¼šFine-tuningæ˜¯æŒ‡åœ¨å·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨**æ–°æ•°æ®é›†**å†æ¬¡è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿æ¨¡å‹é’ˆå¯¹ç‰¹å®šä»»åŠ¡æˆ–ç‰¹å®šé¢†åŸŸçš„è¯­è¨€ä½¿ç”¨æƒ…å†µè¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨Fine-tuningè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†**é¢å¤–çŸ¥è¯†**ä½œä¸ºæ–°çš„æ•°æ®é›†åŠ å…¥åˆ°è®­ç»ƒä¸­ã€‚
- `Knowledge Distillation`ï¼šKnowledge Distillationæ˜¯æŒ‡å°†ä¸€ä¸ªâ€œå¤§æ¨¡å‹â€çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªâ€œå°æ¨¡å‹â€ä¸­ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªå°å‹çš„æ¨¡å‹ä¸­ï¼Œä½¿å¾—å°å‹æ¨¡å‹èƒ½å¤Ÿä½¿ç”¨å¤§å‹æ¨¡å‹ä¸­çš„çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é€šè¿‡å°†é¢å¤–çš„çŸ¥è¯†åŠ å…¥åˆ°â€œå¤§æ¨¡å‹â€ä¸­ï¼Œä»è€Œä½¿å¾—â€œå°æ¨¡å‹â€å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†ã€‚
- `æ•°æ®å¢å¼º`ï¼šæ•°æ®å¢å¼ºæ˜¯æŒ‡åœ¨å·²æœ‰çš„æ•°æ®é›†ä¸­ï¼Œæ·»åŠ ä¸€äº›ç±»ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒçš„æ•°æ®æ¥å¢åŠ æ•°æ®çš„æ•°é‡å’Œå¤šæ ·æ€§ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿å¾—æ¨¡å‹æ›´åŠ å…¨é¢åœ°å­¦ä¹ åˆ°ä¸åŒçš„è¯­è¨€ä½¿ç”¨æƒ…å†µï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨æ•°æ®å¢å¼ºçš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥æ·»åŠ é¢å¤–çš„çŸ¥è¯†ï¼Œä¾‹å¦‚åŒä¹‰è¯ã€åä¹‰è¯ã€ä¸“ä¸šæœ¯è¯­ç­‰ã€‚
  - è¯å‘é‡ï¼šå°†é¢†åŸŸç‰¹å®šçš„è¯æ±‡å’Œè¯å‘é‡æ·»åŠ åˆ°æ¨¡å‹çš„è¯æ±‡è¡¨ä¸­ã€‚è¿™äº›è¯æ±‡å¯ä»¥æ˜¯åœ¨ç›®æ ‡é¢†åŸŸä¸­ç‹¬æœ‰çš„è¯æ±‡æˆ–è€…åœ¨å¸¸è§„æ•°æ®é›†ä¸­ç¼ºå¤±çš„è¯æ±‡ã€‚
  - å¤–éƒ¨æ•°æ®é›†ï¼šä»å¤–éƒ¨æ•°æ®é›†ä¸­æ”¶é›†ä¸ç›®æ ‡é¢†åŸŸç›¸å…³çš„æ•°æ®ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦æ‰¾åˆ°ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨é€‚å½“çš„æ–¹æ³•å°†å…¶åˆå¹¶åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚
  - å¤–éƒ¨çŸ¥è¯†åº“ï¼šå°†å¤–éƒ¨çš„çŸ¥è¯†åº“ï¼Œå¦‚ç™¾ç§‘å…¨ä¹¦ã€çŸ¥è¯†å›¾è°±ç­‰ï¼Œä¸æ¨¡å‹é›†æˆï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†æ¥è¾…åŠ©å…¶ç”Ÿæˆæ–‡æœ¬ã€‚
  - äººå·¥æ ‡æ³¨ï¼šé€šè¿‡äººå·¥æ ‡æ³¨çš„æ–¹å¼ï¼Œå°†é¢†åŸŸç‰¹å®šçš„ä¿¡æ¯æ·»åŠ åˆ°è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦å¤§é‡çš„äººåŠ›å’Œæ—¶é—´ï¼Œå¹¶ä¸”å¯¹äºå¤§å‹æ•°æ®é›†æ¥è¯´å¯èƒ½ä¸åˆ‡å®é™…ã€‚
- `å¤šä»»åŠ¡å­¦ä¹ `ï¼šå¤šä»»åŠ¡å­¦ä¹ æ˜¯æŒ‡åŒæ—¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹å®Œæˆå¤šä¸ªä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨è®­ç»ƒGPT/LLMæ¨¡å‹æ—¶ï¼Œå¯ä»¥è®©æ¨¡å‹åŒæ—¶å®Œæˆæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ï¼Œä»è€Œä½¿å¾—æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ›´åŠ å¤šæ ·åŒ–çš„çŸ¥è¯†ã€‚åœ¨å¤šä»»åŠ¡å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†é¢å¤–çš„çŸ¥è¯†æ·»åŠ åˆ°å…¶ä»–ä»»åŠ¡ä¸­ï¼Œä»è€Œé—´æ¥åœ°å½±å“åˆ°æ¨¡å‹åœ¨ä¸»è¦ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

ã€2023-4-22ã€‘åŸºäºllama-indexå’ŒChatGPT APIå®šåˆ¶ç§æœ‰å¯¹è¯æœºå™¨äººçš„æ–¹å¼ã€‚

æ–¹æ¡ˆ
- 1ã€fine-tuneså¾®è°ƒã€‚ç”¨å¤§é‡æ•°æ®å¯¹GPTæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°ä¸€ä¸ªç†è§£æ–‡æ¡£çš„æ¨¡å‹ã€‚
  - ä½†å¾®è°ƒéœ€è¦èŠ±è´¹å¾ˆå¤šmoneyï¼Œè€Œä¸”éœ€è¦ä¸€ä¸ªæœ‰å®ä¾‹çš„å¤§æ•°æ®é›†ã€‚ä¹Ÿä¸å¯èƒ½åœ¨æ–‡ä»¶æœ‰å˜åŒ–æ—¶æ¯æ¬¡éƒ½è¿›è¡Œå¾®è°ƒã€‚
  - å¾®è°ƒä¸å¯èƒ½è®©æ¨¡å‹ â€œçŸ¥é“â€œ æ–‡æ¡£ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œæ˜¯è¦æ•™ç»™æ¨¡å‹ä¸€ç§æ–°çš„æŠ€èƒ½ã€‚
  - å› æ­¤ï¼Œå¾®è°ƒä¸æ˜¯ä¸€ä¸ªå¥½åŠæ³•ã€‚
- 2ã€å°†ç§æœ‰æ–‡æœ¬å†…å®¹ä½œä¸ºpromptçš„ä¸Šä¸‹æ–‡ï¼Œè®¿é—®ChatGPTã€‚
  - openai apiå­˜åœ¨æœ€å¤§é•¿åº¦çš„é™åˆ¶ï¼ŒChatGPT 3.5çš„æœ€å¤§tokenæ•°ä¸º4096ï¼Œå¦‚æœè¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œä¼šç›´æ¥å¯¹æ–‡æ¡£æˆªæ–­ï¼Œå­˜åœ¨ä¸Šä¸‹æ–‡ä¸¢å¤±çš„é—®é¢˜ã€‚
  - å¹¶ä¸”apiçš„è°ƒç”¨è´¹ç”¨å’Œtokené•¿åº¦æˆæ­£æ¯”ï¼Œtokensæ•°å¤ªå¤§ï¼Œåˆ™æ¯æ¬¡è°ƒç”¨çš„æˆæœ¬ä¹Ÿä¼šå¾ˆé«˜ã€‚

### llama-index

ã€2023-4-23ã€‘å‚è€ƒ
- [å®šåˆ¶è‡ªå·±çš„æ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/623523968)
- [LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

æ—¢ç„¶tokensæœ‰é™åˆ¶ï¼Œé‚£ä¹ˆæœ‰æ²¡æœ‰å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œ**é¢„å¤„ç†**çš„å·¥å…·ï¼Ÿä¸è¶…è¿‡tokenæ•°é™åˆ¶ã€‚
- å€ŸåŠ©llama-indexå¯ä»¥ä»æ–‡æœ¬ä¸­åªæå–å‡ºç›¸å…³éƒ¨åˆ†ï¼Œç„¶åå°†å…¶åé¦ˆç»™promptã€‚
- [llama-index](https://gpt-index.readthedocs.io/en/latest/), [github](https://github.com/jerryjliu/llama_index)æ”¯æŒè®¸å¤šä¸åŒçš„æ•°æ®æºï¼Œå¦‚APIã€PDFã€æ–‡æ¡£ã€SQL ã€Google Docsç­‰ã€‚

[llama-index](https://gpt-index.readthedocs.io/en/latest/) Ecosystem
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼šsupport parsing a wide range of file types: .pdf, .jpg, .png, .docx, etc.
- ğŸ¡ [LlamaHub](https://llamahub.ai), åŒ…å«å„ç±»æ’ä»¶ï¼Œå¦‚ï¼šç½‘é¡µã€faissè¯­ä¹‰ç´¢å¼•ã€bç«™è§†é¢‘è„šæœ¬ã€ESã€Milvusã€æ•°æ®åº“ç­‰
- ğŸ§ª [LlamaLab](https://github.com/run-llama/llama-lab)

ã€2023-5-17ã€‘[åŸºäºChatGPTçš„è§†é¢‘æ‘˜è¦åº”ç”¨å¼€å‘](https://www.toutiao.com/article/7230786095158690362)
- å½“æ–‡æ¡£è¢«é€å…¥ LLM æ—¶ï¼Œå®ƒä¼šæ ¹æ®å…¶å¤§å°åˆ†æˆå—æˆ–èŠ‚ç‚¹ã€‚ ç„¶åå°†è¿™äº›å—è½¬æ¢ä¸ºåµŒå…¥å¹¶å­˜å‚¨ä¸ºå‘é‡ã€‚
- å½“æç¤ºç”¨æˆ·æŸ¥è¯¢æ—¶ï¼Œæ¨¡å‹å°†æœç´¢å‘é‡å­˜å‚¨ä»¥æ‰¾åˆ°æœ€ç›¸å…³çš„å—å¹¶æ ¹æ®è¿™äº›ç‰¹å®šå—ç”Ÿæˆç­”æ¡ˆã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨å¤§å‹æ–‡æ¡£ï¼ˆå¦‚ 20 åˆ†é’Ÿçš„è§†é¢‘è½¬å½•æœ¬ï¼‰ä¸ŠæŸ¥è¯¢â€œæ–‡ç« æ‘˜è¦â€ï¼Œæ¨¡å‹å¯èƒ½åªä¼šç”Ÿæˆæœ€å 5 åˆ†é’Ÿçš„æ‘˜è¦ï¼Œå› ä¸ºæœ€åä¸€å—ä¸ä¸Šä¸‹æ–‡æœ€ç›¸å…³ çš„â€œæ€»ç»“â€ã€‚
- ![image](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d0a76dbf2a11400f97220283ea233fa9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=dohd7TRWXXfBH5PRvGLj3ldXBh0%3D)

æµç¨‹å›¾
- ![flow](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/38966bfef5f641f294301647b92def7e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=Mdb8NbIuzxqhc1X9FW60XawIOK0%3D)

ä¸€ç§å…¨æ–°çš„ LlamaIndex æ•°æ®ç»“æ„ï¼š**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**ï¼Œä¸ä¼ ç»Ÿ**è¯­ä¹‰æœç´¢**ç›¸æ¯”ï¼Œæ£€ç´¢æ€§èƒ½æ›´å¥½

å¤šæ•°æ„å»º LLM æ”¯æŒçš„ QA ç³»ç»Ÿæ­¥éª¤ï¼š
- è·å–**æºæ–‡æ¡£**ï¼Œå°†æ¯ä¸ªæ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**
- å°†**æ–‡æœ¬å—**å­˜å‚¨åœ¨**å‘é‡æ•°æ®åº“**ä¸­
- æŸ¥è¯¢æ—¶ï¼Œé€šè¿‡**åµŒå…¥ç›¸ä¼¼æ€§** å’Œ/æˆ– **å…³é”®å­—è¿‡æ»¤å™¨**æ¥æ£€ç´¢æ–‡æœ¬å—ã€‚
- æ‰§è¡Œå“åº”å¹¶**æ±‡æ€»**ç­”æ¡ˆ

ç”±äºå„ç§åŸå› ï¼Œè¿™ç§æ–¹æ³•æ£€ç´¢æ€§èƒ½æœ‰é™ã€‚
- æ–‡æœ¬å—**ç¼ºä¹å…¨å±€ä¸Šä¸‹æ–‡**ã€‚é€šå¸¸queryä¸Šä¸‹æ–‡è¶…å‡ºäº†ç‰¹å®šå—ä¸­ç´¢å¼•çš„å†…å®¹ã€‚
- ä»”ç»†è°ƒæ•´ top-k / ç›¸ä¼¼åº¦åˆ†æ•°é˜ˆå€¼ã€‚
  - å‡è®¾å€¼å¤ªå°ï¼Œä½ ä¼šé”™è¿‡ä¸Šä¸‹æ–‡ã€‚
  - å‡è®¾å€¼å€¼å¤ªå¤§ï¼Œå¹¶ä¸”æˆæœ¬/å»¶è¿Ÿå¯èƒ½ä¼šéšç€æ›´å¤šä¸ç›¸å…³çš„ä¸Šä¸‹æ–‡è€Œå¢åŠ ï¼Œå™ªéŸ³å¢åŠ ã€‚
- åµŒå…¥é€‰æ‹©çš„ä¸Šä¸‹æ–‡ä¸ä¸€å®šæœ€ç›¸å…³ã€‚
  - åµŒå…¥æœ¬è´¨ä¸Šæ˜¯åœ¨æ–‡æœ¬å’Œä¸Šä¸‹æ–‡ä¹‹é—´åˆ†åˆ«ç¡®å®šçš„ã€‚

æ·»åŠ **å…³é”®å­—è¿‡æ»¤å™¨**æ˜¯å¢å¼ºæ£€ç´¢ç»“æœçš„ä¸€ç§æ–¹æ³•ã€‚
- ä½†éœ€è¦æ‰‹åŠ¨æˆ–é€šè¿‡ NLP å…³é”®å­—æå–/ä¸»é¢˜æ ‡è®°æ¨¡å‹ä¸ºæ¯ä¸ªæ–‡æ¡£å……åˆ†ç¡®å®šåˆé€‚çš„å…³é”®å­—ã€‚
- æ­¤å¤–ï¼Œè¿˜éœ€è¦ä»æŸ¥è¯¢ä¸­å……åˆ†æ¨æ–­å‡ºæ­£ç¡®çš„å…³é”®å­—ã€‚

LlamaIndexä¸­æå‡ºäº†ä¸€ä¸ªæ–°ç´¢å¼•ï¼Œä¸ºæ¯ä¸ªæ–‡æ¡£æå–/ç´¢å¼•**éç»“æ„åŒ–æ–‡æœ¬æ‘˜è¦**ã€‚
- è¯¥ç´¢å¼•å¯ä»¥æé«˜æ£€ç´¢æ€§èƒ½ï¼Œè¶…è¶Šç°æœ‰çš„æ£€ç´¢æ–¹æ³•ã€‚æœ‰åŠ©äºç´¢å¼•æ¯”å•ä¸ªæ–‡æœ¬å—æ›´å¤šçš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ¯”å…³é”®å­—æ ‡ç­¾å…·æœ‰æ›´å¤šçš„è¯­ä¹‰ã€‚

å¦‚ä½•æ„å»ºï¼Ÿ
- æå–æ¯ä¸ªæ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨ LLM ä»æ¯ä¸ªæ–‡æ¡£ä¸­æå–**æ‘˜è¦**ã€‚
- å°†æ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**ï¼ˆèŠ‚ç‚¹ï¼‰ã€‚æ‘˜è¦å’ŒèŠ‚ç‚¹éƒ½å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨æŠ½è±¡ä¸­ã€‚
- ç»´æŠ¤ä»**æ‘˜è¦**åˆ°**æºæ–‡æ¡£/èŠ‚ç‚¹**çš„æ˜ å°„ã€‚

åœ¨æŸ¥è¯¢æœŸé—´ï¼Œæ ¹æ®æ‘˜è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ä»¥è¿›è¡ŒæŸ¥è¯¢ï¼š
- åŸºäº **LLM** çš„æ£€ç´¢ï¼šå‘ LLM æä¾›æ–‡æ¡£æ‘˜è¦é›†ï¼Œå¹¶è¦æ±‚ LLM ç¡®å®š: å“ªäº›æ–‡æ¡£æ˜¯ç›¸å…³çš„+ç›¸å…³æ€§åˆ†æ•°ã€‚
- åŸºäº **åµŒå…¥** çš„æ£€ç´¢ï¼šæ ¹æ®æ‘˜è¦åµŒå…¥ç›¸ä¼¼æ€§ï¼ˆä½¿ç”¨ top-k æˆªæ­¢å€¼ï¼‰æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚

æ³¨æ„
- æ£€ç´¢æ–‡æ¡£**æ‘˜è¦**çš„æ–¹æ³•ä¸åŒäºåŸºäº**åµŒå…¥**çš„æ–‡æœ¬å—æ£€ç´¢ã€‚**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**æ£€ç´¢**ä»»ä½•**é€‰å®šæ–‡æ¡£çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯è¿”å›èŠ‚ç‚¹çº§åˆ«çš„ç›¸å…³å—ã€‚

å­˜å‚¨æ–‡æ¡£çš„æ‘˜è¦è¿˜å¯ä»¥å®ç°åŸºäº LLM çš„æ£€ç´¢ã€‚
- å…ˆè®© LLM æ£€æŸ¥ç®€æ˜çš„æ–‡æ¡£æ‘˜è¦ï¼Œçœ‹çœ‹æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³ï¼Œè€Œä¸æ˜¯ä¸€å¼€å§‹å°±å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLMã€‚
- è¿™åˆ©ç”¨äº† LLM çš„æ¨ç†èƒ½åŠ›ï¼Œå®ƒæ¯”åŸºäºåµŒå…¥çš„æŸ¥æ‰¾æ›´å…ˆè¿›ï¼Œä½†é¿å…äº†å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLM çš„æˆæœ¬/å»¶è¿Ÿ

å¸¦**æ‘˜è¦**çš„æ–‡æ¡£æ£€ç´¢æ˜¯**è¯­ä¹‰æœç´¢**å’Œæ‰€æœ‰æ–‡æ¡£çš„å¼ºåŠ›æ‘˜è¦ä¹‹é—´çš„â€œä¸­é—´åœ°å¸¦â€ã€‚

ç¤ºä¾‹
- æ„å»ºæ–¹æ³•è§åŸæ–‡ï¼š[LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

```sh
pip install llama-index # install
```

```py
from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader
documents = SimpleDirectoryReader('data').load_data() # åŠ è½½æ•°æ®
index = GPTVectorStoreIndex.from_documents(documents) # åˆ›å»ºç´¢å¼•
query_engine = index.as_query_engine() # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
response = query_engine.query("What did the author do growing up?") # æ‰§è¡ŒæŸ¥è¯¢
print(response) # è¿”å›ç»“æœ
# --------- æŒä¹…åŒ–å‘é‡ç´¢å¼• ---------
from llama_index import StorageContext, load_index_from_storage
index.storage_context.persist() # æŒä¹…åŒ–å­˜å‚¨ï¼ˆé»˜è®¤æ”¾å†…å­˜ï¼‰
# rebuild storage context
storage_context = StorageContext.from_defaults(persist_dir="./storage")
# load index
index = load_index_from_storage(storage_context)
```


é«˜çº§api

```py
query_engine = doc_summary_index.as_query_engine(
  response_mode="tree_summarize", use_async=True
)
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```

åº•å±‚api

```py
# use retriever as part of a query engine
from llama_index.query_engine import RetrieverQueryEngine

# configure response synthesizer
response_synthesizer = ResponseSynthesizer.from_args()

# assemble query engine
query_engine = RetrieverQueryEngine(
    retriever=retriever,
    response_synthesizer=response_synthesizer,
)
# query
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```



å®‰è£…

```sh
pip install openai
pip install llama-index
```

è°ƒç”¨ä»£ç 
- construct_indexæ–¹æ³•ä¸­ï¼Œä½¿ç”¨llama_indexçš„ç›¸å…³æ–¹æ³•ï¼Œè¯»å–data_directory_pathè·¯å¾„ä¸‹çš„txtæ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆç´¢å¼•æ–‡ä»¶å­˜å‚¨åœ¨index_cache_pathæ–‡ä»¶ä¸­ã€‚

```py
from llama_index import SimpleDirectoryReader, GPTListIndex, GPTSimpleVectorIndex, LLMPredictor, PromptHelper,ServiceContext
from langchain import OpenAI 
import gradio as gr 
import sys 
import os 
os.environ["OPENAI_API_KEY"] = 'your openai api key'
data_directory_path = 'your txt data directory path'
index_cache_path = 'your index file path'
â€‹
#æ„å»ºç´¢å¼•
def construct_index(directory_path): 
        max_input_size = 4096 
        num_outputs = 2000 
        max_chunk_overlap = 20 
        chunk_size_limit = 500
      
        llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name="text-davinci-003", max_tokens=num_outputs))
        # æŒ‰æœ€å¤§tokenæ•°500æ¥æŠŠåŸæ–‡æ¡£åˆ‡åˆ†ä¸ºå¤šä¸ªå°çš„chunk
        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=chunk_size_limit)
        # è¯»å–directory_pathæ–‡ä»¶å¤¹ä¸‹çš„æ–‡æ¡£
        documents = SimpleDirectoryReader(directory_path).load_data() 
 
        index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)
        # ä¿å­˜ç´¢å¼•
        index.save_to_disk(index_cache_path) 
        return index 
        
def chatbot(input_text): 
        # åŠ è½½ç´¢å¼•
        index = GPTSimpleVectorIndex.load_from_disk(index_cache_path) 
        response = index.query(input_text, response_mode="compact") 
        return response.response 
        
if __name__ == "__main__":
        #ä½¿ç”¨gradioåˆ›å»ºå¯äº¤äº’ui  
        iface = gr.Interface(fn=chatbot, 
                        inputs=gr.inputs.Textbox(lines=7, label="Enter your text"), 
                        outputs="text", 
                        title="Text AI Chatbot") 
        index = construct_index(data_directory_path) 
        iface.launch(share=True)
```

llama-indexçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š
- åˆ›å»ºæ–‡æœ¬å—ç´¢å¼•
- æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æœ¬å—
- ä½¿ç”¨ç›¸å…³çš„æ–‡æœ¬å—å‘ GPT-3ï¼ˆæˆ–å…¶ä»–openaiçš„æ¨¡å‹ï¼‰ æé—®
- åœ¨è°ƒç”¨queryæ¥å£çš„æ—¶å€™ï¼Œllama-indexé»˜è®¤ä¼šæ„é€ å¦‚ä¸‹çš„prompt:

```sh
"Context information is below. \n"
    "---------------------\n"
    "{context_str}"
    "\n---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the question: {query_str}\n"
```

ä½¿ç”¨ä»¥ä¸Špromptè¯·æ±‚openai çš„æ¨¡å‹æ—¶ï¼Œæ¨¡å‹æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å’Œæå‡ºçš„é—®é¢˜ï¼Œä½¿ç”¨å…¶é€»è¾‘æ¨ç†èƒ½åŠ›å¾—åˆ°æƒ³è¦çš„ç­”æ¡ˆã€‚

![](https://pic2.zhimg.com/80/v2-9aa943fe84bc25da03b866e7f52a940d_1440w.webp)

ã€2023-4-13ã€‘[å¦‚ä½•ä¸ºGPT/LLMæ¨¡å‹æ·»åŠ é¢å¤–çŸ¥è¯†ï¼Ÿ](https://www.zhihu.com/question/591935281/answer/2979220793)


#### å¦‚ä½•åˆ†å¥

ã€2023-5-25ã€‘llama-indexçš„åˆ†å¥æ–¹æ³•ï¼šåŠ è‡ªå®šä¹‰éƒ¨åˆ†ï¼ˆå‰åç¼€ç­‰ï¼‰â†’è°ƒç”¨nltk.tokenize.punktåˆ†å¥ï¼ˆè‡ªå®šä¹‰å¥æœ«æ­£åˆ™ï¼‰â†’æŒ‰ç…§chunk_sizeæˆªæ–­â†’åˆ†å¥åˆ—è¡¨ï¼Œ[æºç ](https://github.com/jerryjliu/llama_index/blob/c5a4cc1581cc6ee8277f970e7b0b2cbbd6351eb5/llama_index/langchain_helpers/text_splitter.py#LL267C7-L267C23)



### retrieve-then-generate

1ã€retrieve-then-generateï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
 
æ ¸å¿ƒï¼šæ ¹æ® è¾“å…¥query æ£€ç´¢æœ¬åœ°/ç§æœ‰æ•°æ®åº“/æ–‡æ¡£ä¸­çš„æ–‡æ¡£ç‰‡æ®µï¼ˆæ£€ç´¢å¯ä»¥æ˜¯æ–‡æœ¬æ£€ç´¢æˆ–åŸºäºå‘é‡çš„æ£€ç´¢ï¼‰ï¼Œä½œä¸ºæ‰©å……çš„ä¸Šä¸‹æ–‡ contextï¼Œé€šè¿‡ prompt template ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„è¾“å…¥ï¼Œç»§è€Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆresponseã€‚

ç®€ç‰ˆå·¥ä½œæµï¼š
- chunk -> index -> retrieve -> construct input -> LLM
 
æ¨èå¼€æºå·¥å…·ï¼š
- ï¼ˆ1ï¼‰OpenAI çš„å®˜æ–¹æ’ä»¶ï¼š[ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin)
- ï¼ˆ2ï¼‰llama-indexï¼š[https://github.com/jerryjliu/llama_index](https://github.com/jerryjliu/llama_index)ï¼Œæä¾›äº†ä¸€ä¸ªæœ¬åœ°/ç§æœ‰æ•°æ®æ”¶é›†ï¼ˆingestionï¼‰å’Œæ•°æ®ç´¢å¼•ï¼ˆindexingï¼‰çš„è§£å†³æ–¹æ¡ˆï¼Œæ„å»ºèµ·å¤–éƒ¨æ•°æ®å’Œ LLM ä¹‹é—´çš„æ¥å£ã€‚

ä¸€ä¸ªåˆ©ç”¨ llama-index å®šåˆ¶ä¸ªäººè®ºæ–‡æ£€ç´¢çš„ç¤ºä¾‹ï¼š[llama_index/examples/paul_graham_essay at main Â· jerryjliu/llama_index](https://github.com/jerryjliu/llama_index/tree/main/examples/paul_graham_essay)ã€‚
 
ï¼ˆåœ¨æ²¡æœ‰OpenAI APIçš„æƒ…å†µä¸‹ï¼Œllama-index æ”¯æŒè°ƒç”¨è‡ªå®šä¹‰çš„ LLMã€‚ï¼‰
 
ï¼ˆ3ï¼‰LangChainï¼š[langchain](https://github.com/hwchase17/langchain)ï¼Œä¹Ÿæ˜¯ä¸ºäº†æ›´å¥½çš„æ„å»ºå¤–éƒ¨æ•°æ®ã€å…¶ä»–åº”ç”¨ä¸ LLM è¿›è¡Œäº¤äº’çš„æ¥å£å±‚æ¡†æ¶ã€‚

LangChainåº”ç”¨å‚è€ƒç¤ºä¾‹ï¼š[GPT-4 & LangChainâ€”â€”PDFèŠå¤©æœºå™¨äºº-åœ°è¡¨æœ€å¼ºå…¨æ–‡æœç´¢](https://www.bilibili.com/read/cv22589352)ã€‚
 
llama-index å’Œ LangChain å¯ä»¥ç»„åˆä½¿ç”¨ï¼ŒLangChain ä¸­æä¾›äº† é¢å‘ä¸åŒä»»åŠ¡çš„ prompt template å’Œ prompt chainã€‚
 
### åŸºäº fine-tuning çš„æ–¹å¼

2ã€åŸºäº fine-tuning çš„æ–¹å¼ï¼Œç›¸æ¯”äºç¬¬ä¸€ç§æ–¹æ¡ˆï¼ŒåŸºäº fine-tuning çš„æ–¹å¼éœ€è¦é¢å¤–çš„è®­ç»ƒå¼€é”€ï¼ŒåŒæ—¶è¿˜æ˜¯ä¼šå—é™äºLLMçš„æœ€å¤§é•¿åº¦é™åˆ¶ã€‚

â€œè®© LLM å…·å¤‡ç†è§£å®šåˆ¶æ•°æ®åº“çš„èƒ½åŠ›â€æ˜¯å¾ˆæœ‰æŒ‘æˆ˜çš„ç›®æ ‡ï¼ŒåŒæ—¶ä¹Ÿä¼šæœ‰å¾ˆå¤šåº”ç”¨åœºæ™¯ã€‚

ä½¿ç”¨Hugging Faceå®ç°å°†ç»´åŸºç™¾ç§‘çš„çŸ¥è¯†åº“æ·»åŠ åˆ°GPT-2æ¨¡å‹ä¸­
- ä½œè€…ï¼š[å°æ–å®æˆ˜](https://www.zhihu.com/question/591935281/answer/2960837503)

```py
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')

# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# åŠ è½½ç»´åŸºç™¾ç§‘çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°æ®é›†
dataset = TextDataset(
    tokenizer=tokenizer,
    file_path='path/to/wiki.txt',
    block_size=128
)

# åˆ›å»ºdata collator
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer, 
    mlm=False
)

# è®¾ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir='./results',          # è¾“å‡ºç›®å½•
    num_train_epochs=3,              # è®­ç»ƒçš„è½®æ•°
    per_device_train_batch_size=8,   # è®­ç»ƒæ—¶æ¯ä¸ªGPUçš„batch size
    per_device_eval_batch_size=8,    # éªŒè¯æ—¶æ¯ä¸ªGPUçš„batch size
    evaluation_strategy='steps',     # è¯„ä¼°ç­–ç•¥
    save_steps=500,                  # å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹
    save_total_limit=2,              # æœ€å¤šä¿å­˜å‡ ä¸ªæ¨¡å‹
    logging_steps=500,               # å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    learning_rate=5e-5,              # å­¦ä¹ ç‡
# åˆ›å»ºTrainerå¯¹è±¡
trainer = Trainer(
model=model,
args=training_args,
train_dataset=dataset,
data_collator=data_collator,
prediction_loss_only=True
)

# å¼€å§‹è®­ç»ƒ
trainer.train()

# ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
trainer.save_model('./fine-tuned-model')
```

### çŸ¥è¯†å›¾è°±å¢å¼º

ä½¿ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºGPT-2æ¨¡å‹çš„ç¤ºä¾‹ä»£ç ï¼š

```python
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')
# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
# åŠ è½½çŸ¥è¯†å›¾è°±: è¡¨ç¤ºä¸€äº›å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚
knowledge_graph = {
    'John': {
        'is a': 'person',
        'born in': 'New York',
        'works at': 'Google'
    },
    'Google': {
        'is a': 'company',
        'headquartered in': 'California',
        'founded by': 'Larry Page and Sergey Brin'
    }
}

# å°†çŸ¥è¯†å›¾è°±åµŒå…¥åˆ°æ¨¡å‹ä¸­
model.resize_token_embeddings(len(tokenizer))
for entity in knowledge_graph.keys():
    entity_id = tokenizer.convert_tokens_to_ids(entity)
    entity_embedding = torch.randn(768)
    model.transformer.wte.weight.data[entity_id] = entity_embedding

# ç”Ÿæˆå¥å­
input_text = 'John works at'
input_ids = tokenizer.encode(input_text, return_tensors='pt')
output = model.generate(
    input_ids,
    max_length=50,
    do_sample=True,
    top_k=50
)
output_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(output_text)
```

## LLMåº”ç”¨

### LLMåº”ç”¨æŠ€æœ¯æ¶æ„

- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/871e57dfdaf24ba3a064e79ba0522a7b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=eQeTT9ERDeEgx00BF9U9cVyrx%2FY%3D)

å…¸å‹LLMåº”ç”¨å¼€å‘æ¶æ„å››å±‚ï¼š
- ï¼ˆ1ï¼‰`å­˜å‚¨å±‚`ï¼šä¸»è¦ä¸º`å‘é‡æ•°æ®åº“`ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰ç¼–ç åçš„ç‰¹å¾å‘é‡ï¼Œæ”¯æŒå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢ä¸åˆ†æã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨åšæ–‡æœ¬è¯­ä¹‰æ£€ç´¢æ—¶ï¼Œé€šè¿‡æ¯”è¾ƒè¾“å…¥æ–‡æœ¬çš„ç‰¹å¾å‘é‡ä¸åº•åº“æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œæ£€ç´¢ç›®æ ‡æ–‡æœ¬ï¼Œå³åˆ©ç”¨äº†å‘é‡æ•°æ®åº“ä¸­çš„ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ï¼‰ã€‚
  - ã€ä»£è¡¨æ€§æ•°æ®åº“ã€‘`Pinecone`ã€`Qdrant`ã€‚
- ï¼ˆ2ï¼‰`æ¨¡å‹å±‚`ï¼šé€‰æ‹©å¤§è¯­è¨€æ¨¡å‹ï¼Œå¦‚OpenAIçš„GPTç³»åˆ—æ¨¡å‹ã€Hugging Faceä¸­çš„å¼€æºLLMç³»åˆ—ç­‰ã€‚
  - æ¨¡å‹å±‚æä¾›æœ€æ ¸å¿ƒæ”¯æ’‘ï¼ŒåŒ…æ‹¬èŠå¤©æ¥å£ã€ä¸Šä¸‹æ–‡QAé—®ç­”æ¥å£ã€æ–‡æœ¬æ€»ç»“æ¥å£ã€æ–‡æœ¬ç¿»è¯‘æ¥å£ç­‰ã€‚
  - ã€ä»£è¡¨æ€§æ¨¡å‹ã€‘OpenAIçš„`GPT-3.5/4`ï¼ŒAnthropicçš„`Claude`ï¼ŒGoogleçš„`PaLM`ï¼ŒTHUçš„`ChatGLM`ç­‰ã€‚
- ï¼ˆ3ï¼‰`æœåŠ¡å±‚`ï¼šå°†å„ç§è¯­è¨€æ¨¡å‹æˆ–å¤–éƒ¨**èµ„æºæ•´åˆ**ï¼Œæ„å»ºå®ç”¨çš„LLMæ¨¡å‹ã€‚
  - `Langchain`æ˜¯ä¸€ä¸ªå¼€æºLLMåº”ç”¨æ¡†æ¶ï¼Œæ¦‚å¿µæ–°é¢–ï¼Œå°†LLMæ¨¡å‹ã€å‘é‡æ•°æ®åº“ã€äº¤äº’å±‚Promptã€å¤–éƒ¨çŸ¥è¯†ã€å¤–éƒ¨å·¥å…·æ•´åˆåˆ°ä¸€èµ·ï¼Œå¯è‡ªç”±æ„å»ºLLMåº”ç”¨ã€‚
  - ã€ä»£è¡¨æ€§æ¡†æ¶ã€‘ï¼š`LangChain`ï¼Œ`AutoGPT`ï¼Œ`BabyAGI`ï¼Œ`Llama-Index`ç­‰ã€‚
- ï¼ˆ4ï¼‰`äº¤äº’å±‚`ï¼šç”¨æˆ·é€šè¿‡UIä¸LLMåº”ç”¨äº¤äº’
  - `langflow`æ˜¯`langchain`çš„GUIï¼Œé€šè¿‡æ‹–æ”¾ç»„ä»¶å’ŒèŠå¤©æ¡†æ¶æä¾›ä¸€ç§è½»æ¾çš„å®éªŒå’ŒåŸå‹æµç¨‹æ–¹å¼ã€‚
  - å®ç°ä¸€ä¸ªç®€å•çš„èŠå¤©åº”ç”¨ï¼Œè¾“å…¥â€œåŸå¸‚åå­—â€ï¼ŒèŠå¤©æœºå™¨äººå›å¤â€œè¯¥åŸå¸‚çš„å¤©æ°”æƒ…å†µâ€ã€‚
  - åªéœ€è¦æ‹–åŠ¨ä¸‰ä¸ªç»„ä»¶ï¼šPromptTemplateã€OpenAIã€LLMChainã€‚å®ŒæˆPromptTemplateã€OpenAIã€LLMChainçš„ç•Œé¢åŒ–ç®€å•é…ç½®å³å¯ç”Ÿæˆåº”ç”¨ã€‚
  - ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/03233a4e108f4ffaae147afcac50d03e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=Z9D%2Blt1IqZVkBHXAGG1QjyORqLk%3D)


### LLM åº”ç”¨

ã€2023-5-30ã€‘[ä¸‡å­—é•¿æ–‡ï¼šLLMåº”ç”¨æ„å»ºå…¨è§£æ](https://www.toutiao.com/article/7238815236906680836)


#### LLM åº”ç”¨æ€»ç»“

LLM åº”ç”¨
- 1ã€**æœ¬åœ°æ–‡æ¡£**çŸ¥è¯†é—®ç­”åŠ©ç†(chat with pdf)ï¼Œå¦‚ï¼šç§åŸŸçŸ¥è¯†é—®ç­”åŠ©ç†ï¼Œæ™ºèƒ½å®¢æœï¼Œè¯­ä¹‰æ£€ç´¢æ€»ç»“ã€è¾…åŠ©æ•™å­¦ã€‚
- 2ã€**è§†é¢‘**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with video)ï¼Œå¦‚ï¼šè§†é¢‘è‡ªåŠ¨ç¼–ç›®ã€è§†é¢‘æ£€ç´¢é—®ç­”ã€‚
- 3ã€**è¡¨æ ¼**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with csv)ï¼Œå¦‚ï¼šå•†ä¸šæ•°æ®åˆ†æã€å¸‚åœºè°ƒç ”åˆ†æã€å®¢æˆ·æ•°æ®ç²¾å‡†åˆ†æç­‰

#### 1. Doc-Chat æ–‡æ¡£é—®ç­”

æœ‰å¤§é‡æœ¬åœ°æ–‡æ¡£æ•°æ®ï¼Œå¸Œæœ›é€šè¿‡é—®ç­”çš„æ–¹å¼å¿«é€Ÿè·å–æƒ³è¦çš„çŸ¥è¯†æˆ–ä¿¡æ¯ï¼Œæé«˜å·¥ä½œæ•ˆç‡

è§£å†³æ–¹æ¡ˆï¼š
> langchain + llms

æœ¬åœ°åŒ–çŸ¥è¯†ä¸“å±é—®ç­”åŠ©ç†æ„å»ºè¿‡ç¨‹å¯ç®€å•æ¦‚æ‹¬å¦‚ä¸‹ï¼š
- ç¬¬ä¸€æ­¥ï¼š**æ•°æ®åŠ è½½&é¢„å¤„ç†**ï¼ˆå°†æ•°æ®æºè½¬æ¢ä¸ºtextï¼Œå¹¶åštext splitç­‰é¢„å¤„ç†ï¼‰
- ç¬¬äºŒæ­¥ï¼š**å‘é‡åŒ–**ï¼ˆå°†å¤„ç†å®Œæˆçš„æ•°æ®embeddingå¤„ç†ï¼‰
- ç¬¬ä¸‰æ­¥ï¼š**å¬å›**ï¼ˆé€šè¿‡å‘é‡æ£€ç´¢å·¥å…·Faissç­‰å¯¹queryç›¸å…³æ–‡æ¡£å¬å›ï¼‰
- ç¬¬å››æ­¥ï¼šé˜…è¯»ç†è§£ï¼Œ**æ€»ç»“ç­”æ¡ˆ**ï¼ˆå°†contextä¸queryä¼ ç»™llmsï¼Œæ€»ç»“ç­”æ¡ˆï¼‰
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a978188a6d0d4d7db75e0818e286c32c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=daelWSDLtJ1ruh29TjQfkyddRhg%3D)

##### ï¼ˆ1ï¼‰æ•°æ®åŠ è½½&é¢„å¤„ç†

åŠ è½½pdfæ–‡ä»¶ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—
- æ¯ä¸ªåˆ†å—çš„æœ€å¤§é•¿åº¦ä¸º3000ä¸ªå­—ç¬¦)ã€‚è¿™ä¸ªæœ€å¤§é•¿åº¦æ ¹æ®llmçš„è¾“å…¥å¤§å°ç¡®å®šï¼Œæ¯”å¦‚gpt-3.5-turboæœ€å¤§è¾“å…¥æ˜¯4096ä¸ªtokenã€‚
- ç›¸é‚»å—ä¹‹é—´çš„é‡å éƒ¨åˆ†ä¸º400ä¸ªå­—ç¬¦ï¼Œç›®çš„æ˜¯æ¯ä¸ªç‰‡æ®µä¿ç•™ä¸€å®šçš„**ä¸Šæ–‡ä¿¡æ¯**ï¼Œåç»­å¤„ç†ä»»åŠ¡åˆ©ç”¨é‡å ä¿¡æ¯æ›´å¥½ç†è§£æ–‡æœ¬ã€‚

æ–¹æ¡ˆ
- LangChain + FAISS + OpenAI

```py
import os

openai_api_key = 'sk-F9Oxxxxxx3BlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key
from langchain.llms import OpenAI
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
from langchain import PromptTemplate

llm = OpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=openai_api_key)

# data loader
loader = PyPDFLoader("data/ZT91.pdf")
doc = loader.load()
# text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)
docs = text_splitter.split_documents(doc)
```

##### ï¼ˆ2ï¼‰å‘é‡åŒ–

è°ƒç”¨ OpenAIEmbeddingsæ¥å£å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ã€‚
- å®é™…åº”ç”¨ä¸­ï¼Œå¯ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆOpenAIEmbeddingsç”¨çš„æ˜¯ç¬¬6ä¸ªï¼‰ã€‚åŒæ—¶ï¼Œä¸­æ–‡embeddingæ•ˆæœä¼˜ç§€çš„æ¨¡å‹æœ‰ç™¾åº¦çš„ERNIEã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/495e57fd56ea4ccc9790418aab290354~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=X394ecc51Xmjra6dRr2AiK6Bwqc%3D)

```py
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
```

##### ï¼ˆ3ï¼‰å¬å›

ç”¨FAISSå·¥å…·å¯¹è¾“å…¥æ–‡æ¡£æ„å»ºFAISSç´¢å¼•ï¼Œè¿”å›æ„å»ºå¥½çš„FAISSç´¢å¼•å¯¹è±¡ã€‚

åˆ›å»ºFAISSç´¢å¼•åŒ…å«çš„å·¥ä½œæœ‰ï¼š
- ä¸ºç´¢å¼•åˆ†é…å†…å­˜ç©ºé—´ï¼›
- é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹ä¸å‚æ•°ï¼ˆæ¯”å¦‚Flat IVFFlatç­‰ï¼‰ï¼›
- å°†æ–‡æ¡£å‘é‡æ·»åŠ åˆ°ç´¢å¼•ä¸­ã€‚

```py
docsearch = FAISS.from_documents(docs, embeddings)
# docsearch.as_retriever(search_kwargs={"k": 5})è¡¨ç¤ºè¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„chunksï¼Œé»˜è®¤æ˜¯4ï¼Œå¯ä»¥ä¿®æ”¹
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})


```

##### ï¼ˆ4ï¼‰æ€»ç»“ç­”æ¡ˆ

- è¾“å…¥ï¼šquery + context
- è¾“å‡ºï¼šanswer

å…¶ä¸­ context ä¸ºé€šè¿‡faiss retrieveræ£€ç´¢å‡ºçš„ç›¸å…³æ–‡æ¡£ï¼š

ç‰¹åˆ«çš„ï¼Œä¸ºäº†è®©gptåªå›ç­”æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œåœ¨prompt_template å¢åŠ äº†çº¦æŸï¼šâ€œè¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼šâ€ã€‚å³å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç”¨æˆ·æé—®ç›¸å…³å†…å®¹ï¼Œéœ€è¦å›ç­”â€œä¸çŸ¥é“â€ï¼Œé˜²æ­¢â€œç­”éæ‰€é—®â€è¯¯å¯¼ç”¨æˆ·ã€‚

```py
prompt_template = """è¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼š
    Context: {context}
    Question: {question}
    Answer:"""
# è¾“å…¥ï¼šquery + context
PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
query = "å®æ—¶ç”»é¢æ— æ³•æŸ¥çœ‹ï¼Œæ€æ ·è§£å†³ï¼Ÿ"
# FAISSæ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£ï¼šretriever=docsearch.as_retriever(search_kwargs={"k": 5})
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})
# queryä¸ºç”¨æˆ·è¾“å…¥çš„æé—®
qa.run(query)
```

#### 2. è§†é¢‘çŸ¥è¯†æ€»ç»“

LLM çœ‹å®Œè§†é¢‘ï¼Œå›ç­”é—®é¢˜

éœ€æ±‚æè¿°ï¼š
- youtubeç­‰è§†é¢‘ç½‘ç«™ä¸Šæ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡è§†é¢‘ï¼Œè™½ç„¶æ¨èç³»ç»ŸæŒ‰ç…§å–œå¥½è¿›è¡Œäº†æ¨èï¼Œä½†è§‚çœ‹å¤§é‡æœ‰ä»·å€¼çš„è§†é¢‘ä¾ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚æœèƒ½å¤Ÿå¿«é€Ÿäº†è§£è§†é¢‘å†…å®¹ï¼Œå¹¶å¾—åˆ°å…³æ³¨çš„ä¿¡æ¯ï¼Œå°†æå¤§æé«˜ä¿¡æ¯è·å–æ•ˆç‡ã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain + transcript + llms
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d565d76640004377abc1bcd989577fa7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=XoDjL3a6u4n%2FIC8AbQRMBoJF9zQ%3D)

ä¸pdfæ–‡æ¡£å¤„ç†æ–¹å¼ä¸åŒï¼ŒYoutubeLoaderåº“ä»youtube**è§†é¢‘é“¾æ¥**ä¸­åŠ è½½æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºæ–‡æ¡£ã€‚
- æ–‡æ¡£è·å–è¿‡ç¨‹: é€šè¿‡youtube-transcript-apiè·å–çš„è§†é¢‘çš„å­—å¹•æ–‡ä»¶ï¼Œè¿™ä¸ªå­—å¹•æ–‡ä»¶æ˜¯youtubeç”Ÿæˆçš„ã€‚å½“ç”¨æˆ·å°†è§†é¢‘ä¸Šä¼ è‡³youtubeæ—¶ï¼Œyoutubeä¼šé€šè¿‡å†…ç½®çš„è¯­éŸ³è¯†åˆ«ç®—æ³•å°†è§†é¢‘è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ã€‚å½“åŠ è½½youtubeè§†é¢‘å­—å¹•æ–‡æ¡£åï¼Œæ¥ä¸‹æ¥çš„å¤„ç†å·¥ä½œä¸ç¬¬ä¸€ä¸ªä¾‹å­ç±»ä¼¼ã€‚

```py
# åŠ è½½ youtube é¢‘é“
loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=_rcnWQ0b2lM')
# å°†æ•°æ®è½¬æˆ document
documents = loader.load()
```

Question:
> â€œå¯¹è§†é¢‘ä¸­ä»‹ç»çš„å†…å®¹ï¼Œé€æ¡åˆ—ä¸¾ï¼Ÿâ€



#### 3. è¡¨æ ¼é—®ç­”

LLM åˆ†æå®Œ 54ä¸‡æ¡æ•°æ®ï¼Œç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œå®Œæˆäº†æ•°æ®åˆ†æå¸ˆ1å¤©çš„å·¥ä½œã€‚

éœ€æ±‚æè¿°ï¼š
- é›¶å”®å•†æœ‰å®¢æˆ·çš„äº¤æ˜“æ•°æ®ã€‚å¸Œæœ›ä»æ•°æ®ä¸­ç”Ÿæˆä¸€äº›åŸºæœ¬è§è§£ï¼Œä»¥ä¾¿è¯†åˆ«æœ€ä½³å®¢æˆ·ã€‚
- ä¾‹å¦‚ï¼šæŒ‰æ€§åˆ«å’Œå¹´é¾„ç»„åˆ’åˆ†çš„å¹³å‡æ”¯å‡ºã€æ¯ç§ç±»å‹çš„å®¢æˆ·è´­ä¹°çš„äº§å“ã€äº§å“åœ¨å“ªä¸ªåŸå¸‚å’Œå•†åº—çš„é”€å”®é¢æœ€é«˜ç­‰ç­‰
- æ•°æ®åˆ†æå¸ˆå°†è·å–æ•°æ®ï¼Œç¼–å†™ä¸€äº› SQL æˆ– Python æˆ– R ä»£ç ï¼Œç”Ÿæˆè§è§£ï¼Œæ•°æ®åˆ†æå¸ˆå¯èƒ½éœ€è¦ä¸€å¤©çš„æ—¶é—´æ¥æä¾›è¿™äº›ç»“æœã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain+llm + agents
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/c12a12fb285e431b94a9179846dd67e8~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=pGos9u09HxT9ppxKfL4lz74LA%2F4%3D)

ä»»åŠ¡
- (1) æ˜¾ç¤ºè¡¨æ ¼ä¸­ç”¨æˆ·çš„æ•°é‡
  - éªŒè¯: agentç»™å‡ºçš„ç­”æ¡ˆå®Œå…¨æ­£ç¡®
- (2) å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´ç›¸å…³æ€§åˆ†æ
  - åˆ†æä¸‹å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§ï¼šå¹´é¾„ä¸æ¶ˆè´¹æˆæ­£ç›¸å…³ï¼Œä½†æ˜¯ç›¸å…³æ€§å¾ˆå¼±
- (3) äº§å“é”€å”®é‡ç»Ÿè®¡å¹¶ç”»å‡ºæŸ±çŠ¶å›¾
  - ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾


```py
import os
from langchain.agents import create_csv_agent
from langchain.llms import OpenAI

openai_api_key = 'sk-F9O70vxxxxxxxBlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key

agent = create_csv_agent(OpenAI(openai_api_key=openai_api_key, temperature=0), 'train.csv', verbose=True)
# ç»Ÿè®¡ç”¨æˆ·æ•°
agent.run("è¯·æŒ‰ç…§æ€§åˆ«å¯¹ç”¨æˆ·æ•°é‡è¿›è¡Œæ˜¾ç¤ºï¼Ÿ")
# å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§
agent.run("åœ¨è¿™ä»½è¡¨æ ¼ä¸­,å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§?")
# ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾
agent.run("äº§å“1æ€»é‡,äº§å“2æ€»é‡,äº§å“3æ€»é‡åˆ†åˆ«æ˜¯å¤šå°‘,å°†ä¸‰ä¸ªæ€»é‡é€šè¿‡æŸ±çŠ¶å›¾ç”»å‡ºæ¥å¹¶æ˜¾ç¤º")
```




## å­˜å‚¨å±‚ï¼šæ–‡æ¡£å‘é‡åŒ–

è‡ªç ”æ¡†æ¶çš„é€‰æ‹©
- åŸºäºOpenAIEmbeddingsï¼Œå®˜æ–¹ç»™å‡ºäº†åŸºäºembeddingsæ£€ç´¢æ¥è§£å†³GPTæ— æ³•å¤„ç†é•¿æ–‡æœ¬å’Œæœ€æ–°æ•°æ®çš„é—®é¢˜çš„å®ç°æ–¹æ¡ˆã€‚[å‚è€ƒ](https://www.datalearner.com/blog/1051681543488862)
- ä¹Ÿå¯ä»¥ä½¿ç”¨ LangChain æ¡†æ¶ã€‚

å‚è€ƒ
- [ChatGPTæ€ä¹ˆå»ºç«‹ç§æœ‰çŸ¥è¯†åº“ï¼Ÿ](https://www.zhihu.com/question/596838257/answer/3004754396)
- [åˆ©ç”¨LangChainå’Œå›½äº§å¤§æ¨¡å‹ChatGLMå®ç°åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­”](https://www.zhihu.com/zvideo/1630964532179812353)

é™¤äº†ä»æ–‡æ¡£ä¸­æŠ“å–æ•°æ®ï¼Œä»æŒ‡å®šç½‘ç«™URLæŠ“å–æ•°æ®ï¼Œå®ç°æ™ºèƒ½å®¢æœå¤–éƒ¨çŸ¥è¯†åº“ï¼Œå¯ä»¥å€ŸåŠ©ChatGPTå†™Pythonä»£ç ï¼ŒPythonBeautiful Soupåº“çš„å®ç°æ–¹å¼å¾ˆæˆç†Ÿ

å¤§å‚äº§å“æˆªå›¾ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“å»ºè®¾
- ä¼ä¸šèµ„æ–™åº“ï¼Œå…³è”å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨æœç´¢
- ![a](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYAg6aFUKbz~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=5kqgHWkZX6LPdrX2H9Zq59m%2BwO0%3D)
- å¤§æ¨¡å‹æ–‡æ¡£çŸ¥è¯†æŠ½å–å’Œâ€œå³æœå³é—®â€
- ![b](https://p9-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYkN7rAGx03~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=gO%2FqHxavS7KVAfE08Mv0WayLjLQ%3D)
- ![b](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYmX2ImA5oO~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=rlim2GCZ8zsapnPyzA47LCHJkEo%3D)


### æ–‡æœ¬åˆ‡åˆ†

LangChain åˆ‡åˆ†å·¥å…·
- [Text Splittersæ–‡æ¡£](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html): é€‰æ‹©å¯¹åº”çš„æ–‡æœ¬åˆ‡åˆ†å™¨ï¼Œå¦‚æœæ˜¯é€šç”¨æ–‡æœ¬çš„è¯ï¼Œå»ºè®®é€‰æ‹© `RecursiveCharacterTextSplitter`

```py
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¯¼å…¥æ–‡æœ¬
loader = UnstructuredFileLoader("./data/news_test.txt")
# å°†æ–‡æœ¬è½¬æˆ Document å¯¹è±¡
data = loader.load()
print(f'documents:{len(data)}')

# åˆå§‹åŒ–åŠ è½½å™¨
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)
# åˆ‡å‰²åŠ è½½çš„ document
split_docs = text_splitter.split_documents(data)
print("split_docs size:",len(split_docs))
```

### ç›¸ä¼¼åº¦

ç›¸ä¼¼åº¦ç´¢å¼•
- åªç”¨embeddingæ¥è®¡ç®—å¥å­çš„ç›¸ä¼¼åº¦

```py
# åˆå§‹åŒ– prompt å¯¹è±¡
question = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
# æœ€å¤šè¿”å›åŒ¹é…çš„å‰4æ¡ç›¸ä¼¼åº¦æœ€é«˜çš„å¥å­
similarDocs = db.similarity_search(question, include_metadata=True,k=4)
# [print(x) for x in similarDocs]
```

æ¥å…¥ChatGLMæ¥å¸®å¿™åšæ€»ç»“å’Œæ±‡æ€»

```py
from langchain.chains import RetrievalQA
import IPython
# æ›´æ¢ LLM
qa = RetrievalQA.from_chain_type(llm=ChatGLM(temperature=0.1), chain_type="stuff", retriever=retriever)
# è¿›è¡Œé—®ç­”
query = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
print(qa.run(query))
```

### å‘é‡æ•°æ®åº“

å‘é‡æ•°æ®åº“ï¼ˆVectorstoresï¼‰ç”¨äºå­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰ç¼–ç åçš„**ç‰¹å¾å‘é‡**ï¼Œæ”¯æŒå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢ä¸åˆ†æã€‚
- æ–‡æœ¬è¯­ä¹‰æ£€ç´¢ï¼Œé€šè¿‡æ¯”è¾ƒè¾“å…¥æ–‡æœ¬çš„ç‰¹å¾å‘é‡ä¸åº•åº“æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œæ£€ç´¢ç›®æ ‡æ–‡æœ¬ï¼Œå³åˆ©ç”¨äº†å‘é‡æ•°æ®åº“ä¸­çš„ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ï¼‰ã€‚

å› ä¸ºæ•°æ®ç›¸å…³æ€§æœç´¢å…¶å®æ˜¯å‘é‡è¿ç®—ã€‚æ‰€ä»¥ï¼Œä¸ç®¡ä½¿ç”¨ openai api embedding åŠŸèƒ½è¿˜æ˜¯ç›´æ¥é€šè¿‡ å‘é‡æ•°æ®åº“ ç›´æ¥æŸ¥è¯¢ï¼Œéƒ½éœ€è¦å°†åŠ è½½è¿›æ¥çš„æ•°æ® Document è¿›è¡Œ**å‘é‡åŒ–**ï¼Œæ‰èƒ½è¿›è¡Œå‘é‡è¿ç®—æœç´¢ã€‚

è½¬æ¢æˆå‘é‡ä¹Ÿå¾ˆç®€å•ï¼Œåªéœ€è¦æŠŠæ•°æ®å­˜å‚¨åˆ°å¯¹åº”çš„å‘é‡æ•°æ®åº“ä¸­å³å¯å®Œæˆå‘é‡çš„è½¬æ¢ã€‚

å®˜æ–¹ä¹Ÿæä¾›äº†å¾ˆå¤šçš„å‘é‡æ•°æ®åº“ä¾›æˆ‘ä»¬ä½¿ç”¨ï¼ŒåŒ…æ‹¬ï¼š
- Annoy
- Chroma
- ElasticSearch
- FAISS
- Milvus
- PGVector
- Pinecone
- Redis

ä»£è¡¨æ€§æ•°æ®åº“
- Chromaã€Pineconeã€Qdrand

æ›´å¤šæ”¯æŒçš„å‘é‡æ•°æ®åº“ä½¿ç”¨æ–¹æ³•ï¼Œå¯è½¬è‡³é“¾æ¥ã€‚

### OpenAIEmbeddings

OpenAIå®˜æ–¹çš„embeddingæœåŠ¡

OpenAIEmbeddingsï¼š
- ä½¿ç”¨ç®€å•ï¼Œå¹¶ä¸”æ•ˆæœæ¯”è¾ƒå¥½ï¼›

é—®é¢˜
- ä¼šæ¶ˆè€—openaiçš„tokenï¼Œç‰¹åˆ«æ˜¯å¤§æ®µæ–‡æœ¬æ—¶ï¼Œ**æ¶ˆè€—çš„token**è¿˜ä¸å°‘ï¼Œå¦‚æœçŸ¥è¯†åº“æ˜¯æ¯”è¾ƒå›ºå®šçš„ï¼Œå¯ä»¥è€ƒè™‘å°†æ¯æ¬¡ç”Ÿæˆçš„embeddingåšæŒä¹…åŒ–ï¼Œè¿™æ ·å°±ä¸éœ€è¦å†è°ƒç”¨openaiäº†ï¼Œå¯ä»¥å¤§å¤§èŠ‚çº¦tokençš„æ¶ˆè€—ï¼›
- å¯èƒ½ä¼šæœ‰**æ•°æ®æ³„éœ²**çš„é£é™©ï¼Œå¦‚æœæ˜¯ä¸€äº›é«˜åº¦ç§å¯†çš„æ•°æ®ï¼Œä¸å»ºè®®ç›´æ¥è°ƒç”¨ã€‚

```py
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import VectorDBQA
from langchain.document_loaders import UnstructuredMarkdownLoader
from langchain.embeddings.openai import OpenAIEmbeddings
import IPython
import os
from dotenv import load_dotenv
load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_BASE"] = os.getenv("OPENAI_API_BASE")

embeddings = OpenAIEmbeddings()

# ---- ç®€æ´ç‰ˆ -------
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
```

### HuggingFaceEmbeddings

HuggingFaceEmbeddingsï¼š

å¯ä»¥åœ¨HuggingFaceä¸Šé¢é€‰æ‹©å„ç§sentence-similarityæ¨¡å‹æ¥è¿›è¡Œå®éªŒï¼Œæ•°æ®éƒ½æ˜¯åœ¨æœ¬æœºä¸Šè¿›è¡Œè®¡ç®—
éœ€è¦ä¸€å®šçš„ç¡¬ä»¶æ”¯æŒï¼Œæœ€å¥½æ˜¯æœ‰GPUæ”¯æŒï¼Œä¸ç„¶ç”Ÿæˆæ•°æ®å¯èƒ½ä¼šéå¸¸æ…¢
ç”Ÿæˆçš„å‘é‡æ•ˆæœå¯èƒ½ä¸æ˜¯å¾ˆå¥½ï¼Œå¹¶ä¸”HuggingFaceä¸Šçš„ä¸­æ–‡å‘é‡æ¨¡å‹ä¸æ˜¯å¾ˆå¤šã€‚

```py
from langchain.vectorstores import Chroma
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
import IPython
import sentence_transformers

embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "GanymedeNil/text2vec-large-chinese",
    "text2vec2":"uer/sbert-base-chinese-nli",
    "text2vec3":"shibing624/text2vec-base-chinese",
}

EMBEDDING_MODEL = "text2vec3"
# åˆå§‹åŒ– hugginFace çš„ embeddings å¯¹è±¡
embeddings = HuggingFaceEmbeddings(model_name=embedding_model_dict[EMBEDDING_MODEL], )
embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='mps')
```

### Faiss


```py
from langchain.vectorstores import FAISS

db = FAISS.from_documents(split_docs, embeddings)
db.save_local("./faiss/news_test")
# åŠ è½½æŒä¹…åŒ–å‘é‡
db = FAISS.load_local("./faiss/news_test",embeddings=embeddings)
# ====== æˆ– ========
vs_path = "./vector_store"
if vs_path and os.path.isdir(vs_path):
    vector_store = FAISS.load_local(vs_path, embeddings)
    vector_store.add_documents(docs)
else:
    if not vs_path:
        vs_path = f"""{VS_ROOT_PATH}{os.path.splitext(file)[0]}_FAISS_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}"""
    vector_store = FAISS.from_documents(docs, embeddings)

vector_store.save_local(vs_path)
docs = vector_store.similarity_search(query)
docs_and_scores = vector_store.similarity_search_with_score(query)
```


### Mulvus


```py
vector_db = Milvus.from_documents(
    docs,
    embeddings,
    connection_args={"host": "127.0.0.1", "port": "19530"},
)
docs = vector_db.similarity_search(query)
docs[0]
```


### Chroma

Chroma æ¯”è¾ƒè½»é‡ï¼Œç›´æ¥å®‰è£…åº“

```py
from langchain.vectorstores import Chroma
# åˆå§‹åŒ–åŠ è½½å™¨
db = Chroma.from_documents(split_docs, embeddings,persist_directory="./chroma/openai/news_test")
# æŒä¹…åŒ–
db.persist()
# æŒä¹…åŒ–åï¼Œå¯ä»¥ç›´æ¥é€‰æ‹©ä»æŒä¹…åŒ–æ–‡ä»¶ä¸­åŠ è½½ï¼Œä¸éœ€è¦å†é‡æ–°å°±å¯ä½¿ç”¨äº†
db = Chroma(persist_directory="./chroma/news_test", embedding_function=embeddings)
```

```py
# pip install chromadb
# åŠ è½½ç´¢å¼•
from langchain.vectorstores import Chroma
vectordb = Chroma(persist_directory="./vector_store", embedding_function=embeddings)
# å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
query = "æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—"
docs = vectordb.similarity_search(query)
docs2 = vectordb.similarity_search_with_score(query)
print(docs[0].page_content)
# åœ¨æ£€ç´¢å™¨æ¥å£ä¸­å…¬å¼€è¯¥ç´¢å¼•
retriever = vectordb.as_retriever(search_type="mmr")
docs = retriever.get_relevant_documents(query)[0]
print(docs.page_content)
```

### Pinecone

```py
import pinecone 

# Connecting to Pinecone
pinecone.deinit()
pinecone.init(
    api_key="YOUR_API_KEY",  # find at app.pinecone.io
    environment="YOUR_ENV"  # next to api key in console
)

# similarity_search
docsearch = Pinecone.from_documents(docs, embeddings, index_name="langchain-demo")
docs = docsearch.similarity_search(query)
print(docs[0].page_content)

# Create a Pinecone Service
pinecone_service = pinecone.Service()

# Create an Embedding Model
from langchain.embeddings.openai import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()

# Create a Vectorstore
from langchain.vectorstores import Chroma
vectorstore = Chroma(embeddings, pinecone_service)

# Upload documents to Pinecone Vectorstore
from langchain.vectorstores import Chroma
docsearch = Chroma.from_documents(texts, embeddings, collection_name="collection_name")
```

### PGVector

```py
from langchain.vectorstores.pgvector import PGVector
import os
CONNECTION_STRING = PGVector.connection_string_from_db_params(
    driver=os.environ.get("PGVECTOR_DRIVER", "psycopg2"),
    host=os.environ.get("PGVECTOR_HOST", "localhost"),
    port=int(os.environ.get("PGVECTOR_PORT", "5432")),
    database=os.environ.get("PGVECTOR_DATABASE", "postgres"),
    user=os.environ.get("PGVECTOR_USER", "postgres"),
    password=os.environ.get("PGVECTOR_PASSWORD", "postgres"),
)
db = PGVector.from_documents(
    embedding=embeddings,
    documents=docs,
    collection_name="state_of_the_union",
    connection_string=CONNECTION_STRING,
)

query = "What did the president say about Ketanji Brown Jackson"
docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)
for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print(doc.page_content)
    print("-" * 80)
```


## æœåŠ¡å±‚ï¼šLLMæ¡†æ¶

### LLaMA-Index



### LangChain

LangChain, è¯­è¨€é“¾æ¡ï¼Œä¹Ÿç§°ï¼š`å…°é“¾`ï¼ŒHarrison Chaseåˆ›å»ºçš„ä¸€ä¸ª Python åº“ï¼Œä¸€ç§LLMè¯­è¨€å¤§æ¨¡å‹å¼€å‘å·¥å…·ï¼Œå‡ åˆ†é’Ÿå†…æ„å»º GPT é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚

LangChain å¯ä»¥å¸®åŠ©å¼€å‘è€…å°†LLMä¸å…¶ä»–è®¡ç®—æˆ–çŸ¥è¯†æºç»“åˆèµ·æ¥ï¼Œåˆ›å»ºæ›´å¼ºå¤§çš„åº”ç”¨ç¨‹åºã€‚

å°†è¯­è¨€æ¨¡å‹ä¸å…¶ä»–æ•°æ®æºç›¸è¿æ¥ï¼Œå¹¶å…è®¸è¯­è¨€æ¨¡å‹ä¸ç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œæä¾›äº†ä¸°å¯Œçš„API
- ä¸ LLM äº¤äº’
- LLM è¿æ¥å¤–éƒ¨æ•°æ®æº

AGIçš„åŸºç¡€å·¥å…·æ¨¡å—åº“ï¼Œç±»ä¼¼æ¨¡å—åº“è¿˜æœ‰mavinã€‚
-  LangChain provides an amazing suite of tools for everything around LLMs. 
- Itâ€™s kind of like HuggingFace but specialized for LLMs

LangChain æ„å»ºçš„æœ‰è¶£åº”ç”¨ç¨‹åºåŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰ï¼š
- èŠå¤©æœºå™¨äºº
- ç‰¹å®šé¢†åŸŸçš„æ€»ç»“å’Œé—®ç­”
- æŸ¥è¯¢æ•°æ®åº“ä»¥è·å–ä¿¡æ¯ç„¶åå¤„ç†å®ƒä»¬çš„åº”ç”¨ç¨‹åº
- è§£å†³ç‰¹å®šé—®é¢˜çš„ä»£ç†ï¼Œä¾‹å¦‚æ•°å­¦å’Œæ¨ç†éš¾é¢˜

- [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/en/latest/index.html)
- [GPTå¼€å‘åˆ©å™¨LangChainæŒ‡åŒ—](https://mp.weixin.qq.com/s/VGtjETMC-hRTAiL6hp5gyg)
- [Github](https://github.com/hwchase17/langchain )(å·²ç»æœ‰4Wå¤šçš„star)

#### LangChain ç»„ä»¶

LangChainåŒ…å«å…­éƒ¨åˆ†ç»„ä»¶
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/f101b9ecf540489280e7f95017243fb9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=j8hpvldp7FTdOSIGCFjEyUEmbhs%3D)
- Modelsã€Promptsã€Indexesã€Memoryã€Chainsã€Agentsã€‚

##### Document Loaders and Utils

LangChain çš„ Document Loaders å’Œ Utils æ¨¡å—åˆ†åˆ«ç”¨äº**è¿æ¥åˆ°æ•°æ®æº**å’Œ**è®¡ç®—æº**ã€‚

å½“ä½¿ç”¨loaderåŠ è½½å™¨è¯»å–åˆ°æ•°æ®æºåï¼Œæ•°æ®æºéœ€è¦è½¬æ¢æˆ Document å¯¹è±¡åï¼Œåç»­æ‰èƒ½è¿›è¡Œä½¿ç”¨ã€‚

Document Loaders çš„Unstructured å¯ä»¥å°†è¿™äº›åŸå§‹æ•°æ®æºè½¬æ¢ä¸ºå¯å¤„ç†çš„æ–‡æœ¬ã€‚

The following document loaders are provided:
- CSV Loader CSVæ–‡ä»¶
- DataFrame Loader ä» pandas æ•°æ®å¸§åŠ è½½æ•°æ®
- Diffbot ä» URL åˆ—è¡¨ä¸­æå– HTML æ–‡æ¡£ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„æ–‡æ¡£æ ¼å¼
- Directory Loader åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
- EverNote å°è±¡ç¬”è®°
- Git ä» Git å­˜å‚¨åº“åŠ è½½æ–‡æœ¬æ–‡ä»¶
- Google Drive Googleç½‘ç›˜
- HTML HTML æ–‡æ¡£
- Markdown
- Notebook å°† .ipynb ç¬”è®°æœ¬ä¸­çš„æ•°æ®åŠ è½½ä¸ºé€‚åˆ LangChain çš„æ ¼å¼
- Notion
- PDF
- PowerPoint
- Unstructured File Loader ä½¿ç”¨UnstructuredåŠ è½½å¤šç§ç±»å‹çš„æ–‡ä»¶ï¼Œç›®å‰æ”¯æŒåŠ è½½æ–‡æœ¬æ–‡ä»¶ã€powerpointsã€htmlã€pdfã€å›¾åƒç­‰
- URL åŠ è½½ URL åˆ—è¡¨ä¸­çš„ HTML æ–‡æ¡£å†…å®¹
- Word Documents

##### Text Spltters

æ–‡æœ¬åˆ†å‰²å°±æ˜¯ç”¨æ¥åˆ†å‰²æ–‡æœ¬çš„ã€‚

ä¸ºä»€ä¹ˆéœ€è¦åˆ†å‰²æ–‡æœ¬ï¼Ÿ
- å› ä¸ºæ¯æ¬¡ä¸ç®¡æŠŠæ–‡æœ¬å½“ä½œ prompt å‘ç»™ openai api ï¼Œè¿˜æ˜¯ä½¿ç”¨ embedding åŠŸèƒ½, éƒ½æ˜¯æœ‰å­—ç¬¦é™åˆ¶çš„ã€‚

æ¯”å¦‚å°†ä¸€ä»½300é¡µçš„ pdf å‘ç»™ openai apiï¼Œè¿›è¡Œæ€»ç»“ï¼Œè‚¯å®šä¼šæŠ¥è¶…è¿‡æœ€å¤§ Token é”™ã€‚æ‰€ä»¥è¿™é‡Œå°±éœ€è¦ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨å»åˆ†å‰² loader è¿›æ¥çš„ Documentã€‚
- é»˜è®¤æ¨èçš„æ–‡æœ¬æ‹†åˆ†å™¨æ˜¯ RecursiveCharacterTextSplitterã€‚
- é»˜è®¤æƒ…å†µä»¥ [â€œ\n\nâ€, â€œ\nâ€, â€œ â€œ, â€œâ€] å­—ç¬¦è¿›è¡Œæ‹†åˆ†ã€‚
- å…¶å®ƒå‚æ•°è¯´æ˜ï¼š
  - length_function å¦‚ä½•è®¡ç®—å—çš„é•¿åº¦ã€‚é»˜è®¤åªè®¡ç®—å­—ç¬¦æ•°ï¼Œä½†åœ¨è¿™é‡Œä¼ é€’ä»¤ç‰Œè®¡æ•°å™¨æ˜¯å¾ˆå¸¸è§çš„ã€‚
  - chunk_sizeï¼šå—çš„æœ€å¤§å¤§å°ï¼ˆç”±é•¿åº¦å‡½æ•°æµ‹é‡ï¼‰ã€‚
  - chunk_overlapï¼šå—ä¹‹é—´çš„æœ€å¤§é‡å ã€‚æœ‰ä¸€äº›é‡å å¯ä»¥å¾ˆå¥½åœ°ä¿æŒå—ä¹‹é—´çš„ä¸€äº›è¿ç»­æ€§ï¼ˆä¾‹å¦‚ï¼Œåšä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼‰
- CharacterTextSplitter é»˜è®¤æƒ…å†µä¸‹ä»¥ separator="\n\n"è¿›è¡Œæ‹†åˆ†
- TiktokenText Splitter ä½¿ç”¨OpenAI çš„å¼€æºåˆ†è¯å™¨åŒ…æ¥ä¼°è®¡ä½¿ç”¨çš„ä»¤ç‰Œ

```py
# This is a long document we can split up.
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()
from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(        
    separator = "\n\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)
metadatas = [{"document": 1}, {"document": 2}]
documents = text_splitter.create_documents([state_of_the_union, state_of_the_union], metadatas=metadatas)
print(texts[0])
```

```py
# This is a long document we can split up.
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()
from langchain.text_splitter import TokenTextSplitter
text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)
texts = text_splitter.split_text(state_of_the_union)
print(texts[0])
```


##### ï¼ˆ1ï¼‰Modelsï¼ˆæ¨¡å‹ï¼‰ï¼šLLMé€‰æ‹©

ï¼ˆ1ï¼‰Modelsï¼ˆæ¨¡å‹ï¼‰: å¯é€‰æ‹©ä¸åŒçš„LLMä¸Embeddingæ¨¡å‹ã€‚å¯ä»¥ç›´æ¥è°ƒç”¨ API å·¥ä½œï¼Œä¹Ÿå¯ä»¥è¿è¡Œæœ¬åœ°æ¨¡å‹ã€‚
- LLMs
- Chat Models
- HuggingFace Models
- Text Embeddingï¼šç”¨äºæ–‡æœ¬çš„å‘é‡åŒ–è¡¨ç¤ºã€‚è®¾è®¡ç”¨äºä¸åµŒå…¥äº¤äº’çš„ç±»
  - ç”¨äºå®ç°åŸºäºçŸ¥è¯†åº“çš„é—®ç­”å’Œsemantic searchï¼Œç›¸æ¯” fine-tuning æœ€å¤§çš„ä¼˜åŠ¿ï¼šä¸ç”¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”å¯ä»¥å®æ—¶æ·»åŠ æ–°çš„å†…å®¹ï¼Œè€Œä¸ç”¨åŠ ä¸€æ¬¡æ–°çš„å†…å®¹å°±è®­ç»ƒä¸€æ¬¡ï¼Œå¹¶ä¸”å„æ–¹é¢æˆæœ¬è¦æ¯” fine-tuning ä½å¾ˆå¤šã€‚
  - ä¾‹å¦‚ï¼Œå¯è°ƒç”¨OpenAIã€Cohereã€HuggingFaceç­‰Embeddingæ ‡å‡†æ¥å£ï¼Œå¯¹æ–‡æœ¬å‘é‡åŒ–ã€‚
  - ä¸¤ä¸ªæ–¹æ³•ï¼š`embed_documents` å’Œ `embed_query`ã€‚æœ€å¤§åŒºåˆ«åœ¨äºæ¥å£ä¸åŒï¼šä¸€ç§å¤„ç†**å¤š**ä¸ªæ–‡æ¡£ï¼Œè€Œå¦ä¸€ç§å¤„ç†**å•**ä¸ªæ–‡æ¡£ã€‚
  - æ–‡æœ¬åµŒå…¥æ¨¡å‹é›†æˆäº†å¦‚ä¸‹çš„æºï¼šAzureOpenAIã€Hugging Face Hubã€InstructEmbeddingsã€Llama-cppã€OpenAI ç­‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯Modelsçš„æ ¸å¿ƒï¼Œä¹Ÿæ˜¯LangChainçš„åŸºç¡€ç»„æˆéƒ¨åˆ†ï¼ŒLLMsæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ…è£…å™¨ï¼Œé€šè¿‡è¯¥æ¥å£ä¸å„ç§å¤§æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚
- è¿™äº›æ¨¡å‹åŒ…æ‹¬OpenAIçš„GPT-3.5/4ã€è°·æ­Œçš„LaMDA/PaLMï¼ŒMeta AIçš„LLaMAç­‰ã€‚

LLMs ç±»çš„åŠŸèƒ½å¦‚ä¸‹ï¼š
- æ”¯æŒå¤šç§æ¨¡å‹æ¥å£ï¼Œå¦‚ OpenAIã€Hugging Face Hubã€Anthropicã€Azure OpenAIã€GPT4Allã€Llama-cppâ€¦
- Fake LLMï¼Œç”¨äºæµ‹è¯•
- ç¼“å­˜çš„æ”¯æŒï¼Œæ¯”å¦‚ in-memï¼ˆå†…å­˜ï¼‰ã€SQLiteã€Redisã€SQL
- ç”¨é‡è®°å½•
- æ”¯æŒæµæ¨¡å¼ï¼ˆå°±æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—çš„è¿”å›ï¼Œç±»ä¼¼æ‰“å­—æ•ˆæœï¼‰

LangChainè°ƒç”¨OpenAIçš„gpt-3.5-turboå¤§è¯­è¨€æ¨¡å‹çš„ç®€å•ç¤ºä¾‹

```py
import os
from langchain.llms import OpenAI

openai_api_key = 'sk-F9O70vxxxxxlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key

llm = OpenAI(model_name="gpt-3.5-turbo")
# llm = OpenAI(model_name="text-davinci-003", n=2, best_of=2)
print(llm("è®²ä¸ªç¬‘è¯ï¼Œå¾ˆå†·çš„ç¬‘è¯"))
# ä¸ºä»€ä¹ˆé¸Ÿå„¿ä¼šæˆä¸ºæ¸¸æ³³é«˜æ‰‹ï¼Ÿå› ä¸ºå®ƒä»¬æœ‰ä¸€åªè„šæ¯”å¦ä¸€åªè„šæ›´é•¿ï¼Œæ‰€ä»¥æ¸¸èµ·æ³³æ¥ä¸è´¹åŠ›ï¼ï¼ˆç¬‘ï¼‰
llm_result = llm.generate(["Tell me a joke", "Tell me a poem"])
llm_result.llm_output    # è¿”å› tokens ä½¿ç”¨é‡
```

æ¨¡å‹æ‹‰åˆ°æœ¬åœ°ä½¿ç”¨çš„å¥½å¤„ï¼š
- è®­ç»ƒæ¨¡å‹
- å¯ä»¥ä½¿ç”¨æœ¬åœ°çš„ GPU
- æœ‰äº›æ¨¡å‹æ— æ³•åœ¨ HuggingFace è¿è¡Œ

LangChain Embeddingç¤ºä¾‹
- HuggingFace

```py
from langchain.embeddings import HuggingFaceEmbeddings 

embeddings = HuggingFaceEmbeddings() 
text = "This is a test document." 
query_result = embeddings.embed_query(text) 
doc_result = embeddings.embed_documents([text])
```

- llama-cpp

```py
# !pip install llama-cpp-python
from langchain.embeddings import LlamaCppEmbeddings

llama = LlamaCppEmbeddings(model_path="/path/to/model/ggml-model-q4_0.bin")
text = "This is a test document."
query_result = llama.embed_query(text)
doc_result = llama.embed_documents([text])
```

- OpenAI

```py
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text = "This is a test document."
query_result = embeddings.embed_query(text)
doc_result = embeddings.embed_documents([text])
```


##### ï¼ˆ2ï¼‰Promptsï¼ˆæç¤ºè¯­ï¼‰: æ¨¡æ¿åŒ–

Promptsï¼ˆæç¤ºè¯­ï¼‰: ç®¡ç†LLMè¾“å…¥
- PromptTemplate è´Ÿè´£æ„å»ºæ­¤è¾“å…¥
- LangChain æä¾›äº†å¯ç”¨äºæ ¼å¼åŒ–è¾“å…¥å’Œè®¸å¤šå…¶ä»–å®ç”¨ç¨‹åºçš„æç¤ºæ¨¡æ¿ã€‚

å½“ç”¨æˆ·ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹è¯æ—¶ï¼Œç”¨æˆ·å†…å®¹å³Promptï¼ˆæç¤ºè¯­ï¼‰ã€‚
- å¦‚æœç”¨æˆ·æ¯æ¬¡è¾“å…¥çš„Promptä¸­åŒ…å«å¤§é‡çš„é‡å¤å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ª**Promptæ¨¡æ¿**ï¼Œå°†é€šç”¨éƒ¨åˆ†æå–å‡ºæ¥ï¼Œç”¨æˆ·è¾“å…¥è¾“å…¥éƒ¨åˆ†ä½œä¸ºå˜é‡ã€‚

Promptæ¨¡æ¿ååˆ†æœ‰ç”¨
- åˆ©ç”¨langchainæ„å»ºä¸“å±**å®¢æœåŠ©ç†**ï¼Œå¹¶ä¸”æ˜ç¡®å‘Šè¯‰å…¶åªå›ç­”**çŸ¥è¯†åº“**ï¼ˆäº§å“ä»‹ç»ã€è´­ä¹°æµç¨‹ç­‰ï¼‰é‡Œé¢çš„çŸ¥è¯†ï¼Œå…¶ä»–æ— å…³çš„è¯¢é—®ï¼Œåªå›ç­”â€œæˆ‘è¿˜æ²¡æœ‰å­¦ä¹ åˆ°ç›¸å…³çŸ¥è¯†â€ã€‚
- è¿™æ—¶å¯åˆ©ç”¨Promptæ¨¡æ¿å¯¹llmè¿›è¡Œçº¦æŸã€‚

è°ƒç”¨LangChainçš„PromptTemplate

```py
from langchain import PromptTemplate

name_template = """
æˆ‘æƒ³è®©ä½ æˆä¸ºä¸€ä¸ªèµ·åå­—çš„ä¸“å®¶ã€‚ç»™æˆ‘è¿”å›ä¸€ä¸ªåå­—çš„åå•. åå­—å¯“æ„ç¾å¥½ï¼Œç®€å•æ˜“è®°ï¼Œæœ—æœ—ä¸Šå£.
å…³äº{name_description},å¥½å¬çš„åå­—æœ‰å“ªäº›?
"""
# åˆ›å»ºä¸€ä¸ªpromptæ¨¡æ¿
prompt_template = PromptTemplate(input_variables=["name_description"], template=name_template)
description = "ç”·å­©åå­—"
print(prompt_template.format(name_description=description))
# æˆ‘æƒ³è®©ä½ æˆä¸ºä¸€ä¸ªèµ·åå­—çš„ä¸“å®¶ã€‚ç»™æˆ‘è¿”å›ä¸€ä¸ªåå­—çš„åå•. åå­—å¯“æ„ç¾å¥½ï¼Œç®€å•æ˜“è®°ï¼Œæœ—æœ—ä¸Šå£.å…³äºç”·å­©åå­—,å¥½å¬çš„åå­—æœ‰å“ªäº›?
```

##### ï¼ˆ3ï¼‰Indexesï¼ˆç´¢å¼•ï¼‰ï¼šæ–‡æ¡£ç»“æ„åŒ–

Indexesï¼ˆç´¢å¼•ï¼‰ï¼šæ–‡æ¡£ç»“æ„åŒ–, ä»¥ä¾¿LLMæ›´å¥½çš„äº¤äº’
- ç´¢å¼•æ˜¯æŒ‡å¯¹æ–‡æ¡£è¿›è¡Œç»“æ„åŒ–çš„æ–¹æ³•ï¼Œä»¥ä¾¿LLMèƒ½å¤Ÿæ›´å¥½çš„ä¸ä¹‹äº¤äº’ã€‚

è¯¥ç»„ä»¶ä¸»è¦åŒ…æ‹¬ï¼šDocument Loadersï¼ˆ`æ–‡æ¡£åŠ è½½å™¨`ï¼‰ã€Text Splittersï¼ˆ`æ–‡æœ¬æ‹†åˆ†å™¨`ï¼‰ã€VectorStoresï¼ˆ`å‘é‡å­˜å‚¨å™¨`ï¼‰ä»¥åŠRetrieversï¼ˆ`æ£€ç´¢å™¨`ï¼‰ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/5078c23e1fea4bee99746ebec0847be5~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=Uzl65uwWtcvNhfi1OHpX8u%2BGzko%3D)
- `æ–‡æœ¬æ£€ç´¢å™¨`ï¼šå°†ç‰¹å®šæ ¼å¼æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬ã€‚è¾“å…¥å¯ä»¥æ˜¯ pdfã€wordã€csvã€images ç­‰ã€‚
- `æ–‡æœ¬æ‹†åˆ†å™¨`ï¼šå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå°çš„**æ–‡æœ¬å—**ï¼Œä¾¿äºLLMæ¨¡å‹å¤„ç†ã€‚
  - ç”±äºæ¨¡å‹å¤„ç†æ•°æ®æ—¶ï¼Œå¯¹è¾“å…¥é•¿åº¦æœ‰é™åˆ¶ï¼Œå› æ­¤éœ€è¦å¯¹é•¿æ–‡æœ¬è¿›è¡Œ**åˆ†å—**ã€‚
  - ä¸åŒè¯­è¨€æ¨¡å‹å¯¹å—çš„å¤§å°å®šä¹‰ä¸åŒï¼Œæ¯”å¦‚OpenAIçš„GPTå¯¹åˆ†å—çš„é•¿åº¦é€šè¿‡tokenå¤§å°æ¥é™åˆ¶ï¼Œæ¯”å¦‚GPT-3.5æ˜¯**4096**ï¼Œå³è¿™ä¸ªåˆ†å—æ‰€åŒ…å«çš„Tokenæ•°é‡ä¸èƒ½è¶…è¿‡4096ã€‚
  - ä¸€èˆ¬çš„åˆ†å—æ–¹æ³•ï¼šé¦–å…ˆï¼Œå¯¹é•¿æ–‡æœ¬è¿›è¡Œ**æ–­å¥**ï¼Œå³åˆ†æˆä¸€å¥ä¸€å¥è¯ã€‚ç„¶åï¼Œè®¡ç®—æ¯å¥è¯åŒ…å«çš„tokenæ•°é‡ï¼Œå¹¶ä»ç¬¬ä¸€å¥è¯å¼€å§‹å¾€åä¾æ¬¡ç´¯åŠ ï¼Œç›´åˆ°è¾¾åˆ°æŒ‡å®šæ•°é‡ï¼Œç»„æˆä¸º1ä¸ªåˆ†å—ã€‚ä¾æ¬¡é‡å¤ä¸Šè¿°æ“ä½œã€‚æ¯”å¦‚æŒ‰ç…§**å­—æ¯**åˆ‡åˆ†çš„`Character`ï¼ŒæŒ‰ç…§**token**åˆ‡åˆ†çš„`Tiktoken`ç­‰ã€‚
- `å‘é‡å­˜å‚¨å™¨`ï¼šå­˜å‚¨æå–çš„æ–‡æœ¬å‘é‡ï¼ŒåŒ…æ‹¬Faissã€Milvusã€Pineconeã€Chromaç­‰ã€‚
- `å‘é‡æ£€ç´¢å™¨`ï¼šé€šè¿‡ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œæ£€ç´¢å™¨è´Ÿè´£ä»åº•åº“ä¸­æ£€ç´¢å‡ºç‰¹å®šç›¸å…³åº¦çš„æ–‡æ¡£ã€‚åº¦é‡å‡†åˆ™åŒ…æ‹¬ä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ã€‚

ç¤ºä¾‹

```py
# pip install chromadb
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
# æŒ‡å®šè¦ä½¿ç”¨çš„æ–‡æ¡£åŠ è½½å™¨
from langchain.document_loaders import TextLoader
documents = TextLoader('../state_of_the_union.txt', encoding='utf8')
# æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ–‡æ¡£æ‹†åˆ†æˆå—ã€‚
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
# ç„¶åæˆ‘ä»¬å°†é€‰æ‹©æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„åµŒå…¥ã€‚
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
# æˆ‘ä»¬ç°åœ¨åˆ›å»º vectorstore ç”¨ä½œç´¢å¼•ã€‚
from langchain.vectorstores import Chroma
db = Chroma.from_documents(texts, embeddings)
# è¿™å°±æ˜¯åˆ›å»ºç´¢å¼•ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨æ£€ç´¢å™¨æ¥å£ä¸­å…¬å¼€è¯¥ç´¢å¼•ã€‚
retriever = db.as_retriever()
# åˆ›å»ºä¸€ä¸ªé“¾å¹¶ç”¨å®ƒæ¥å›ç­”é—®é¢˜ï¼
qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=retriever)
query = "What did the president say about Ketanji Brown Jackson"
qa.run(query)
```

###### Retrievers

æ£€ç´¢å™¨æ¥å£æ˜¯ä¸€ä¸ªé€šç”¨æ¥å£ï¼Œå¯ä»¥è½»æ¾åœ°å°†æ–‡æ¡£ä¸è¯­è¨€æ¨¡å‹ç»“åˆèµ·æ¥ã€‚
- æ­¤æ¥å£å…¬å¼€äº†ä¸€ä¸ª get_relevant_documents æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªæŸ¥è¯¢ï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰å¹¶è¿”å›ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œç”¨çš„éƒ½æ˜¯ VectorStore Retrieverã€‚
- æ­¤æ£€ç´¢å™¨ç”± VectorStore å¤§åŠ›æ”¯æŒã€‚ä¸€æ—¦ä½ æ„é€ äº†ä¸€ä¸ª VectorStoreï¼Œæ„é€ ä¸€ä¸ªæ£€ç´¢å™¨å°±å¾ˆå®¹æ˜“äº†ã€‚

```py
# # pip install faiss-cpu
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.document_loaders import DirectoryLoader
# åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰txtç±»å‹çš„æ–‡ä»¶ï¼Œå¹¶è½¬æˆ document å¯¹è±¡
loader = DirectoryLoader('./data/', glob='**/*.txt')
documents = loader.load()
# æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ–‡æ¡£æ‹†åˆ†æˆå—ã€‚
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
# ç„¶åæˆ‘ä»¬å°†é€‰æ‹©æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„åµŒå…¥ã€‚
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
from langchain.vectorstores import FAISS
db = FAISS.from_documents(texts, embeddings)
query = "æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—"
docs = db.similarity_search(query)
docs_and_scores = db.similarity_search_with_score(query)
print(docs)

retriever = db.as_retriever()	# æœ€å¤§è¾¹é™…ç›¸å…³æ€§æœç´¢ mmr
# retriever = db.as_retriever(search_kwargs={"k": 1})	# æœç´¢å…³é”®å­—
docs = retriever.get_relevant_documents("æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—")
print(len(docs))

# db.save_local("faiss_index")
# new_db = FAISS.load_local("faiss_index", embeddings)
# docs = new_db.similarity_search(query)
# docs[0]
```


##### ï¼ˆ4ï¼‰Chainsï¼ˆé“¾æ¡ï¼‰ï¼šç»„åˆé“¾è·¯

Chainsï¼ˆé“¾æ¡ï¼‰ï¼šå°†LLMä¸å…¶ä»–ç»„ä»¶ç»“åˆ, é“¾å…è®¸å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„åº”ç”¨ç¨‹åºã€‚

Chainæä¾›äº†ä¸€ç§å°†å„ç§ç»„ä»¶ç»Ÿä¸€åˆ°åº”ç”¨ç¨‹åºä¸­çš„æ–¹æ³•ã€‚
- ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ªChainï¼Œå®ƒæ¥å—æ¥è‡ªç”¨æˆ·çš„è¾“å…¥ï¼Œå¹¶é€šè¿‡PromptTemplateå°†å…¶æ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–çš„è¾“å‡ºä¼ å…¥åˆ°LLMæ¨¡å‹ä¸­ã€‚
- é€šè¿‡å¤šä¸ªChainä¸å…¶ä»–éƒ¨ä»¶ç»“åˆï¼Œå¯ç”Ÿæˆå¤æ‚çš„é“¾ï¼Œå®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚
- ![Chainsç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/4d5ba1c00889406fb3bc7c86fbb9660f~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=pLKYIarzSV1QkVxKv%2Blc0t8lDrE%3D)

LLMä¸å…¶ä»–ç»„ä»¶ç»“åˆï¼Œåˆ›å»ºä¸åŒåº”ç”¨ï¼Œä¸€äº›ä¾‹å­ï¼š
- å°†LLMä¸**æç¤ºæ¨¡æ¿**ç›¸ç»“åˆ
- ç¬¬ä¸€ä¸ª LLM çš„è¾“å‡ºä½œä¸ºç¬¬äºŒä¸ª LLM çš„è¾“å…¥, **é¡ºåºç»„åˆ**å¤šä¸ª LLM
- LLMä¸**å¤–éƒ¨æ•°æ®**ç»“åˆï¼Œæ¯”å¦‚ï¼Œé€šè¿‡langchainè·å–youtubeè§†é¢‘é“¾æ¥ï¼Œé€šè¿‡LLMè§†é¢‘é—®ç­”
- LLMä¸**é•¿æœŸè®°å¿†**ç»“åˆï¼Œæ¯”å¦‚èŠå¤©æœºå™¨äºº

```py
from langchain import LLMChain

llm_chain = LLMChain(prompt=prompt, llm=llm)
question = "Can Barack Obama have a conversation with George Washington?"
print(llm_chain.run(question))
```

LLMChainæ˜¯ä¸€ä¸ªç®€å•çš„é“¾ï¼Œå®ƒæ¥å—ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨ç”¨æˆ·è¾“å…¥æ ¼å¼åŒ–å®ƒå¹¶è¿”å›æ¥è‡ª LLM çš„å“åº”ã€‚

```py
from langchain.llms import OpenAI
from langchain.docstore.document import Document
import requests
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
import pathlib
import subprocess
import tempfile
"""
ç”Ÿæˆå¯¹ä»¥å‰æ’°å†™çš„åšå®¢æ–‡ç« æœ‰ç†è§£çš„åšå®¢æ–‡ç« ï¼Œæˆ–è€…å¯ä»¥å‚è€ƒäº§å“æ–‡æ¡£çš„äº§å“æ•™ç¨‹
"""

source_chunks = ""
search_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings())

from langchain.chains import LLMChain
prompt_template = """Use the context below to write a 400 word blog post about the topic below:
    Context: {context}
    Topic: {topic}
    Blog post:"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "topic"]
)

llm = OpenAI(temperature=0)

chain = LLMChain(llm=llm, prompt=PROMPT)

def generate_blog_post(topic):
    docs = search_index.similarity_search(topic, k=4)
    inputs = [{"context": doc.page_content, "topic": topic} for doc in docs]
    print(chain.apply(inputs))

generate_blog_post("environment variables")
```

æ‰§è¡Œå¤šä¸ªchain
- é¡ºåºé“¾æ˜¯æŒ‰é¢„å®šä¹‰é¡ºåºæ‰§è¡Œå…¶é“¾æ¥çš„é“¾ã€‚
- ä½¿ç”¨SimpleSequentialChainï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ä¸€ä¸ªè¾“å…¥/è¾“å‡ºï¼Œä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºæ˜¯ä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚

```py
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

# location é“¾
llm = OpenAI(temperature=1)
template = """Your job is to come up with a classic dish from the area that the users suggests.
% USER LOCATION
{user_location}

YOUR RESPONSE:
"""
prompt_template = PromptTemplate(input_variables=["user_location"], template=template)
location_chain = LLMChain(llm=llm, prompt=prompt_template)

# meal é“¾
template = """Given a meal, give a short and simple recipe on how to make that dish at home.
% MEAL
{user_meal}

YOUR RESPONSE:
"""
prompt_template = PromptTemplate(input_variables=["user_meal"], template=template)
meal_chain = LLMChain(llm=llm, prompt=prompt_template)

# é€šè¿‡ SimpleSequentialChain ä¸²è”èµ·æ¥ï¼Œç¬¬ä¸€ä¸ªç­”æ¡ˆä¼šè¢«æ›¿æ¢ç¬¬äºŒä¸ªä¸­çš„user_mealï¼Œç„¶åå†è¿›è¡Œè¯¢é—®
overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)
review = overall_chain.run("Rome")
```

##### ï¼ˆ5ï¼‰Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰ï¼šå…¶ä»–å·¥å…·

â€œé“¾â€å¯ä»¥å¸®åŠ©å°†ä¸€ç³»åˆ— LLM è°ƒç”¨é“¾æ¥åœ¨ä¸€èµ·ã€‚
- ç„¶è€Œï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼Œè°ƒç”¨é¡ºåºé€šå¸¸æ˜¯**ä¸ç¡®å®š**çš„ã€‚ä¸‹ä¸€æ­¥å¯èƒ½å–å†³äºç”¨æˆ·è¾“å…¥å’Œå‰é¢æ­¥éª¤ä¸­çš„å“åº”ã€‚

LangChain åº“æä¾›äº†ä»£ç†â€œAgentsâ€ï¼Œæ ¹æ®**æœªçŸ¥**è¾“å…¥è€Œä¸æ˜¯ç¡¬ç¼–ç æ¥å†³å®šä¸‹ä¸€æ­¥é‡‡å–çš„è¡ŒåŠ¨ã€‚ 

Agent ä½¿ç”¨LLMæ¥ç¡®å®šè¦é‡‡å–å“ªäº›è¡ŒåŠ¨ä»¥åŠæŒ‰ä»€ä¹ˆé¡ºåºé‡‡å–çš„è¡ŒåŠ¨ã€‚æ“ä½œå¯ä»¥ä½¿ç”¨å·¥å…·å¹¶è§‚å¯Ÿå…¶è¾“å‡ºï¼Œä¹Ÿå¯ä»¥è¿”å›ç”¨æˆ·ã€‚åˆ›å»ºagentæ—¶çš„å‚æ•°ï¼š
- å·¥å…·ï¼šæ‰§è¡Œç‰¹å®šèŒè´£çš„åŠŸèƒ½ã€‚æ¯”å¦‚ï¼šGoogleæœç´¢ï¼Œæ•°æ®åº“æŸ¥æ‰¾ï¼ŒPython Replã€‚å·¥å…·çš„æ¥å£å½“å‰æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå°†å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œå­—ç¬¦ä¸²ä½œä¸ºè¾“å‡ºã€‚
- LLMï¼šä¸ºä»£ç†æä¾›åŠ¨åŠ›çš„è¯­è¨€æ¨¡å‹ã€‚
- ä»£ç†ï¼šhighest level APIã€custom agent. è¦ä½¿ç”¨çš„ä»£ç†ã€‚è¿™åº”è¯¥æ˜¯ä¸€ä¸ªå¼•ç”¨æ”¯æŒä»£ç†ç±»çš„å­—ç¬¦ä¸²ã€‚ç”±äºæœ¬ç¬”è®°æœ¬ä¾§é‡äºæœ€ç®€å•ã€æœ€é«˜çº§åˆ«çš„ APIï¼Œå› æ­¤ä»…æ¶µç›–ä½¿ç”¨æ ‡å‡†æ”¯æŒçš„ä»£ç†ã€‚å¦‚æœæ‚¨æƒ³å®æ–½è‡ªå®šä¹‰ä»£ç†ï¼Œè¯·å‚é˜…è‡ªå®šä¹‰ä»£ç†çš„æ–‡æ¡£ï¼ˆå³å°†æ¨å‡ºï¼‰ã€‚

```py
# Create RetrievalQA Chain
from langchain.chains import RetrievalQA
retrieval_qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever())

# Create an Agent
from langchain.agents import initialize_agent, Tool
tools = [
    Tool(
        name="Example QA System",
        func=retrieval_qa.run,
        description="Example description of the tool."
    ),
]
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)

# Use Agent
agent.run("Ask a question related to the documents")
```

Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰ï¼šè®¿é—®å…¶ä»–å·¥å…·

Agentsæ˜¯LLMä¸å·¥å…·ä¹‹é—´çš„**æ¥å£**ï¼ŒAgentsç”¨æ¥ç¡®å®šä»»åŠ¡ä¸å·¥å…·ã€‚

ä¸€èˆ¬çš„Agentsæ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ï¼š
- a. é¦–å…ˆï¼Œæ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œå¹¶è½¬åŒ–ä¸ºPromptTemplate
- b. å…¶æ¬¡ï¼ŒAgentsé€šè¿‡è°ƒç”¨LLMè¾“å‡ºactionï¼Œå¹¶å†³å®šä½¿ç”¨å“ªç§å·¥å…·æ‰§è¡Œaction
- c. æœ€åï¼ŒAgentsè°ƒç”¨å·¥å…·å®Œæˆactionä»»åŠ¡
- ![agentç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/b53d13fc3ceb4d5fa43081721e2b97b9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=HzMa7h7l78O8xFoMDsdNIx%2Bf0yg%3D)

Agentså¯ä»¥è°ƒç”¨é‚£äº›å·¥å…·å®Œæˆä»»åŠ¡ï¼Ÿ

| å·¥å…· | æè¿° | 
| --- | --- | 
| æœç´¢ | è°ƒç”¨è°·æ­Œæµè§ˆå™¨æˆ–å…¶ä»–æµè§ˆå™¨æœç´¢æŒ‡å®šå†…å®¹ |
| ç»ˆç«¯ | åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå‘½ä»¤ï¼Œè¾“å…¥åº”è¯¥æ˜¯æœ‰æ•ˆçš„å‘½ä»¤ï¼Œè¾“å‡ºå°†æ˜¯è¿è¡Œè¯¥å‘½ä»¤çš„ä»»ä½•è¾“å‡º |
| Wikipedia | ä»ç»´åŸºç™¾ç§‘ç”Ÿæˆç»“æœ |
| Wolfram-Alpha | WA æœç´¢æ’ä»¶â€”â€”å¯ä»¥å›ç­”å¤æ‚çš„æ•°å­¦ã€ç‰©ç†æˆ–ä»»ä½•æŸ¥è¯¢ï¼Œå°†æœç´¢æŸ¥è¯¢ä½œä¸ºè¾“å…¥ã€‚ |
| Python REPL | ç”¨äºè¯„ä¼°å’Œæ‰§è¡Œ Python å‘½ä»¤çš„ Python shellã€‚å®ƒä»¥ python ä»£ç ä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºç»“æœã€‚è¾“å…¥çš„ python ä»£ç å¯ä»¥ä» LangChain ä¸­çš„å¦ä¸€ä¸ªå·¥å…·ç”Ÿæˆ |


Agenté€šè¿‡è°ƒç”¨wikipediaå·¥å…·ï¼Œå¯¹ç”¨æˆ·æå‡ºçš„é—®é¢˜å›ç­”ã€‚å°½ç®¡gpt-3.5åŠŸèƒ½å¼ºå¤§ï¼Œä½†æ˜¯å…¶çŸ¥è¯†åº“æˆªæ­¢åˆ°2021å¹´9æœˆï¼Œå› æ­¤ï¼Œagentè°ƒç”¨wikipediaå¤–éƒ¨çŸ¥è¯†åº“å¯¹ç”¨æˆ·é—®é¢˜å›ç­”ã€‚å›ç­”è¿‡ç¨‹å¦‚ä¸‹ï¼š
- a. åˆ†æç”¨æˆ·è¾“å…¥é—®é¢˜ï¼Œé‡‡å–çš„Actionä¸ºé€šè¿‡Wikipediaå®ç°ï¼Œå¹¶ç»™å‡ºäº†Actionçš„è¾“å…¥
- b. æ ¹æ®åˆ†æå¾—åˆ°äº†æœ€ç›¸å…³çš„ä¸¤é¡µï¼Œå¹¶è¿›è¡Œäº†æ€»ç»“
- c. å¯¹æœ€åçš„å†…å®¹è¿›ä¸€æ­¥æç‚¼ï¼Œå¾—åˆ°æœ€ç»ˆç­”æ¡ˆ

```py
import os
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.llms import OpenAI

openai_api_key = 'sk-F9xxxxxxx55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key
llm = OpenAI(temperature=0)
tools = load_tools(["wikipedia","llm-math"], llm=llm)
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)
print(agent.run("åˆ—ä¸¾spaceXæ˜Ÿèˆ°åœ¨2022å¹´åçš„å‘å°„è®°å½•?"))
```

##### ï¼ˆ6ï¼‰Memoryï¼ˆè®°å¿†ï¼‰ï¼š

å¯¹äºåƒèŠå¤©æœºå™¨äººè¿™æ ·çš„åº”ç”¨ç¨‹åºï¼Œéœ€è¦è®°ä½ä»¥å‰çš„å¯¹è¯å†…å®¹ã€‚
- ä½†é»˜è®¤æƒ…å†µä¸‹ï¼ŒLLMå¯¹å†å²å†…å®¹**æ²¡æœ‰è®°å¿†åŠŸèƒ½**ã€‚LLMçš„è¾“å‡ºåªé’ˆå¯¹ç”¨æˆ·å½“å‰çš„æé—®å†…å®¹å›ç­”ã€‚
- ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒLangchainæä¾›äº†**è®°å¿†ç»„ä»¶**ï¼Œç”¨æ¥ç®¡ç†ä¸ç»´æŠ¤å†å²å¯¹è¯å†…å®¹ã€‚
- ![memoryç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/c64ff3021d1a4ba68c3a6a5dd470cdc6~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=M2fWwrITBkva%2BXT%2BiQINk6VD54M%3D)

langchainæä¾›ä¸åŒçš„Memoryç»„ä»¶å®Œæˆå†…å®¹è®°å¿†ï¼Œä¸‹é¢åˆ—ä¸¾å››ç§ï¼š
- `ConversationBufferMemory`ï¼šè®°ä½**å…¨éƒ¨å¯¹è¯å†…å®¹**ã€‚è¿™æ˜¯æœ€ç®€å•çš„å†…å­˜è®°å¿†ç»„ä»¶ï¼Œå®ƒçš„åŠŸèƒ½æ˜¯ç›´æ¥å°†ç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„èŠå¤©å†…å®¹è®°å½•åœ¨å†…å­˜ä¸­ã€‚[img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/8b04d8cc8c8f462bafa21bc473066efc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=ljnOnmukL7V9UH5OzY4l%2BpwkfpU%3D)
- `ConversationBufferWindowMemory`ï¼šè®°ä½**æœ€è¿‘kè½®**çš„èŠå¤©å†…å®¹ã€‚ä¸ä¹‹å‰çš„ConversationBufferMemoryç»„ä»¶çš„å·®åˆ«æ˜¯å®ƒå¢åŠ äº†ä¸€ä¸ªçª—å£å‚æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯å¯ä»¥æŒ‡å®šä¿å­˜å¤šè½®å¯¹è¯çš„æ•°é‡ã€‚[img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a830075b33094ef38f3aea87010fdd58~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=BbNKPeRu0j9knJWw02kEPUOu1uI%3D)
  - â€‹åœ¨è¯¥ä¾‹å­ä¸­è®¾ç½®äº†å¯¹è¯è½®æ•°k=2ï¼Œå³åªèƒ½è®°ä½å‰ä¸¤è½®çš„å†…å®¹ï¼Œâ€œæˆ‘çš„åå­—â€æ˜¯åœ¨å‰3è½®ä¸­çš„Answerä¸­å›ç­”çš„ï¼Œå› æ­¤å…¶æ²¡æœ‰å¯¹å…¶è¿›è¡Œè®°å¿†ï¼Œæ‰€ä»¥æ— æ³•å›ç­”å‡ºæ­£ç¡®ç­”æ¡ˆã€‚
- `ConversationSummaryMemory`ï¼šConversationSummaryMemoryå®ƒä¸ä¼šå°†ç”¨æˆ·å’Œæœºå™¨äººä¹‹å‰çš„æ‰€æœ‰å¯¹è¯éƒ½å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚å®ƒåªä¼šå­˜å‚¨ä¸€ä¸ªç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„**èŠå¤©å†…å®¹çš„æ‘˜è¦**ï¼Œè¿™æ ·åšçš„ç›®çš„å¯èƒ½æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜å¼€é”€å’Œtokençš„æ•°é‡ã€‚
  - ConversationSummaryMemory[ç¬¬ä¸€è½®å¯¹è¯](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/6b3c8f69e31440af9cb954bc903fd65d~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=X8kxNoQQtJqKKBIufAI5%2BGTprxo%3D): ä½ å¥½ï¼Œæˆ‘æ˜¯ç‹è€å…­
  - ConversationSummaryMemory[ç¬¬äºŒè½®å¯¹è¯](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/ab4fbe8ad6cb4286a1e8f9e10141d2ef~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=tf%2FsfV5MF%2BIK7yWow48%2BvO%2FV%2BqY%3D): ä½ å«ä»€ä¹ˆåå­—
  - åœ¨ç¬¬ä¸€è½®å¯¹è¯å®Œæˆåï¼ŒMemoryå¯¹ç¬¬ä¸€è½®å¯¹è¯çš„å†…å®¹è¿›è¡Œäº†æ€»ç»“ï¼Œæ”¾åˆ°äº†æ‘˜è¦ä¸­ã€‚åœ¨ç¬¬äºŒè½®å¯¹è¯ä¸­ï¼ŒLLMåŸºäºæ‘˜è¦ä¸è¯¥è½®çš„é—®é¢˜è¿›è¡Œå›ç­”ã€‚
- `VectorStored-Backed Memory`: å°†æ‰€æœ‰ä¹‹å‰çš„å¯¹è¯é€šè¿‡**å‘é‡**çš„æ–¹å¼å­˜å‚¨åˆ°VectorDBï¼ˆå‘é‡æ•°æ®åº“ï¼‰ä¸­ï¼Œåœ¨æ¯ä¸€è½®æ–°çš„å¯¹è¯ä¸­ï¼Œä¼šæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ä¿¡æ¯ï¼ŒåŒ¹é…å‘é‡æ•°æ®åº“ä¸­**æœ€ç›¸ä¼¼çš„Kç»„**å¯¹è¯ã€‚





å›½å†…ä¸å°‘LLmå›¢é˜Ÿé‡‡ç”¨langChainï¼Œé›†æˆllmæœ¬åœ°åŒ–çŸ¥è¯†åº“

langChainï¼ŒbabyAGI æƒ³åšAGIç”Ÿæ€ï¼Œè¿™ä¸ªå°±æœ‰äº›åŠ›ä¸ä»å¿ƒäº†ã€‚autoGPTå¥½ä¸€ç‚¹ï¼Œç›¸å¯¹ç®€å•ã€‚

langChainï¼ŒbabyAGIçš„å­æ¨¡å—ï¼Œéƒ½æ˜¯å‡ ç™¾ä¸ªã€‚ç‰¹åˆ«æ˜¯langChainï¼Œæ¨¡å—åº“å±…ç„¶æœ‰600å¤šå¼ å­æ¨¡å—mapæ¶æ„å›¾

[æ— éœ€OpenAI API Keyï¼Œæ„å»ºä¸ªäººåŒ–çŸ¥è¯†åº“çš„ç»ˆææŒ‡å—](https://mp.weixin.qq.com/s/ponKZ1OaHXX2nzuSxXg8-Q)

æ„å»ºçŸ¥è¯†åº“çš„ä¸»è¦æµç¨‹ï¼š
1. åŠ è½½æ–‡æ¡£
2. æ–‡æœ¬åˆ†å‰²
3. æ„å»ºçŸ¢é‡æ•°æ®åº“
4. å¼•å…¥LLM
5. åˆ›å»ºqa_chainï¼Œå¼€å§‹æé—®


####  LangChain + Milvus

```py
from langchain.embeddings.openai import OpenAIEmbeddings # openai
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI  # openai
import os

os.environ["OPENAI_API_KEY"] = "OPENAI_API_KEY"

# Question Answering Chain
# â‘  åŠ è½½æ–‡æ¡£
with open("../test.txt") as f:
    state_of_the_union = f.read()
# â‘¡ æ–‡æœ¬åˆ†å‰²
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0) # æŒ‡å®šåˆ†å‰²å™¨
texts = text_splitter.split_text(state_of_the_union) # åˆ†å‰²æ–‡æœ¬
embeddings = OpenAIEmbeddings() # ä½¿ç”¨OpenAIçš„embeddingæœåŠ¡
# â‘¢ æ„å»ºé€‚é‡æ•°æ®åº“
docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{"source": str(i)} for i in range(len(texts))]).as_retriever()
query = "What did the president say about Justice Breyer"
docs = docsearch.get_relevant_documents(query)
# â‘£ å¼•å…¥LLMï¼Œåˆ›å»ºqa_chain
chain = load_qa_chain(OpenAI(temperature=0), chain_type="stuff")
# â‘¤ å¼€å§‹æé—®
answer = chain.run(input_documents=docs, question=query)
print(answer)
```

ä»¥ä¸Šæ„å»ºä¾èµ–OpenAIï¼Œæœ‰ç¬¬ä¸‰æ–¹å…è´¹æœåŠ¡å—ï¼Ÿ
- [transformers-course](Githubï¼šhttps://github.com/Liu-Shihao/transformers-course)

Huggingfaceå¼€æºAIæ¨¡å‹æ„å»ºæœ¬åœ°çŸ¥è¯†åº“
- å¼€æºçš„google/flan-t5-xlAIæ¨¡å‹

```py
from langchain import HuggingFacePipeline
from langchain.chains import RetrievalQA
from langchain.chains.question_answering import load_qa_chain
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms.base import LLM
import os

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

os.environ["HUGGINGFACEHUB_API_TOKEN"] = 'HUGGINGFACEHUB_API_TOKEN'

# Document Loaders
loader = TextLoader('../example_data/test.txt', encoding='utf8')
documents = loader.load()

# Text Splitters
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# select embeddings
embeddings = HuggingFaceEmbeddings()

# create vectorstores
db = Chroma.from_documents(texts, embeddings)

# Retriever
retriever = db.as_retriever(search_kwargs={"k": 2})

query = "what is embeddings?"
docs = retriever.get_relevant_documents(query)

for item in docs:
    print("page_content:")
    print(item.page_content)
    print("source:")
    print(item.metadata['source'])
    print("---------------------------")


tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-xl")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-xl")
pipe = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_length=512,
    temperature=0,
    top_p=0.95,
    repetition_penalty=1.15
)

llm = HuggingFacePipeline(pipeline=pipe)

chain = load_qa_chain(llm, chain_type="stuff")
llm_response = chain.run(input_documents=docs, question=query)
print(llm_response)
print("done.")
```

é›†æˆäº† Milvus å’Œ LangChainï¼š[å‚è€ƒ](https://mp.weixin.qq.com/s/tgQ-SOoc0h-hqDZy9N3rfg)

```py
class VectorStore(ABC):
    """Interface for vector stores."""    @abstractmethoddef add_texts(
        self,
        texts: Iterable[str],
        metadatas: Optional[List[dict]] = None,
kwargs:Any,
    ) ->List[str]:
"""Run more texts through the embeddings and add to the vectorstore."""    @abstractmethoddefsimilarity_search(
        self, query:str, k:int =4,kwargs: Any) -> List[Document]:
        """Return docs most similar to query."""def max_marginal_relevance_search(
        self, query: str, k: int = 4, fetch_k: int = 20) -> List[Document]:
        """Return docs selected using the maximal marginal relevance."""raise NotImplementedError

    @classmethod    @abstractmethoddef from_texts(
        cls: Type[VST],
        texts: List[str],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        **kwargs: Any,
    ) -> VST:
        """Return VectorStore initialized from texts and embeddings."""
```                


å°† Milvus é›†æˆåˆ° LangChain ä¸­ï¼Œå®ç°å‡ ä¸ªå…³é”®å‡½æ•°ï¼šadd_texts()ã€similarity_search()ã€max_marginal_relevance_search()å’Œ from_text()

å°† Milvus é›†æˆåˆ° LangChain ä¸­çš„ç¡®å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œæœ€ä¸»è¦çš„æ˜¯ Milvus æ— æ³•å¤„ç† JSON æ–‡ä»¶ã€‚ç›®å‰ï¼Œåªæœ‰ä¸¤ç§è§£å†³æ–¹æ³•ï¼š
- ç°æœ‰çš„ Milvus collection ä¸Šåˆ›å»ºä¸€ä¸ª VectorStoreã€‚
- åŸºäºä¸Šä¼ è‡³ Milvus çš„ç¬¬ä¸€ä¸ªæ–‡æ¡£åˆ›å»ºä¸€ä¸ª VectorStoreã€‚

#### LangChain + Faiss + Ray å®è·µ

ã€2023-5-29ã€‘[Building an LLM open source search engine in 100 lines using LangChain and Ray](https://www.anyscale.com/blog/llm-open-source-search-engine-langchain-ray)
- Building the index: Build a document index easily with Ray and Langchain
- ![](https://images.ctfassets.net/xjan103pcp94/4OzISThpksdKgjZ0gVJUiB/85bb7fccdfef1df3d061c57e9af1062a/index-langchain.jpg)
- Build a document index 4-8x faster with Ray
- ![](https://images.ctfassets.net/xjan103pcp94/7tDpD5Q7nxtRyX9lgDvbkI/6209fbd875c5cd379c2289ef6f6554f0/Screen_Shot_2023-04-16_at_6.20.10_PM.png)
- Serving: Serve search queries with Ray and Langchain
- ![](https://images.ctfassets.net/xjan103pcp94/1g6zBePU72Rmz5MBH2reaB/db400e9bbbc445d7214d45658f81992f/Screen_Shot_2023-04-16_at_9.42.46_PM.png)


#### LangChain+ChatGLM æœ¬åœ°é—®ç­”

[LangChain+ChatGLM å®ç°æœ¬åœ°é—®ç­”](https://juejin.cn/post/7236028062873550908)

ChatGLM-6B apiéƒ¨ç½²ï¼š[ChatGLM é›†æˆè¿›LangChainå·¥å…·](https://juejin.cn/post/7226157821708681277)
- [api.py](https://github.com/THUDM/ChatGLM-6B/blob/main/api.py#L53:5)
- é»˜è®¤æœ¬åœ°çš„ 8000 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨

```sh
pip install fastapi uvicorn
python api.py
```

æ•ˆæœ

```sh
curl -X POST "http://{your_host}:8000" \
     -H 'Content-Type: application/json' \
     -d '{"prompt": "ä½ å¥½", "history": []}'
# ç»“æœ
{
  "response":"ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚",
  "history":[["ä½ å¥½","ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"]],
  "status":200,
  "time":"2023-03-23 21:38:40"
}
```

å°è£… ChatGLM APIåˆ°LangChainä¸­

```py
from langchain.llms.base import LLM
from langchain.llms.utils import enforce_stop_tokens
from typing import Dict, List, Optional, Tuple, Union

import requests
import json

class ChatGLM(LLM):
    max_token: int = 10000
    temperature: float = 0.1
    top_p = 0.9
    history = []

    def __init__(self):
        super().__init__()

    @property
    def _llm_type(self) -> str:
        return "ChatGLM"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        # headersä¸­æ·»åŠ ä¸Šcontent-typeè¿™ä¸ªå‚æ•°ï¼ŒæŒ‡å®šä¸ºjsonæ ¼å¼
        headers = {'Content-Type': 'application/json'}
        data=json.dumps({
          'prompt':prompt,
          'temperature':self.temperature,
          'history':self.history,
          'max_length':self.max_token
        })
        # print("ChatGLM prompt:",prompt)
        # è°ƒç”¨api
        response = requests.post("{your_host}/api",headers=headers,data=data)
		# print("ChatGLM resp:",response)
        if response.status_code!=200:
          return "æŸ¥è¯¢ç»“æœé”™è¯¯"
        resp = response.json()
        if stop is not None:
            response = enforce_stop_tokens(response, stop)
        self.history = self.history+[[None, resp['response']]]
        return resp['response']
# è°ƒç”¨
llm = ChatGLM()
print(llm("ä½ ä¼šåšä»€ä¹ˆ"))
# ChatGLM prompt: ä½ ä¼šåšä»€ä¹ˆ
# æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¢«è®­ç»ƒæ¥å›ç­”äººç±»æå‡ºçš„é—®é¢˜ã€‚æˆ‘ä¸èƒ½åšä»»ä½•å®é™…çš„äº‹æƒ…ï¼Œåªèƒ½é€šè¿‡æ–‡å­—å›ç­”é—®é¢˜ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ã€‚

```


### å¾®è½¯guidanceï¼ˆLangChainç®€åŒ–ï¼‰

ã€2023-5-26ã€‘[å¾®è½¯å‘å¸ƒlangChainæ€æ‰‹ï¼šguidanceæ¶æ„å›¾å…¨çƒé¦–å‘](https://mp.weixin.qq.com/s/tdN5KXSXfM9dKDMWbXV2WA)

å¾®è½¯å‘å¸ƒguidanceæ¨¡å—åº“ï¼Œå¹¶è¿…é€Ÿç™»ä¸Šgithubç½‘ç«™TOPæ¦œé¦–ï¼š
- guidanceï¼Œä¼ ç»Ÿæç¤ºæˆ–é“¾æ¥æ›´æœ‰æ•ˆã€æ›´é«˜æ•ˆåœ°æ§åˆ¶æ–°å¼è¯­è¨€æ¨¡å‹ã€‚
- ååŠ©ç”¨æˆ·å°†ç”Ÿæˆã€æç¤ºå’Œé€»è¾‘æ§åˆ¶äº¤é”™åˆ°å•ä¸ªè¿ç»­æµä¸­ï¼Œä»¥åŒ¹é…è¯­è¨€æ¨¡å‹å®é™…å¤„ç†æ–‡æœ¬çš„æ–¹å¼ã€‚
- ç®€å•çš„è¾“å‡ºç»“æ„ï¼Œå¦‚æ€ç»´é“¾åŠå…¶è®¸å¤šå˜ä½“ï¼ˆä¾‹å¦‚ARTï¼ŒAuto-CoTç­‰ï¼‰å·²è¢«è¯æ˜å¯ä»¥æé«˜LLMçš„æ€§èƒ½ã€‚
- åƒGPT-4è¿™æ ·æ›´å¼ºå¤§çš„LLMçš„å‡ºç°å…è®¸æ›´ä¸°å¯Œçš„ç»“æ„ï¼Œå¹¶ä½¿è¯¥ç»“æ„æ›´å®¹æ˜“ï¼Œæ›´ä¾¿å®œã€‚

ç®€å•æ¥è¯´ï¼Œå¾®è½¯guidanceæ¨¡å—åº“ï¼Œæ˜¯langChainæ¨¡å—åº“çš„**ç®€åŒ–ç‰ˆ**ï¼Œæˆ–è€…è¯´ï¼šlangChainæ€æ‰‹ã€‚

### ChatGLM QA

ã€2023-5-22ã€‘
- [åŸºäºchatglmæ­å»ºæ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/622418308): é“è·¯äº¤é€šå®‰å…¨æ³•é¢†åŸŸï¼Œä¸åˆ°100è¡Œçš„pythonæ–‡ä»¶
  - åŸºäºlangchain/llama-indexå·²ç»å¯ä»¥å¿«é€Ÿå®Œæˆç±»ä¼¼çš„åŠŸèƒ½ï¼Œä½†ä»£ç é‡å¤§ï¼Œå­¦ä¹ é—¨æ§›é«˜
- [chatglm-qabot-v2: ä»q-dåŒ¹é…åˆ°q-qåŒ¹é…](https://github.com/xinsblog/chatglm-qabot)
- [chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)

ä¸€äº›å…³é”®ç»„ä»¶çš„é…ç½®ï¼š
- LLMä½¿ç”¨çš„æ˜¯æ¸…åçš„chatglm-6b
- è®¡ç®—embeddingç”¨çš„æ˜¯è‹ç¥çš„**simbertV2**
- æ²¡åšembeddingçš„ç´¢å¼•ä¼˜åŒ–ï¼Œç›´æ¥æ”¾listé‡Œæš´åŠ›æŸ¥æ‰¾
- æ¯æ¬¡é»˜è®¤æŸ¥æ‰¾top3ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µç”¨äºæ„é€ prompt
- æ„é€ promptçš„æ¨¡æ¿è§ä»£ç 
- ç”Ÿæˆç­”æ¡ˆçš„é•¿åº¦æ²¡åšé™åˆ¶ï¼Œè¦åšçš„è¯åœ¨ä»£ç ä¸­åŠ è¯·æ±‚chatglmçš„å‚æ•°å³å¯

```py
import sys

# åˆå§‹åŒ–é—®ç­”æœºå™¨äºº
qabot = QaBot(doc_path="data/ä¸­åäººæ°‘å…±å’Œå›½é“è·¯äº¤é€šå®‰å…¨æ³•.txt", chatglm_api_url=sys.argv[1])
# æ ¹æ®æ–‡æ¡£å›ç­”é—®é¢˜
answer, _ = qabot.query('é…’åé©¾é©¶ä¼šåç‰¢å—')
```

åˆå§‹åŒ–çš„ä»£ç å¦‚ä¸‹

```py
def __init__(self, doc_path: str, chatglm_api_url: str):
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨äºå°†æ–‡æ¡£è½¬ä¸ºembedding
    pretrained_model = "junnyu/roformer_chinese_sim_char_small"
    self.tokenizer = RoFormerTokenizer.from_pretrained(pretrained_model)
    self.model = RoFormerForCausalLM.from_pretrained(pretrained_model)
    # åŠ è½½æ–‡æ¡£ï¼Œé¢„å…ˆè®¡ç®—æ¯ä¸ªchunkçš„embedding
    self.chunks, self.index = self._build_index(doc_path)
    # chatglmçš„apiåœ°å€
    self.chatglm_api_url = chatglm_api_url
```

æ¯æ¬¡é—®ç­”çš„ä»£ç å¦‚ä¸‹

```py
def query(self, question: str) -> Tuple[str, str]:
    # è®¡ç®—questionçš„embedding
    query_embedding = self._encode_text(question)
    # æ ¹æ®questionçš„embeddingï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„3ä¸ªchunk
    relevant_chunks = self._search_index(query_embedding, topk=3)
    # æ ¹æ®questionå’Œæœ€ç›¸å…³çš„3ä¸ªchunkï¼Œæ„é€ prompt
    prompt = self._generate_prompt(question, relevant_chunks)
    # è¯·æ±‚chatglmçš„apiè·å¾—ç­”æ¡ˆ
    answer = self._ask_chatglm(prompt)
    # åŒæ—¶è¿”å›ç­”æ¡ˆå’Œprompt
    return answer, prompt
```

æ•ˆæœ
- ![](https://pic3.zhimg.com/80/v2-f263dca70c9ae78e85f2284f1f66685e_1440w.webp)
- ![](https://pic1.zhimg.com/80/v2-70c79cadf68c65c30160dedf8ef17b34_1440w.webp)
- ![](https://pic4.zhimg.com/80/v2-c323e0e63b47f2cb006dddba14ef57ab_1440w.webp)

åŸºäºchatglmåšæ–‡æ¡£é—®ç­”ï¼Œé€šå¸¸çš„åšæ³•æ˜¯"å…ˆæ£€ç´¢å†æ•´åˆ"ï¼Œå¤§è‡´æ€è·¯
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†æ¯ä¸ªchunkè½¬ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“
- å½“ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªchunk
- å°†é—®é¢˜å’Œchunkåˆå¹¶é‡å†™ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

å°†ç”¨æˆ·è¯·æ±‚çš„queryå’ŒdocumentåšåŒ¹é…ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„`q-dåŒ¹é…`ã€‚

q-dåŒ¹é…çš„é—®é¢˜
- queryå’Œdocumentåœ¨**è¡¨è¾¾æ–¹å¼å­˜åœ¨è¾ƒå¤§å·®å¼‚**ï¼Œé€šå¸¸queryæ˜¯ä»¥**ç–‘é—®å¥**ä¸ºä¸»ï¼Œè€Œdocumentåˆ™ä»¥**é™ˆè¿°è¯´æ˜**ä¸ºä¸»ï¼Œè¿™ç§å·®å¼‚å¯èƒ½ä¼šå½±å“æœ€ç»ˆåŒ¹é…çš„æ•ˆæœã€‚
- ä¸€ç§æ”¹è¿›çš„æ–¹æ³•æ˜¯ä¸åš`q-dåŒ¹é…`ï¼Œè€Œæ˜¯å…ˆé€šè¿‡documentç”Ÿæˆä¸€æ‰¹å€™é€‰çš„questionï¼Œå½“ç”¨æˆ·å‘æ¥è¯·æ±‚çš„æ—¶å€™ï¼Œé¦–å…ˆæ˜¯æŠŠqueryå’Œå€™é€‰çš„questionåšåŒ¹é…ï¼Œè¿›è€Œæ‰¾åˆ°ç›¸å…³çš„documentç‰‡æ®µ
- å¦ä¸€ä¸ªæ€è·¯é€šè¿‡HyDEå»ä¼˜åŒ–
  - ä¸ºqueryå…ˆç”Ÿæˆä¸€ä¸ªå‡ç­”æ¡ˆï¼Œç„¶åé€šè¿‡å‡ç­”æ¡ˆå»æ£€ç´¢ï¼Œè¿™æ ·å¯ä»¥çœå»ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆé—®é¢˜çš„è¿‡ç¨‹ï¼Œä»£ä»·ç›¸å¯¹è¾ƒå°

ç¬¬ä¸€ç§æ–¹æ³•å°±æ˜¯'`q-qåŒ¹é…`'ï¼Œå…·ä½“æ€è·¯å¦‚ä¸‹ï¼š
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- éƒ¨ç½²chatglmçš„apiï¼Œ[éƒ¨ç½²æ–¹æ³•](https://github.com/THUDM/ChatGLM-6B#api%E9%83%A8%E7%BD%B2)
- è°ƒapiï¼Œæ ¹æ®æ¯ä¸ªchunkç”Ÿæˆ5ä¸ªå€™é€‰çš„questionï¼Œä½¿ç”¨çš„promptæ ¼å¼ä¸º'è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ç”Ÿæˆ5ä¸ªé—®é¢˜: ...'ï¼Œç”Ÿæˆæ•ˆæœè§ä¸‹å›¾ï¼š
  - ![](https://pic2.zhimg.com/80/v2-7790ad31e0621bff9e10233b448100f1_1440w.jpg)
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†ç”Ÿæˆçš„questionè½¬ä¸ºå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œå¹¶è®°å½•questionå’ŒåŸå§‹chunkçš„å¯¹åº”å…³ç³»
- ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªquestionï¼Œè¿›è€Œæ‰¾åˆ°å¯¹åº”çš„chunk
- å°†é—®é¢˜å’Œchunk**åˆå¹¶é‡å†™**ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

[chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)
- qabot_v1.pyå®ç°äº†q-dåŒ¹é…æ–¹æ³•
- qabot_v2.pyå®ç°äº†q-qåŒ¹é…æ–¹æ³•

`q-dåŒ¹é…`å’Œ`q-qåŒ¹é…`çš„ä»£ç å·®å¼‚
- åˆå§‹åŒ–æ„å»ºç´¢å¼•çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic1.zhimg.com/80/v2-e3e8a1922e93fe67a6432866882b4490_1440w.webp)
- æŸ¥è¯¢ç´¢å¼•æ—¶çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic2.zhimg.com/80/v2-273d529bbcd4577f55003cd6fe508fa5_1440w.webp)

æµ‹è¯•é—®é¢˜ä¸ºè¡Œé©¶è¯çš„å¼æ ·ç”±è°æ¥ç›‘åˆ¶ï¼Œv1å’Œv2çš„æ•ˆæœå¯¹æ¯”å¦‚ä¸‹ï¼š
- ![](https://pic2.zhimg.com/80/v2-14832aaedad809d62ce0d9157c770c69_1440w.webp)

åœ¨æ„å»ºç´¢å¼•é˜¶æ®µï¼Œv2èŠ±è´¹çš„æ—¶é—´æ˜¯è¿œè¶…è¿‡v1çš„ï¼š

```sh
# è®¡ç®—chunksçš„embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00, 7.81it/s]
# ç”Ÿæˆquestionå¹¶è®¡ç®—embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [07:24<00:00, 22.24s/it]
```


## å®šåˆ¶çŸ¥è¯†åº“

ã€2023-5-24ã€‘
- [åŸºäº ChatGLM-6B æ­å»ºä¸ªäººä¸“å±çŸ¥è¯†åº“](https://www.toutiao.com/article/7236562318920876596)
- [å¦‚ä½•ä½¿ç”¨LangChainï¼‹LLM æ¥æ„å»ºæœ¬åœ°çŸ¥è¯†åº“](https://mp.weixin.qq.com/s/ponKZ1OaHXX2nzuSxXg8-Q)

### ä¸šåŠ¡åœºæ™¯

è°ƒæ•´ promptï¼ŒåŒ¹é…ä¸åŒçš„çŸ¥è¯†åº“ï¼Œè®© LLM æ‰®æ¼”ä¸åŒçš„è§’è‰²
- â€¢ ä¸Šä¼ å…¬å¸è´¢æŠ¥ï¼Œå……å½“è´¢åŠ¡åˆ†æå¸ˆ
- â€¢ ä¸Šä¼ å®¢æœèŠå¤©è®°å½•ï¼Œå……å½“æ™ºèƒ½å®¢æœ
- â€¢ ä¸Šä¼ ç»å…¸Caseï¼Œå……å½“å¾‹å¸ˆåŠ©æ‰‹
- â€¢ ä¸Šä¼ åŒ»é™¢ç™¾ç§‘å…¨ä¹¦ï¼Œå……å½“åœ¨çº¿é—®è¯ŠåŒ»ç”Ÿ

### é—®é¢˜

å¾®è°ƒçš„ç“¶é¢ˆ
- éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œå¾ˆå¤šè®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œä»¥ä¾¿åœ¨ä¸åŒè¶…å‚æ•°è®¾ç½®è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œå¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ª
- åŠ¨æ€æ‰©å±•æ¯”è¾ƒå·®ï¼Œæ–°å¢å’Œä¿®æ”¹åŸæœ‰çš„æ•°æ®éƒ½è¦é‡æ–°å¾®è°ƒä¸€æ¬¡ã€‚

æ€»ä¹‹ï¼Œå¾®è°ƒå¯¹éä¸“ä¸šäººå‘˜ä¸å‹å¥½ã€‚

å¦‚ä½•ä¸ç”¨å¾®è°ƒå°±èƒ½å®ç°å‚ç›´é¢†åŸŸçš„ä¸“ä¸šé—®ç­”ï¼Ÿ
- æ–¹æ¡ˆï¼šChatGLM-6B + langchain å®ç°ä¸ªäººä¸“å±çŸ¥è¯†åº“

### æŠ€æœ¯åŸç†

æŠ€æœ¯åŸç†
- åŠ è½½æ–‡ä»¶ -> è¯»å–æ–‡æœ¬ -> æ–‡æœ¬åˆ†å‰² -> æ–‡æœ¬å‘é‡åŒ– -> é—®å¥å‘é‡åŒ– -> åœ¨æ–‡æœ¬å‘é‡ä¸­åŒ¹é…å‡ºä¸é—®å¥å‘é‡æœ€ç›¸ä¼¼çš„top kä¸ª -> åŒ¹é…å‡ºçš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æ·»åŠ åˆ° prompt ä¸­ -> æäº¤ç»™ LLM ç”Ÿæˆå›ç­”ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/0d835cc528ba470d8e0e000f950780c7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=5lntZ3rovTBKBRNYBptf8gdfeOM%3D)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/ddc11018f9324f6cae76611a7486894b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=O88KtsSqlFFGJqlLUTLF4IzYYhs%3D)

æ ¸å¿ƒæŠ€æœ¯æ˜¯: å‘é‡ embedding
- å°†ç”¨æˆ·çŸ¥è¯†åº“å†…å®¹ç»è¿‡ embedding å­˜å…¥å‘é‡çŸ¥è¯†åº“ï¼Œç„¶åç”¨æˆ·æ¯ä¸€æ¬¡æé—®ä¹Ÿä¼šç»è¿‡ embeddingï¼Œåˆ©ç”¨å‘é‡ç›¸å…³æ€§ç®—æ³•ï¼ˆä¾‹å¦‚ä½™å¼¦ç®—æ³•ï¼‰æ‰¾åˆ°æœ€åŒ¹é…çš„å‡ ä¸ªçŸ¥è¯†åº“ç‰‡æ®µï¼Œå°†è¿™äº›çŸ¥è¯†åº“ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·ä½œä¸º prompt æäº¤ç»™ LLM å›ç­”

å…¸å‹çš„prompt

```json
å·²çŸ¥ä¿¡æ¯ï¼š
{context} 
æ ¹æ®ä¸Šè¿°å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´å’Œä¸“ä¸šçš„æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ— æ³•ä»ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·è¯´ â€œæ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜â€ æˆ– â€œæ²¡æœ‰æä¾›è¶³å¤Ÿçš„ç›¸å…³ä¿¡æ¯â€ï¼Œä¸å…è®¸åœ¨ç­”æ¡ˆä¸­æ·»åŠ ç¼–é€ æˆåˆ†ï¼Œç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚ 
é—®é¢˜æ˜¯ï¼š{question}
```

### å®ç°

```sh
# ä¸‹è½½æºç 
git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git
# å®‰è£…ä¾èµ–
cd langchain-ChatGLM
pip install -r requirements.txt
# ä¸‹è½½æ¨¡å‹

# å®‰è£… git lfs
git lfs install
# ä¸‹è½½ LLM æ¨¡å‹
git clone https://huggingface.co/THUDM/chatglm-6b /your_path/chatglm-6b
# ä¸‹è½½ Embedding æ¨¡å‹
git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese /your_path/text2vec
# æ¨¡å‹éœ€è¦æ›´æ–°æ—¶ï¼Œå¯æ‰“å¼€æ¨¡å‹æ‰€åœ¨æ–‡ä»¶å¤¹åæ‹‰å–æœ€æ–°æ¨¡å‹æ–‡ä»¶/ä»£ç 
git pull
```

æ¨¡å‹ä¸‹è½½å®Œæˆåï¼Œè¯·åœ¨ configs/model_config.py æ–‡ä»¶ä¸­ï¼Œå¯¹embedding_model_dictå’Œllm_model_dictå‚æ•°è¿›è¡Œä¿®æ”¹ã€‚

```py
embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "/your_path/text2vec"
}
llm_model_dict = {
    "chatyuan": "ClueAI/ChatYuan-large-v2",
    "chatglm-6b-int4-qe": "THUDM/chatglm-6b-int4-qe",
    "chatglm-6b-int4": "THUDM/chatglm-6b-int4",
    "chatglm-6b-int8": "THUDM/chatglm-6b-int8",
    "chatglm-6b": "/your_path/chatglm-6b",
}
```

å¯åŠ¨æœåŠ¡

```py
# Web æ¨¡å¼å¯åŠ¨
pip install gradio
python webui.py
# API æ¨¡å¼å¯åŠ¨
python api.py
# å‘½ä»¤è¡Œæ¨¡å¼å¯åŠ¨
python cli_demo.py
```

### æ•ˆæœ

gradioé¡µé¢
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/558af5fd53d34b5a859afddbc82a331c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=N%2FKm%2FGcW8WSiFxrAAD04P3klhig%3D)

Chatgpt-Next-Web é¡¹ç›®åŸºç¡€ä¸Šè¿›è¡Œäº†é€‚é…ä¿®æ”¹ï¼Œæ‰“é€ äº†ä¸€æ¬¾é¢å‘ç”¨æˆ·ä½¿ç”¨çš„æœ¬åœ°çŸ¥è¯†åº“å‰ç«¯ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/55d11a03e5a742ce9c201aa355b38e3c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=fYTBeLwxkicrZBzWsYQusCVfiJk%3D)


### FastGPT

ã€2023-5-17ã€‘[FastGPT](https://github.com/c121914yu/FastGPT), è°ƒç”¨ gpt-3.5 å’Œ embedding æ„å»ºè‡ªå·±çš„çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“æ„å»ºåŸç†
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/KBProcess.jpg?raw=true)

æ•ˆæœ
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/demo.png?raw=true)



åœ¨çº¿ä½“éªŒ
- ğŸ‰ [fastgpt.run](https://fastgpt.run/) ï¼ˆå›½å†…ç‰ˆï¼‰
- ğŸ‰ [ai.fastgpt.run](https://ai.fastgpt.run/) ï¼ˆæµ·å¤–ç‰ˆï¼‰



## ä¸šç•Œæ¡ˆä¾‹

### New Bing

- ä¼˜åŠ¿ï¼šå…è´¹ï¼Œå¿«æ·ï¼Œå¯ä»¥è”ç½‘ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥é˜…è¯»æœ¬åœ°PDFå’Œç½‘ç»œè®ºæ–‡ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’
- ç¼ºç‚¹ï¼šä¸ç¨³å®šï¼Œè¯†åˆ«å†…å®¹æœ‰é™ï¼Œç”šè‡³äºä¿¡æ¯é‡ä½äºæ‘˜è¦çš„å†…å®¹ã€‚ç»å¸¸ä¼šè¾“å‡ºä¸€åŠå°±æ–­äº†ã€‚

### chatpdf

[ChatPDF](https://www.chatpdf.com) ç•Œé¢å¹²å‡€ï¼Œä¸Šä¼ pdfåï¼Œç›´æ¥å¯¹è¯ã€‚
- ä¸Šä¼ é€Ÿåº¦å¾ˆå¿«ï¼Œå¯¹è¯å“åº”ä¹Ÿéå¸¸çš„å¿«ã€‚
- å¯¹æ–‡æ¡£å†…å®¹çš„è§£æå¾ˆå‡†ç¡®ï¼ŒåŒ…æ‹¬ä¸€äº›éšè—åœ¨å†…éƒ¨çš„çŸ¥è¯†ç‚¹ä¹Ÿå¯ä»¥å¿«é€Ÿæœç´¢æ‰¾åˆ°
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY88FTkaxGc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=A9yfB6gzbQrwWdUHuBZ2o0bRZzM%3D)

ä¼˜åŠ¿ï¼š
- äº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ç¼ºç‚¹ï¼šå…¨æ–‡æ€»ç»“ä¿¡æ¯é‡è¾ƒä½ï¼Œé—®ç­”æ¨¡å¼åå‘äºå…³é”®è¯å®šä½ï¼Œç„¶åä¸Šä¸‹æ–‡ç¿»è¯‘ï¼Œä¸”å·²ç»æ”¶è´¹ï¼Œæ¯æœˆ5åˆ€ã€‚åªæ”¯æŒæœ¬åœ°PDFæ–‡æ¡£ä¸Šä¼ ã€‚

### scispace

- ä¼˜åŠ¿ï¼šäº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ï¼Œæ”¯æŒæœ¬åœ°è®ºæ–‡ä¸Šä¼ ï¼Œå¯ä»¥å…¬å¼æˆªå›¾è§£æï¼Œå¯ä»¥è§£é‡Šä¼ªä»£ç 
- ç¼ºç‚¹ï¼šå¯¹ä¸­æ–‡æ”¯æŒè¾ƒå·®ï¼Œå…¨æ–‡æ€»ç»“æ•ˆæœè¾ƒå·®ã€‚

### aminer.cn

æ¸…åå”æ°è€å¸ˆä»–ä»¬ç»„çš„å·¥ä½œï¼
- ![](https://pic1.zhimg.com/80/v2-33843cf159df1ca9e4a28fa32a15a759_1440w.webp?source=1940ef5c)
- ![](https://pic1.zhimg.com/80/v2-765efacd5340b65de02e79087ee91a07_1440w.webp?source=1940ef5c)

- ä¼˜åŠ¿ï¼šæœ‰çƒ­ç‚¹è®ºæ–‡æ¨é€ï¼æœ‰è®ºæ–‡æ‰“åˆ†ï¼Œå’Œåˆ«äººçš„æé—®è®°å½•
- ç¼ºç‚¹ï¼šè¯­ä¹‰ç†è§£æœ‰é™

### ChatPaper å¼€æº

ä¸­ç§‘å¤§å‡ºå“ï¼šChatPaper, Use ChatGPT to summarize the arXiv papers. å…¨æµç¨‹åŠ é€Ÿç§‘ç ”ï¼Œåˆ©ç”¨chatgptè¿›è¡Œè®ºæ–‡æ€»ç»“+æ¶¦è‰²+å®¡ç¨¿+å®¡ç¨¿å›å¤
- åŠŸèƒ½ï¼šè®ºæ–‡ï¼ˆç¦»çº¿/åœ¨çº¿ï¼‰æ€»ç»“+è®ºæ–‡æ¶¦è‰²+AIå®¡ç¨¿+AIå®¡ç¨¿å›å¤ç­‰åŠŸèƒ½ã€‚
- [github](https://github.com/kaixindelele/chatpaper), [demo](https://chatpaper.org/)

é—®é¢˜ï¼š
- å‰é¢å‡ æ¬¾å·¥å…·éƒ½é¢ä¸´ä¸€ä¸ªé—®é¢˜ï¼Œå…¨æ–‡æ€»ç»“çš„ä¿¡æ¯é‡è¾ƒä½ï¼Œå› ä¸ºGPTsçš„è¾“å…¥tokenæ˜¯**è¿œä½äº**è®ºæ–‡çš„å…¨æ–‡æ–‡æœ¬çš„ï¼Œè€Œç®€å•çš„ç¿»è¯‘æ€»ç»“æ‘˜è¦ï¼Œåˆæ‹¿ä¸åˆ°å¤šå°‘æœ‰æ•ˆä¿¡æ¯

æ–¹æ¡ˆï¼š
- å°†abstractå’Œintroductionè¿›è¡Œå‹ç¼©ï¼Œç„¶åè¾“å…¥ç»™chatè¿›è¡Œæ€»ç»“

æ•ˆæœ
- æ¯ç¯‡æ–‡ç« ï¼Œè°ƒç”¨äº”æ¬¡chatï¼Œå¯ä»¥è·å¾—7åˆ°8æˆçš„ä¿¡æ¯é‡ï¼Œå¹¶ä¸”æ ¼å¼åŒ–è¾“å‡ºæˆä¸­å›½äººå®¹æ˜“çœ‹æ‡‚çš„æ–‡æœ¬ï¼Œæå¤§çš„é™ä½äº†å¤§å®¶çš„é˜…è¯»é—¨æ§›ã€‚å‡ ä¹å¯ä»¥è¾¾åˆ°ï¼ŒAIèŠ±ä¸€åˆ†é’Ÿæ€»ç»“ï¼ŒäººèŠ±ä¸€åˆ†é’Ÿçœ‹æ€»ç»“ï¼Œå°±å¯ä»¥åˆ¤æ–­è¿™ç¯‡æ–‡ç« æ˜¯å¦éœ€è¦ç²¾è¯»çš„æ•ˆæœã€‚
- å¦‚æœéœ€è¦**ç²¾è¯»**ï¼Œåˆ™å¯ä»¥è°ƒç”¨ä¸Šé¢çš„å„ç§å·¥å…·ï¼Œå°¤å…¶æ¨èscispaceå’Œaminer.


### PandasGPT

[PandaGPT](https://www.pandagpt.io/), è®¿é—®é€Ÿåº¦åæ…¢ï¼ŒUIå¯¹è¯æ ·å¼ä¸€è¨€éš¾å°½ï¼Œæ²¡æœ‰ä¸€ä¸ªç‰ˆå—ä¸æ˜¯äº’ç›¸é®æŒ¡çš„
- å·²æœ‰3wä¸ªæ–‡æ¡£ï¼Œ10wä¸ªé—®é¢˜
- ä¸Šä¼ æ–‡æ¡£ï¼Œç›´æ¥é’ˆå¯¹æ–‡æ¡£é—®ç­”; è¿˜èƒ½ç”ŸæˆçŸ¥è¯†å›¾è°±ï¼ŒGenerate Knowledge Graph
- ![](https://uploads-ssl.webflow.com/6405047c9d73416a60b878b4/6405068dec8bf7442171f160_Screenshot%202023-03-05%20at%204.15.30%20PM.png)

- é—®é¢˜å›ç­”åŸºæœ¬åˆ°ä½ï¼Œç›¸æ¯”ChatPDFï¼Œç•¥æ˜¾å•°å—¦
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY8iElGGYks~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=BO6bt9JW5V%2Fsitc%2F%2FKWe6sBmUHY%3D)

ç±»ä¼¼çš„ï¼Œè¿˜æœ‰ AMiner ä¸Šçš„åæ™ºå†°

### ChatDOC

ã€2023-3-28ã€‘[ChatDOC](https://chatdoc.com/)æ–‡æ¡£é˜…è¯»å·¥å…·ï¼Œæ”¯æŒä¸­æ–‡ï¼åˆå¿«åˆå…è´¹ï¼ä½¿ç”¨ ChatGPT é˜…è¯»æ–‡ä»¶çš„AIé—®ç­”æœºå™¨äºº
- åŸºäº ChatGPT çš„æ–‡ä»¶é˜…è¯»åŠ©æ‰‹ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥å¿«é€Ÿä»ä¸Šä¼ ç ”ç©¶è®ºæ–‡ã€ä¹¦ç±ã€æ‰‹å†Œç­‰æ–‡ä»¶ä¸­æå–ã€å®šä½å’Œæ±‡æ€»æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶é€šè¿‡èŠå¤©çš„æ–¹å¼åœ¨å‡ ç§’é’Ÿå†…ç»™å‡ºé—®é¢˜çš„ç­”æ¡ˆã€‚
- ChatDOC è¿˜å¯ä»¥ç†è§£æ–‡æ¡£ä¸­çš„è¡¨æ ¼æˆ–æ–‡å­—ï¼Œä¼˜åŒ–å…¶æ•°æ®åˆ†ææ€§èƒ½ï¼Œå¹¶ä¸ºæ¯ä¸ªå›ç­”æä¾›ç›´æ¥å¼•ç”¨çš„æ¥æºï¼Œæ–¹ä¾¿æ ¸å®AIçš„è§£è¯»å‡†ç¡®æ€§ã€‚
- ChatDOC ç›®å‰å…è´¹ï¼Œæ–‡ä»¶å¤§å°é™åˆ¶ä¸º 200 é¡µï¼Œæœ€å¤šå¯ä»¥ä¸Šä¼  5 ä¸ªæ–‡æ¡£ã€‚åœ¨å³å°†æ›´æ–°çš„ç‰ˆæœ¬ä¸­ï¼Œè¿˜æ”¯æŒè·¨å¤šä¸ªæ–‡æ¡£çš„ç»¼åˆæŸ¥è¯¢å’Œé—®ç­”ã€‚
- ![](https://pic2.zhimg.com/80/v2-c73f17ecea423a82aad0ac7c110bd625_720w.webp)


### typeset

[typeset](https://typeset.io)
- ä¸»æ‰“è®ºæ–‡æ£€ç´¢ï¼Œä¹Ÿæ”¯æŒpdfæ–‡æ¡£è§£è¯»ã€‚
- ä¸Šä¼ ã€å¯¹è¯å“åº”éƒ½ååˆ†ç¼“æ…¢ï¼Œå¯¹è¯çš„æ•ˆæœå·®ï¼Œå¾ˆå¤šçŸ¥è¯†ç‚¹æ— æ³•è§£è¯»ï¼Œä¸€å¾‹å›å¤æ— æ³•æ‰¾åˆ°è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY9mB4FVHsf~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=DjAXODUMrVrnilF7CAXPLSUT0qs%3D)

### privateGPT (æœ¬åœ°ã€ç¦»çº¿)

ã€2023-5-17ã€‘å¼€æºçš„ [privateGPT](https://www.privategpt.io/), [privateGPTä»£ç ](https://github.com/imartinez/privateGPT)ï¼Œå®ƒä½¿ç”¨GPTçš„å¼ºå¤§åŠŸèƒ½ï¼Œå¯ä»¥åœ¨100%ç§å¯†çš„æƒ…å†µä¸‹ä¸æœ¬åœ°æ–‡æ¡£è¿›è¡Œç§å¯†äº¤äº’ï¼Œä¸ä¼šæœ‰ä»»ä½•æ•°æ®æ³„æ¼ã€‚
- ä½¿ç”¨LLaMaã€LangChainå’ŒGPT4Allæ„å»ºã€‚
- [Demo](https://docs.boosterframework.com/)

The supported extensions are:
- .csv: CSV,
- .docx: Word Document,
- .enex: EverNote,
- .eml: Email,
- .epub: EPub,
- .html: HTML File,
- .md: Markdown,
- .msg: Outlook Message,
- .odt: Open Document Text,
- .pdf: Portable Document Format (PDF),
- .pptx : PowerPoint Document,
- .txt: Text file (UTF-8)


### ChatBase

ã€2023-5-28ã€‘[ChatGPT é€ å¯Œâ€œç¥è¯â€ï¼šå¤§å››å­¦ç”Ÿæ”¾å¼ƒå¤§å‚å»åˆ›ä¸šï¼ŒåŠå¹´åæœˆæ”¶å…¥45ä¸‡](https://mp.weixin.qq.com/s/IS5NvCAzs0q4Xi5ABfszFQ)

åŸƒåŠå¤§å­¦ç”Ÿ[Yasser](https://twitter.com/yasser_elsaid_)åœ¨ Meta å’Œ Tesla ç­‰å¤§å‚å®ä¹ åŠå¹´åï¼Œå…¶åˆ›åŠçš„èŠå¤©æœºå™¨äººå…¬å¸å°±å·²ç»ç¨³å®šæœˆæ”¶ 6.4 ä¸‡ç¾å…ƒï¼ˆçº¦åˆ 45 ä¸‡äººæ°‘å¸ï¼‰ï¼Œè€Œä¸”è‡ªé¦–æ¬¡ä¸Šçº¿ä»¥æ¥ï¼Œä¸šåŠ¡æµé‡ä»æœªä¸‹æ»‘ç¼©æ°´ã€‚
- Chatbase å¸‚åœºå®šä½å¹¶ä¸å¤æ‚ï¼Œä¹Ÿæ²¡åšè¿‡éªŒè¯æˆ–è€…å•†ä¸šè°ƒæŸ¥ã€‚æ¯•ç«Ÿ AI è¿™ä¸ªé¢†åŸŸæ‰åˆšåˆšè¯ç”Ÿï¼Œå¯¹æˆ‘æ¥è¯´â€˜ç”¨ ChatGPT å¤„ç†æ•°æ®â€™è‚¯å®šæœ‰æå¤´ï¼Œèƒ½å¸®åŠ©è®¸è®¸å¤šå¤šç”¨æˆ·è§£å†³å®é™…éœ€æ±‚
- Chatbase æœ€åˆå…¶å®æ˜¯æƒ³åšæˆä¸€æ¬¾å¤„ç† PDF çš„ ChatGPT å·¥å…·ï¼Œè¿™æ˜¯ Yasser å½“æ—¶æƒ³åˆ°çš„æœ€ç›´è§‚çš„ç”¨ä¾‹ã€‚æ¯”å¦‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä¸€ä»½ PDFï¼Œç„¶åè®© ChatGPT æ€»ç»“ä¸€ä¸‹å…¶ä¸­çš„å†…å®¹ã€‚
- ç¬¬ä¸€ä¸ªç‰ˆæœ¬èŠ±äº†ä¸¤ä¸ªæœˆæ—¶é—´ï¼Œ2023 å¹´ 2 æœˆ 2 å·ï¼ŒYasser å‘å¸ƒç»™äº† Twitter ä¸Šçš„å…¨éƒ¨ 16 ä¸ªå…³æ³¨è€…ï¼Œç»“æœä¸€ä¸‹å­å°±ç«äº†ï¼Œå·¨å¤§çš„å•†æœºï¼ŒYasser é©¬ä¸Šä¸­æ­¢äº†åœ¨æ ¡è¯¾ä¸šï¼ŒæŠŠæ‰€æœ‰æ—¶é—´å’Œç²¾åŠ›éƒ½é›†ä¸­åœ¨ Chatbase ä¸Š

[Chatbase.co](https://www.chatbase.co/) æ˜¯ä¸€æ¬¾ä¸ºç½‘ç«™æ„å»ºè‡ªå®šä¹‰ ChatGPT ç•Œé¢çš„å·¥å…·ï¼Œç”¨æˆ·åªéœ€ä¸Šä¼ **æ–‡æ¡£**æˆ–æ·»åŠ åˆ°**ç½‘ç«™é“¾æ¥**ï¼Œå°±å¯ä»¥è·å¾—ä¸€ä¸ªç±»ä¼¼ ChatGPT çš„èŠå¤©æœºå™¨äººï¼Œå¹¶å°†å®ƒä½œä¸ºå°ç»„ä»¶æ·»åŠ åˆ°ç½‘ç«™ä¸Šã€‚

Yasser ç”¨ Reactã€Next.js å’Œ Supabase æ¥æ„ web åº”ç”¨ã€‚Yasser è¿˜åœ¨åº”ç”¨çš„ AI éƒ¨åˆ†ä½¿ç”¨äº† OpenAI çš„ APIã€Langchain è¿˜æœ‰ Pineconeã€‚ä»˜æ¬¾éƒ¨åˆ†ç”¨çš„æ˜¯ Stripeã€‚ç›®å‰è¿™å¥—æŠ€æœ¯æ ˆè¿è¡Œå¾—ä¸é”™ï¼Œä½†åç»­ Yasser å¯èƒ½éœ€è¦åšäº›è°ƒæ•´æ¥æ§åˆ¶æˆæœ¬ï¼Œæ¯”å¦‚å°è¯•ä¸åŒçš„ Vector æ•°æ®åº“æˆ–è€…æ‰˜ç®¡é€‰é¡¹

å¯é›†æˆåˆ°è‡ªå·±çš„ç½‘ç«™, å®˜æ–¹æä¾›[çœ‹æ¿é…ç½®](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX/dashboard)
- ç¤ºä¾‹ï¼š[test](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX)
- å›½å¤–ä»‹ç»ï¼š[How a college student reached $64,000/mo in 6 months by being an AI first mover](https://www.indiehackers.com/post/how-a-college-student-reached-64-000-mo-in-6-months-by-being-an-ai-first-mover-ba7981f6e1)


# ç»“æŸ