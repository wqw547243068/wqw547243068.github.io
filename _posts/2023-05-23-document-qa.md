---
layout: post
title:  æ–‡æ¡£é—®ç­”åŸç†åŠå®è·µ Doucument QA
date:   2023-05-23 19:10:00
categories: å¤§æ¨¡å‹
tags: ChatGPT å¯¹è¯ç³»ç»Ÿ çŸ¥è¯†åº“ å‘é‡åŒ– milvus
excerpt: æ–‡æ¡£é—®ç­”çš„åŸç†ã€æ¡ˆä¾‹åŠå®è·µ
mathjax: true
permalink: /doc_chat
---

* content
{:toc}

# æ–‡æ¡£é—®ç­”


## èµ„è®¯

ã€2023-3-27ã€‘æ–‡æ¡£é—®ç­”

ä½œè€…ï¼š[å¼ºåŒ–å­¦å¾’](https://www.zhihu.com/question/589726461/answer/2961450933)

ã€2023-5-9ã€‘[å¤§è¯­è¨€æ¨¡å‹å®ç°æ™ºèƒ½å®¢æœçŸ¥è¯†åº“æ–‡æ¡£æ•°æ®æå–åŠŸèƒ½](https://www.toutiao.com/article/7231062779061502501)
- æ™ºèƒ½å®¢æœçš„çŸ¥è¯†åº“æœ‰ä¸¤ç±»ï¼š**æœºå™¨äºº**çŸ¥è¯†åº“å’Œ**åå¸­**çŸ¥è¯†åº“ï¼Œåˆ†åˆ«æ˜¯ä¸ºæœºå™¨äººå’Œåå¸­è¿›è¡ŒæœåŠ¡æ—¶ï¼Œæä¾›æ•°æ®çš„æ”¯æ’‘ã€‚
- å¦‚ä½•é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ï¼Œè®©ä¼ä¸šçš„æ–‡æ¡£å¯æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨å‘¢ï¼Ÿ

å½“å‰çš„ä¸»æµå®¢æœäº§å“
- æ™ºèƒ½å®¢æœç³»ç»Ÿä¼šæ ‡é…`çŸ¥è¯†åº“ç®¡ç†`åŠŸèƒ½ï¼Œå¸¸è§çš„å½¢å¼æ˜¯**æ ‘çŠ¶ç»“æ„**ï¼Œæä¾›åˆ†ç±»ç®¡ç†ã€çŸ¥è¯†åº“æ¡ç›®ç®¡ç†ï¼Œå¹¶æ”¯æŒçŸ¥è¯†åº“çš„æ‰¹é‡å¯¼å…¥å¯¼å‡ºæ“ä½œã€‚
- ä½¿ç”¨ä¸­ï¼Œä¼ä¸šéœ€è¦ç»å¸¸æ€§åœ°ç»´æŠ¤ç®¡ç†çŸ¥è¯†åº“å†…å®¹ï¼Œå°†ä¼ä¸šå·²æœ‰çŸ¥è¯†å†…å®¹æ–‡æ¡£ä¸Šä¼ ï¼Œä½†å¦‚æœæ˜¯å°†åŸæ–‡ä»¶ä¸Šä¼ ï¼Œåˆ™ç³»ç»Ÿæœ€å¤šèƒ½æ”¯æŒé¢„è§ˆåŠŸèƒ½ï¼Œä½¿ç”¨è€…åœ¨æ“ä½œç•Œé¢åªèƒ½ç‚¹å‡»æ‰“å¼€å…¨æ–‡æ£€ç´¢ã€‚è€Œå¦‚æœæ˜¯æœºå™¨äººçŸ¥è¯†åº“ï¼Œç›´æ¥ä¸Šä¼ æ–‡æ¡£æ˜¯ä¸å¯ç”¨çš„ï¼Œéœ€è¦æ“ä½œè€…æ‰‹å·¥æ•´ç†æ–‡æ¡£ä¸­çš„å†…å®¹ä¸ºæœºå™¨äººæ ‡å‡†é—®ç­”å¯¹ã€‚

å¤§æ¨¡å‹æ—¶ä»£
- æ‰€æœ‰ä¼ä¸šçš„æ–‡æ¡£å¯ä»¥æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥å¯è‡ªåŠ¨è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨ã€‚

ã€2023-6-26ã€‘å´æ©è¾¾å¤§æ¨¡å‹ç³»åˆ—è¯¾ç¨‹ï¼š
- [LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain/lesson/1/introduction)
- å­¦ä¹ ç¬”è®°ï¼š[åŸºäºLangChainå¼€å‘å¤§è¯­è¨€åº”ç”¨æ¨¡å‹](https://blog.csdn.net/qq_36080693/article/details/131269201)

- ã€2023-9-22ã€‘LLM Searchï¼šæä¾›ä¸€ä¸ªæ–¹ä¾¿çš„åŸºäºLLMçš„é—®ç­”ç³»ç»Ÿï¼Œå¯ä¸å¤šä¸ªæœ¬åœ°æ–‡æ¡£é›†åˆè¿›è¡Œäº¤äº’
  - 'LLM Search - Querying local documents, powered by LLM' Denis Lapchev [GitHub](github.com/snexus/llm-search)

## èƒŒæ™¯

### æ–‡æœ¬å‘é‡åŒ–

`åµŒå…¥`ï¼ˆEmbeddingï¼‰æ˜¯ä¸€ç§å°†**æ–‡æœ¬æˆ–å¯¹è±¡**è½¬æ¢ä¸º**å‘é‡è¡¨ç¤º**çš„æŠ€æœ¯ï¼Œå°†è¯è¯­ã€å¥å­æˆ–å…¶ä»–æ–‡æœ¬å½¢å¼è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºã€‚
- åµŒå…¥å‘é‡æ˜¯ç”±ä¸€ç³»åˆ—æµ®ç‚¹æ•°æ„æˆçš„**å‘é‡**ã€‚
- é€šè¿‡è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡ä¹‹é—´çš„è·ç¦»ï¼Œå¯ä»¥è¡¡é‡å®ƒä»¬ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è·ç¦»è¾ƒå°çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ç›¸å…³æ€§ï¼Œè€Œè·ç¦»è¾ƒå¤§çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´ç›¸å…³æ€§è¾ƒä½ã€‚

ä»¥ `Milvus` ä¸ºä»£è¡¨çš„`å‘é‡æ•°æ®åº“`åˆ©ç”¨è¯­ä¹‰æœç´¢ï¼ˆSemantic Searchï¼‰æ›´å¿«åœ°æ£€ç´¢åˆ°ç›¸å…³æ€§æ›´å¼ºçš„æ–‡æ¡£ã€‚

è¯¦è§ï¼šç«™å†…ä¸“é¢˜é‡Œçš„[æ–‡æœ¬å‘é‡åŒ–](vec)

### Token

ä»€ä¹ˆæ˜¯tokenï¼Ÿ
- tokens ä¸æ˜¯æŒ‡ prompt å­—ç¬¦ä¸²çš„é•¿åº¦ï¼›
- token æŒ‡ä¸€æ®µè¯ä¸­å¯èƒ½è¢«åˆ†å‡ºæ¥çš„**è¯æ±‡**ã€‚
  - æ¯”å¦‚ï¼ši love youï¼Œå°±æ˜¯ä¸‰ä¸ªtokenï¼Œåˆ†åˆ«ä¸º ã€Œiã€ã€Œloveã€ã€Œyouã€ã€‚
- ä¸åŒè¯­è¨€tokenè®¡ç®—ä¸ä¸€æ ·ã€‚[åœ¨çº¿æµ‹è¯•](platform.openai.com/tokenizer)
  - ä¸­æ–‡çš„ã€Œæˆ‘çˆ±ä½ ã€å…¶å®æ˜¯ç®— 5ä¸ªtokenï¼Œå› ä¸ºä¼šå…ˆæŠŠå†…å®¹è½¬æˆ unicodeã€‚
  - æœ‰äº› emoji çš„tokené•¿åº¦ä¼šè¶…å‡ºæƒ³è±¡ï¼Œé•¿è¾¾11ä¸ªã€‚

ChatGPT has an upper limit of 4096

GPT-4 æ”¯æŒï¼Œè¯¦è§[å®˜ç½‘](https://platform.openai.com/docs/models/gpt-4)
- 8k context
- 32k context

| Model | Price for 1000 tokens (prompt) |
|---|---|
| Ada | 2048 |
| Babbage | 2048 | 
| Curie | 2048 |
| DaVinci | 4096 |
| ChatGPT | 4096 |
| GPT-4 8k context | 8192 |
| GPT-4 32k context | 32768 |

Remember, the sum of your prompt and maximum tokens should always be less than equal to the model's maximum token limit, OR your output is truncated.

å¤‡æ³¨
- `ç¼–ç å™¨`ï¼šå¯æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚å¦‚æœåºåˆ—é•¿åº¦å°äºè¯¥é™åˆ¶ï¼Œå°±åœ¨å…¶åå¡«å…¥é¢„å…ˆå®šä¹‰çš„ç©ºç™½å•è¯ã€‚
  - å¦‚ï¼ŒåŸå§‹ transformer è®ºæ–‡ä¸­çš„ç¼–ç å™¨æ¨¡å—å¯ä»¥æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚
- `è§£ç å™¨`ï¼šåŒºåˆ«
  - åŠ å…¥äº†ä¸€å±‚é‡ç‚¹å…³æ³¨ç¼–ç å™¨è¾“å‡ºçš„æŸä¸€ç‰‡æ®µï¼Œ**ç¼–ç å™¨-è§£ç å™¨è‡ªæ³¨æ„åŠ›**ï¼ˆencoder-decoder self-attentionï¼‰å±‚
  - åé¢çš„å•è¯æ©ç›–æ‰äº†ã€‚ä½†å¹¶ä¸åƒ BERT ä¸€æ ·å°†å®ƒä»¬æ›¿æ¢æˆç‰¹æ®Šå®šä¹‰çš„å•è¯ < mask >ï¼Œè€Œæ˜¯åœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—çš„æ—¶å€™å±è”½äº†æ¥è‡ªå½“å‰è®¡ç®—ä½ç½®å³è¾¹æ‰€æœ‰å•è¯çš„ä¿¡æ¯ã€‚

ç»éªŒ
- è‹±æ–‡ï¼š100 tokens ~= 75 words)
- ä¸­æ–‡ï¼šä¸€ä¸ªæ±‰å­—å 2-3ä¸ªtoken
- å…¶å®ƒï¼šemojiè¡¨æƒ…ç¬¦å·ï¼Œå ç”¨æ›´å¤šï¼Œæœ‰çš„é«˜è¾¾11ä¸ª

æ›´å¤šè§ç«™å†…[åˆ†è¯ä¸“é¢˜](https://wqw547243068.github.io/nlp#%E8%AF%8D%E5%BA%93%E6%9E%84%E5%BB%BA)

### å¦‚ä½•å¢å¼ºLLMèƒ½åŠ›


#### Full Stack LLM è¯¾ç¨‹

ã€2023-5-21ã€‘[LLMè®­ç»ƒè¥è¯¾ç¨‹ç¬”è®°â€”Augmented Language Models](https://zhuanlan.zhihu.com/p/630195581)
- [è‹±æ–‡ppt](https://drive.google.com/file/d/1A5RcMETecn6Aa4nNzpVx9kTKdyeErqrI/view), [è®²ä¹‰æ€»ç»“](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)
- There are three ways to augment language models: retrieval, chains, and tools.
- Retrieval involves providing an external corpus of data for the model to search, chains use the output of one language model as input for another, and tools allow models to interact with external data sources.

ã€2023-6-24ã€‘The Full Stack å‡ºå“çš„ LLM Bootcamp Spring 2023
- LLM Foundations [ppt](https://drive.google.com/file/d/1A4Sh6l3cqn0k5ho1vnFOnzU0Fz7dQOK7/view)
- LLM ops å¤§æ¨¡å‹éƒ¨ç½² [ppt](https://drive.google.com/file/d/1LZXTrRdrloIqAJT6xaNTl4WQd6y95o7K/view)
  - LLMOps: Deployment and Learning in Production

å¾ˆéš¾ç”¨ä¼ ç»ŸMLæ–¹æ³•è¯„ä¼°ï¼ŒLLMè¾“å‡ºç‰¹ç‚¹ï¼šå¤šæ ·æ€§

å¦‚ä½•è¯„ä¼°LLMsæ•ˆæœ Evaluation metrics for LLMs
- å¸¸è§„è¯„ä¼°æ ‡å‡†ï¼š å¦‚ æ­£ç¡®ç‡ä¹‹ç±»
- å€Ÿé‰´åŒ¹é…æ ‡å‡†ï¼š
  - è¯­ä¹‰ç›¸ä¼¼åº¦
  - ç”¨å¦ä¸€ä¸ªLLMè¯„åˆ¤ä¸¤ä¸ªå¤§éš¾äº‹å®æ˜¯å¦ä¸€è‡´
- å“ªä¸ªæ›´å¥½ which is better
  - è®©LLMæ ¹æ®æä¾›çš„è¦ç‚¹åˆ¤æ–­ä¸¤ä¸ªç­”æ¡ˆå“ªä¸ªæ›´å¥½
- åé¦ˆæ˜¯å¦åŒ…å« is the feedback incorporated
  - è®©LLMåˆ¤æ–­æ–°ç­”æ¡ˆæ˜¯å¦åŒ…å«æ—§ç­”æ¡ˆä¸Šçš„åé¦ˆ
- ç»Ÿè®¡æŒ‡æ ‡
  - éªŒè¯è¾“å…¥ç»“æ„ï¼Œå¦‚ æ˜¯å¦ jsonæ ¼å¼
  - è®©LLMç»™ç­”æ¡ˆæ‰“åˆ†ï¼Œå¦‚ 1-5åˆ†

æ€»ç»“ï¼Œè¯„ä¼°é¡ºåº
1. æœ‰æ­£ç¡®ç­”æ¡ˆå—ï¼Ÿæ˜¯â†’ç”¨ä¼ ç»ŸMLçš„æŒ‡æ ‡ï¼Œå¦åˆ™
1. æœ‰å‚è€ƒç­”æ¡ˆå—ï¼Ÿæ˜¯â†’ç”¨åŒ¹é…æŒ‡æ ‡ï¼Œæ‹¿å‚è€ƒç­”æ¡ˆè®¡ç®—åŒ¹é…åº¦ï¼Œå¦åˆ™
1. æœ‰å…¶ä»–ç­”æ¡ˆå—ï¼Ÿæ˜¯â†’LLMåˆ¤æ–­å“ªä¸ªæ›´å¥½ï¼ˆwhich is betterï¼‰ï¼Œå¦åˆ™
1. æœ‰äººå·¥åé¦ˆå—ï¼Ÿæ˜¯â†’LLMåˆ¤æ–­åé¦ˆæ˜¯å¦é‡‡çº³ï¼ˆis the feedback incorporatedï¼‰ï¼Œå¦åˆ™
1. ç»Ÿè®¡æŒ‡æ ‡

å¦‚ä½•æå‡ç”Ÿäº§ç¯å¢ƒä¸­LLMsè¾“å‡ºæ•ˆæœ
- åé—®æ¨¡å‹æ˜¯å¦æ­£ç¡® Self-critique è‡ªæˆ‘æ€€ç–‘
  - Ask an LLM â€œis this the right answerâ€
- å¤šæ¬¡è¯·æ±‚é€‰æœ€ä½³ Sample many times, choose the best option
- å¤šæ¬¡è¯·æ±‚é›†æˆ Sample many times, ensemble

å¦‚ä½•æ”¹è¿›æŒç»­promptæ•ˆæœï¼Ÿ
- æ ¹æ®ç”¨æˆ·åé¦ˆäººå·¥ç­›é€‰æœªè§£å†³çš„æ¡ˆä¾‹
- è°ƒæ•´promptï¼Œæ–¹æ³•ï¼šâ‘  æç¤ºå·¥ç¨‹ â‘¡ æ”¹å˜context

é‚£ä¹ˆï¼Œè¿™ä¸ªæµç¨‹å¦‚ä½•è‡ªåŠ¨åŒ–ï¼Ÿ Fine-tuning LLMs å¾®è°ƒå¤§æ¨¡å‹
- SFT
  - æƒ³å°†å¤§æ¨¡å‹é€‚é…åˆ°å…·ä½“ä»»åŠ¡ï¼Œæˆ– ICLæ•ˆæœä¸å¥½
  - æœ‰å¤§é‡é¢†åŸŸæ•°æ®
  - æ„å»ºå°/ä¾¿å®œæ¨¡å‹ï¼Œé™ä½æ€»æˆæœ¬
- åŸºäºäººå·¥åé¦ˆå¾®è°ƒ
  - ç”±äºæŠ€æœ¯å¤æ‚ã€æ˜‚è´µï¼Œæ²¡å¤šå°‘å…¬å¸è‡ªå·±åš
  - æ–¹æ³•ï¼šRLHFã€RLAIF

LLMsçš„SFTç±»å‹ï¼šæ•ˆæœä¸Šé€çº§æå‡ï¼Œä½†è®­ç»ƒæ•ˆç‡ä¸Šä¸æ–­é™ä½
- ï¼ˆ1ï¼‰åŸºäº**ç‰¹å¾**ï¼šå†»ç»“LLMsï¼ˆå¦‚é¢„è®­ç»ƒtransformer)ï¼Œè¾“å‡ºembeddingä¿¡æ¯åï¼Œå•ç‹¬æ›´æ–°é™„åŠ æ¨¡å‹ï¼ˆå¦‚åˆ†ç±»ï¼‰
- ï¼ˆ2ï¼‰**éƒ¨åˆ†å‚æ•°**å¾®è°ƒï¼šå†»ç»“LLMsï¼Œåªæ›´æ–°æ–°å¢çš„å…¨è¿æ¥å±‚å‚æ•°ï¼ˆä¸å†å•ç‹¬åŠ æ¨¡å‹ï¼‰
- ï¼ˆ3ï¼‰**å…¨å‚æ•°**å¾®è°ƒï¼šå…¨éƒ¨å‚æ•°ä¸€èµ·å¾®è°ƒ

PEFTæŠ€æœ¯ï¼šParameter-efficient fine tuning
- Prompt modificationï¼š
  - Hard prompt tuning
  - Soft prompt tuning
  - Prefix tuning
- Adapter methods
  - Adapters: å¦‚ LLaMA-Adapterï¼ˆåŸºäºprefix tuningï¼‰
- Reparameterization
  - LoRAï¼ˆLow rank adaptationï¼‰

LLMé—®é¢˜
- Most common: often UI stuff
  - å“åº”æ—¶é—´é•¿ Latency especially 
- å›ç­”é”™è¯¯/å¹»è§‰ Incorrect answers / â€œhallucinationsâ€ 
- è¿‡äºå•°å—¦ Long-winded answers 
- å›é¿é—®é¢˜ Too many â€œdodgedâ€ questions 
- æç¤ºæ”»å‡» Prompt injection attacks 
- é“å¾·å®‰å…¨ Toxicity, profanity 

LLM Bootcamp 2023 Augmented language models

LLMæ“…é•¿ä»€ä¹ˆï¼ŸWhat (base) LLMs are good at ?
- â€¢ è¯­è¨€ç†è§£ language understanding
- â€¢ éµå¾ªæŒ‡ä»¤ instruction following
- â€¢ åŸºç¡€æ¨ç† basic reasoning
- â€¢ ä»£ç ç†è§£ code understanding

LLMåœ¨å“ªäº›æ–¹é¢éœ€è¦å¸®åŠ©ï¼Ÿ What they need help with ?
- â€¢ è·å–æœ€æ–°çŸ¥è¯† up-to-date knowledge
- â€¢ ç”¨æˆ·æ•°æ®åŒ…å«çš„çŸ¥è¯† knowledge of your data
- â€¢ æ›´æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç† more challenging reasoning
- â€¢ ä¸å¤–ç•Œäº¤äº’ interacting with the world



#### å¦‚ä½•å¢å¼ºLLMèƒ½åŠ›

å¦‚ä½•å¢å¼ºLLMçš„èƒ½åŠ›ï¼Ÿ
- LLMæ›´åŠ æ“…é•¿**é€šç”¨æ¨ç†**ï¼Œè€Œä¸æ˜¯**ç‰¹å®šçŸ¥è¯†**ã€‚
- LLMs are for general reasoning, not specific knowledge

ä¸ºäº†è®©LLMèƒ½å¤Ÿå–å¾—æ›´å¥½çš„è¡¨ç°ï¼Œæœ€å¸¸è§æ–¹æ³•å°±æ˜¯ç»™LLMæä¾›åˆé€‚çš„**ä¸Šä¸‹æ–‡ä¿¡æ¯**å¸®åŠ©LLMè¿›è¡Œæ¨ç†ã€‚
- A baseline: using the context window
- Context is the way to give LLM unique, up-to-date information ... But it only fits a limited amount of information
- ä¸Šä¸‹æ–‡ä¿¡æ¯é€‚åˆæä¾›ç‹¬ç‰¹ã€å®æ—¶ä¿¡æ¯ï¼Œä½†è¿›é€‚ç”¨äºæœ‰é™çš„ä¿¡æ¯é‡


éšç€æœ€è¿‘LLMçš„ä¸æ–­å‘å±•ï¼Œå„ç±»å¤§æ¨¡å‹æ‰€èƒ½æ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡**é•¿åº¦**ä¹Ÿè¶Šæ¥è¶Šå¤§ï¼Œä½†æ˜¯åœ¨å¯é¢„è§çš„ä¸€æ®µæ—¶é—´å†…ä»ä¸å¯èƒ½åŒ…å«æ‰€æœ‰å†…å®¹ï¼Œå¹¶ä¸”è¶Šå¤šçš„ä¸Šä¸‹æ–‡æ„å‘³ç€æ›´å¤šçš„è®¡ç®—æˆæœ¬ã€‚
- Context windows are growing fast, but wonâ€™t fit everything for a while (Plus, more context = more $$$)
- ![](https://pic3.zhimg.com/80/v2-01d520894c2ada7c23aa4f450aae71ca_1440w.webp)

how to make the most of a limited context by augmenting the language model ï¼Ÿ

å¦‚ä½•å……åˆ†åˆ©ç”¨å½“å‰æ‰€èƒ½æ”¯æŒçš„æœ‰é™çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè®©LLMè¡¨ç°æ›´å¥½ï¼Œå€¼å¾—ç ”ç©¶ã€‚

æœ‰é™ä¸‹æ–‡æƒ…å†µä¸‹å……åˆ†æ¿€å‘LLM èƒ½åŠ›çš„æ–¹æ³•æœ‰ä¸‰ç§ï¼š
- æ£€ç´¢ `Retrieval`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å†…ï¼Œå¹¶è¡Œæ‰¾ç›¸å…³å†…å®¹ä½œä¸ºpromptï¼›Augment with a bigger corpus
- é“¾å¼ `Chain`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å¤–ï¼Œä¸²è¡Œè¯·æ±‚ï¼›Augment with more LLM calls
- å·¥å…· `Tools`ï¼šè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼›Augment with outside sources

ï¼ˆ1ï¼‰é€šè¿‡**Retrievalå¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å†…</span>
 
outline
- A. Why retrieval augmentation? 
  - Q: We want our model to have access to data from thousands of uses in the context
  - æµ·é‡ç”¨æˆ·æ•°æ®å¡åˆ°contextä¸­
- B. ä¼ ç»Ÿä¿¡æ¯æ£€ç´¢ Traditional information retrievalï¼Œè¦ç´ ï¼š
  - **Query**. Formal statement of your information need. E.g., a search string.
  - **Object**. Entity inside your content collection. E.g., a document. 
  - **Relevance**. Measure of how well an object satisfies the information need
    - é€šè¿‡å¸ƒå°”æœç´¢(boolean search) 
    - E.g., only return the docs that contain: simple AND rest AND apis AND distributed
AND nature
  - **Ranking**. Ordering of relevant results based on desirability
    - é€šè¿‡ BM25, å—3ä¸ªå› ç´ å½±å“ Ranking via BM25. Affected by 3 factors
    - â‘  è¯é¢‘ Term frequency (`TF`) â€” More appearances of search term = more relevant object
    - â‘¡ é€†æ–‡æ¡£æ¦‚ç‡ Inverse document frequency (`IDF`) â€” More objects containing search term = less important search term
    - â‘¢ å­—æ®µé•¿åº¦ Field length â€” If a document contains a search term in a field that is very short (i.e. has few words), it is more likely relevant than a document that contains a search term in a field that is very long (i.e. has many words).
  - æ–¹æ³•ï¼šé€šè¿‡**å€’æ’ç´¢å¼•**æœç´¢ search via inverted indexesï¼Œå¦å¤–è¿˜æœ‰å¾ˆå¤šï¼š
    - æ–‡æ¡£æ³¨å…¥ Document ingestion
    - æ–‡æ¡£å¤„ç† Document processing (e.g., remove stop words, lower case, etc)
    - è½¬æ¢å¤„ç† Transaction handling (adding / deleting documents, merging index files)
    - ç¼©æ”¾ Scaling via shards Ranking & relevance
  - å±€é™æ€§ï¼šLimitations of â€œsparseâ€ traditional search
    - åªå»ºæ¨¡ç®€å•è¯é¢‘ä¿¡æ¯ Only models simple word frequencies
    - æ— æ³•æ•æ‰è¯­ä¹‰ä¿¡æ¯ã€ç›¸å…³ä¿¡æ¯ç­‰ Doesnâ€™t capture semantic information, correlation information, etc
    - E.g., searching for â€œwhat is the top hand in bridgeâ€ might return documents about ğŸŒ‰, â™ , ğŸ’¸
- C. åŸºäºembeddingçš„ä¿¡æ¯æ£€ç´¢ AI-powered Information retrieval via embeddings 
  - Search and AI make each other better
    - `AI`ï¼šBetter representations of data (embeddings)
    - `Search`ï¼š Better information in the context
  - ä»€ä¹ˆæ˜¯embeddingï¼Ÿå­¦ä¹ åˆ°çš„æŠ½è±¡ã€ç¨ å¯†ã€å‹ç¼©ã€å®šé•¿çš„æ•°æ®è¡¨ç¤º
    - Embeddings are an abstract, dense, compact, fixed-size, (usually) learned representation of data
- D. Patterns and case studies

ä¸€ä¸ªå…¸å‹çš„åœ¨æ–‡æ¡£QAåœºæ™¯ä½¿ç”¨æ£€ç´¢æ–¹å¼æ¥å¢å¼ºLLMèƒ½åŠ›çš„æ–¹å¼ï¼Œåˆ†ä¸ºå‡ ä¸ªæµç¨‹ï¼š
*   ç”¨æˆ·é—®é¢˜embedding
*   ä»æµ·é‡æ–‡æ¡£ä¸­æ£€ç´¢å‡ºTop Nä¸é—®é¢˜embeddingç›¸ä¼¼çš„å€™é€‰æ–‡æ¡£
*   åŸºäºTopNæ–‡æ¡£å†…å®¹æ„é€ Prompt
*   è°ƒç”¨LLMè·å–æœ€ç»ˆç­”æ¡ˆ
 
![](https://pic1.zhimg.com/80/v2-72a51d5f2be59ac526ea858e8fe15678_1440w.webp)
 
å¸¸ç”¨çš„RetrievalæŠ€æœ¯
 
å¯¹Retrievalçš„æŠ€æœ¯ç»†èŠ‚ä»¥åŠä¸€äº›å¸¸ç”¨çš„å·¥å…·è¿›è¡Œäº†è¯¦ç»†çš„ä»‹ç»ï¼ŒåŒ…æ‹¬**ä¼ ç»ŸRetrieval**ä»¥åŠ**åŸºäºEmbeddingçš„Retrieval**è¿™ä¸¤ç§æŠ€æœ¯è·¯çº¿ï¼Œ[åŸæ•™ç¨‹](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)å­¦ä¹ æˆ–è€…å‚è€ƒä¸€äº›å…¶ä»–çš„[ä¿¡æ¯æ£€ç´¢èµ„æ–™](https://github.com/%2520%2520sebastian-hofstaetter/teaching)ã€‚
 
ï¼ˆ2ï¼‰é€šè¿‡**Chain**å¢å¼ºLLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å¤–</span>
 
æŸäº›æƒ…å†µä¸‹ï¼Œæœ€ä½³çš„contextå¯èƒ½å¹¶**ä¸å­˜åœ¨äºç”¨æˆ·è¯­æ–™åº“**ä¸­ã€‚ä¸Šä¸€ä¸ªLLMçš„è¾“å‡ºç»“æœå¯èƒ½æ­£å¥½æ˜¯å½“å‰LLMçš„æœ€å¥½çš„è¾“å…¥contextã€‚
 
æ­¤æ—¶ï¼Œå¯ä»¥ç”¨Chainå½¢å¼å°†ä¸åŒçš„LLMè¿æ¥èµ·æ¥ï¼Œå»å¢å¼ºæœ€ç»ˆä»»åŠ¡çš„æ•ˆæœã€‚ä¾‹å¦‚ä¸‹å›¾çš„æ‘˜è¦ä»»åŠ¡ï¼š
- é¦–å…ˆå°†æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œå¯¹äºæ¯ä¸ªéƒ¨åˆ†ä½¿ç”¨LLMåšä¸€ä¸ªå±€éƒ¨æ‘˜è¦ï¼Œç„¶åå†ç”¨LLMå¯¹å„ä¸ªæ‘˜è¦è¿›è¡Œåˆå¹¶è¾“å‡ºå…¨å±€çš„æ‘˜è¦ã€‚
- ![](https://pic3.zhimg.com/80/v2-65144390d9958a95f33a316618a32092_1440w.webp)

å…¸å‹è¿›è¡Œè¿™æ ·ä»»åŠ¡ç¼–æ’çš„å·¥å…·æ˜¯[LangChain](https://github.com/hwchase17/langchain)ï¼Œå¯ä»¥åˆ©ç”¨å®ƒæ¥å¼€å‘å¾ˆå¤šæœ‰æ„æ€çš„åº”ç”¨ã€‚
 
ï¼ˆ3ï¼‰é€šè¿‡**Toolså¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>å€ŸåŠ©å¤–ç•Œå·¥å…·</span>
 
é€šè¿‡å„ç§å„æ ·çš„å·¥å…·è®©LLMä¸å¤–ç•Œè¿›è¡Œäº¤äº’ï¼Œæ¯”å¦‚ä½¿ç”¨æœç´¢å¼•æ“ã€æ‰§è¡ŒSQLè¯­å¥ç­‰ï¼Œä»è€Œå»ä¸°å¯ŒLLMçš„åŠŸèƒ½ã€‚
- æœ‰æ—¶æœ€å¥½çš„contextå¹¶ä¸ç›´æ¥å­˜åœ¨äºè¯­æ–™ï¼Œè€Œæ˜¯æºè‡ªå¦ä¸€ä¸ªLLMçš„è¾“å‡ºã€‚

æ„å»ºå·¥å…·é“¾çš„å‡ ä¸ªæ¡ˆä¾‹ Example patterns for building chains
- é—®ç­”æ¨¡å¼ The QA pattern
  - Question â¡ embedding â¡ similar docs â¡ QA prompt
- å‡æƒ³æ–‡æ¡£æ˜ å°„ Hypothetical document embeddings (HyDE)
  - Question â¡ document generating prompt â¡ rest of QA chain
- æ‘˜è¦ Summarization
  - Document corpus â¡ apply a summarization prompt to each â¡ pass all document summaries to another prompt â¡ get global summary back

Toolsæ–¹å¼å¤§è‡´æœ‰ä¸¤ç§
- ä¸€ç§æ˜¯åŸºäº**Chain**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¿…é€‰é¡¹**ï¼Œå‰é¢æœ‰ä¸€ä¸ªLLMæ¥æ„é€ Toolçš„è¾“å…¥ï¼Œåé¢ä¼šæœ‰å¦ä¸€ä¸ªLLMæ¥æ€»ç»“Toolçš„è¾“å‡ºå¹¶å¾—åˆ°æœ€ç»ˆçš„ç»“æœï¼›
- ä¸€ç§æ˜¯åŸºäº**Plugin**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¯é€‰é¡¹**ï¼Œè®©LLMæ¥å†³å®šç”¨ä¸ç”¨ä»¥åŠæ€ä¹ˆç”¨Toolã€‚

![](https://pic2.zhimg.com/80/v2-2038fc84985ec24ed8831bf66f16a4b1_1440w.webp)

æ€»ç»“
- â€¢ é€šè¿‡ä¸å¤–ç•Œæ•°æ®çš„äº¤äº’ï¼ŒLLMçš„èƒ½åŠ›èƒ½å¤Ÿæ›´åŠ å¼ºå¤§ã€‚
- â€¢ é€šè¿‡ä½¿ç”¨è§„åˆ™å’Œå¯å‘å¼æ–¹æ³•ï¼Œå¯ä»¥å®ç°å„ç§å„æ ·çš„åŠŸèƒ½ã€‚

éšç€çŸ¥è¯†åº“çš„æ‰©å¤§ï¼Œåº”è¯¥å°†å…¶è§†ä¸ºä¸€ä¸ª**ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿ**ã€‚ä½¿ç”¨Chainçš„æ–¹å¼å¯ä»¥å¸®åŠ©ç¼–ç æ›´å¤æ‚çš„æ¨ç†ï¼Œå¹¶ä¸”ç»•è¿‡tokené•¿åº¦çš„é™åˆ¶ã€‚å„ç§å„æ ·çš„å¤–éƒ¨å·¥å…·å¯ä»¥è®©æ¨¡å‹è®¿é—®æ›´å¤šçš„èµ„æºã€‚


## æ–¹æ³•æ€»ç»“

[ä½œè€…](https://www.zhihu.com/question/591935281/answer/2961925796)

å¸¸è§çš„æ–¹æ³•ï¼š
- `retrieve-then-generate`ï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
  - æ ¹æ®è¾“å…¥queryæ¥æŠ½å–ç›¸å…³å¤–éƒ¨æ–‡æœ¬ï¼ŒæŠŠæŠ½å–åˆ°çš„æ–‡æœ¬å’Œqueryä¸€èµ·ä½œä¸ºpromptå†æ¥åšåç»­å­—ç¬¦çš„æ¨ç†ã€‚
  - chatpdfè¿™ç§äº§å“çš„æ–¹æ³•ä¹Ÿç±»ä¼¼ï¼Œå…ˆæŠŠä½ è¾“å…¥çš„æ–‡æ¡£åˆ†æˆå¤šä¸ªchunkåˆ†åˆ«åšembeddingæ”¾åˆ°å‘é‡æ•°æ®åº“é‡Œï¼Œç„¶åæ ¹æ®è¾“å…¥embeddingçš„å‘é‡åšåŒ¹é…ï¼Œå†æŠŠåŒ¹é…åˆ°çš„å‘é‡å¯¹åº”çš„chunkå’Œè¾“å…¥ä¸€èµ·ä½œä¸ºpromptç»™LLMã€‚
  - è®ºæ–‡ï¼šã€2020-2-10ã€‘[REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)
- `Fine-tuning`ï¼šFine-tuningæ˜¯æŒ‡åœ¨å·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨**æ–°æ•°æ®é›†**å†æ¬¡è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿æ¨¡å‹é’ˆå¯¹ç‰¹å®šä»»åŠ¡æˆ–ç‰¹å®šé¢†åŸŸçš„è¯­è¨€ä½¿ç”¨æƒ…å†µè¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨Fine-tuningè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†**é¢å¤–çŸ¥è¯†**ä½œä¸ºæ–°çš„æ•°æ®é›†åŠ å…¥åˆ°è®­ç»ƒä¸­ã€‚
- `Knowledge Distillation`ï¼šKnowledge Distillationæ˜¯æŒ‡å°†ä¸€ä¸ªâ€œå¤§æ¨¡å‹â€çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªâ€œå°æ¨¡å‹â€ä¸­ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªå°å‹çš„æ¨¡å‹ä¸­ï¼Œä½¿å¾—å°å‹æ¨¡å‹èƒ½å¤Ÿä½¿ç”¨å¤§å‹æ¨¡å‹ä¸­çš„çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é€šè¿‡å°†é¢å¤–çš„çŸ¥è¯†åŠ å…¥åˆ°â€œå¤§æ¨¡å‹â€ä¸­ï¼Œä»è€Œä½¿å¾—â€œå°æ¨¡å‹â€å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†ã€‚
- `æ•°æ®å¢å¼º`ï¼šæ•°æ®å¢å¼ºæ˜¯æŒ‡åœ¨å·²æœ‰çš„æ•°æ®é›†ä¸­ï¼Œæ·»åŠ ä¸€äº›ç±»ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒçš„æ•°æ®æ¥å¢åŠ æ•°æ®çš„æ•°é‡å’Œå¤šæ ·æ€§ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿å¾—æ¨¡å‹æ›´åŠ å…¨é¢åœ°å­¦ä¹ åˆ°ä¸åŒçš„è¯­è¨€ä½¿ç”¨æƒ…å†µï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨æ•°æ®å¢å¼ºçš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥æ·»åŠ é¢å¤–çš„çŸ¥è¯†ï¼Œä¾‹å¦‚åŒä¹‰è¯ã€åä¹‰è¯ã€ä¸“ä¸šæœ¯è¯­ç­‰ã€‚
  - è¯å‘é‡ï¼šå°†é¢†åŸŸç‰¹å®šçš„è¯æ±‡å’Œè¯å‘é‡æ·»åŠ åˆ°æ¨¡å‹çš„è¯æ±‡è¡¨ä¸­ã€‚è¿™äº›è¯æ±‡å¯ä»¥æ˜¯åœ¨ç›®æ ‡é¢†åŸŸä¸­ç‹¬æœ‰çš„è¯æ±‡æˆ–è€…åœ¨å¸¸è§„æ•°æ®é›†ä¸­ç¼ºå¤±çš„è¯æ±‡ã€‚
  - å¤–éƒ¨æ•°æ®é›†ï¼šä»å¤–éƒ¨æ•°æ®é›†ä¸­æ”¶é›†ä¸ç›®æ ‡é¢†åŸŸç›¸å…³çš„æ•°æ®ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦æ‰¾åˆ°ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨é€‚å½“çš„æ–¹æ³•å°†å…¶åˆå¹¶åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚
  - å¤–éƒ¨çŸ¥è¯†åº“ï¼šå°†å¤–éƒ¨çš„çŸ¥è¯†åº“ï¼Œå¦‚ç™¾ç§‘å…¨ä¹¦ã€çŸ¥è¯†å›¾è°±ç­‰ï¼Œä¸æ¨¡å‹é›†æˆï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†æ¥è¾…åŠ©å…¶ç”Ÿæˆæ–‡æœ¬ã€‚
  - äººå·¥æ ‡æ³¨ï¼šé€šè¿‡äººå·¥æ ‡æ³¨çš„æ–¹å¼ï¼Œå°†é¢†åŸŸç‰¹å®šçš„ä¿¡æ¯æ·»åŠ åˆ°è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦å¤§é‡çš„äººåŠ›å’Œæ—¶é—´ï¼Œå¹¶ä¸”å¯¹äºå¤§å‹æ•°æ®é›†æ¥è¯´å¯èƒ½ä¸åˆ‡å®é™…ã€‚
- `å¤šä»»åŠ¡å­¦ä¹ `ï¼šå¤šä»»åŠ¡å­¦ä¹ æ˜¯æŒ‡åŒæ—¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹å®Œæˆå¤šä¸ªä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨è®­ç»ƒGPT/LLMæ¨¡å‹æ—¶ï¼Œå¯ä»¥è®©æ¨¡å‹åŒæ—¶å®Œæˆæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ï¼Œä»è€Œä½¿å¾—æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ›´åŠ å¤šæ ·åŒ–çš„çŸ¥è¯†ã€‚åœ¨å¤šä»»åŠ¡å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†é¢å¤–çš„çŸ¥è¯†æ·»åŠ åˆ°å…¶ä»–ä»»åŠ¡ä¸­ï¼Œä»è€Œé—´æ¥åœ°å½±å“åˆ°æ¨¡å‹åœ¨ä¸»è¦ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

ã€2023-4-22ã€‘åŸºäºllama-indexå’ŒChatGPT APIå®šåˆ¶ç§æœ‰å¯¹è¯æœºå™¨äººçš„æ–¹å¼ã€‚

æ–¹æ¡ˆ
- 1ã€fine-tuneså¾®è°ƒã€‚ç”¨å¤§é‡æ•°æ®å¯¹GPTæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°ä¸€ä¸ªç†è§£æ–‡æ¡£çš„æ¨¡å‹ã€‚
  - ä½†å¾®è°ƒéœ€è¦èŠ±è´¹å¾ˆå¤šmoneyï¼Œè€Œä¸”éœ€è¦ä¸€ä¸ªæœ‰å®ä¾‹çš„å¤§æ•°æ®é›†ã€‚ä¹Ÿä¸å¯èƒ½åœ¨æ–‡ä»¶æœ‰å˜åŒ–æ—¶æ¯æ¬¡éƒ½è¿›è¡Œå¾®è°ƒã€‚
  - å¾®è°ƒä¸å¯èƒ½è®©æ¨¡å‹ â€œçŸ¥é“â€œ æ–‡æ¡£ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œæ˜¯è¦æ•™ç»™æ¨¡å‹ä¸€ç§æ–°çš„æŠ€èƒ½ã€‚
  - å› æ­¤ï¼Œå¾®è°ƒä¸æ˜¯ä¸€ä¸ªå¥½åŠæ³•ã€‚
- 2ã€å°†ç§æœ‰æ–‡æœ¬å†…å®¹ä½œä¸ºpromptçš„ä¸Šä¸‹æ–‡ï¼Œè®¿é—®ChatGPTã€‚
  - openai apiå­˜åœ¨æœ€å¤§é•¿åº¦çš„é™åˆ¶ï¼ŒChatGPT 3.5çš„æœ€å¤§tokenæ•°ä¸º4096ï¼Œå¦‚æœè¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œä¼šç›´æ¥å¯¹æ–‡æ¡£æˆªæ–­ï¼Œå­˜åœ¨ä¸Šä¸‹æ–‡ä¸¢å¤±çš„é—®é¢˜ã€‚
  - å¹¶ä¸”apiçš„è°ƒç”¨è´¹ç”¨å’Œtokené•¿åº¦æˆæ­£æ¯”ï¼Œtokensæ•°å¤ªå¤§ï¼Œåˆ™æ¯æ¬¡è°ƒç”¨çš„æˆæœ¬ä¹Ÿä¼šå¾ˆé«˜ã€‚

### è¾“å…¥é•¿åº¦é™åˆ¶

ã€2023-7-26ã€‘[æµ…è°ˆLLMçš„é•¿åº¦å¤–æ¨](https://mp.weixin.qq.com/s/5_mBahrpeA2cHlTXylgF9w)

éšç€å¤§æ¨¡å‹åº”ç”¨çš„ä¸æ–­å‘å±•ï¼ŒçŸ¥è¯†å¤–æŒ‚å·²ç»æˆä¸ºäº†é‡è¦æ‰‹æ®µã€‚ä½†åªæ˜¯å¤–æŒ‚æ‰‹æ®µå¾€å¾€å—é™äºæ¨¡å‹æœ¬èº«**å¯æ¥å—é•¿åº¦**ï¼Œä»¥åŠæ¨¡å‹å¤–æ¨èƒ½åŠ›ã€‚

æˆªæ­¢20230724ï¼Œå¤–æ¨ç­–ç•¥ï¼šNBCEï¼Œçº¿æ€§å†…æ’ï¼ŒNTK-Aware Scaled RoPEï¼ŒDynamically Scaled RoPEï¼Œconsistent of Dynamically Scaled RoPEã€‚

#### NBCE

NBCEï¼šä½¿ç”¨æœ´ç´ è´å¶æ–¯æ‰©å±•LLMçš„Contextå¤„ç†é•¿åº¦ï¼Œ[ä»‹ç»](https://kexue.fm/archives/9617)
- è‹ç¥æœ€æ—©æå‡ºçš„æ‰©å±•LLMçš„contextæ–¹æ³•ï¼ŒåŸºäºbayeså¯å‘å¾—åˆ°çš„å…¬å¼
- åœ¨é—®ç­”ä¸‹å®æµ‹ç¡®å®ä¸é”™ï¼Œåœ¨è¾ƒé•¿contextä¸‹çš„é˜…è¯»ç†è§£è¿˜ç®—å¥½ç”¨ã€‚

å±€é™
- æ— åºæ€§ï¼Œå³æ— æ³•è¯†åˆ«Contextçš„è¾“å…¥é¡ºåºï¼Œè¿™åœ¨ç»­å†™æ•…äº‹ç­‰åœºæ™¯å¯èƒ½è¡¨ç°æ¬ ä½³ï¼Œåšä¸€äº›ä¾èµ–æ¯ä¸ªcontextç”Ÿæˆç­”æ¡ˆï¼Œæ¯”å¦‚æå–æ–‡æ¡£æ‘˜è¦ï¼Œæ•ˆæœè¾ƒå·®

```py
outputs = model(input_ids=input_ids,
                        attention_mask=attention_mask,
                        return_dict=True,
                        use_cache=True,
                        past_key_values=past_key_values
                       )
past_key_values = outputs.past_key_values
        
# ===== æ ¸å¿ƒä»£ç å¼€å§‹ =====
beta = 0.25
probas = torch.nn.functional.softmax(outputs.logits[:, -1], dim=-1)
logits = probas.log()
k = (probas * logits).sum(dim=-1)[1:].argmax() + 1
logits_max = logits[k]
logits_uncond = logits[0]
logits = (1 + beta) * logits_max - beta * logits_uncond
# ===== æ ¸å¿ƒä»£ç ç»“æŸ =====
        
# æ„å»ºåˆ†å¸ƒï¼Œé‡‡æ ·
tau = 0.01  # tau = 1æ˜¯æ ‡å‡†çš„éšæœºé‡‡æ ·ï¼Œtau->0åˆ™æ˜¯è´ªå¿ƒæœç´¢
probas = torch.nn.functional.softmax(logits[None] / tau , dim=-1)
next_tokens = torch.multinomial(probas, num_samples=1).squeeze(1)  
```

#### çº¿æ€§å†…æ’

llama åŸºäº rotary embeddingåœ¨2048é•¿åº¦ä¸Šé¢„è®­ç»ƒï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†positionå‹ç¼©åˆ°0~2048ä¹‹é—´ï¼Œä»è€Œè¾¾åˆ°é•¿åº¦å¤–æ¨çš„ç›®çš„ã€‚

longchatå°†æ¨¡å‹å¾®è°ƒä¸ºä¸Šä¸‹æ–‡é•¿åº¦å¤–æ‰©ä¸º16384ï¼Œå‹ç¼©æ¯”ä¸º 8ã€‚ä¾‹å¦‚ï¼Œposition_ids = 10000 çš„ token å˜ä¸ºposition_ids = 10000 / 8 = 1250ï¼Œç›¸é‚» token 10001 å˜ä¸º 10001 / 8 = 1250.125

è¯¥æ–¹æ³•çš„ç¼ºé™·æ˜¯éœ€è¦è¿›è¡Œä¸€å®šé‡çš„å¾®è°ƒï¼Œè®©æ¨¡å‹æ¥é€‚åº”è¿™ç§æ”¹å˜ã€‚

èµ„æ–™
- [context](https://kaiokendev.github.io/context)
- lmsys [longchat](https://lmsys.org/blog/2023-06-29-longchat/)

#### NTK-Aware Scaled RoPE

NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.
- [refer](https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/)

RoPEæ˜¯ä¸€ç§Î²è¿›åˆ¶ç¼–ç : [re](https://spaces.ac.cn/archives/9675)

RoPE çš„è¡Œä¸ºå°±åƒä¸€ä¸ªæ—¶é’Ÿã€‚12å°æ—¶æ—¶é’ŸåŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªç»´åº¦ä¸º 3ã€åº•æ•°ä¸º 60 çš„ RoPEã€‚å› æ­¤ï¼Œæ¯ç§’é’Ÿï¼Œåˆ†é’ˆè½¬åŠ¨ 1/60 åˆ†é’Ÿï¼Œæ¯åˆ†é’Ÿï¼Œæ—¶é’ˆè½¬åŠ¨ 1/60ã€‚ç°åœ¨ï¼Œå¦‚æœå°†æ—¶é—´å‡æ…¢ 4 å€ï¼Œé‚£å°±æ˜¯äºŒä½¿ç”¨çš„çº¿æ€§RoPE ç¼©æ”¾ã€‚ä¸å¹¸çš„æ˜¯ï¼Œç°åœ¨åŒºåˆ†æ¯ä¸€ç§’ï¼Œå› ä¸ºç°åœ¨ç§’é’ˆå‡ ä¹æ¯ç§’éƒ½ä¸ä¼šç§»åŠ¨ã€‚å› æ­¤ï¼Œå¦‚æœæœ‰äººç»™ä½ ä¸¤ä¸ªä¸åŒçš„æ—¶é—´ï¼Œä»…ç›¸å·®ä¸€ç§’ï¼Œä½ å°†æ— æ³•ä»è¿œå¤„åŒºåˆ†å®ƒä»¬ã€‚NTK-Aware RoPE æ‰©å±•ä¸ä¼šå‡æ…¢æ—¶é—´ã€‚ä¸€ç§’ä»ç„¶æ˜¯ä¸€ç§’ï¼Œä½†å®ƒä¼šä½¿åˆ†é’Ÿå‡æ…¢ 1.5 å€ï¼Œå°†å°æ—¶å‡æ…¢ 2 å€ã€‚è¿™æ ·ï¼Œæ‚¨å¯ä»¥å°† 90 åˆ†é’Ÿå®¹çº³åœ¨ä¸€ä¸ªå°æ—¶ä¸­ï¼Œå°† 24 å°æ—¶å®¹çº³åœ¨åŠå¤©ä¸­ã€‚æ‰€ä»¥ç°åœ¨ä½ åŸºæœ¬ä¸Šæœ‰äº†ä¸€ä¸ªå¯ä»¥æµ‹é‡ 129.6k ç§’è€Œä¸æ˜¯ 43.2k ç§’çš„æ—¶é’Ÿã€‚ç”±äºåœ¨æŸ¥çœ‹æ—¶é—´æ—¶ä¸éœ€è¦ç²¾ç¡®æµ‹é‡æ—¶é’ˆï¼Œå› æ­¤ä¸ç§’ç›¸æ¯”ï¼Œæ›´å¤§ç¨‹åº¦åœ°ç¼©æ”¾å°æ—¶è‡³å…³é‡è¦ã€‚ä¸æƒ³å¤±å»ç§’é’ˆçš„ç²¾åº¦ï¼Œä½†å¯ä»¥æ‰¿å—åˆ†é’ˆç”šè‡³æ—¶é’ˆçš„ç²¾åº¦æŸå¤±ã€‚

#### Dynamically Scaled RoPE

[dynamically_scaled_rope_further_increases](https://www.reddit.com/r/LocalLLaMA/comments/14mrgpr/dynamically_scaled_rope_further_increases/)

æ–¹æ³•äºŒã€ä¸‰ï¼Œéƒ½æ¶‰åŠåˆ°ä¸€ä¸ªè¶…å‚æ•°Î±ï¼Œç”¨äºè°ƒèŠ‚ç¼©æ”¾æ¯”ä¾‹ï¼Œè¯¥æ–¹æ³•æ˜¯é€šè¿‡åºåˆ—é•¿åº¦åŠ¨æ€é€‰æ‹©æ­£ç¡®çš„æ¯”ä¾‹å‚æ•°ï¼Œæ•ˆæœå¯ä»¥çœ‹ä¸Šå›¾ã€‚

å¯¹äºçº¿æ€§æ’å€¼ï¼Œå‰ 2k ä¸Šä¸‹æ–‡çš„ç²¾ç¡®ä½ç½®å€¼ï¼Œç„¶ååœ¨æ¨¡å‹é€ä¸ªç”Ÿæˆæ ‡è®°æ—¶é‡æ–°è®¡ç®—æ¯ä¸ªæ–°åºåˆ—é•¿åº¦çš„ä½ç½®å‘é‡ã€‚æœ¬è´¨ä¸Šï¼Œå°†æ¯”ä¾‹è®¾ç½®ä¸ºåŸå§‹æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦/å½“å‰åºåˆ—é•¿åº¦ã€‚

å¯¹äºåŠ¨æ€ NTKï¼ŒÎ± çš„ç¼©æ”¾è®¾ç½®ä¸º (Î± * å½“å‰åºåˆ—é•¿åº¦ / åŸå§‹æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦) - (Î± - 1)ã€‚éšç€åºåˆ—é•¿åº¦çš„å¢åŠ åŠ¨æ€ç¼©æ”¾è¶…å‚æ•°ã€‚

#### consistent of Dynamically Scaled RoPE

[Consistent-DynamicNTKRoPE](https://github.com/NormXU/Consistent-DynamicNTKRoPE)


### è¾“å‡ºé•¿åº¦å—é™

#### RecurrentGPTï¼ˆè¾“å‡ºä¸å—é™ï¼‰

ã€2023-5-30ã€‘[ChatGPTèƒ½å†™é•¿ç¯‡å°è¯´äº†ï¼ŒETHæå‡ºRecurrentGPTå®ç°äº¤äº’å¼è¶…é•¿æ–‡æœ¬](https://www.toutiao.com/article/7238442944003310084)
- è‹é»ä¸–è”é‚¦ç†å·¥å’Œæ³¢å½¢æ™ºèƒ½çš„å›¢é˜Ÿå‘å¸ƒäº† RecurrentGPTï¼Œä¸€ç§è®©å¤§è¯­è¨€æ¨¡å‹ (å¦‚ ChatGPT ç­‰) èƒ½å¤Ÿæ¨¡æ‹Ÿ RNN/LSTMï¼Œé€šè¿‡ Recurrent Prompting æ¥å®ç°äº¤äº’å¼**è¶…é•¿**æ–‡æœ¬ç”Ÿæˆï¼Œè®©åˆ©ç”¨ ChatGPT è¿›è¡Œé•¿ç¯‡å°è¯´åˆ›ä½œæˆä¸ºäº†å¯èƒ½ã€‚
- [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2305.13304)
- [é¡¹ç›®åœ°å€](https://github.com/aiwaves-cn/RecurrentGPT)
- åœ¨çº¿ Demo: [é•¿ç¯‡å°è¯´å†™ä½œ](https://www.aiwaves.org/recurrentgpt), [äº¤äº’å¼å°è¯´](https://www.aiwaves.org/interactivefiction)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a679b4e41e0d483bae2b1ac35ae2da63~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034283&x-signature=1GLOG8XAvQwzzXbm0v1ip16bz5Q%3D)

Transformer å¤§è¯­è¨€æ¨¡å‹æœ€æ˜æ˜¾çš„é™åˆ¶ä¹‹ä¸€: è¾“å…¥å’Œè¾“å‡ºçš„**é•¿åº¦é™åˆ¶**ã€‚
- è™½ç„¶è¾“å…¥ç«¯çš„é•¿åº¦é™åˆ¶å¯ä»¥é€šè¿‡ **VectorDB** ç­‰æ–¹å¼ç¼“è§£
- è¾“å‡ºå†…å®¹çš„é•¿åº¦é™åˆ¶å§‹ç»ˆæ˜¯é•¿å†…å®¹ç”Ÿæˆçš„å…³é”®éšœç¢ã€‚

ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¿‡å»å¾ˆå¤šç ”ç©¶è¯•å›¾ä½¿ç”¨åŸºäºå‘é‡åŒ–çš„ State æˆ– Memory æ¥è®© Transformer å¯ä»¥è¿›è¡Œ**å¾ªç¯**è®¡ç®—ã€‚è¿™æ ·çš„æ–¹æ³•è™½ç„¶åœ¨é•¿æ–‡æœ¬å»ºæ¨¡ä¸Šå±•ç°äº†ä¸€å®šçš„ä¼˜åŠ¿ï¼Œä½†æ˜¯å´è¦æ±‚ä½¿ç”¨è€…æ‹¥æœ‰å¹¶å¯ä»¥**ä¿®æ”¹æ¨¡å‹çš„ç»“æ„å’Œå‚æ•°**ï¼Œè¿™åœ¨ç›®å‰é—­æºæ¨¡å‹é¥é¥é¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ä¸­æ˜¯ä¸ç¬¦åˆå®é™…çš„ã€‚

RecurrentGPT åˆ™å¦è¾Ÿè¹Šå¾„ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œ**äº¤äº’å¼**é•¿æ–‡æœ¬ç”Ÿæˆçš„é¦–ä¸ªæˆåŠŸå®è·µã€‚å®ƒåˆ©ç”¨ ChatGPT ç­‰å¤§è¯­è¨€æ¨¡å‹ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æ¨¡æ‹Ÿäº†å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNsï¼‰çš„å¾ªç¯è®¡ç®—æœºåˆ¶ã€‚
- æ¯ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ï¼ŒRecurrentGPT ä¼šæ¥æ”¶ä¸Šä¸€ä¸ªæ—¶é—´æ­¥ç”Ÿæˆçš„å†…å®¹ã€æœ€è¿‘ç”Ÿæˆå†…å®¹çš„æ‘˜è¦ï¼ˆçŸ­æœŸè®°å¿†ï¼‰ï¼Œå†å²ç”Ÿæˆå†…å®¹ä¸­å’Œå½“å‰æ—¶é—´æ­¥æœ€ç›¸å…³çš„å†…å®¹ (é•¿æœŸè®°å¿†)ï¼Œä»¥åŠä¸€ä¸ªå¯¹ä¸‹ä¸€æ­¥ç”Ÿæˆå†…å®¹çš„æ¢—æ¦‚ã€‚RecurrentGPT æ ¹æ®è¿™äº›å†…å®¹ç”Ÿæˆä¸€æ®µå†…å®¹ï¼Œæ›´æ–°å…¶é•¿çŸ­æ—¶è®°å¿†ï¼Œå¹¶æœ€åç”Ÿæˆå‡ ä¸ªå¯¹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ç”Ÿæˆå†…å®¹çš„è§„åˆ’ï¼Œå¹¶å°†å½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ã€‚è¿™æ ·çš„å¾ªç¯è®¡ç®—æœºåˆ¶æ‰“ç ´äº†å¸¸è§„Transformer æ¨¡å‹åœ¨ç”Ÿæˆé•¿ç¯‡æ–‡æœ¬æ–¹é¢çš„é™åˆ¶ï¼Œä»è€Œå®ç°ä»»æ„é•¿åº¦æ–‡æœ¬çš„ç”Ÿæˆï¼Œè€Œä¸é—å¿˜è¿‡å»çš„ä¿¡æ¯ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/f1bd9be64d144e18914652db4ce325c8~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034283&x-signature=4WMRfq0FjPeJxmK0ujy7roS3sbA%3D)


### llama-index

ã€2023-4-23ã€‘å‚è€ƒ
- [å®šåˆ¶è‡ªå·±çš„æ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/623523968)
- [LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

æ—¢ç„¶tokensæœ‰é™åˆ¶ï¼Œé‚£ä¹ˆæœ‰æ²¡æœ‰å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œ**é¢„å¤„ç†**çš„å·¥å…·ï¼Ÿä¸è¶…è¿‡tokenæ•°é™åˆ¶ã€‚
- å€ŸåŠ©llama-indexå¯ä»¥ä»æ–‡æœ¬ä¸­åªæå–å‡ºç›¸å…³éƒ¨åˆ†ï¼Œç„¶åå°†å…¶åé¦ˆç»™promptã€‚
- [llama-index](https://gpt-index.readthedocs.io/en/latest/), [github](https://github.com/jerryjliu/llama_index)æ”¯æŒè®¸å¤šä¸åŒçš„æ•°æ®æºï¼Œå¦‚APIã€PDFã€æ–‡æ¡£ã€SQL ã€Google Docsç­‰ã€‚

[llama-index](https://gpt-index.readthedocs.io/en/latest/) Ecosystem
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼šsupport parsing a wide range of file types: .pdf, .jpg, .png, .docx, etc.
- ğŸ¡ [LlamaHub](https://llamahub.ai), åŒ…å«å„ç±»æ’ä»¶ï¼Œå¦‚ï¼šç½‘é¡µã€faissè¯­ä¹‰ç´¢å¼•ã€bç«™è§†é¢‘è„šæœ¬ã€ESã€Milvusã€æ•°æ®åº“ç­‰
- ğŸ§ª [LlamaLab](https://github.com/run-llama/llama-lab)

ã€2023-5-17ã€‘[åŸºäºChatGPTçš„è§†é¢‘æ‘˜è¦åº”ç”¨å¼€å‘](https://www.toutiao.com/article/7230786095158690362)
- å½“æ–‡æ¡£è¢«é€å…¥ LLM æ—¶ï¼Œå®ƒä¼šæ ¹æ®å…¶å¤§å°åˆ†æˆå—æˆ–èŠ‚ç‚¹ã€‚ ç„¶åå°†è¿™äº›å—è½¬æ¢ä¸ºåµŒå…¥å¹¶å­˜å‚¨ä¸ºå‘é‡ã€‚
- å½“æç¤ºç”¨æˆ·æŸ¥è¯¢æ—¶ï¼Œæ¨¡å‹å°†æœç´¢å‘é‡å­˜å‚¨ä»¥æ‰¾åˆ°æœ€ç›¸å…³çš„å—å¹¶æ ¹æ®è¿™äº›ç‰¹å®šå—ç”Ÿæˆç­”æ¡ˆã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨å¤§å‹æ–‡æ¡£ï¼ˆå¦‚ 20 åˆ†é’Ÿçš„è§†é¢‘è½¬å½•æœ¬ï¼‰ä¸ŠæŸ¥è¯¢â€œæ–‡ç« æ‘˜è¦â€ï¼Œæ¨¡å‹å¯èƒ½åªä¼šç”Ÿæˆæœ€å 5 åˆ†é’Ÿçš„æ‘˜è¦ï¼Œå› ä¸ºæœ€åä¸€å—ä¸ä¸Šä¸‹æ–‡æœ€ç›¸å…³ çš„â€œæ€»ç»“â€ã€‚
- ![image](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d0a76dbf2a11400f97220283ea233fa9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=dohd7TRWXXfBH5PRvGLj3ldXBh0%3D)

æµç¨‹å›¾
- ![flow](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/38966bfef5f641f294301647b92def7e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=Mdb8NbIuzxqhc1X9FW60XawIOK0%3D)

ä¸€ç§å…¨æ–°çš„ LlamaIndex æ•°æ®ç»“æ„ï¼š**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**ï¼Œä¸ä¼ ç»Ÿ**è¯­ä¹‰æœç´¢**ç›¸æ¯”ï¼Œæ£€ç´¢æ€§èƒ½æ›´å¥½

å¤šæ•°æ„å»º LLM æ”¯æŒçš„ QA ç³»ç»Ÿæ­¥éª¤ï¼š
- è·å–**æºæ–‡æ¡£**ï¼Œå°†æ¯ä¸ªæ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**
- å°†**æ–‡æœ¬å—**å­˜å‚¨åœ¨**å‘é‡æ•°æ®åº“**ä¸­
- æŸ¥è¯¢æ—¶ï¼Œé€šè¿‡**åµŒå…¥ç›¸ä¼¼æ€§** å’Œ/æˆ– **å…³é”®å­—è¿‡æ»¤å™¨**æ¥æ£€ç´¢æ–‡æœ¬å—ã€‚
- æ‰§è¡Œå“åº”å¹¶**æ±‡æ€»**ç­”æ¡ˆ

ç”±äºå„ç§åŸå› ï¼Œè¿™ç§æ–¹æ³•æ£€ç´¢æ€§èƒ½æœ‰é™ã€‚
- æ–‡æœ¬å—**ç¼ºä¹å…¨å±€ä¸Šä¸‹æ–‡**ã€‚é€šå¸¸queryä¸Šä¸‹æ–‡è¶…å‡ºäº†ç‰¹å®šå—ä¸­ç´¢å¼•çš„å†…å®¹ã€‚
- ä»”ç»†è°ƒæ•´ top-k / ç›¸ä¼¼åº¦åˆ†æ•°é˜ˆå€¼ã€‚
  - å‡è®¾å€¼å¤ªå°ï¼Œä½ ä¼šé”™è¿‡ä¸Šä¸‹æ–‡ã€‚
  - å‡è®¾å€¼å€¼å¤ªå¤§ï¼Œå¹¶ä¸”æˆæœ¬/å»¶è¿Ÿå¯èƒ½ä¼šéšç€æ›´å¤šä¸ç›¸å…³çš„ä¸Šä¸‹æ–‡è€Œå¢åŠ ï¼Œå™ªéŸ³å¢åŠ ã€‚
- åµŒå…¥é€‰æ‹©çš„ä¸Šä¸‹æ–‡ä¸ä¸€å®šæœ€ç›¸å…³ã€‚
  - åµŒå…¥æœ¬è´¨ä¸Šæ˜¯åœ¨æ–‡æœ¬å’Œä¸Šä¸‹æ–‡ä¹‹é—´åˆ†åˆ«ç¡®å®šçš„ã€‚

æ·»åŠ **å…³é”®å­—è¿‡æ»¤å™¨**æ˜¯å¢å¼ºæ£€ç´¢ç»“æœçš„ä¸€ç§æ–¹æ³•ã€‚
- ä½†éœ€è¦æ‰‹åŠ¨æˆ–é€šè¿‡ NLP å…³é”®å­—æå–/ä¸»é¢˜æ ‡è®°æ¨¡å‹ä¸ºæ¯ä¸ªæ–‡æ¡£å……åˆ†ç¡®å®šåˆé€‚çš„å…³é”®å­—ã€‚
- æ­¤å¤–ï¼Œè¿˜éœ€è¦ä»æŸ¥è¯¢ä¸­å……åˆ†æ¨æ–­å‡ºæ­£ç¡®çš„å…³é”®å­—ã€‚

LlamaIndexä¸­æå‡ºäº†ä¸€ä¸ªæ–°ç´¢å¼•ï¼Œä¸ºæ¯ä¸ªæ–‡æ¡£æå–/ç´¢å¼•**éç»“æ„åŒ–æ–‡æœ¬æ‘˜è¦**ã€‚
- è¯¥ç´¢å¼•å¯ä»¥æé«˜æ£€ç´¢æ€§èƒ½ï¼Œè¶…è¶Šç°æœ‰çš„æ£€ç´¢æ–¹æ³•ã€‚æœ‰åŠ©äºç´¢å¼•æ¯”å•ä¸ªæ–‡æœ¬å—æ›´å¤šçš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ¯”å…³é”®å­—æ ‡ç­¾å…·æœ‰æ›´å¤šçš„è¯­ä¹‰ã€‚

å¦‚ä½•æ„å»ºï¼Ÿ
- æå–æ¯ä¸ªæ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨ LLM ä»æ¯ä¸ªæ–‡æ¡£ä¸­æå–**æ‘˜è¦**ã€‚
- å°†æ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**ï¼ˆèŠ‚ç‚¹ï¼‰ã€‚æ‘˜è¦å’ŒèŠ‚ç‚¹éƒ½å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨æŠ½è±¡ä¸­ã€‚
- ç»´æŠ¤ä»**æ‘˜è¦**åˆ°**æºæ–‡æ¡£/èŠ‚ç‚¹**çš„æ˜ å°„ã€‚

åœ¨æŸ¥è¯¢æœŸé—´ï¼Œæ ¹æ®æ‘˜è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ä»¥è¿›è¡ŒæŸ¥è¯¢ï¼š
- åŸºäº **LLM** çš„æ£€ç´¢ï¼šå‘ LLM æä¾›æ–‡æ¡£æ‘˜è¦é›†ï¼Œå¹¶è¦æ±‚ LLM ç¡®å®š: å“ªäº›æ–‡æ¡£æ˜¯ç›¸å…³çš„+ç›¸å…³æ€§åˆ†æ•°ã€‚
- åŸºäº **åµŒå…¥** çš„æ£€ç´¢ï¼šæ ¹æ®æ‘˜è¦åµŒå…¥ç›¸ä¼¼æ€§ï¼ˆä½¿ç”¨ top-k æˆªæ­¢å€¼ï¼‰æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚

æ³¨æ„
- æ£€ç´¢æ–‡æ¡£**æ‘˜è¦**çš„æ–¹æ³•ä¸åŒäºåŸºäº**åµŒå…¥**çš„æ–‡æœ¬å—æ£€ç´¢ã€‚**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**æ£€ç´¢**ä»»ä½•**é€‰å®šæ–‡æ¡£çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯è¿”å›èŠ‚ç‚¹çº§åˆ«çš„ç›¸å…³å—ã€‚

å­˜å‚¨æ–‡æ¡£çš„æ‘˜è¦è¿˜å¯ä»¥å®ç°åŸºäº LLM çš„æ£€ç´¢ã€‚
- å…ˆè®© LLM æ£€æŸ¥ç®€æ˜çš„æ–‡æ¡£æ‘˜è¦ï¼Œçœ‹çœ‹æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³ï¼Œè€Œä¸æ˜¯ä¸€å¼€å§‹å°±å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLMã€‚
- è¿™åˆ©ç”¨äº† LLM çš„æ¨ç†èƒ½åŠ›ï¼Œå®ƒæ¯”åŸºäºåµŒå…¥çš„æŸ¥æ‰¾æ›´å…ˆè¿›ï¼Œä½†é¿å…äº†å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLM çš„æˆæœ¬/å»¶è¿Ÿ

å¸¦**æ‘˜è¦**çš„æ–‡æ¡£æ£€ç´¢æ˜¯**è¯­ä¹‰æœç´¢**å’Œæ‰€æœ‰æ–‡æ¡£çš„å¼ºåŠ›æ‘˜è¦ä¹‹é—´çš„â€œä¸­é—´åœ°å¸¦â€ã€‚

ç¤ºä¾‹
- æ„å»ºæ–¹æ³•è§åŸæ–‡ï¼š[LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

```sh
pip install llama-index # install
```

```py
from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader
documents = SimpleDirectoryReader('data').load_data() # åŠ è½½æ•°æ®
index = GPTVectorStoreIndex.from_documents(documents) # åˆ›å»ºç´¢å¼•
query_engine = index.as_query_engine() # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
response = query_engine.query("What did the author do growing up?") # æ‰§è¡ŒæŸ¥è¯¢
print(response) # è¿”å›ç»“æœ
# --------- æŒä¹…åŒ–å‘é‡ç´¢å¼• ---------
from llama_index import StorageContext, load_index_from_storage
index.storage_context.persist() # æŒä¹…åŒ–å­˜å‚¨ï¼ˆé»˜è®¤æ”¾å†…å­˜ï¼‰
# rebuild storage context
storage_context = StorageContext.from_defaults(persist_dir="./storage")
# load index
index = load_index_from_storage(storage_context)
```


é«˜çº§api

```py
query_engine = doc_summary_index.as_query_engine(
  response_mode="tree_summarize", use_async=True
)
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```

åº•å±‚api

```py
# use retriever as part of a query engine
from llama_index.query_engine import RetrieverQueryEngine

# configure response synthesizer
response_synthesizer = ResponseSynthesizer.from_args()

# assemble query engine
query_engine = RetrieverQueryEngine(
    retriever=retriever,
    response_synthesizer=response_synthesizer,
)
# query
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```



å®‰è£…

```sh
pip install openai
pip install llama-index
```

è°ƒç”¨ä»£ç 
- construct_indexæ–¹æ³•ä¸­ï¼Œä½¿ç”¨llama_indexçš„ç›¸å…³æ–¹æ³•ï¼Œè¯»å–data_directory_pathè·¯å¾„ä¸‹çš„txtæ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆç´¢å¼•æ–‡ä»¶å­˜å‚¨åœ¨index_cache_pathæ–‡ä»¶ä¸­ã€‚

```py
from llama_index import SimpleDirectoryReader, GPTListIndex, GPTSimpleVectorIndex, LLMPredictor, PromptHelper,ServiceContext
from langchain import OpenAI 
import gradio as gr 
import sys 
import os 
os.environ["OPENAI_API_KEY"] = 'your openai api key'
data_directory_path = 'your txt data directory path'
index_cache_path = 'your index file path'
â€‹
#æ„å»ºç´¢å¼•
def construct_index(directory_path): 
        max_input_size = 4096 
        num_outputs = 2000 
        max_chunk_overlap = 20 
        chunk_size_limit = 500
      
        llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name="text-davinci-003", max_tokens=num_outputs))
        # æŒ‰æœ€å¤§tokenæ•°500æ¥æŠŠåŸæ–‡æ¡£åˆ‡åˆ†ä¸ºå¤šä¸ªå°çš„chunk
        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=chunk_size_limit)
        # è¯»å–directory_pathæ–‡ä»¶å¤¹ä¸‹çš„æ–‡æ¡£
        documents = SimpleDirectoryReader(directory_path).load_data() 
 
        index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)
        # ä¿å­˜ç´¢å¼•
        index.save_to_disk(index_cache_path) 
        return index 
        
def chatbot(input_text): 
        # åŠ è½½ç´¢å¼•
        index = GPTSimpleVectorIndex.load_from_disk(index_cache_path) 
        response = index.query(input_text, response_mode="compact") 
        return response.response 
        
if __name__ == "__main__":
        #ä½¿ç”¨gradioåˆ›å»ºå¯äº¤äº’ui  
        iface = gr.Interface(fn=chatbot, 
                        inputs=gr.inputs.Textbox(lines=7, label="Enter your text"), 
                        outputs="text", 
                        title="Text AI Chatbot") 
        index = construct_index(data_directory_path) 
        iface.launch(share=True)
```

llama-indexçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š
- åˆ›å»ºæ–‡æœ¬å—ç´¢å¼•
- æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æœ¬å—
- ä½¿ç”¨ç›¸å…³çš„æ–‡æœ¬å—å‘ GPT-3ï¼ˆæˆ–å…¶ä»–openaiçš„æ¨¡å‹ï¼‰ æé—®
- åœ¨è°ƒç”¨queryæ¥å£çš„æ—¶å€™ï¼Œllama-indexé»˜è®¤ä¼šæ„é€ å¦‚ä¸‹çš„prompt:

```sh
"Context information is below. \n"
    "---------------------\n"
    "{context_str}"
    "\n---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the question: {query_str}\n"
```

ä½¿ç”¨ä»¥ä¸Špromptè¯·æ±‚openai çš„æ¨¡å‹æ—¶ï¼Œæ¨¡å‹æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å’Œæå‡ºçš„é—®é¢˜ï¼Œä½¿ç”¨å…¶é€»è¾‘æ¨ç†èƒ½åŠ›å¾—åˆ°æƒ³è¦çš„ç­”æ¡ˆã€‚

![](https://pic2.zhimg.com/80/v2-9aa943fe84bc25da03b866e7f52a940d_1440w.webp)

ã€2023-4-13ã€‘[å¦‚ä½•ä¸ºGPT/LLMæ¨¡å‹æ·»åŠ é¢å¤–çŸ¥è¯†ï¼Ÿ](https://www.zhihu.com/question/591935281/answer/2979220793)


#### å¦‚ä½•åˆ†å¥

ã€2023-5-25ã€‘llama-indexçš„åˆ†å¥æ–¹æ³•ï¼šåŠ è‡ªå®šä¹‰éƒ¨åˆ†ï¼ˆå‰åç¼€ç­‰ï¼‰â†’è°ƒç”¨nltk.tokenize.punktåˆ†å¥ï¼ˆè‡ªå®šä¹‰å¥æœ«æ­£åˆ™ï¼‰â†’æŒ‰ç…§chunk_sizeæˆªæ–­â†’åˆ†å¥åˆ—è¡¨ï¼Œ[æºç ](https://github.com/jerryjliu/llama_index/blob/c5a4cc1581cc6ee8277f970e7b0b2cbbd6351eb5/llama_index/langchain_helpers/text_splitter.py#LL267C7-L267C23)



### retrieve-then-generate

1ã€retrieve-then-generateï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
 
æ ¸å¿ƒï¼šæ ¹æ® è¾“å…¥query æ£€ç´¢æœ¬åœ°/ç§æœ‰æ•°æ®åº“/æ–‡æ¡£ä¸­çš„æ–‡æ¡£ç‰‡æ®µï¼ˆæ£€ç´¢å¯ä»¥æ˜¯æ–‡æœ¬æ£€ç´¢æˆ–åŸºäºå‘é‡çš„æ£€ç´¢ï¼‰ï¼Œä½œä¸ºæ‰©å……çš„ä¸Šä¸‹æ–‡ contextï¼Œé€šè¿‡ prompt template ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„è¾“å…¥ï¼Œç»§è€Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆresponseã€‚

ç®€ç‰ˆå·¥ä½œæµï¼š
- chunk -> index -> retrieve -> construct input -> LLM
 
æ¨èå¼€æºå·¥å…·ï¼š
- ï¼ˆ1ï¼‰OpenAI çš„å®˜æ–¹æ’ä»¶ï¼š[ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin)
- ï¼ˆ2ï¼‰llama-indexï¼š[https://github.com/jerryjliu/llama_index](https://github.com/jerryjliu/llama_index)ï¼Œæä¾›äº†ä¸€ä¸ªæœ¬åœ°/ç§æœ‰æ•°æ®æ”¶é›†ï¼ˆingestionï¼‰å’Œæ•°æ®ç´¢å¼•ï¼ˆindexingï¼‰çš„è§£å†³æ–¹æ¡ˆï¼Œæ„å»ºèµ·å¤–éƒ¨æ•°æ®å’Œ LLM ä¹‹é—´çš„æ¥å£ã€‚

ä¸€ä¸ªåˆ©ç”¨ llama-index å®šåˆ¶ä¸ªäººè®ºæ–‡æ£€ç´¢çš„ç¤ºä¾‹ï¼š[llama_index/examples/paul_graham_essay at main Â· jerryjliu/llama_index](https://github.com/jerryjliu/llama_index/tree/main/examples/paul_graham_essay)ã€‚
 
ï¼ˆåœ¨æ²¡æœ‰OpenAI APIçš„æƒ…å†µä¸‹ï¼Œllama-index æ”¯æŒè°ƒç”¨è‡ªå®šä¹‰çš„ LLMã€‚ï¼‰
 
ï¼ˆ3ï¼‰LangChainï¼š[langchain](https://github.com/hwchase17/langchain)ï¼Œä¹Ÿæ˜¯ä¸ºäº†æ›´å¥½çš„æ„å»ºå¤–éƒ¨æ•°æ®ã€å…¶ä»–åº”ç”¨ä¸ LLM è¿›è¡Œäº¤äº’çš„æ¥å£å±‚æ¡†æ¶ã€‚

LangChainåº”ç”¨å‚è€ƒç¤ºä¾‹ï¼š[GPT-4 & LangChainâ€”â€”PDFèŠå¤©æœºå™¨äºº-åœ°è¡¨æœ€å¼ºå…¨æ–‡æœç´¢](https://www.bilibili.com/read/cv22589352)ã€‚
 
llama-index å’Œ LangChain å¯ä»¥ç»„åˆä½¿ç”¨ï¼ŒLangChain ä¸­æä¾›äº† é¢å‘ä¸åŒä»»åŠ¡çš„ prompt template å’Œ prompt chainã€‚
 
### åŸºäº fine-tuning çš„æ–¹å¼

2ã€åŸºäº fine-tuning çš„æ–¹å¼ï¼Œç›¸æ¯”äºç¬¬ä¸€ç§æ–¹æ¡ˆï¼ŒåŸºäº fine-tuning çš„æ–¹å¼éœ€è¦é¢å¤–çš„è®­ç»ƒå¼€é”€ï¼ŒåŒæ—¶è¿˜æ˜¯ä¼šå—é™äºLLMçš„æœ€å¤§é•¿åº¦é™åˆ¶ã€‚

â€œè®© LLM å…·å¤‡ç†è§£å®šåˆ¶æ•°æ®åº“çš„èƒ½åŠ›â€æ˜¯å¾ˆæœ‰æŒ‘æˆ˜çš„ç›®æ ‡ï¼ŒåŒæ—¶ä¹Ÿä¼šæœ‰å¾ˆå¤šåº”ç”¨åœºæ™¯ã€‚

ä½¿ç”¨Hugging Faceå®ç°å°†ç»´åŸºç™¾ç§‘çš„çŸ¥è¯†åº“æ·»åŠ åˆ°GPT-2æ¨¡å‹ä¸­
- ä½œè€…ï¼š[å°æ–å®æˆ˜](https://www.zhihu.com/question/591935281/answer/2960837503)

```py
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')

# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# åŠ è½½ç»´åŸºç™¾ç§‘çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°æ®é›†
dataset = TextDataset(
    tokenizer=tokenizer,
    file_path='path/to/wiki.txt',
    block_size=128
)

# åˆ›å»ºdata collator
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer, 
    mlm=False
)

# è®¾ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir='./results',          # è¾“å‡ºç›®å½•
    num_train_epochs=3,              # è®­ç»ƒçš„è½®æ•°
    per_device_train_batch_size=8,   # è®­ç»ƒæ—¶æ¯ä¸ªGPUçš„batch size
    per_device_eval_batch_size=8,    # éªŒè¯æ—¶æ¯ä¸ªGPUçš„batch size
    evaluation_strategy='steps',     # è¯„ä¼°ç­–ç•¥
    save_steps=500,                  # å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹
    save_total_limit=2,              # æœ€å¤šä¿å­˜å‡ ä¸ªæ¨¡å‹
    logging_steps=500,               # å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    learning_rate=5e-5,              # å­¦ä¹ ç‡
# åˆ›å»ºTrainerå¯¹è±¡
trainer = Trainer(
model=model,
args=training_args,
train_dataset=dataset,
data_collator=data_collator,
prediction_loss_only=True
)

# å¼€å§‹è®­ç»ƒ
trainer.train()

# ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
trainer.save_model('./fine-tuned-model')
```

### çŸ¥è¯†å›¾è°±å¢å¼º

ä½¿ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºGPT-2æ¨¡å‹çš„ç¤ºä¾‹ä»£ç ï¼š

```python
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')
# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
# åŠ è½½çŸ¥è¯†å›¾è°±: è¡¨ç¤ºä¸€äº›å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚
knowledge_graph = {
    'John': {
        'is a': 'person',
        'born in': 'New York',
        'works at': 'Google'
    },
    'Google': {
        'is a': 'company',
        'headquartered in': 'California',
        'founded by': 'Larry Page and Sergey Brin'
    }
}

# å°†çŸ¥è¯†å›¾è°±åµŒå…¥åˆ°æ¨¡å‹ä¸­
model.resize_token_embeddings(len(tokenizer))
for entity in knowledge_graph.keys():
    entity_id = tokenizer.convert_tokens_to_ids(entity)
    entity_embedding = torch.randn(768)
    model.transformer.wte.weight.data[entity_id] = entity_embedding

# ç”Ÿæˆå¥å­
input_text = 'John works at'
input_ids = tokenizer.encode(input_text, return_tensors='pt')
output = model.generate(
    input_ids,
    max_length=50,
    do_sample=True,
    top_k=50
)
output_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(output_text)
```

## LLMåº”ç”¨

### LLMåº”ç”¨æŠ€æœ¯æ¶æ„

- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/871e57dfdaf24ba3a064e79ba0522a7b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=eQeTT9ERDeEgx00BF9U9cVyrx%2FY%3D)

å…¸å‹LLMåº”ç”¨å¼€å‘æ¶æ„å››å±‚ï¼š
- ï¼ˆ1ï¼‰`å­˜å‚¨å±‚`ï¼šä¸»è¦ä¸º`å‘é‡æ•°æ®åº“`ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰ç¼–ç åçš„ç‰¹å¾å‘é‡ï¼Œæ”¯æŒå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢ä¸åˆ†æã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨åšæ–‡æœ¬è¯­ä¹‰æ£€ç´¢æ—¶ï¼Œé€šè¿‡æ¯”è¾ƒè¾“å…¥æ–‡æœ¬çš„ç‰¹å¾å‘é‡ä¸åº•åº“æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œæ£€ç´¢ç›®æ ‡æ–‡æœ¬ï¼Œå³åˆ©ç”¨äº†å‘é‡æ•°æ®åº“ä¸­çš„ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ï¼‰ã€‚
  - ã€ä»£è¡¨æ€§æ•°æ®åº“ã€‘`Pinecone`ã€`Qdrant`ã€‚
- ï¼ˆ2ï¼‰`æ¨¡å‹å±‚`ï¼šé€‰æ‹©å¤§è¯­è¨€æ¨¡å‹ï¼Œå¦‚OpenAIçš„GPTç³»åˆ—æ¨¡å‹ã€Hugging Faceä¸­çš„å¼€æºLLMç³»åˆ—ç­‰ã€‚
  - æ¨¡å‹å±‚æä¾›æœ€æ ¸å¿ƒæ”¯æ’‘ï¼ŒåŒ…æ‹¬èŠå¤©æ¥å£ã€ä¸Šä¸‹æ–‡QAé—®ç­”æ¥å£ã€æ–‡æœ¬æ€»ç»“æ¥å£ã€æ–‡æœ¬ç¿»è¯‘æ¥å£ç­‰ã€‚
  - ã€ä»£è¡¨æ€§æ¨¡å‹ã€‘OpenAIçš„`GPT-3.5/4`ï¼ŒAnthropicçš„`Claude`ï¼ŒGoogleçš„`PaLM`ï¼ŒTHUçš„`ChatGLM`ç­‰ã€‚
- ï¼ˆ3ï¼‰`æœåŠ¡å±‚`ï¼šå°†å„ç§è¯­è¨€æ¨¡å‹æˆ–å¤–éƒ¨**èµ„æºæ•´åˆ**ï¼Œæ„å»ºå®ç”¨çš„LLMæ¨¡å‹ã€‚
  - `Langchain`æ˜¯ä¸€ä¸ªå¼€æºLLMåº”ç”¨æ¡†æ¶ï¼Œæ¦‚å¿µæ–°é¢–ï¼Œå°†LLMæ¨¡å‹ã€å‘é‡æ•°æ®åº“ã€äº¤äº’å±‚Promptã€å¤–éƒ¨çŸ¥è¯†ã€å¤–éƒ¨å·¥å…·æ•´åˆåˆ°ä¸€èµ·ï¼Œå¯è‡ªç”±æ„å»ºLLMåº”ç”¨ã€‚
  - ã€ä»£è¡¨æ€§æ¡†æ¶ã€‘ï¼š`LangChain`ï¼Œ`AutoGPT`ï¼Œ`BabyAGI`ï¼Œ`Llama-Index`ç­‰ã€‚
- ï¼ˆ4ï¼‰`äº¤äº’å±‚`ï¼šç”¨æˆ·é€šè¿‡UIä¸LLMåº”ç”¨äº¤äº’
  - `langflow`æ˜¯`langchain`çš„GUIï¼Œé€šè¿‡æ‹–æ”¾ç»„ä»¶å’ŒèŠå¤©æ¡†æ¶æä¾›ä¸€ç§è½»æ¾çš„å®éªŒå’ŒåŸå‹æµç¨‹æ–¹å¼ã€‚
  - å®ç°ä¸€ä¸ªç®€å•çš„èŠå¤©åº”ç”¨ï¼Œè¾“å…¥â€œåŸå¸‚åå­—â€ï¼ŒèŠå¤©æœºå™¨äººå›å¤â€œè¯¥åŸå¸‚çš„å¤©æ°”æƒ…å†µâ€ã€‚
  - åªéœ€è¦æ‹–åŠ¨ä¸‰ä¸ªç»„ä»¶ï¼šPromptTemplateã€OpenAIã€LLMChainã€‚å®ŒæˆPromptTemplateã€OpenAIã€LLMChainçš„ç•Œé¢åŒ–ç®€å•é…ç½®å³å¯ç”Ÿæˆåº”ç”¨ã€‚
  - ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/03233a4e108f4ffaae147afcac50d03e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=Z9D%2Blt1IqZVkBHXAGG1QjyORqLk%3D)


### LLM åº”ç”¨

ã€2023-5-30ã€‘[ä¸‡å­—é•¿æ–‡ï¼šLLMåº”ç”¨æ„å»ºå…¨è§£æ](https://www.toutiao.com/article/7238815236906680836)


#### LLM åº”ç”¨æ€»ç»“

LLM åº”ç”¨
- 1ã€**æœ¬åœ°æ–‡æ¡£**çŸ¥è¯†é—®ç­”åŠ©ç†(chat with pdf)ï¼Œå¦‚ï¼šç§åŸŸçŸ¥è¯†é—®ç­”åŠ©ç†ï¼Œæ™ºèƒ½å®¢æœï¼Œè¯­ä¹‰æ£€ç´¢æ€»ç»“ã€è¾…åŠ©æ•™å­¦ã€‚
- 2ã€**è§†é¢‘**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with video)ï¼Œå¦‚ï¼šè§†é¢‘è‡ªåŠ¨ç¼–ç›®ã€è§†é¢‘æ£€ç´¢é—®ç­”ã€‚
- 3ã€**è¡¨æ ¼**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with csv)ï¼Œå¦‚ï¼šå•†ä¸šæ•°æ®åˆ†æã€å¸‚åœºè°ƒç ”åˆ†æã€å®¢æˆ·æ•°æ®ç²¾å‡†åˆ†æç­‰

#### 1. Doc-Chat æ–‡æ¡£é—®ç­”

LangChain é¢å¯¹éæœºæ„åŒ–æ•°æ®æ—¶ï¼Œé€šè¿‡å€ŸåŠ© Embedding èƒ½åŠ›ï¼Œå¯¹PDFæ–‡ä»¶æ•°æ®è¿›è¡Œ**å‘é‡åŒ–**ï¼ŒLangChainåœ¨æ­¤åŸºç¡€ä¸Šå…è®¸ç”¨æˆ·å°†è¾“å…¥çš„æ•°æ®ä¸PDFä¸­çš„æ•°æ®è¿›è¡Œ**è¯­ä¹‰åŒ¹é…**ï¼Œä»è€Œå®ç°ç”¨æˆ·åœ¨PDFæ–‡ä»¶ä¸­çš„å†…å®¹æœç´¢ã€‚
- [refer](https://aitechtogether.com/python/105086.html)
- ![img](https://aitechtogether.com/wp-content/uploads/2023/05/952a8e3f-3f59-496f-b0e1-5fc7e12b9cef.webp)

æœ‰å¤§é‡æœ¬åœ°æ–‡æ¡£æ•°æ®ï¼Œå¸Œæœ›é€šè¿‡é—®ç­”çš„æ–¹å¼å¿«é€Ÿè·å–æƒ³è¦çš„çŸ¥è¯†æˆ–ä¿¡æ¯ï¼Œæé«˜å·¥ä½œæ•ˆç‡

è§£å†³æ–¹æ¡ˆï¼š
> langchain + llms

æœ¬åœ°åŒ–çŸ¥è¯†ä¸“å±é—®ç­”åŠ©ç†æ„å»ºè¿‡ç¨‹å¯ç®€å•æ¦‚æ‹¬å¦‚ä¸‹ï¼š
- ç¬¬ä¸€æ­¥ï¼š**æ•°æ®åŠ è½½&é¢„å¤„ç†**ï¼ˆå°†æ•°æ®æºè½¬æ¢ä¸ºtextï¼Œå¹¶åštext splitç­‰é¢„å¤„ç†ï¼‰
- ç¬¬äºŒæ­¥ï¼š**å‘é‡åŒ–**ï¼ˆå°†å¤„ç†å®Œæˆçš„æ•°æ®embeddingå¤„ç†ï¼‰
- ç¬¬ä¸‰æ­¥ï¼š**å¬å›**ï¼ˆé€šè¿‡å‘é‡æ£€ç´¢å·¥å…·Faissç­‰å¯¹queryç›¸å…³æ–‡æ¡£å¬å›ï¼‰
- ç¬¬å››æ­¥ï¼šé˜…è¯»ç†è§£ï¼Œ**æ€»ç»“ç­”æ¡ˆ**ï¼ˆå°†contextä¸queryä¼ ç»™llmsï¼Œæ€»ç»“ç­”æ¡ˆï¼‰
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a978188a6d0d4d7db75e0818e286c32c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=daelWSDLtJ1ruh29TjQfkyddRhg%3D)

##### langchaini + pinecone å®ç°


```py
from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

oader = UnstructuredPDFLoader("../data/field-guide-to-data-science.pdf")
data = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(data)

# Create embeddings of your documents to get ready for semantic search
from langchain.vectorstores import Chroma, Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone

OPENAI_API_KEY = '...'
PINECONE_API_KEY = '...'
PINECONE_API_ENV = 'us-east1-gcp'

embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# initialize pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  # find at app.pinecone.io
    environment=PINECONE_API_ENV  # next to api key in console
)
index_name = "langchaintest" # put in the name of your pinecone index here

docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)

query = "What are examples of good data science teams?"
docs = docsearch.similarity_search(query, include_metadata=True)

#. Query those docs to get your answer back
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain

llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
chain = load_qa_chain(llm, chain_type="stuff")

query = "What is the collect stage of data maturity?"
docs = docsearch.similarity_search(query, include_metadata=True)

chain.run(input_documents=docs, question=query)
#. OUTPUT: ' The collect stage of data maturity focuses on collecting internal or external datasets. Examples include gathering sales records and corresponding weather data.'
```


##### ï¼ˆ1ï¼‰æ•°æ®åŠ è½½&é¢„å¤„ç†

åŠ è½½pdfæ–‡ä»¶ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—
- æ¯ä¸ªåˆ†å—çš„æœ€å¤§é•¿åº¦ä¸º3000ä¸ªå­—ç¬¦)ã€‚è¿™ä¸ªæœ€å¤§é•¿åº¦æ ¹æ®llmçš„è¾“å…¥å¤§å°ç¡®å®šï¼Œæ¯”å¦‚gpt-3.5-turboæœ€å¤§è¾“å…¥æ˜¯4096ä¸ªtokenã€‚
- ç›¸é‚»å—ä¹‹é—´çš„é‡å éƒ¨åˆ†ä¸º400ä¸ªå­—ç¬¦ï¼Œç›®çš„æ˜¯æ¯ä¸ªç‰‡æ®µä¿ç•™ä¸€å®šçš„**ä¸Šæ–‡ä¿¡æ¯**ï¼Œåç»­å¤„ç†ä»»åŠ¡åˆ©ç”¨é‡å ä¿¡æ¯æ›´å¥½ç†è§£æ–‡æœ¬ã€‚

æ–¹æ¡ˆ
- LangChain + FAISS + OpenAI

```py
import os

openai_api_key = 'sk-F9Oxxxxxx3BlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key
from langchain.llms import OpenAI
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
from langchain import PromptTemplate

llm = OpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=openai_api_key)

# data loader
loader = PyPDFLoader("data/ZT91.pdf")
doc = loader.load()
# text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)
docs = text_splitter.split_documents(doc)
```

##### ï¼ˆ2ï¼‰å‘é‡åŒ–

è°ƒç”¨ OpenAIEmbeddingsæ¥å£å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ã€‚
- å®é™…åº”ç”¨ä¸­ï¼Œå¯ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆOpenAIEmbeddingsç”¨çš„æ˜¯ç¬¬6ä¸ªï¼‰ã€‚åŒæ—¶ï¼Œä¸­æ–‡embeddingæ•ˆæœä¼˜ç§€çš„æ¨¡å‹æœ‰ç™¾åº¦çš„ERNIEã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/495e57fd56ea4ccc9790418aab290354~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=X394ecc51Xmjra6dRr2AiK6Bwqc%3D)

```py
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
```

##### ï¼ˆ3ï¼‰å¬å›

ç”¨FAISSå·¥å…·å¯¹è¾“å…¥æ–‡æ¡£æ„å»ºFAISSç´¢å¼•ï¼Œè¿”å›æ„å»ºå¥½çš„FAISSç´¢å¼•å¯¹è±¡ã€‚

åˆ›å»ºFAISSç´¢å¼•åŒ…å«çš„å·¥ä½œæœ‰ï¼š
- ä¸ºç´¢å¼•åˆ†é…å†…å­˜ç©ºé—´ï¼›
- é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹ä¸å‚æ•°ï¼ˆæ¯”å¦‚Flat IVFFlatç­‰ï¼‰ï¼›
- å°†æ–‡æ¡£å‘é‡æ·»åŠ åˆ°ç´¢å¼•ä¸­ã€‚

```py
docsearch = FAISS.from_documents(docs, embeddings)
# docsearch.as_retriever(search_kwargs={"k": 5})è¡¨ç¤ºè¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„chunksï¼Œé»˜è®¤æ˜¯4ï¼Œå¯ä»¥ä¿®æ”¹
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})


```

##### ï¼ˆ4ï¼‰æ€»ç»“ç­”æ¡ˆ

- è¾“å…¥ï¼šquery + context
- è¾“å‡ºï¼šanswer

å…¶ä¸­ context ä¸ºé€šè¿‡faiss retrieveræ£€ç´¢å‡ºçš„ç›¸å…³æ–‡æ¡£ï¼š

ç‰¹åˆ«çš„ï¼Œä¸ºäº†è®©gptåªå›ç­”æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œåœ¨prompt_template å¢åŠ äº†çº¦æŸï¼šâ€œè¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼šâ€ã€‚å³å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç”¨æˆ·æé—®ç›¸å…³å†…å®¹ï¼Œéœ€è¦å›ç­”â€œä¸çŸ¥é“â€ï¼Œé˜²æ­¢â€œç­”éæ‰€é—®â€è¯¯å¯¼ç”¨æˆ·ã€‚

```py
prompt_template = """è¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼š
    Context: {context}
    Question: {question}
    Answer:"""
# è¾“å…¥ï¼šquery + context
PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
query = "å®æ—¶ç”»é¢æ— æ³•æŸ¥çœ‹ï¼Œæ€æ ·è§£å†³ï¼Ÿ"
# FAISSæ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£ï¼šretriever=docsearch.as_retriever(search_kwargs={"k": 5})
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})
# queryä¸ºç”¨æˆ·è¾“å…¥çš„æé—®
qa.run(query)
```

#### 2. è§†é¢‘çŸ¥è¯†æ€»ç»“

LLM çœ‹å®Œè§†é¢‘ï¼Œå›ç­”é—®é¢˜

éœ€æ±‚æè¿°ï¼š
- youtubeç­‰è§†é¢‘ç½‘ç«™ä¸Šæ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡è§†é¢‘ï¼Œè™½ç„¶æ¨èç³»ç»ŸæŒ‰ç…§å–œå¥½è¿›è¡Œäº†æ¨èï¼Œä½†è§‚çœ‹å¤§é‡æœ‰ä»·å€¼çš„è§†é¢‘ä¾ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚æœèƒ½å¤Ÿå¿«é€Ÿäº†è§£è§†é¢‘å†…å®¹ï¼Œå¹¶å¾—åˆ°å…³æ³¨çš„ä¿¡æ¯ï¼Œå°†æå¤§æé«˜ä¿¡æ¯è·å–æ•ˆç‡ã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain + transcript + llms
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d565d76640004377abc1bcd989577fa7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=XoDjL3a6u4n%2FIC8AbQRMBoJF9zQ%3D)

ä¸pdfæ–‡æ¡£å¤„ç†æ–¹å¼ä¸åŒï¼ŒYoutubeLoaderåº“ä»youtube**è§†é¢‘é“¾æ¥**ä¸­åŠ è½½æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºæ–‡æ¡£ã€‚
- æ–‡æ¡£è·å–è¿‡ç¨‹: é€šè¿‡youtube-transcript-apiè·å–çš„è§†é¢‘çš„å­—å¹•æ–‡ä»¶ï¼Œè¿™ä¸ªå­—å¹•æ–‡ä»¶æ˜¯youtubeç”Ÿæˆçš„ã€‚å½“ç”¨æˆ·å°†è§†é¢‘ä¸Šä¼ è‡³youtubeæ—¶ï¼Œyoutubeä¼šé€šè¿‡å†…ç½®çš„è¯­éŸ³è¯†åˆ«ç®—æ³•å°†è§†é¢‘è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ã€‚å½“åŠ è½½youtubeè§†é¢‘å­—å¹•æ–‡æ¡£åï¼Œæ¥ä¸‹æ¥çš„å¤„ç†å·¥ä½œä¸ç¬¬ä¸€ä¸ªä¾‹å­ç±»ä¼¼ã€‚

LangChainæ”¯æŒå¯¹YouTubeè§†é¢‘å†…å®¹è¿›è¡Œæ‘˜è¦å†…å®¹ç”Ÿæˆï¼Œé€šè¿‡è°ƒç”¨ document_loaders æ¨¡å—ä¸­çš„ YoutubeLoade ï¼ŒåŒæ—¶ä¼ å…¥YouTubeçš„è§†é¢‘é“¾æ¥ï¼Œç„¶åå³å¯æ”¯æŒè§†é¢‘å†…å®¹çš„æ‘˜è¦æå–ã€‚
- [refer](https://aitechtogether.com/python/105086.html)
- ![img](https://aitechtogether.com/wp-content/uploads/2023/05/8d8bb508-68eb-4733-90ef-86a8bd890026.webp)

```py
from langchain.document_loaders import YoutubeLoader
from langchain.llms import OpenAI
from langchain.chains.summarize import load_summarize_chain

OPENAI_API_KEY = '...'
# åŠ è½½ youtube é¢‘é“
loader = YoutubeLoader.from_youtube_url("https://www.youtube.com/watch?v=QsYGlZkevEg", add_video_info=True)
# å°†æ•°æ®è½¬æˆ document
result = loader.load()
```

Question:
> â€œå¯¹è§†é¢‘ä¸­ä»‹ç»çš„å†…å®¹ï¼Œé€æ¡åˆ—ä¸¾ï¼Ÿâ€



#### 3. è¡¨æ ¼é—®ç­”

LLM åˆ†æå®Œ 54ä¸‡æ¡æ•°æ®ï¼Œç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œå®Œæˆäº†æ•°æ®åˆ†æå¸ˆ1å¤©çš„å·¥ä½œã€‚

éœ€æ±‚æè¿°ï¼š
- é›¶å”®å•†æœ‰å®¢æˆ·çš„äº¤æ˜“æ•°æ®ã€‚å¸Œæœ›ä»æ•°æ®ä¸­ç”Ÿæˆä¸€äº›åŸºæœ¬è§è§£ï¼Œä»¥ä¾¿è¯†åˆ«æœ€ä½³å®¢æˆ·ã€‚
- ä¾‹å¦‚ï¼šæŒ‰æ€§åˆ«å’Œå¹´é¾„ç»„åˆ’åˆ†çš„å¹³å‡æ”¯å‡ºã€æ¯ç§ç±»å‹çš„å®¢æˆ·è´­ä¹°çš„äº§å“ã€äº§å“åœ¨å“ªä¸ªåŸå¸‚å’Œå•†åº—çš„é”€å”®é¢æœ€é«˜ç­‰ç­‰
- æ•°æ®åˆ†æå¸ˆå°†è·å–æ•°æ®ï¼Œç¼–å†™ä¸€äº› SQL æˆ– Python æˆ– R ä»£ç ï¼Œç”Ÿæˆè§è§£ï¼Œæ•°æ®åˆ†æå¸ˆå¯èƒ½éœ€è¦ä¸€å¤©çš„æ—¶é—´æ¥æä¾›è¿™äº›ç»“æœã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain+llm + agents
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/c12a12fb285e431b94a9179846dd67e8~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=pGos9u09HxT9ppxKfL4lz74LA%2F4%3D)

ä»»åŠ¡
- (1) æ˜¾ç¤ºè¡¨æ ¼ä¸­ç”¨æˆ·çš„æ•°é‡
  - éªŒè¯: agentç»™å‡ºçš„ç­”æ¡ˆå®Œå…¨æ­£ç¡®
- (2) å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´ç›¸å…³æ€§åˆ†æ
  - åˆ†æä¸‹å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§ï¼šå¹´é¾„ä¸æ¶ˆè´¹æˆæ­£ç›¸å…³ï¼Œä½†æ˜¯ç›¸å…³æ€§å¾ˆå¼±
- (3) äº§å“é”€å”®é‡ç»Ÿè®¡å¹¶ç”»å‡ºæŸ±çŠ¶å›¾
  - ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾


```py
import os
from langchain.agents import create_csv_agent
from langchain.llms import OpenAI

openai_api_key = 'sk-F9O70vxxxxxxxBlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key

agent = create_csv_agent(OpenAI(openai_api_key=openai_api_key, temperature=0), 'train.csv', verbose=True)
# ç»Ÿè®¡ç”¨æˆ·æ•°
agent.run("è¯·æŒ‰ç…§æ€§åˆ«å¯¹ç”¨æˆ·æ•°é‡è¿›è¡Œæ˜¾ç¤ºï¼Ÿ")
# å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§
agent.run("åœ¨è¿™ä»½è¡¨æ ¼ä¸­,å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§?")
# ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾
agent.run("äº§å“1æ€»é‡,äº§å“2æ€»é‡,äº§å“3æ€»é‡åˆ†åˆ«æ˜¯å¤šå°‘,å°†ä¸‰ä¸ªæ€»é‡é€šè¿‡æŸ±çŠ¶å›¾ç”»å‡ºæ¥å¹¶æ˜¾ç¤º")
```




## å­˜å‚¨å±‚ï¼šæ–‡æ¡£å‘é‡åŒ–

è‡ªç ”æ¡†æ¶çš„é€‰æ‹©
- åŸºäºOpenAIEmbeddingsï¼Œå®˜æ–¹ç»™å‡ºäº†åŸºäºembeddingsæ£€ç´¢æ¥è§£å†³GPTæ— æ³•å¤„ç†é•¿æ–‡æœ¬å’Œæœ€æ–°æ•°æ®çš„é—®é¢˜çš„å®ç°æ–¹æ¡ˆã€‚[å‚è€ƒ](https://www.datalearner.com/blog/1051681543488862)
- ä¹Ÿå¯ä»¥ä½¿ç”¨ LangChain æ¡†æ¶ã€‚

å‚è€ƒ
- [ChatGPTæ€ä¹ˆå»ºç«‹ç§æœ‰çŸ¥è¯†åº“ï¼Ÿ](https://www.zhihu.com/question/596838257/answer/3004754396)
- [åˆ©ç”¨LangChainå’Œå›½äº§å¤§æ¨¡å‹ChatGLMå®ç°åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­”](https://www.zhihu.com/zvideo/1630964532179812353)

é™¤äº†ä»æ–‡æ¡£ä¸­æŠ“å–æ•°æ®ï¼Œä»æŒ‡å®šç½‘ç«™URLæŠ“å–æ•°æ®ï¼Œå®ç°æ™ºèƒ½å®¢æœå¤–éƒ¨çŸ¥è¯†åº“ï¼Œå¯ä»¥å€ŸåŠ©ChatGPTå†™Pythonä»£ç ï¼ŒPythonBeautiful Soupåº“çš„å®ç°æ–¹å¼å¾ˆæˆç†Ÿ

å¤§å‚äº§å“æˆªå›¾ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“å»ºè®¾
- ä¼ä¸šèµ„æ–™åº“ï¼Œå…³è”å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨æœç´¢
- ![a](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYAg6aFUKbz~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=5kqgHWkZX6LPdrX2H9Zq59m%2BwO0%3D)
- å¤§æ¨¡å‹æ–‡æ¡£çŸ¥è¯†æŠ½å–å’Œâ€œå³æœå³é—®â€
- ![b](https://p9-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYkN7rAGx03~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=gO%2FqHxavS7KVAfE08Mv0WayLjLQ%3D)
- ![b](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYmX2ImA5oO~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=rlim2GCZ8zsapnPyzA47LCHJkEo%3D)


éƒ½æœ‰ChatGPTäº†ï¼Œä¸ºä»€ä¹ˆè¿˜è¦äº†è§£Embeddingè¿™ç§ã€Œä½çº§è´§ã€æŠ€æœ¯ï¼Ÿä¸¤ä¸ªåŸå› ï¼š
- æœ‰äº›é—®é¢˜ä½¿ç”¨Embeddingè§£å†³ï¼ˆæˆ–å…¶ä»–éChatGPTçš„æ–¹å¼ï¼‰ä¼šæ›´åŠ åˆç†ã€‚é€šä¿—æ¥è¯´å°±æ˜¯ã€Œæ€é¸¡ç„‰ç”¨ç‰›åˆ€ã€ã€‚
- ChatGPT**æ€§èƒ½**æ–¹é¢ä¸æ˜¯ç‰¹åˆ«å‹å¥½ï¼Œæ¯•ç«Ÿæ˜¯é€å­—ç”Ÿæˆï¼ˆä¸€ä¸ªTokenä¸€ä¸ªTokenåå‡ºæ¥çš„ï¼‰ã€‚

æ›´å¤šï¼š[ChatGPTç›¸ä¼¼åº¦åŒ¹é…ç¬”è®°](https://github.com/datawhalechina/hugging-llm/blob/main/content/ChatGPT%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E2%80%94%E2%80%94%E7%9B%B8%E4%BC%BC%E5%8C%B9%E9%85%8D.ipynb)

### æ–‡æœ¬åˆ‡åˆ†

LangChain åˆ‡åˆ†å·¥å…·
- [Text Splittersæ–‡æ¡£](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html): é€‰æ‹©å¯¹åº”çš„æ–‡æœ¬åˆ‡åˆ†å™¨ï¼Œå¦‚æœæ˜¯é€šç”¨æ–‡æœ¬çš„è¯ï¼Œå»ºè®®é€‰æ‹© `RecursiveCharacterTextSplitter`

```py
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¯¼å…¥æ–‡æœ¬
loader = UnstructuredFileLoader("./data/news_test.txt")
# å°†æ–‡æœ¬è½¬æˆ Document å¯¹è±¡
data = loader.load()
print(f'documents:{len(data)}')

# åˆå§‹åŒ–åŠ è½½å™¨
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)
# åˆ‡å‰²åŠ è½½çš„ document
split_docs = text_splitter.split_documents(data)
print("split_docs size:",len(split_docs))
```

### ç›¸ä¼¼åº¦

ç›¸ä¼¼åº¦ç´¢å¼•
- åªç”¨embeddingæ¥è®¡ç®—å¥å­çš„ç›¸ä¼¼åº¦

```py
# åˆå§‹åŒ– prompt å¯¹è±¡
question = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
# æœ€å¤šè¿”å›åŒ¹é…çš„å‰4æ¡ç›¸ä¼¼åº¦æœ€é«˜çš„å¥å­
similarDocs = db.similarity_search(question, include_metadata=True,k=4)
# [print(x) for x in similarDocs]
```

æ¥å…¥ChatGLMæ¥å¸®å¿™åšæ€»ç»“å’Œæ±‡æ€»

```py
from langchain.chains import RetrievalQA
import IPython
# æ›´æ¢ LLM
qa = RetrievalQA.from_chain_type(llm=ChatGLM(temperature=0.1), chain_type="stuff", retriever=retriever)
# è¿›è¡Œé—®ç­”
query = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
print(qa.run(query))
```

### å‘é‡åŒ–æ–¹æ¡ˆ

#### OpenAIEmbeddings

OpenAIå®˜æ–¹çš„embeddingæœåŠ¡

OpenAIEmbeddingsï¼š
- ä½¿ç”¨ç®€å•ï¼Œå¹¶ä¸”æ•ˆæœæ¯”è¾ƒå¥½ï¼›

##### OpenAIçš„EmbeddingæœåŠ¡

ç›´æ¥ä½¿ç”¨openaiçš„embeddingæœåŠ¡

```py
import os
import openai

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
# OPENAI_API_KEY = "å¡«å…¥ä¸“å±çš„API key"
openai.api_key = OPENAI_API_KEY

text = "æˆ‘å–œæ¬¢ä½ "
model = "text-embedding-ada-002"
emb_req = openai.Embedding.create(input=[text], model=model)
emb = emb_req.data[0].embedding
len(emb), type(emb)
# ç›¸ä¼¼åº¦è®¡ç®—
from openai.embeddings_utils import get_embedding, cosine_similarity

# æ³¨æ„å®ƒé»˜è®¤çš„æ¨¡å‹æ˜¯text-similarity-davinci-001ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ¢æˆtext-embedding-ada-002
text1 = "æˆ‘å–œæ¬¢ä½ "
text2 = "æˆ‘é’Ÿæ„ä½ "
text3 = "æˆ‘ä¸å–œæ¬¢ä½ "
emb1 = get_embedding(text1)
emb1 = get_embedding(text1, "text-embedding-ada-002") # æŒ‡å®šæ¨¡å‹
emb2 = get_embedding(text2)
emb3 = get_embedding(text3)
cosine_similarity(emb1, emb2) # 0.9246855139297101
cosine_similarity(emb1, emb3) # 0.8578009661644189
```

é—®é¢˜
- ä¼šæ¶ˆè€—openaiçš„tokenï¼Œç‰¹åˆ«æ˜¯å¤§æ®µæ–‡æœ¬æ—¶ï¼Œ**æ¶ˆè€—çš„token**è¿˜ä¸å°‘ï¼Œå¦‚æœçŸ¥è¯†åº“æ˜¯æ¯”è¾ƒå›ºå®šçš„ï¼Œå¯ä»¥è€ƒè™‘å°†æ¯æ¬¡ç”Ÿæˆçš„embeddingåšæŒä¹…åŒ–ï¼Œè¿™æ ·å°±ä¸éœ€è¦å†è°ƒç”¨openaiäº†ï¼Œå¯ä»¥å¤§å¤§èŠ‚çº¦tokençš„æ¶ˆè€—ï¼›
- å¯èƒ½ä¼šæœ‰**æ•°æ®æ³„éœ²**çš„é£é™©ï¼Œå¦‚æœæ˜¯ä¸€äº›é«˜åº¦ç§å¯†çš„æ•°æ®ï¼Œä¸å»ºè®®ç›´æ¥è°ƒç”¨ã€‚

##### LangChainè°ƒç”¨OpenAI

```py
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import VectorDBQA
from langchain.document_loaders import UnstructuredMarkdownLoader
from langchain.embeddings.openai import OpenAIEmbeddings
import IPython
import os
from dotenv import load_dotenv
load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_BASE"] = os.getenv("OPENAI_API_BASE")

embeddings = OpenAIEmbeddings()

# ---- ç®€æ´ç‰ˆ -------
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
```

#### HuggingFaceEmbeddings

HuggingFaceEmbeddingsï¼š

å¯ä»¥åœ¨HuggingFaceä¸Šé¢é€‰æ‹©å„ç§sentence-similarityæ¨¡å‹æ¥è¿›è¡Œå®éªŒï¼Œæ•°æ®éƒ½æ˜¯åœ¨æœ¬æœºä¸Šè¿›è¡Œè®¡ç®—
éœ€è¦ä¸€å®šçš„ç¡¬ä»¶æ”¯æŒï¼Œæœ€å¥½æ˜¯æœ‰GPUæ”¯æŒï¼Œä¸ç„¶ç”Ÿæˆæ•°æ®å¯èƒ½ä¼šéå¸¸æ…¢
ç”Ÿæˆçš„å‘é‡æ•ˆæœå¯èƒ½ä¸æ˜¯å¾ˆå¥½ï¼Œå¹¶ä¸”HuggingFaceä¸Šçš„ä¸­æ–‡å‘é‡æ¨¡å‹ä¸æ˜¯å¾ˆå¤šã€‚

```py
from langchain.vectorstores import Chroma
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
import IPython
import sentence_transformers

embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "GanymedeNil/text2vec-large-chinese",
    "text2vec2":"uer/sbert-base-chinese-nli",
    "text2vec3":"shibing624/text2vec-base-chinese",
}

EMBEDDING_MODEL = "text2vec3"
# åˆå§‹åŒ– hugginFace çš„ embeddings å¯¹è±¡
embeddings = HuggingFaceEmbeddings(model_name=embedding_model_dict[EMBEDDING_MODEL], )
embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='mps')
```

è¯¦è§ï¼šç«™å†…[å‘é‡åŒ–ä¸“é¢˜](vec)

## æœåŠ¡å±‚ï¼šLLMæ¡†æ¶

LLMså°±åƒæ˜¯C++çš„ç¼–è¯‘å™¨ï¼ŒPythonçš„è§£é‡Šå™¨ä¸€æ ·ï¼š

| è¯­è¨€ç±»å‹	| æ‰§è¡ŒåŸç† |
| ---	| --- |
| C++è¯­è¨€	| C++è¯­è¨€ â†’ ç¼–è¯‘å™¨/é“¾æ¥å™¨ â†’ æ—¢å®šä»»åŠ¡ |
| Javaè¯­è¨€	| Javaè¯­è¨€ â†’ ç¼–è¯‘å™¨/è™šæ‹Ÿæœº â†’ æ—¢å®šä»»åŠ¡ |
| Pythonè¯­è¨€	| Pythonè¯­è¨€ â†’ è§£é‡Šå™¨ â†’ æ—¢å®šä»»åŠ¡ |
| äººç±»è‡ªç„¶è¯­è¨€	| äººç±»è‡ªç„¶è¯­è¨€ â†’ LLMs â†’ å„ç§åç«¯ç»„ä»¶ â†’ æ—¢å®šä»»åŠ¡ |

å°†è¯­è¨€æ¨¡å‹ä¸å…¶ä»–æ•°æ®æºç›¸è¿æ¥ï¼Œå¹¶å…è®¸è¯­è¨€æ¨¡å‹ä¸ç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œæä¾›äº†ä¸°å¯Œçš„API
- ä¸ LLM äº¤äº’
- LLM è¿æ¥å¤–éƒ¨æ•°æ®æº

AGIçš„åŸºç¡€å·¥å…·æ¨¡å—åº“ï¼Œç±»ä¼¼æ¨¡å—åº“è¿˜æœ‰ mavinã€‚
-  LangChain provides an amazing suite of tools for everything around LLMs. 
- Itâ€™s kind of like HuggingFace but specialized for LLMs

### æ–°å…´ LLM æŠ€æœ¯æ ˆ

å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯æ ˆç”±å››ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼š
- `æ•°æ®é¢„å¤„ç†æµç¨‹`ï¼ˆdata preprocessing pipelineï¼‰: 
  - ä¸æ•°æ®æºè¿æ¥çš„è¿æ¥å™¨ï¼ˆä¾‹å¦‚S3å­˜å‚¨æ¡¶æˆ–CRMï¼‰ã€æ•°æ®è½¬æ¢å±‚ä»¥åŠä¸‹æ¸¸è¿æ¥å™¨ï¼ˆä¾‹å¦‚å‘çŸ¢é‡æ•°æ®åº“ï¼‰
  - é€šå¸¸ï¼Œè¾“å…¥åˆ°LLMä¸­çš„æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ä¹Ÿæ˜¯æœ€éš¾å¤„ç†çš„ï¼ˆå¦‚PDFã€PPTXã€HTMLç­‰ï¼‰ï¼Œä½†åŒæ—¶ï¼Œæ˜“äºè®¿é—®æ–‡æœ¬çš„æ–‡æ¡£ï¼ˆä¾‹å¦‚.DOCXï¼‰ä¸­ä¹ŸåŒ…å«ç”¨æˆ·ä¸å¸Œæœ›å‘é€åˆ°æ¨ç†ç»ˆç«¯çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚å¹¿å‘Šã€æ³•å¾‹æ¡æ¬¾ç­‰ï¼‰ã€‚
- `åµŒå…¥ç«¯ç‚¹`ï¼ˆembeddings endpoint ï¼‰+`å‘é‡å­˜å‚¨`ï¼ˆvector storeï¼‰
  - åµŒå…¥ç«¯ç‚¹ï¼ˆç”¨äºç”Ÿæˆå’Œè¿”å›è¯¸å¦‚è¯å‘é‡ã€æ–‡æ¡£å‘é‡ç­‰åµŒå…¥å‘é‡çš„ API ç«¯ç‚¹ï¼‰å’Œå‘é‡å­˜å‚¨ï¼ˆç”¨äºå­˜å‚¨å’Œæ£€ç´¢å‘é‡çš„æ•°æ®åº“æˆ–æ•°æ®å­˜å‚¨ç³»ç»Ÿï¼‰ä»£è¡¨äº†æ•°æ®å­˜å‚¨å’Œè®¿é—®æ–¹å¼çš„é‡å¤§æ¼”å˜ã€‚
  - ä»¥å‰ï¼ŒåµŒå…¥ä¸»è¦ç”¨äºè¯¸å¦‚**æ–‡æ¡£èšç±»**ä¹‹ç±»çš„ç‰¹å®šä»»åŠ¡
  - åœ¨æ–°æ¶æ„ä¸­ï¼Œå°†æ–‡æ¡£åŠå…¶åµŒå…¥å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œå¯ä»¥é€šè¿‡LLMç«¯ç‚¹å®ç°å…³é”®çš„äº¤äº’æ¨¡å¼ã€‚
  - ç›´æ¥å­˜å‚¨åŸå§‹åµŒå…¥ï¼Œæ„å‘³ç€æ•°æ®å¯ä»¥ä»¥å…¶è‡ªç„¶æ ¼å¼å­˜å‚¨ï¼Œä»è€Œå®ç°æ›´å¿«çš„å¤„ç†æ—¶é—´å’Œæ›´é«˜æ•ˆçš„æ•°æ®æ£€ç´¢ã€‚
  - æ­¤å¤–ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥æ›´å®¹æ˜“åœ°å¤„ç†å¤§å‹æ•°æ®é›†ï¼Œå› ä¸ºå®ƒå¯ä»¥å‡å°‘è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­éœ€è¦å¤„ç†çš„æ•°æ®é‡ã€‚
- `LLM ç»ˆç«¯`ï¼ˆLLM endpointsï¼‰
  - æ¥æ”¶è¾“å…¥æ•°æ®å¹¶ç”ŸæˆLLMè¾“å‡ºçš„ç»ˆç«¯ã€‚LLMç»ˆç«¯è´Ÿè´£ç®¡ç†æ¨¡å‹çš„èµ„æºï¼ŒåŒ…æ‹¬å†…å­˜å’Œè®¡ç®—èµ„æºï¼Œå¹¶æä¾›å¯æ‰©å±•å’Œå®¹é”™çš„æ¥å£ï¼Œç”¨äºå‘ä¸‹æ¸¸åº”ç”¨ç¨‹åºæä¾›LLMè¾“å‡ºã€‚
- `LLM ç¼–ç¨‹æ¡†æ¶`ï¼ˆLLM programming frameworkï¼‰
  - ä¸€å¥—å·¥å…·å’ŒæŠ½è±¡ï¼Œç”¨äºä½¿ç”¨è¯­è¨€æ¨¡å‹æ„å»ºåº”ç”¨ç¨‹åºã€‚åœ¨ç°ä»£æŠ€æœ¯æ ˆä¸­å‡ºç°äº†å„ç§ç±»å‹çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼šLLMæä¾›å•†ã€åµŒå…¥æ¨¡å‹ã€å‘é‡å­˜å‚¨ã€æ–‡æ¡£åŠ è½½å™¨ã€å…¶ä»–å¤–éƒ¨å·¥å…·ï¼ˆè°·æ­Œæœç´¢ç­‰ï¼‰ï¼Œè¿™äº›æ¡†æ¶çš„ä¸€ä¸ªé‡è¦åŠŸèƒ½æ˜¯åè°ƒå„ç§ç»„ä»¶ã€‚

å›¾è§£
- ![img](https://pic2.zhimg.com/80/v2-06c1d00721f768055a329539694c3529_720w.webp)


### LLaMA-Index

å¾…è¡¥å……

### LangChain

è¯¦è§ç«™å†… [LangChain ä¸“é¢˜](/langchain)

### å¾®è½¯guidanceï¼ˆLangChainç®€åŒ–ï¼‰

ã€2023-5-26ã€‘[å¾®è½¯å‘å¸ƒlangChainæ€æ‰‹ï¼šguidanceæ¶æ„å›¾å…¨çƒé¦–å‘](https://mp.weixin.qq.com/s/tdN5KXSXfM9dKDMWbXV2WA)

å¾®è½¯å‘å¸ƒguidanceæ¨¡å—åº“ï¼Œå¹¶è¿…é€Ÿç™»ä¸Šgithubç½‘ç«™TOPæ¦œé¦–ï¼š
- guidanceï¼Œä¼ ç»Ÿæç¤ºæˆ–é“¾æ¥æ›´æœ‰æ•ˆã€æ›´é«˜æ•ˆåœ°æ§åˆ¶æ–°å¼è¯­è¨€æ¨¡å‹ã€‚
- ååŠ©ç”¨æˆ·å°†ç”Ÿæˆã€æç¤ºå’Œé€»è¾‘æ§åˆ¶äº¤é”™åˆ°å•ä¸ªè¿ç»­æµä¸­ï¼Œä»¥åŒ¹é…è¯­è¨€æ¨¡å‹å®é™…å¤„ç†æ–‡æœ¬çš„æ–¹å¼ã€‚
- ç®€å•çš„è¾“å‡ºç»“æ„ï¼Œå¦‚æ€ç»´é“¾åŠå…¶è®¸å¤šå˜ä½“ï¼ˆä¾‹å¦‚ARTï¼ŒAuto-CoTç­‰ï¼‰å·²è¢«è¯æ˜å¯ä»¥æé«˜LLMçš„æ€§èƒ½ã€‚
- åƒGPT-4è¿™æ ·æ›´å¼ºå¤§çš„LLMçš„å‡ºç°å…è®¸æ›´ä¸°å¯Œçš„ç»“æ„ï¼Œå¹¶ä½¿è¯¥ç»“æ„æ›´å®¹æ˜“ï¼Œæ›´ä¾¿å®œã€‚

ç®€å•æ¥è¯´ï¼Œå¾®è½¯guidanceæ¨¡å—åº“ï¼Œæ˜¯langChainæ¨¡å—åº“çš„**ç®€åŒ–ç‰ˆ**ï¼Œæˆ–è€…è¯´ï¼šlangChainæ€æ‰‹ã€‚

### ChatGLM QA

ã€2023-5-22ã€‘
- [åŸºäºchatglmæ­å»ºæ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/622418308): é“è·¯äº¤é€šå®‰å…¨æ³•é¢†åŸŸï¼Œä¸åˆ°100è¡Œçš„pythonæ–‡ä»¶
  - åŸºäºlangchain/llama-indexå·²ç»å¯ä»¥å¿«é€Ÿå®Œæˆç±»ä¼¼çš„åŠŸèƒ½ï¼Œä½†ä»£ç é‡å¤§ï¼Œå­¦ä¹ é—¨æ§›é«˜
- [chatglm-qabot-v2: ä»q-dåŒ¹é…åˆ°q-qåŒ¹é…](https://github.com/xinsblog/chatglm-qabot)
- [chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)
- [Chinese-LangChain](https://github.com/yanqiangmiffy/Chinese-LangChain)ï¼šä¸­æ–‡langchainé¡¹ç›®ï¼ŒåŸºäºChatGLM-6b+langchainå®ç°æœ¬åœ°åŒ–çŸ¥è¯†åº“æ£€ç´¢ä¸æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ
  - ![img](https://github.com/yanqiangmiffy/Chinese-LangChain/raw/master/images/web_demos/v3.png)

ä¸€äº›å…³é”®ç»„ä»¶çš„é…ç½®ï¼š
- LLMä½¿ç”¨çš„æ˜¯æ¸…åçš„chatglm-6b
- è®¡ç®—embeddingç”¨çš„æ˜¯è‹ç¥çš„**simbertV2**
- æ²¡åšembeddingçš„ç´¢å¼•ä¼˜åŒ–ï¼Œç›´æ¥æ”¾listé‡Œæš´åŠ›æŸ¥æ‰¾
- æ¯æ¬¡é»˜è®¤æŸ¥æ‰¾top3ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µç”¨äºæ„é€ prompt
- æ„é€ promptçš„æ¨¡æ¿è§ä»£ç 
- ç”Ÿæˆç­”æ¡ˆçš„é•¿åº¦æ²¡åšé™åˆ¶ï¼Œè¦åšçš„è¯åœ¨ä»£ç ä¸­åŠ è¯·æ±‚chatglmçš„å‚æ•°å³å¯

```py
import sys

# åˆå§‹åŒ–é—®ç­”æœºå™¨äºº
qabot = QaBot(doc_path="data/ä¸­åäººæ°‘å…±å’Œå›½é“è·¯äº¤é€šå®‰å…¨æ³•.txt", chatglm_api_url=sys.argv[1])
# æ ¹æ®æ–‡æ¡£å›ç­”é—®é¢˜
answer, _ = qabot.query('é…’åé©¾é©¶ä¼šåç‰¢å—')
```

åˆå§‹åŒ–çš„ä»£ç å¦‚ä¸‹

```py
def __init__(self, doc_path: str, chatglm_api_url: str):
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨äºå°†æ–‡æ¡£è½¬ä¸ºembedding
    pretrained_model = "junnyu/roformer_chinese_sim_char_small"
    self.tokenizer = RoFormerTokenizer.from_pretrained(pretrained_model)
    self.model = RoFormerForCausalLM.from_pretrained(pretrained_model)
    # åŠ è½½æ–‡æ¡£ï¼Œé¢„å…ˆè®¡ç®—æ¯ä¸ªchunkçš„embedding
    self.chunks, self.index = self._build_index(doc_path)
    # chatglmçš„apiåœ°å€
    self.chatglm_api_url = chatglm_api_url
```

æ¯æ¬¡é—®ç­”çš„ä»£ç å¦‚ä¸‹

```py
def query(self, question: str) -> Tuple[str, str]:
    # è®¡ç®—questionçš„embedding
    query_embedding = self._encode_text(question)
    # æ ¹æ®questionçš„embeddingï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„3ä¸ªchunk
    relevant_chunks = self._search_index(query_embedding, topk=3)
    # æ ¹æ®questionå’Œæœ€ç›¸å…³çš„3ä¸ªchunkï¼Œæ„é€ prompt
    prompt = self._generate_prompt(question, relevant_chunks)
    # è¯·æ±‚chatglmçš„apiè·å¾—ç­”æ¡ˆ
    answer = self._ask_chatglm(prompt)
    # åŒæ—¶è¿”å›ç­”æ¡ˆå’Œprompt
    return answer, prompt
```

æ•ˆæœ
- ![](https://pic3.zhimg.com/80/v2-f263dca70c9ae78e85f2284f1f66685e_1440w.webp)
- ![](https://pic1.zhimg.com/80/v2-70c79cadf68c65c30160dedf8ef17b34_1440w.webp)
- ![](https://pic4.zhimg.com/80/v2-c323e0e63b47f2cb006dddba14ef57ab_1440w.webp)

åŸºäºchatglmåšæ–‡æ¡£é—®ç­”ï¼Œé€šå¸¸çš„åšæ³•æ˜¯"å…ˆæ£€ç´¢å†æ•´åˆ"ï¼Œå¤§è‡´æ€è·¯
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†æ¯ä¸ªchunkè½¬ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“
- å½“ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªchunk
- å°†é—®é¢˜å’Œchunkåˆå¹¶é‡å†™ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

å°†ç”¨æˆ·è¯·æ±‚çš„queryå’ŒdocumentåšåŒ¹é…ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„`q-dåŒ¹é…`ã€‚

q-dåŒ¹é…çš„é—®é¢˜
- queryå’Œdocumentåœ¨**è¡¨è¾¾æ–¹å¼å­˜åœ¨è¾ƒå¤§å·®å¼‚**ï¼Œé€šå¸¸queryæ˜¯ä»¥**ç–‘é—®å¥**ä¸ºä¸»ï¼Œè€Œdocumentåˆ™ä»¥**é™ˆè¿°è¯´æ˜**ä¸ºä¸»ï¼Œè¿™ç§å·®å¼‚å¯èƒ½ä¼šå½±å“æœ€ç»ˆåŒ¹é…çš„æ•ˆæœã€‚
- ä¸€ç§æ”¹è¿›çš„æ–¹æ³•æ˜¯ä¸åš`q-dåŒ¹é…`ï¼Œè€Œæ˜¯å…ˆé€šè¿‡documentç”Ÿæˆä¸€æ‰¹å€™é€‰çš„questionï¼Œå½“ç”¨æˆ·å‘æ¥è¯·æ±‚çš„æ—¶å€™ï¼Œé¦–å…ˆæ˜¯æŠŠqueryå’Œå€™é€‰çš„questionåšåŒ¹é…ï¼Œè¿›è€Œæ‰¾åˆ°ç›¸å…³çš„documentç‰‡æ®µ
- å¦ä¸€ä¸ªæ€è·¯é€šè¿‡HyDEå»ä¼˜åŒ–
  - ä¸ºqueryå…ˆç”Ÿæˆä¸€ä¸ªå‡ç­”æ¡ˆï¼Œç„¶åé€šè¿‡å‡ç­”æ¡ˆå»æ£€ç´¢ï¼Œè¿™æ ·å¯ä»¥çœå»ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆé—®é¢˜çš„è¿‡ç¨‹ï¼Œä»£ä»·ç›¸å¯¹è¾ƒå°

ç¬¬ä¸€ç§æ–¹æ³•å°±æ˜¯'`q-qåŒ¹é…`'ï¼Œå…·ä½“æ€è·¯å¦‚ä¸‹ï¼š
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- éƒ¨ç½²chatglmçš„apiï¼Œ[éƒ¨ç½²æ–¹æ³•](https://github.com/THUDM/ChatGLM-6B#api%E9%83%A8%E7%BD%B2)
- è°ƒapiï¼Œæ ¹æ®æ¯ä¸ªchunkç”Ÿæˆ5ä¸ªå€™é€‰çš„questionï¼Œä½¿ç”¨çš„promptæ ¼å¼ä¸º'è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ç”Ÿæˆ5ä¸ªé—®é¢˜: ...'ï¼Œç”Ÿæˆæ•ˆæœè§ä¸‹å›¾ï¼š
  - ![](https://pic2.zhimg.com/80/v2-7790ad31e0621bff9e10233b448100f1_1440w.jpg)
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†ç”Ÿæˆçš„questionè½¬ä¸ºå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œå¹¶è®°å½•questionå’ŒåŸå§‹chunkçš„å¯¹åº”å…³ç³»
- ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªquestionï¼Œè¿›è€Œæ‰¾åˆ°å¯¹åº”çš„chunk
- å°†é—®é¢˜å’Œchunk**åˆå¹¶é‡å†™**ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

[chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)
- qabot_v1.pyå®ç°äº†q-dåŒ¹é…æ–¹æ³•
- qabot_v2.pyå®ç°äº†q-qåŒ¹é…æ–¹æ³•

`q-dåŒ¹é…`å’Œ`q-qåŒ¹é…`çš„ä»£ç å·®å¼‚
- åˆå§‹åŒ–æ„å»ºç´¢å¼•çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic1.zhimg.com/80/v2-e3e8a1922e93fe67a6432866882b4490_1440w.webp)
- æŸ¥è¯¢ç´¢å¼•æ—¶çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic2.zhimg.com/80/v2-273d529bbcd4577f55003cd6fe508fa5_1440w.webp)

æµ‹è¯•é—®é¢˜ä¸ºè¡Œé©¶è¯çš„å¼æ ·ç”±è°æ¥ç›‘åˆ¶ï¼Œv1å’Œv2çš„æ•ˆæœå¯¹æ¯”å¦‚ä¸‹ï¼š
- ![](https://pic2.zhimg.com/80/v2-14832aaedad809d62ce0d9157c770c69_1440w.webp)

åœ¨æ„å»ºç´¢å¼•é˜¶æ®µï¼Œv2èŠ±è´¹çš„æ—¶é—´æ˜¯è¿œè¶…è¿‡v1çš„ï¼š

```sh
# è®¡ç®—chunksçš„embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00, 7.81it/s]
# ç”Ÿæˆquestionå¹¶è®¡ç®—embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [07:24<00:00, 22.24s/it]
```


## å®šåˆ¶çŸ¥è¯†åº“

ã€2023-5-24ã€‘
- [åŸºäº ChatGLM-6B æ­å»ºä¸ªäººä¸“å±çŸ¥è¯†åº“](https://www.toutiao.com/article/7236562318920876596)
- [å¦‚ä½•ä½¿ç”¨LangChainï¼‹LLM æ¥æ„å»ºæœ¬åœ°çŸ¥è¯†åº“](https://mp.weixin.qq.com/s/ponKZ1OaHXX2nzuSxXg8-Q)

### ä¸šåŠ¡åœºæ™¯

è°ƒæ•´ promptï¼ŒåŒ¹é…ä¸åŒçš„çŸ¥è¯†åº“ï¼Œè®© LLM æ‰®æ¼”ä¸åŒçš„è§’è‰²
- â€¢ ä¸Šä¼ å…¬å¸è´¢æŠ¥ï¼Œå……å½“è´¢åŠ¡åˆ†æå¸ˆ
- â€¢ ä¸Šä¼ å®¢æœèŠå¤©è®°å½•ï¼Œå……å½“æ™ºèƒ½å®¢æœ
- â€¢ ä¸Šä¼ ç»å…¸Caseï¼Œå……å½“å¾‹å¸ˆåŠ©æ‰‹
- â€¢ ä¸Šä¼ åŒ»é™¢ç™¾ç§‘å…¨ä¹¦ï¼Œå……å½“åœ¨çº¿é—®è¯ŠåŒ»ç”Ÿ

### é—®é¢˜

å¾®è°ƒçš„ç“¶é¢ˆ
- éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œå¾ˆå¤šè®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œä»¥ä¾¿åœ¨ä¸åŒè¶…å‚æ•°è®¾ç½®è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œå¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ª
- åŠ¨æ€æ‰©å±•æ¯”è¾ƒå·®ï¼Œæ–°å¢å’Œä¿®æ”¹åŸæœ‰çš„æ•°æ®éƒ½è¦é‡æ–°å¾®è°ƒä¸€æ¬¡ã€‚

æ€»ä¹‹ï¼Œå¾®è°ƒå¯¹éä¸“ä¸šäººå‘˜ä¸å‹å¥½ã€‚

å¦‚ä½•ä¸ç”¨å¾®è°ƒå°±èƒ½å®ç°å‚ç›´é¢†åŸŸçš„ä¸“ä¸šé—®ç­”ï¼Ÿ
- æ–¹æ¡ˆï¼šChatGLM-6B + langchain å®ç°ä¸ªäººä¸“å±çŸ¥è¯†åº“

### æŠ€æœ¯åŸç†

æŠ€æœ¯åŸç†
- åŠ è½½æ–‡ä»¶ -> è¯»å–æ–‡æœ¬ -> æ–‡æœ¬åˆ†å‰² -> æ–‡æœ¬å‘é‡åŒ– -> é—®å¥å‘é‡åŒ– -> åœ¨æ–‡æœ¬å‘é‡ä¸­åŒ¹é…å‡ºä¸é—®å¥å‘é‡æœ€ç›¸ä¼¼çš„top kä¸ª -> åŒ¹é…å‡ºçš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æ·»åŠ åˆ° prompt ä¸­ -> æäº¤ç»™ LLM ç”Ÿæˆå›ç­”ã€‚
- [img1](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/0d835cc528ba470d8e0e000f950780c7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=5lntZ3rovTBKBRNYBptf8gdfeOM%3D)
- [img2](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/ddc11018f9324f6cae76611a7486894b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=O88KtsSqlFFGJqlLUTLF4IzYYhs%3D)

æ ¸å¿ƒæŠ€æœ¯æ˜¯: å‘é‡ embedding
- å°†ç”¨æˆ·çŸ¥è¯†åº“å†…å®¹ç»è¿‡ embedding å­˜å…¥å‘é‡çŸ¥è¯†åº“ï¼Œç„¶åç”¨æˆ·æ¯ä¸€æ¬¡æé—®ä¹Ÿä¼šç»è¿‡ embeddingï¼Œåˆ©ç”¨å‘é‡ç›¸å…³æ€§ç®—æ³•ï¼ˆä¾‹å¦‚ä½™å¼¦ç®—æ³•ï¼‰æ‰¾åˆ°æœ€åŒ¹é…çš„å‡ ä¸ªçŸ¥è¯†åº“ç‰‡æ®µï¼Œå°†è¿™äº›çŸ¥è¯†åº“ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·ä½œä¸º prompt æäº¤ç»™ LLM å›ç­”

å…¸å‹çš„prompt

```json
å·²çŸ¥ä¿¡æ¯ï¼š
{context} 
æ ¹æ®ä¸Šè¿°å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´å’Œä¸“ä¸šçš„æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ— æ³•ä»ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·è¯´ â€œæ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜â€ æˆ– â€œæ²¡æœ‰æä¾›è¶³å¤Ÿçš„ç›¸å…³ä¿¡æ¯â€ï¼Œä¸å…è®¸åœ¨ç­”æ¡ˆä¸­æ·»åŠ ç¼–é€ æˆåˆ†ï¼Œç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚ 
é—®é¢˜æ˜¯ï¼š{question}
```

### å®ç°

```sh
# ä¸‹è½½æºç 
git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git
# å®‰è£…ä¾èµ–
cd langchain-ChatGLM
pip install -r requirements.txt
# ä¸‹è½½æ¨¡å‹

# å®‰è£… git lfs
git lfs install
# ä¸‹è½½ LLM æ¨¡å‹
git clone https://huggingface.co/THUDM/chatglm-6b /your_path/chatglm-6b
# ä¸‹è½½ Embedding æ¨¡å‹
git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese /your_path/text2vec
# æ¨¡å‹éœ€è¦æ›´æ–°æ—¶ï¼Œå¯æ‰“å¼€æ¨¡å‹æ‰€åœ¨æ–‡ä»¶å¤¹åæ‹‰å–æœ€æ–°æ¨¡å‹æ–‡ä»¶/ä»£ç 
git pull
```

æ¨¡å‹ä¸‹è½½å®Œæˆåï¼Œè¯·åœ¨ configs/model_config.py æ–‡ä»¶ä¸­ï¼Œå¯¹embedding_model_dictå’Œllm_model_dictå‚æ•°è¿›è¡Œä¿®æ”¹ã€‚

```py
embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "/your_path/text2vec"
}
llm_model_dict = {
    "chatyuan": "ClueAI/ChatYuan-large-v2",
    "chatglm-6b-int4-qe": "THUDM/chatglm-6b-int4-qe",
    "chatglm-6b-int4": "THUDM/chatglm-6b-int4",
    "chatglm-6b-int8": "THUDM/chatglm-6b-int8",
    "chatglm-6b": "/your_path/chatglm-6b",
}
```

å¯åŠ¨æœåŠ¡

```py
# Web æ¨¡å¼å¯åŠ¨
pip install gradio
python webui.py
# API æ¨¡å¼å¯åŠ¨
python api.py
# å‘½ä»¤è¡Œæ¨¡å¼å¯åŠ¨
python cli_demo.py
```

### æ•ˆæœ

gradioé¡µé¢
- [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/558af5fd53d34b5a859afddbc82a331c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=N%2FKm%2FGcW8WSiFxrAAD04P3klhig%3D)

Chatgpt-Next-Web é¡¹ç›®åŸºç¡€ä¸Šè¿›è¡Œäº†é€‚é…ä¿®æ”¹ï¼Œæ‰“é€ äº†ä¸€æ¬¾é¢å‘ç”¨æˆ·ä½¿ç”¨çš„æœ¬åœ°çŸ¥è¯†åº“å‰ç«¯ã€‚
- [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/55d11a03e5a742ce9c201aa355b38e3c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=fYTBeLwxkicrZBzWsYQusCVfiJk%3D)


### FastGPT

ã€2023-5-17ã€‘[FastGPT](https://github.com/c121914yu/FastGPT), è°ƒç”¨ gpt-3.5 å’Œ embedding æ„å»ºè‡ªå·±çš„çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“æ„å»ºåŸç†
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/KBProcess.jpg?raw=true)

æ•ˆæœ
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/demo.png?raw=true)



åœ¨çº¿ä½“éªŒ
- ğŸ‰ [fastgpt.run](https://fastgpt.run/) ï¼ˆå›½å†…ç‰ˆï¼‰
- ğŸ‰ [ai.fastgpt.run](https://ai.fastgpt.run/) ï¼ˆæµ·å¤–ç‰ˆï¼‰



## ä¸šç•Œæ¡ˆä¾‹

### New Bing

- ä¼˜åŠ¿ï¼šå…è´¹ï¼Œå¿«æ·ï¼Œå¯ä»¥è”ç½‘ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥é˜…è¯»æœ¬åœ°PDFå’Œç½‘ç»œè®ºæ–‡ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’
- ç¼ºç‚¹ï¼šä¸ç¨³å®šï¼Œè¯†åˆ«å†…å®¹æœ‰é™ï¼Œç”šè‡³äºä¿¡æ¯é‡ä½äºæ‘˜è¦çš„å†…å®¹ã€‚ç»å¸¸ä¼šè¾“å‡ºä¸€åŠå°±æ–­äº†ã€‚

### chatpdf

[ChatPDF](https://www.chatpdf.com) ç•Œé¢å¹²å‡€ï¼Œä¸Šä¼ pdfåï¼Œç›´æ¥å¯¹è¯ã€‚
- ä¸Šä¼ é€Ÿåº¦å¾ˆå¿«ï¼Œå¯¹è¯å“åº”ä¹Ÿéå¸¸çš„å¿«ã€‚
- å¯¹æ–‡æ¡£å†…å®¹çš„è§£æå¾ˆå‡†ç¡®ï¼ŒåŒ…æ‹¬ä¸€äº›éšè—åœ¨å†…éƒ¨çš„çŸ¥è¯†ç‚¹ä¹Ÿå¯ä»¥å¿«é€Ÿæœç´¢æ‰¾åˆ°
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY88FTkaxGc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=A9yfB6gzbQrwWdUHuBZ2o0bRZzM%3D)

ä¼˜åŠ¿ï¼š
- äº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ç¼ºç‚¹ï¼šå…¨æ–‡æ€»ç»“ä¿¡æ¯é‡è¾ƒä½ï¼Œé—®ç­”æ¨¡å¼åå‘äºå…³é”®è¯å®šä½ï¼Œç„¶åä¸Šä¸‹æ–‡ç¿»è¯‘ï¼Œä¸”å·²ç»æ”¶è´¹ï¼Œæ¯æœˆ5åˆ€ã€‚åªæ”¯æŒæœ¬åœ°PDFæ–‡æ¡£ä¸Šä¼ ã€‚

### scispace

- ä¼˜åŠ¿ï¼šäº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ï¼Œæ”¯æŒæœ¬åœ°è®ºæ–‡ä¸Šä¼ ï¼Œå¯ä»¥å…¬å¼æˆªå›¾è§£æï¼Œå¯ä»¥è§£é‡Šä¼ªä»£ç 
- ç¼ºç‚¹ï¼šå¯¹ä¸­æ–‡æ”¯æŒè¾ƒå·®ï¼Œå…¨æ–‡æ€»ç»“æ•ˆæœè¾ƒå·®ã€‚

### aminer.cn

æ¸…åå”æ°è€å¸ˆä»–ä»¬ç»„çš„å·¥ä½œï¼
- ![](https://pic1.zhimg.com/80/v2-33843cf159df1ca9e4a28fa32a15a759_1440w.webp?source=1940ef5c)
- ![](https://pic1.zhimg.com/80/v2-765efacd5340b65de02e79087ee91a07_1440w.webp?source=1940ef5c)

- ä¼˜åŠ¿ï¼šæœ‰çƒ­ç‚¹è®ºæ–‡æ¨é€ï¼æœ‰è®ºæ–‡æ‰“åˆ†ï¼Œå’Œåˆ«äººçš„æé—®è®°å½•
- ç¼ºç‚¹ï¼šè¯­ä¹‰ç†è§£æœ‰é™

### ChatPaper å¼€æº

ä¸­ç§‘å¤§å‡ºå“ï¼šChatPaper, Use ChatGPT to summarize the arXiv papers. å…¨æµç¨‹åŠ é€Ÿç§‘ç ”ï¼Œåˆ©ç”¨chatgptè¿›è¡Œè®ºæ–‡æ€»ç»“+æ¶¦è‰²+å®¡ç¨¿+å®¡ç¨¿å›å¤
- åŠŸèƒ½ï¼šè®ºæ–‡ï¼ˆç¦»çº¿/åœ¨çº¿ï¼‰æ€»ç»“+è®ºæ–‡æ¶¦è‰²+AIå®¡ç¨¿+AIå®¡ç¨¿å›å¤ç­‰åŠŸèƒ½ã€‚
- [github](https://github.com/kaixindelele/chatpaper), [demo](https://chatpaper.org/)

é—®é¢˜ï¼š
- å‰é¢å‡ æ¬¾å·¥å…·éƒ½é¢ä¸´ä¸€ä¸ªé—®é¢˜ï¼Œå…¨æ–‡æ€»ç»“çš„ä¿¡æ¯é‡è¾ƒä½ï¼Œå› ä¸ºGPTsçš„è¾“å…¥tokenæ˜¯**è¿œä½äº**è®ºæ–‡çš„å…¨æ–‡æ–‡æœ¬çš„ï¼Œè€Œç®€å•çš„ç¿»è¯‘æ€»ç»“æ‘˜è¦ï¼Œåˆæ‹¿ä¸åˆ°å¤šå°‘æœ‰æ•ˆä¿¡æ¯

æ–¹æ¡ˆï¼š
- å°†abstractå’Œintroductionè¿›è¡Œå‹ç¼©ï¼Œç„¶åè¾“å…¥ç»™chatè¿›è¡Œæ€»ç»“

æ•ˆæœ
- æ¯ç¯‡æ–‡ç« ï¼Œè°ƒç”¨äº”æ¬¡chatï¼Œå¯ä»¥è·å¾—7åˆ°8æˆçš„ä¿¡æ¯é‡ï¼Œå¹¶ä¸”æ ¼å¼åŒ–è¾“å‡ºæˆä¸­å›½äººå®¹æ˜“çœ‹æ‡‚çš„æ–‡æœ¬ï¼Œæå¤§çš„é™ä½äº†å¤§å®¶çš„é˜…è¯»é—¨æ§›ã€‚å‡ ä¹å¯ä»¥è¾¾åˆ°ï¼ŒAIèŠ±ä¸€åˆ†é’Ÿæ€»ç»“ï¼ŒäººèŠ±ä¸€åˆ†é’Ÿçœ‹æ€»ç»“ï¼Œå°±å¯ä»¥åˆ¤æ–­è¿™ç¯‡æ–‡ç« æ˜¯å¦éœ€è¦ç²¾è¯»çš„æ•ˆæœã€‚
- å¦‚æœéœ€è¦**ç²¾è¯»**ï¼Œåˆ™å¯ä»¥è°ƒç”¨ä¸Šé¢çš„å„ç§å·¥å…·ï¼Œå°¤å…¶æ¨èscispaceå’Œaminer.

ã€2023-10-19ã€‘[chatwithpaper](https://chatwithpaper.org/)

### PandasGPT

[PandaGPT](https://www.pandagpt.io/), è®¿é—®é€Ÿåº¦åæ…¢ï¼ŒUIå¯¹è¯æ ·å¼ä¸€è¨€éš¾å°½ï¼Œæ²¡æœ‰ä¸€ä¸ªç‰ˆå—ä¸æ˜¯äº’ç›¸é®æŒ¡çš„
- å·²æœ‰3wä¸ªæ–‡æ¡£ï¼Œ10wä¸ªé—®é¢˜
- ä¸Šä¼ æ–‡æ¡£ï¼Œç›´æ¥é’ˆå¯¹æ–‡æ¡£é—®ç­”; è¿˜èƒ½ç”ŸæˆçŸ¥è¯†å›¾è°±ï¼ŒGenerate Knowledge Graph
- ![](https://uploads-ssl.webflow.com/6405047c9d73416a60b878b4/6405068dec8bf7442171f160_Screenshot%202023-03-05%20at%204.15.30%20PM.png)

- é—®é¢˜å›ç­”åŸºæœ¬åˆ°ä½ï¼Œç›¸æ¯”ChatPDFï¼Œç•¥æ˜¾å•°å—¦
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY8iElGGYks~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=BO6bt9JW5V%2Fsitc%2F%2FKWe6sBmUHY%3D)

ç±»ä¼¼çš„ï¼Œè¿˜æœ‰ AMiner ä¸Šçš„åæ™ºå†°

### ChatDOC

ã€2023-3-28ã€‘[ChatDOC](https://chatdoc.com/)æ–‡æ¡£é˜…è¯»å·¥å…·ï¼Œæ”¯æŒä¸­æ–‡ï¼åˆå¿«åˆå…è´¹ï¼ä½¿ç”¨ ChatGPT é˜…è¯»æ–‡ä»¶çš„AIé—®ç­”æœºå™¨äºº
- åŸºäº ChatGPT çš„æ–‡ä»¶é˜…è¯»åŠ©æ‰‹ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥å¿«é€Ÿä»ä¸Šä¼ ç ”ç©¶è®ºæ–‡ã€ä¹¦ç±ã€æ‰‹å†Œç­‰æ–‡ä»¶ä¸­æå–ã€å®šä½å’Œæ±‡æ€»æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶é€šè¿‡èŠå¤©çš„æ–¹å¼åœ¨å‡ ç§’é’Ÿå†…ç»™å‡ºé—®é¢˜çš„ç­”æ¡ˆã€‚
- ChatDOC è¿˜å¯ä»¥ç†è§£æ–‡æ¡£ä¸­çš„è¡¨æ ¼æˆ–æ–‡å­—ï¼Œä¼˜åŒ–å…¶æ•°æ®åˆ†ææ€§èƒ½ï¼Œå¹¶ä¸ºæ¯ä¸ªå›ç­”æä¾›ç›´æ¥å¼•ç”¨çš„æ¥æºï¼Œæ–¹ä¾¿æ ¸å®AIçš„è§£è¯»å‡†ç¡®æ€§ã€‚
- ChatDOC ç›®å‰å…è´¹ï¼Œæ–‡ä»¶å¤§å°é™åˆ¶ä¸º 200 é¡µï¼Œæœ€å¤šå¯ä»¥ä¸Šä¼  5 ä¸ªæ–‡æ¡£ã€‚åœ¨å³å°†æ›´æ–°çš„ç‰ˆæœ¬ä¸­ï¼Œè¿˜æ”¯æŒè·¨å¤šä¸ªæ–‡æ¡£çš„ç»¼åˆæŸ¥è¯¢å’Œé—®ç­”ã€‚
- ![](https://pic2.zhimg.com/80/v2-c73f17ecea423a82aad0ac7c110bd625_720w.webp)


### typeset

[typeset](https://typeset.io)
- ä¸»æ‰“è®ºæ–‡æ£€ç´¢ï¼Œä¹Ÿæ”¯æŒpdfæ–‡æ¡£è§£è¯»ã€‚
- ä¸Šä¼ ã€å¯¹è¯å“åº”éƒ½ååˆ†ç¼“æ…¢ï¼Œå¯¹è¯çš„æ•ˆæœå·®ï¼Œå¾ˆå¤šçŸ¥è¯†ç‚¹æ— æ³•è§£è¯»ï¼Œä¸€å¾‹å›å¤æ— æ³•æ‰¾åˆ°è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY9mB4FVHsf~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=DjAXODUMrVrnilF7CAXPLSUT0qs%3D)

### privateGPT (æœ¬åœ°ã€ç¦»çº¿)

ã€2023-5-17ã€‘å¼€æºçš„ [privateGPT](https://www.privategpt.io/), [privateGPTä»£ç ](https://github.com/imartinez/privateGPT)ï¼Œå®ƒä½¿ç”¨GPTçš„å¼ºå¤§åŠŸèƒ½ï¼Œå¯ä»¥åœ¨100%ç§å¯†çš„æƒ…å†µä¸‹ä¸æœ¬åœ°æ–‡æ¡£è¿›è¡Œç§å¯†äº¤äº’ï¼Œä¸ä¼šæœ‰ä»»ä½•æ•°æ®æ³„æ¼ã€‚
- ä½¿ç”¨LLaMaã€LangChainå’ŒGPT4Allæ„å»ºã€‚
- [Demo](https://docs.boosterframework.com/)

The supported extensions are:
- .csv: CSV,
- .docx: Word Document,
- .enex: EverNote,
- .eml: Email,
- .epub: EPub,
- .html: HTML File,
- .md: Markdown,
- .msg: Outlook Message,
- .odt: Open Document Text,
- .pdf: Portable Document Format (PDF),
- .pptx : PowerPoint Document,
- .txt: Text file (UTF-8)


### ChatBase

ã€2023-5-28ã€‘[ChatGPT é€ å¯Œâ€œç¥è¯â€ï¼šå¤§å››å­¦ç”Ÿæ”¾å¼ƒå¤§å‚å»åˆ›ä¸šï¼ŒåŠå¹´åæœˆæ”¶å…¥45ä¸‡](https://mp.weixin.qq.com/s/IS5NvCAzs0q4Xi5ABfszFQ)

åŸƒåŠå¤§å­¦ç”Ÿ[Yasser](https://twitter.com/yasser_elsaid_)åœ¨ Meta å’Œ Tesla ç­‰å¤§å‚å®ä¹ åŠå¹´åï¼Œå…¶åˆ›åŠçš„èŠå¤©æœºå™¨äººå…¬å¸å°±å·²ç»ç¨³å®šæœˆæ”¶ 6.4 ä¸‡ç¾å…ƒï¼ˆçº¦åˆ 45 ä¸‡äººæ°‘å¸ï¼‰ï¼Œè€Œä¸”è‡ªé¦–æ¬¡ä¸Šçº¿ä»¥æ¥ï¼Œä¸šåŠ¡æµé‡ä»æœªä¸‹æ»‘ç¼©æ°´ã€‚
- Chatbase å¸‚åœºå®šä½å¹¶ä¸å¤æ‚ï¼Œä¹Ÿæ²¡åšè¿‡éªŒè¯æˆ–è€…å•†ä¸šè°ƒæŸ¥ã€‚æ¯•ç«Ÿ AI è¿™ä¸ªé¢†åŸŸæ‰åˆšåˆšè¯ç”Ÿï¼Œå¯¹æˆ‘æ¥è¯´â€˜ç”¨ ChatGPT å¤„ç†æ•°æ®â€™è‚¯å®šæœ‰æå¤´ï¼Œèƒ½å¸®åŠ©è®¸è®¸å¤šå¤šç”¨æˆ·è§£å†³å®é™…éœ€æ±‚
- Chatbase æœ€åˆå…¶å®æ˜¯æƒ³åšæˆä¸€æ¬¾å¤„ç† PDF çš„ ChatGPT å·¥å…·ï¼Œè¿™æ˜¯ Yasser å½“æ—¶æƒ³åˆ°çš„æœ€ç›´è§‚çš„ç”¨ä¾‹ã€‚æ¯”å¦‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä¸€ä»½ PDFï¼Œç„¶åè®© ChatGPT æ€»ç»“ä¸€ä¸‹å…¶ä¸­çš„å†…å®¹ã€‚
- ç¬¬ä¸€ä¸ªç‰ˆæœ¬èŠ±äº†ä¸¤ä¸ªæœˆæ—¶é—´ï¼Œ2023 å¹´ 2 æœˆ 2 å·ï¼ŒYasser å‘å¸ƒç»™äº† Twitter ä¸Šçš„å…¨éƒ¨ 16 ä¸ªå…³æ³¨è€…ï¼Œç»“æœä¸€ä¸‹å­å°±ç«äº†ï¼Œå·¨å¤§çš„å•†æœºï¼ŒYasser é©¬ä¸Šä¸­æ­¢äº†åœ¨æ ¡è¯¾ä¸šï¼ŒæŠŠæ‰€æœ‰æ—¶é—´å’Œç²¾åŠ›éƒ½é›†ä¸­åœ¨ Chatbase ä¸Š

[Chatbase.co](https://www.chatbase.co/) æ˜¯ä¸€æ¬¾ä¸ºç½‘ç«™æ„å»ºè‡ªå®šä¹‰ ChatGPT ç•Œé¢çš„å·¥å…·ï¼Œç”¨æˆ·åªéœ€ä¸Šä¼ **æ–‡æ¡£**æˆ–æ·»åŠ åˆ°**ç½‘ç«™é“¾æ¥**ï¼Œå°±å¯ä»¥è·å¾—ä¸€ä¸ªç±»ä¼¼ ChatGPT çš„èŠå¤©æœºå™¨äººï¼Œå¹¶å°†å®ƒä½œä¸ºå°ç»„ä»¶æ·»åŠ åˆ°ç½‘ç«™ä¸Šã€‚

Yasser ç”¨ Reactã€Next.js å’Œ Supabase æ¥æ„ web åº”ç”¨ã€‚Yasser è¿˜åœ¨åº”ç”¨çš„ AI éƒ¨åˆ†ä½¿ç”¨äº† OpenAI çš„ APIã€Langchain è¿˜æœ‰ Pineconeã€‚ä»˜æ¬¾éƒ¨åˆ†ç”¨çš„æ˜¯ Stripeã€‚ç›®å‰è¿™å¥—æŠ€æœ¯æ ˆè¿è¡Œå¾—ä¸é”™ï¼Œä½†åç»­ Yasser å¯èƒ½éœ€è¦åšäº›è°ƒæ•´æ¥æ§åˆ¶æˆæœ¬ï¼Œæ¯”å¦‚å°è¯•ä¸åŒçš„ Vector æ•°æ®åº“æˆ–è€…æ‰˜ç®¡é€‰é¡¹

å¯é›†æˆåˆ°è‡ªå·±çš„ç½‘ç«™, å®˜æ–¹æä¾›[çœ‹æ¿é…ç½®](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX/dashboard)
- ç¤ºä¾‹ï¼š[test](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX)
- å›½å¤–ä»‹ç»ï¼š[How a college student reached $64,000/mo in 6 months by being an AI first mover](https://www.indiehackers.com/post/how-a-college-student-reached-64-000-mo-in-6-months-by-being-an-ai-first-mover-ba7981f6e1)


# ç»“æŸ