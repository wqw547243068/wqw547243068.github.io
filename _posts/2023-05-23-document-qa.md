---
layout: post
title:  æ–‡æ¡£é—®ç­”åŸç†åŠå®è·µ Thoery and Implemetation of the Doucument QA
date:   2023-03-30 19:10:00
categories: æ·±åº¦å­¦ä¹  è‡ªç„¶è¯­è¨€å¤„ç†
tags: ChatGPT å¯¹è¯ç³»ç»Ÿ çŸ¥è¯†åº“ å‘é‡åŒ– milvus
excerpt: æ–‡æ¡£é—®ç­”çš„åŸç†ã€æ¡ˆä¾‹åŠå®è·µ
mathjax: true
permalink: /doc-chat
---

* content
{:toc}

# æ–‡æ¡£é—®ç­”

ã€2023-3-27ã€‘æ–‡æ¡£é—®ç­”

ä½œè€…ï¼š[å¼ºåŒ–å­¦å¾’](https://www.zhihu.com/question/589726461/answer/2961450933)

ã€2023-5-9ã€‘[å¤§è¯­è¨€æ¨¡å‹å®ç°æ™ºèƒ½å®¢æœçŸ¥è¯†åº“æ–‡æ¡£æ•°æ®æå–åŠŸèƒ½](https://www.toutiao.com/article/7231062779061502501)
- æ™ºèƒ½å®¢æœçš„çŸ¥è¯†åº“æœ‰ä¸¤ç±»ï¼š**æœºå™¨äºº**çŸ¥è¯†åº“å’Œ**åå¸­**çŸ¥è¯†åº“ï¼Œåˆ†åˆ«æ˜¯ä¸ºæœºå™¨äººå’Œåå¸­è¿›è¡ŒæœåŠ¡æ—¶ï¼Œæä¾›æ•°æ®çš„æ”¯æ’‘ã€‚
- å¦‚ä½•é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ï¼Œè®©ä¼ä¸šçš„æ–‡æ¡£å¯æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨å‘¢ï¼Ÿ

å½“å‰çš„ä¸»æµå®¢æœäº§å“
- æ™ºèƒ½å®¢æœç³»ç»Ÿä¼šæ ‡é…`çŸ¥è¯†åº“ç®¡ç†`åŠŸèƒ½ï¼Œå¸¸è§çš„å½¢å¼æ˜¯**æ ‘çŠ¶ç»“æ„**ï¼Œæä¾›åˆ†ç±»ç®¡ç†ã€çŸ¥è¯†åº“æ¡ç›®ç®¡ç†ï¼Œå¹¶æ”¯æŒçŸ¥è¯†åº“çš„æ‰¹é‡å¯¼å…¥å¯¼å‡ºæ“ä½œã€‚
- ä½¿ç”¨ä¸­ï¼Œä¼ä¸šéœ€è¦ç»å¸¸æ€§åœ°ç»´æŠ¤ç®¡ç†çŸ¥è¯†åº“å†…å®¹ï¼Œå°†ä¼ä¸šå·²æœ‰çŸ¥è¯†å†…å®¹æ–‡æ¡£ä¸Šä¼ ï¼Œä½†å¦‚æœæ˜¯å°†åŸæ–‡ä»¶ä¸Šä¼ ï¼Œåˆ™ç³»ç»Ÿæœ€å¤šèƒ½æ”¯æŒé¢„è§ˆåŠŸèƒ½ï¼Œä½¿ç”¨è€…åœ¨æ“ä½œç•Œé¢åªèƒ½ç‚¹å‡»æ‰“å¼€å…¨æ–‡æ£€ç´¢ã€‚è€Œå¦‚æœæ˜¯æœºå™¨äººçŸ¥è¯†åº“ï¼Œç›´æ¥ä¸Šä¼ æ–‡æ¡£æ˜¯ä¸å¯ç”¨çš„ï¼Œéœ€è¦æ“ä½œè€…æ‰‹å·¥æ•´ç†æ–‡æ¡£ä¸­çš„å†…å®¹ä¸ºæœºå™¨äººæ ‡å‡†é—®ç­”å¯¹ã€‚

å¤§æ¨¡å‹æ—¶ä»£
- æ‰€æœ‰ä¼ä¸šçš„æ–‡æ¡£å¯ä»¥æ‰¹é‡ä¸Šä¼ ï¼Œæ— éœ€æ›´å¤šçš„æ•´ç†ï¼Œç›´æ¥å¯è‡ªåŠ¨è½¬åŒ–ä¸ºæœ‰æ•ˆçš„QAï¼Œä¾›åº§å¸­å’Œæœºå™¨äººç›´æ¥è°ƒç”¨ã€‚

ã€2023-6-26ã€‘å´æ©è¾¾å¤§æ¨¡å‹ç³»åˆ—è¯¾ç¨‹ï¼š
- [LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain/lesson/1/introduction)
- å­¦ä¹ ç¬”è®°ï¼š[åŸºäºLangChainå¼€å‘å¤§è¯­è¨€åº”ç”¨æ¨¡å‹](https://blog.csdn.net/qq_36080693/article/details/131269201)

## èƒŒæ™¯

### æ–‡æœ¬å‘é‡åŒ–

`åµŒå…¥`ï¼ˆEmbeddingï¼‰æ˜¯ä¸€ç§å°†**æ–‡æœ¬æˆ–å¯¹è±¡**è½¬æ¢ä¸º**å‘é‡è¡¨ç¤º**çš„æŠ€æœ¯ï¼Œå°†è¯è¯­ã€å¥å­æˆ–å…¶ä»–æ–‡æœ¬å½¢å¼è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºã€‚
- åµŒå…¥å‘é‡æ˜¯ç”±ä¸€ç³»åˆ—æµ®ç‚¹æ•°æ„æˆçš„**å‘é‡**ã€‚
- é€šè¿‡è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡ä¹‹é—´çš„è·ç¦»ï¼Œå¯ä»¥è¡¡é‡å®ƒä»¬ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è·ç¦»è¾ƒå°çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ç›¸å…³æ€§ï¼Œè€Œè·ç¦»è¾ƒå¤§çš„åµŒå…¥å‘é‡è¡¨ç¤ºæ–‡æœ¬ä¹‹é—´ç›¸å…³æ€§è¾ƒä½ã€‚

ä»¥ `Milvus` ä¸ºä»£è¡¨çš„`å‘é‡æ•°æ®åº“`åˆ©ç”¨è¯­ä¹‰æœç´¢ï¼ˆSemantic Searchï¼‰æ›´å¿«åœ°æ£€ç´¢åˆ°ç›¸å…³æ€§æ›´å¼ºçš„æ–‡æ¡£ã€‚

è¯¦è§ï¼šsklearnä¸“é¢˜é‡Œçš„[æ–‡æœ¬å‘é‡åŒ–](sklearn#%E5%90%91%E9%87%8F%E5%8C%96)

### Token

ä»€ä¹ˆæ˜¯tokenï¼Ÿ
- tokens ä¸æ˜¯æŒ‡ prompt å­—ç¬¦ä¸²çš„é•¿åº¦ï¼›
- token æŒ‡ä¸€æ®µè¯ä¸­å¯èƒ½è¢«åˆ†å‡ºæ¥çš„**è¯æ±‡**ã€‚
  - æ¯”å¦‚ï¼ši love youï¼Œå°±æ˜¯ä¸‰ä¸ªtokenï¼Œåˆ†åˆ«ä¸º ã€Œiã€ã€Œloveã€ã€Œyouã€ã€‚
- ä¸åŒè¯­è¨€tokenè®¡ç®—ä¸ä¸€æ ·ã€‚[åœ¨çº¿æµ‹è¯•](platform.openai.com/tokenizer)
  - ä¸­æ–‡çš„ã€Œæˆ‘çˆ±ä½ ã€å…¶å®æ˜¯ç®— 5ä¸ªtokenï¼Œå› ä¸ºä¼šå…ˆæŠŠå†…å®¹è½¬æˆ unicodeã€‚
  - æœ‰äº› emoji çš„tokené•¿åº¦ä¼šè¶…å‡ºæƒ³è±¡ï¼Œé•¿è¾¾11ä¸ªã€‚

ChatGPT has an upper limit of 4096

GPT-4 æ”¯æŒï¼Œè¯¦è§[å®˜ç½‘](https://platform.openai.com/docs/models/gpt-4)
- 8k context
- 32k context

| Model | Price for 1000 tokens (prompt) |
|---|---|
| Ada | 2048 |
| Babbage | 2048 | 
| Curie | 2048 |
| DaVinci | 4096 |
| ChatGPT | 4096 |
| GPT-4 8k context | 8192 |
| GPT-4 32k context | 32768 |

Remember, the sum of your prompt and maximum tokens should always be less than equal to the model's maximum token limit, OR your output is truncated.

å¤‡æ³¨
- `ç¼–ç å™¨`ï¼šå¯æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚å¦‚æœåºåˆ—é•¿åº¦å°äºè¯¥é™åˆ¶ï¼Œå°±åœ¨å…¶åå¡«å…¥é¢„å…ˆå®šä¹‰çš„ç©ºç™½å•è¯ã€‚
  - å¦‚ï¼ŒåŸå§‹ transformer è®ºæ–‡ä¸­çš„ç¼–ç å™¨æ¨¡å—å¯ä»¥æ¥å—é•¿åº¦ä¸è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆå¦‚ 512 ä¸ªå•è¯ï¼‰çš„è¾“å…¥ã€‚
- `è§£ç å™¨`ï¼šåŒºåˆ«
  - åŠ å…¥äº†ä¸€å±‚é‡ç‚¹å…³æ³¨ç¼–ç å™¨è¾“å‡ºçš„æŸä¸€ç‰‡æ®µï¼Œ**ç¼–ç å™¨-è§£ç å™¨è‡ªæ³¨æ„åŠ›**ï¼ˆencoder-decoder self-attentionï¼‰å±‚
  - åé¢çš„å•è¯æ©ç›–æ‰äº†ã€‚ä½†å¹¶ä¸åƒ BERT ä¸€æ ·å°†å®ƒä»¬æ›¿æ¢æˆç‰¹æ®Šå®šä¹‰çš„å•è¯ < mask >ï¼Œè€Œæ˜¯åœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—çš„æ—¶å€™å±è”½äº†æ¥è‡ªå½“å‰è®¡ç®—ä½ç½®å³è¾¹æ‰€æœ‰å•è¯çš„ä¿¡æ¯ã€‚

ç»éªŒ
- è‹±æ–‡ï¼š100 tokens ~= 75 words)
- ä¸­æ–‡ï¼šä¸€ä¸ªæ±‰å­—å 2-3ä¸ªtoken
- å…¶å®ƒï¼šemojiè¡¨æƒ…ç¬¦å·ï¼Œå ç”¨æ›´å¤šï¼Œæœ‰çš„é«˜è¾¾11ä¸ª

æ›´å¤šè§ç«™å†…[åˆ†è¯ä¸“é¢˜](https://wqw547243068.github.io/nlp#%E8%AF%8D%E5%BA%93%E6%9E%84%E5%BB%BA)

### å¦‚ä½•å¢å¼ºLLMèƒ½åŠ›


#### Full Stack LLM è¯¾ç¨‹

ã€2023-5-21ã€‘[LLMè®­ç»ƒè¥è¯¾ç¨‹ç¬”è®°â€”Augmented Language Models](https://zhuanlan.zhihu.com/p/630195581)
- [è‹±æ–‡ppt](https://drive.google.com/file/d/1A5RcMETecn6Aa4nNzpVx9kTKdyeErqrI/view), [è®²ä¹‰æ€»ç»“](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)
- There are three ways to augment language models: retrieval, chains, and tools.
- Retrieval involves providing an external corpus of data for the model to search, chains use the output of one language model as input for another, and tools allow models to interact with external data sources.

ã€2023-6-24ã€‘The Full Stack å‡ºå“çš„ LLM Bootcamp Spring 2023
- LLM Foundations [ppt](https://drive.google.com/file/d/1A4Sh6l3cqn0k5ho1vnFOnzU0Fz7dQOK7/view)
- LLM ops å¤§æ¨¡å‹éƒ¨ç½² [ppt](https://drive.google.com/file/d/1LZXTrRdrloIqAJT6xaNTl4WQd6y95o7K/view)
  - LLMOps: Deployment and Learning in Production

å¾ˆéš¾ç”¨ä¼ ç»ŸMLæ–¹æ³•è¯„ä¼°ï¼ŒLLMè¾“å‡ºç‰¹ç‚¹ï¼šå¤šæ ·æ€§

å¦‚ä½•è¯„ä¼°LLMsæ•ˆæœ Evaluation metrics for LLMs
- å¸¸è§„è¯„ä¼°æ ‡å‡†ï¼š å¦‚ æ­£ç¡®ç‡ä¹‹ç±»
- å€Ÿé‰´åŒ¹é…æ ‡å‡†ï¼š
  - è¯­ä¹‰ç›¸ä¼¼åº¦
  - ç”¨å¦ä¸€ä¸ªLLMè¯„åˆ¤ä¸¤ä¸ªå¤§éš¾äº‹å®æ˜¯å¦ä¸€è‡´
- å“ªä¸ªæ›´å¥½ which is better
  - è®©LLMæ ¹æ®æä¾›çš„è¦ç‚¹åˆ¤æ–­ä¸¤ä¸ªç­”æ¡ˆå“ªä¸ªæ›´å¥½
- åé¦ˆæ˜¯å¦åŒ…å« is the feedback incorporated
  - è®©LLMåˆ¤æ–­æ–°ç­”æ¡ˆæ˜¯å¦åŒ…å«æ—§ç­”æ¡ˆä¸Šçš„åé¦ˆ
- ç»Ÿè®¡æŒ‡æ ‡
  - éªŒè¯è¾“å…¥ç»“æ„ï¼Œå¦‚ æ˜¯å¦ jsonæ ¼å¼
  - è®©LLMç»™ç­”æ¡ˆæ‰“åˆ†ï¼Œå¦‚ 1-5åˆ†

æ€»ç»“ï¼Œè¯„ä¼°é¡ºåº
1. æœ‰æ­£ç¡®ç­”æ¡ˆå—ï¼Ÿæ˜¯â†’ç”¨ä¼ ç»ŸMLçš„æŒ‡æ ‡ï¼Œå¦åˆ™
1. æœ‰å‚è€ƒç­”æ¡ˆå—ï¼Ÿæ˜¯â†’ç”¨åŒ¹é…æŒ‡æ ‡ï¼Œæ‹¿å‚è€ƒç­”æ¡ˆè®¡ç®—åŒ¹é…åº¦ï¼Œå¦åˆ™
1. æœ‰å…¶ä»–ç­”æ¡ˆå—ï¼Ÿæ˜¯â†’LLMåˆ¤æ–­å“ªä¸ªæ›´å¥½ï¼ˆwhich is betterï¼‰ï¼Œå¦åˆ™
1. æœ‰äººå·¥åé¦ˆå—ï¼Ÿæ˜¯â†’LLMåˆ¤æ–­åé¦ˆæ˜¯å¦é‡‡çº³ï¼ˆis the feedback incorporatedï¼‰ï¼Œå¦åˆ™
1. ç»Ÿè®¡æŒ‡æ ‡

å¦‚ä½•æå‡ç”Ÿäº§ç¯å¢ƒä¸­LLMsè¾“å‡ºæ•ˆæœ
- åé—®æ¨¡å‹æ˜¯å¦æ­£ç¡® Self-critique è‡ªæˆ‘æ€€ç–‘
  - Ask an LLM â€œis this the right answerâ€
- å¤šæ¬¡è¯·æ±‚é€‰æœ€ä½³ Sample many times, choose the best option
- å¤šæ¬¡è¯·æ±‚é›†æˆ Sample many times, ensemble

å¦‚ä½•æ”¹è¿›æŒç»­promptæ•ˆæœï¼Ÿ
- æ ¹æ®ç”¨æˆ·åé¦ˆäººå·¥ç­›é€‰æœªè§£å†³çš„æ¡ˆä¾‹
- è°ƒæ•´promptï¼Œæ–¹æ³•ï¼šâ‘  æç¤ºå·¥ç¨‹ â‘¡ æ”¹å˜context

é‚£ä¹ˆï¼Œè¿™ä¸ªæµç¨‹å¦‚ä½•è‡ªåŠ¨åŒ–ï¼Ÿ Fine-tuning LLMs å¾®è°ƒå¤§æ¨¡å‹
- SFT
  - æƒ³å°†å¤§æ¨¡å‹é€‚é…åˆ°å…·ä½“ä»»åŠ¡ï¼Œæˆ– ICLæ•ˆæœä¸å¥½
  - æœ‰å¤§é‡é¢†åŸŸæ•°æ®
  - æ„å»ºå°/ä¾¿å®œæ¨¡å‹ï¼Œé™ä½æ€»æˆæœ¬
- åŸºäºäººå·¥åé¦ˆå¾®è°ƒ
  - ç”±äºæŠ€æœ¯å¤æ‚ã€æ˜‚è´µï¼Œæ²¡å¤šå°‘å…¬å¸è‡ªå·±åš
  - æ–¹æ³•ï¼šRLHFã€RLAIF

LLMsçš„SFTç±»å‹ï¼šæ•ˆæœä¸Šé€çº§æå‡ï¼Œä½†è®­ç»ƒæ•ˆç‡ä¸Šä¸æ–­é™ä½
- ï¼ˆ1ï¼‰åŸºäº**ç‰¹å¾**ï¼šå†»ç»“LLMsï¼ˆå¦‚é¢„è®­ç»ƒtransformer)ï¼Œè¾“å‡ºembeddingä¿¡æ¯åï¼Œå•ç‹¬æ›´æ–°é™„åŠ æ¨¡å‹ï¼ˆå¦‚åˆ†ç±»ï¼‰
- ï¼ˆ2ï¼‰**éƒ¨åˆ†å‚æ•°**å¾®è°ƒï¼šå†»ç»“LLMsï¼Œåªæ›´æ–°æ–°å¢çš„å…¨è¿æ¥å±‚å‚æ•°ï¼ˆä¸å†å•ç‹¬åŠ æ¨¡å‹ï¼‰
- ï¼ˆ3ï¼‰**å…¨å‚æ•°**å¾®è°ƒï¼šå…¨éƒ¨å‚æ•°ä¸€èµ·å¾®è°ƒ

PEFTæŠ€æœ¯ï¼šParameter-efficient fine tuning
- Prompt modificationï¼š
  - Hard prompt tuning
  - Soft prompt tuning
  - Prefix tuning
- Adapter methods
  - Adapters: å¦‚ LLaMA-Adapterï¼ˆåŸºäºprefix tuningï¼‰
- Reparameterization
  - LoRAï¼ˆLow rank adaptationï¼‰

LLMé—®é¢˜
- Most common: often UI stuff
  - å“åº”æ—¶é—´é•¿ Latency especially 
- å›ç­”é”™è¯¯/å¹»è§‰ Incorrect answers / â€œhallucinationsâ€ 
- è¿‡äºå•°å—¦ Long-winded answers 
- å›é¿é—®é¢˜ Too many â€œdodgedâ€ questions 
- æç¤ºæ”»å‡» Prompt injection attacks 
- é“å¾·å®‰å…¨ Toxicity, profanity 

LLM Bootcamp 2023 Augmented language models

LLMæ“…é•¿ä»€ä¹ˆï¼ŸWhat (base) LLMs are good at ?
- â€¢ è¯­è¨€ç†è§£ language understanding
- â€¢ éµå¾ªæŒ‡ä»¤ instruction following
- â€¢ åŸºç¡€æ¨ç† basic reasoning
- â€¢ ä»£ç ç†è§£ code understanding

LLMåœ¨å“ªäº›æ–¹é¢éœ€è¦å¸®åŠ©ï¼Ÿ What they need help with ?
- â€¢ è·å–æœ€æ–°çŸ¥è¯† up-to-date knowledge
- â€¢ ç”¨æˆ·æ•°æ®åŒ…å«çš„çŸ¥è¯† knowledge of your data
- â€¢ æ›´æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç† more challenging reasoning
- â€¢ ä¸å¤–ç•Œäº¤äº’ interacting with the world



#### å¦‚ä½•å¢å¼ºLLMèƒ½åŠ›

å¦‚ä½•å¢å¼ºLLMçš„èƒ½åŠ›ï¼Ÿ
- LLMæ›´åŠ æ“…é•¿**é€šç”¨æ¨ç†**ï¼Œè€Œä¸æ˜¯**ç‰¹å®šçŸ¥è¯†**ã€‚
- LLMs are for general reasoning, not specific knowledge

ä¸ºäº†è®©LLMèƒ½å¤Ÿå–å¾—æ›´å¥½çš„è¡¨ç°ï¼Œæœ€å¸¸è§æ–¹æ³•å°±æ˜¯ç»™LLMæä¾›åˆé€‚çš„**ä¸Šä¸‹æ–‡ä¿¡æ¯**å¸®åŠ©LLMè¿›è¡Œæ¨ç†ã€‚
- A baseline: using the context window
- Context is the way to give LLM unique, up-to-date information ... But it only fits a limited amount of information
- ä¸Šä¸‹æ–‡ä¿¡æ¯é€‚åˆæä¾›ç‹¬ç‰¹ã€å®æ—¶ä¿¡æ¯ï¼Œä½†è¿›é€‚ç”¨äºæœ‰é™çš„ä¿¡æ¯é‡


éšç€æœ€è¿‘LLMçš„ä¸æ–­å‘å±•ï¼Œå„ç±»å¤§æ¨¡å‹æ‰€èƒ½æ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡**é•¿åº¦**ä¹Ÿè¶Šæ¥è¶Šå¤§ï¼Œä½†æ˜¯åœ¨å¯é¢„è§çš„ä¸€æ®µæ—¶é—´å†…ä»ä¸å¯èƒ½åŒ…å«æ‰€æœ‰å†…å®¹ï¼Œå¹¶ä¸”è¶Šå¤šçš„ä¸Šä¸‹æ–‡æ„å‘³ç€æ›´å¤šçš„è®¡ç®—æˆæœ¬ã€‚
- Context windows are growing fast, but wonâ€™t fit everything for a while (Plus, more context = more $$$)
- ![](https://pic3.zhimg.com/80/v2-01d520894c2ada7c23aa4f450aae71ca_1440w.webp)

how to make the most of a limited context by augmenting the language model ï¼Ÿ

å¦‚ä½•å……åˆ†åˆ©ç”¨å½“å‰æ‰€èƒ½æ”¯æŒçš„æœ‰é™çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè®©LLMè¡¨ç°æ›´å¥½ï¼Œå€¼å¾—ç ”ç©¶ã€‚

æœ‰é™ä¸‹æ–‡æƒ…å†µä¸‹å……åˆ†æ¿€å‘LLM èƒ½åŠ›çš„æ–¹æ³•æœ‰ä¸‰ç§ï¼š
- æ£€ç´¢ `Retrieval`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å†…ï¼Œå¹¶è¡Œæ‰¾ç›¸å…³å†…å®¹ä½œä¸ºpromptï¼›Augment with a bigger corpus
- é“¾å¼ `Chain`ï¼šç­”æ¡ˆåœ¨æ–‡æ¡£å¤–ï¼Œä¸²è¡Œè¯·æ±‚ï¼›Augment with more LLM calls
- å·¥å…· `Tools`ï¼šè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼›Augment with outside sources

ï¼ˆ1ï¼‰é€šè¿‡**Retrievalå¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å†…</span>
 
outline
- A. Why retrieval augmentation? 
  - Q: We want our model to have access to data from thousands of uses in the context
  - æµ·é‡ç”¨æˆ·æ•°æ®å¡åˆ°contextä¸­
- B. ä¼ ç»Ÿä¿¡æ¯æ£€ç´¢ Traditional information retrievalï¼Œè¦ç´ ï¼š
  - **Query**. Formal statement of your information need. E.g., a search string.
  - **Object**. Entity inside your content collection. E.g., a document. 
  - **Relevance**. Measure of how well an object satisfies the information need
    - é€šè¿‡å¸ƒå°”æœç´¢(boolean search) 
    - E.g., only return the docs that contain: simple AND rest AND apis AND distributed
AND nature
  - **Ranking**. Ordering of relevant results based on desirability
    - é€šè¿‡ BM25, å—3ä¸ªå› ç´ å½±å“ Ranking via BM25. Affected by 3 factors
    - â‘  è¯é¢‘ Term frequency (`TF`) â€” More appearances of search term = more relevant object
    - â‘¡ é€†æ–‡æ¡£æ¦‚ç‡ Inverse document frequency (`IDF`) â€” More objects containing search term = less important search term
    - â‘¢ å­—æ®µé•¿åº¦ Field length â€” If a document contains a search term in a field that is very short (i.e. has few words), it is more likely relevant than a document that contains a search term in a field that is very long (i.e. has many words).
  - æ–¹æ³•ï¼šé€šè¿‡**å€’æ’ç´¢å¼•**æœç´¢ search via inverted indexesï¼Œå¦å¤–è¿˜æœ‰å¾ˆå¤šï¼š
    - æ–‡æ¡£æ³¨å…¥ Document ingestion
    - æ–‡æ¡£å¤„ç† Document processing (e.g., remove stop words, lower case, etc)
    - è½¬æ¢å¤„ç† Transaction handling (adding / deleting documents, merging index files)
    - ç¼©æ”¾ Scaling via shards Ranking & relevance
  - å±€é™æ€§ï¼šLimitations of â€œsparseâ€ traditional search
    - åªå»ºæ¨¡ç®€å•è¯é¢‘ä¿¡æ¯ Only models simple word frequencies
    - æ— æ³•æ•æ‰è¯­ä¹‰ä¿¡æ¯ã€ç›¸å…³ä¿¡æ¯ç­‰ Doesnâ€™t capture semantic information, correlation information, etc
    - E.g., searching for â€œwhat is the top hand in bridgeâ€ might return documents about ğŸŒ‰, â™ , ğŸ’¸
- C. åŸºäºembeddingçš„ä¿¡æ¯æ£€ç´¢ AI-powered Information retrieval via embeddings 
  - Search and AI make each other better
    - `AI`ï¼šBetter representations of data (embeddings)
    - `Search`ï¼š Better information in the context
  - ä»€ä¹ˆæ˜¯embeddingï¼Ÿå­¦ä¹ åˆ°çš„æŠ½è±¡ã€ç¨ å¯†ã€å‹ç¼©ã€å®šé•¿çš„æ•°æ®è¡¨ç¤º
    - Embeddings are an abstract, dense, compact, fixed-size, (usually) learned representation of data
- D. Patterns and case studies

ä¸€ä¸ªå…¸å‹çš„åœ¨æ–‡æ¡£QAåœºæ™¯ä½¿ç”¨æ£€ç´¢æ–¹å¼æ¥å¢å¼ºLLMèƒ½åŠ›çš„æ–¹å¼ï¼Œåˆ†ä¸ºå‡ ä¸ªæµç¨‹ï¼š
*   ç”¨æˆ·é—®é¢˜embedding
*   ä»æµ·é‡æ–‡æ¡£ä¸­æ£€ç´¢å‡ºTop Nä¸é—®é¢˜embeddingç›¸ä¼¼çš„å€™é€‰æ–‡æ¡£
*   åŸºäºTopNæ–‡æ¡£å†…å®¹æ„é€ Prompt
*   è°ƒç”¨LLMè·å–æœ€ç»ˆç­”æ¡ˆ
 
![](https://pic1.zhimg.com/80/v2-72a51d5f2be59ac526ea858e8fe15678_1440w.webp)
 
å¸¸ç”¨çš„RetrievalæŠ€æœ¯
 
å¯¹Retrievalçš„æŠ€æœ¯ç»†èŠ‚ä»¥åŠä¸€äº›å¸¸ç”¨çš„å·¥å…·è¿›è¡Œäº†è¯¦ç»†çš„ä»‹ç»ï¼ŒåŒ…æ‹¬**ä¼ ç»ŸRetrieval**ä»¥åŠ**åŸºäºEmbeddingçš„Retrieval**è¿™ä¸¤ç§æŠ€æœ¯è·¯çº¿ï¼Œ[åŸæ•™ç¨‹](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)å­¦ä¹ æˆ–è€…å‚è€ƒä¸€äº›å…¶ä»–çš„[ä¿¡æ¯æ£€ç´¢èµ„æ–™](https://github.com/%2520%2520sebastian-hofstaetter/teaching)ã€‚
 
ï¼ˆ2ï¼‰é€šè¿‡**Chain**å¢å¼ºLLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>ç­”æ¡ˆåœ¨æ–‡æ¡£å¤–</span>
 
æŸäº›æƒ…å†µä¸‹ï¼Œæœ€ä½³çš„contextå¯èƒ½å¹¶**ä¸å­˜åœ¨äºç”¨æˆ·è¯­æ–™åº“**ä¸­ã€‚ä¸Šä¸€ä¸ªLLMçš„è¾“å‡ºç»“æœå¯èƒ½æ­£å¥½æ˜¯å½“å‰LLMçš„æœ€å¥½çš„è¾“å…¥contextã€‚
 
æ­¤æ—¶ï¼Œå¯ä»¥ç”¨Chainå½¢å¼å°†ä¸åŒçš„LLMè¿æ¥èµ·æ¥ï¼Œå»å¢å¼ºæœ€ç»ˆä»»åŠ¡çš„æ•ˆæœã€‚ä¾‹å¦‚ä¸‹å›¾çš„æ‘˜è¦ä»»åŠ¡ï¼š
- é¦–å…ˆå°†æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œå¯¹äºæ¯ä¸ªéƒ¨åˆ†ä½¿ç”¨LLMåšä¸€ä¸ªå±€éƒ¨æ‘˜è¦ï¼Œç„¶åå†ç”¨LLMå¯¹å„ä¸ªæ‘˜è¦è¿›è¡Œåˆå¹¶è¾“å‡ºå…¨å±€çš„æ‘˜è¦ã€‚
- ![](https://pic3.zhimg.com/80/v2-65144390d9958a95f33a316618a32092_1440w.webp)

å…¸å‹è¿›è¡Œè¿™æ ·ä»»åŠ¡ç¼–æ’çš„å·¥å…·æ˜¯[LangChain](https://github.com/hwchase17/langchain)ï¼Œå¯ä»¥åˆ©ç”¨å®ƒæ¥å¼€å‘å¾ˆå¤šæœ‰æ„æ€çš„åº”ç”¨ã€‚
 
ï¼ˆ3ï¼‰é€šè¿‡**Toolså¢å¼º**LLMçš„èƒ½åŠ› â€”â€” <span style='color:blue'>å€ŸåŠ©å¤–ç•Œå·¥å…·</span>
 
é€šè¿‡å„ç§å„æ ·çš„å·¥å…·è®©LLMä¸å¤–ç•Œè¿›è¡Œäº¤äº’ï¼Œæ¯”å¦‚ä½¿ç”¨æœç´¢å¼•æ“ã€æ‰§è¡ŒSQLè¯­å¥ç­‰ï¼Œä»è€Œå»ä¸°å¯ŒLLMçš„åŠŸèƒ½ã€‚
- æœ‰æ—¶æœ€å¥½çš„contextå¹¶ä¸ç›´æ¥å­˜åœ¨äºè¯­æ–™ï¼Œè€Œæ˜¯æºè‡ªå¦ä¸€ä¸ªLLMçš„è¾“å‡ºã€‚

æ„å»ºå·¥å…·é“¾çš„å‡ ä¸ªæ¡ˆä¾‹ Example patterns for building chains
- é—®ç­”æ¨¡å¼ The QA pattern
  - Question â¡ embedding â¡ similar docs â¡ QA prompt
- å‡æƒ³æ–‡æ¡£æ˜ å°„ Hypothetical document embeddings (HyDE)
  - Question â¡ document generating prompt â¡ rest of QA chain
- æ‘˜è¦ Summarization
  - Document corpus â¡ apply a summarization prompt to each â¡ pass all document summaries to another prompt â¡ get global summary back

Toolsæ–¹å¼å¤§è‡´æœ‰ä¸¤ç§
- ä¸€ç§æ˜¯åŸºäº**Chain**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¿…é€‰é¡¹**ï¼Œå‰é¢æœ‰ä¸€ä¸ªLLMæ¥æ„é€ Toolçš„è¾“å…¥ï¼Œåé¢ä¼šæœ‰å¦ä¸€ä¸ªLLMæ¥æ€»ç»“Toolçš„è¾“å‡ºå¹¶å¾—åˆ°æœ€ç»ˆçš„ç»“æœï¼›
- ä¸€ç§æ˜¯åŸºäº**Plugin**çš„æ–¹å¼ï¼ŒToolæ˜¯ä¸€ä¸ª**å¯é€‰é¡¹**ï¼Œè®©LLMæ¥å†³å®šç”¨ä¸ç”¨ä»¥åŠæ€ä¹ˆç”¨Toolã€‚

![](https://pic2.zhimg.com/80/v2-2038fc84985ec24ed8831bf66f16a4b1_1440w.webp)

æ€»ç»“
- â€¢ é€šè¿‡ä¸å¤–ç•Œæ•°æ®çš„äº¤äº’ï¼ŒLLMçš„èƒ½åŠ›èƒ½å¤Ÿæ›´åŠ å¼ºå¤§ã€‚
- â€¢ é€šè¿‡ä½¿ç”¨è§„åˆ™å’Œå¯å‘å¼æ–¹æ³•ï¼Œå¯ä»¥å®ç°å„ç§å„æ ·çš„åŠŸèƒ½ã€‚

éšç€çŸ¥è¯†åº“çš„æ‰©å¤§ï¼Œåº”è¯¥å°†å…¶è§†ä¸ºä¸€ä¸ª**ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿ**ã€‚ä½¿ç”¨Chainçš„æ–¹å¼å¯ä»¥å¸®åŠ©ç¼–ç æ›´å¤æ‚çš„æ¨ç†ï¼Œå¹¶ä¸”ç»•è¿‡tokené•¿åº¦çš„é™åˆ¶ã€‚å„ç§å„æ ·çš„å¤–éƒ¨å·¥å…·å¯ä»¥è®©æ¨¡å‹è®¿é—®æ›´å¤šçš„èµ„æºã€‚


## æ–¹æ³•æ€»ç»“

[ä½œè€…](https://www.zhihu.com/question/591935281/answer/2961925796)

å¸¸è§çš„æ–¹æ³•ï¼š
- `retrieve-then-generate`ï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
  - æ ¹æ®è¾“å…¥queryæ¥æŠ½å–ç›¸å…³å¤–éƒ¨æ–‡æœ¬ï¼ŒæŠŠæŠ½å–åˆ°çš„æ–‡æœ¬å’Œqueryä¸€èµ·ä½œä¸ºpromptå†æ¥åšåç»­å­—ç¬¦çš„æ¨ç†ã€‚
  - chatpdfè¿™ç§äº§å“çš„æ–¹æ³•ä¹Ÿç±»ä¼¼ï¼Œå…ˆæŠŠä½ è¾“å…¥çš„æ–‡æ¡£åˆ†æˆå¤šä¸ªchunkåˆ†åˆ«åšembeddingæ”¾åˆ°å‘é‡æ•°æ®åº“é‡Œï¼Œç„¶åæ ¹æ®è¾“å…¥embeddingçš„å‘é‡åšåŒ¹é…ï¼Œå†æŠŠåŒ¹é…åˆ°çš„å‘é‡å¯¹åº”çš„chunkå’Œè¾“å…¥ä¸€èµ·ä½œä¸ºpromptç»™LLMã€‚
  - è®ºæ–‡ï¼šã€2020-2-10ã€‘[REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)
- `Fine-tuning`ï¼šFine-tuningæ˜¯æŒ‡åœ¨å·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨**æ–°æ•°æ®é›†**å†æ¬¡è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿æ¨¡å‹é’ˆå¯¹ç‰¹å®šä»»åŠ¡æˆ–ç‰¹å®šé¢†åŸŸçš„è¯­è¨€ä½¿ç”¨æƒ…å†µè¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨Fine-tuningè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†**é¢å¤–çŸ¥è¯†**ä½œä¸ºæ–°çš„æ•°æ®é›†åŠ å…¥åˆ°è®­ç»ƒä¸­ã€‚
- `Knowledge Distillation`ï¼šKnowledge Distillationæ˜¯æŒ‡å°†ä¸€ä¸ªâ€œå¤§æ¨¡å‹â€çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªâ€œå°æ¨¡å‹â€ä¸­ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„GPT/LLMæ¨¡å‹çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªå°å‹çš„æ¨¡å‹ä¸­ï¼Œä½¿å¾—å°å‹æ¨¡å‹èƒ½å¤Ÿä½¿ç”¨å¤§å‹æ¨¡å‹ä¸­çš„çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é€šè¿‡å°†é¢å¤–çš„çŸ¥è¯†åŠ å…¥åˆ°â€œå¤§æ¨¡å‹â€ä¸­ï¼Œä»è€Œä½¿å¾—â€œå°æ¨¡å‹â€å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†ã€‚
- `æ•°æ®å¢å¼º`ï¼šæ•°æ®å¢å¼ºæ˜¯æŒ‡åœ¨å·²æœ‰çš„æ•°æ®é›†ä¸­ï¼Œæ·»åŠ ä¸€äº›ç±»ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒçš„æ•°æ®æ¥å¢åŠ æ•°æ®çš„æ•°é‡å’Œå¤šæ ·æ€§ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿å¾—æ¨¡å‹æ›´åŠ å…¨é¢åœ°å­¦ä¹ åˆ°ä¸åŒçš„è¯­è¨€ä½¿ç”¨æƒ…å†µï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆæœã€‚åœ¨æ•°æ®å¢å¼ºçš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥æ·»åŠ é¢å¤–çš„çŸ¥è¯†ï¼Œä¾‹å¦‚åŒä¹‰è¯ã€åä¹‰è¯ã€ä¸“ä¸šæœ¯è¯­ç­‰ã€‚
  - è¯å‘é‡ï¼šå°†é¢†åŸŸç‰¹å®šçš„è¯æ±‡å’Œè¯å‘é‡æ·»åŠ åˆ°æ¨¡å‹çš„è¯æ±‡è¡¨ä¸­ã€‚è¿™äº›è¯æ±‡å¯ä»¥æ˜¯åœ¨ç›®æ ‡é¢†åŸŸä¸­ç‹¬æœ‰çš„è¯æ±‡æˆ–è€…åœ¨å¸¸è§„æ•°æ®é›†ä¸­ç¼ºå¤±çš„è¯æ±‡ã€‚
  - å¤–éƒ¨æ•°æ®é›†ï¼šä»å¤–éƒ¨æ•°æ®é›†ä¸­æ”¶é›†ä¸ç›®æ ‡é¢†åŸŸç›¸å…³çš„æ•°æ®ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦æ‰¾åˆ°ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨é€‚å½“çš„æ–¹æ³•å°†å…¶åˆå¹¶åˆ°æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ã€‚
  - å¤–éƒ¨çŸ¥è¯†åº“ï¼šå°†å¤–éƒ¨çš„çŸ¥è¯†åº“ï¼Œå¦‚ç™¾ç§‘å…¨ä¹¦ã€çŸ¥è¯†å›¾è°±ç­‰ï¼Œä¸æ¨¡å‹é›†æˆï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥ä½¿ç”¨è¿™äº›çŸ¥è¯†æ¥è¾…åŠ©å…¶ç”Ÿæˆæ–‡æœ¬ã€‚
  - äººå·¥æ ‡æ³¨ï¼šé€šè¿‡äººå·¥æ ‡æ³¨çš„æ–¹å¼ï¼Œå°†é¢†åŸŸç‰¹å®šçš„ä¿¡æ¯æ·»åŠ åˆ°è®­ç»ƒæ•°æ®ä¸­ã€‚è¿™ç§æ–¹æ³•éœ€è¦å¤§é‡çš„äººåŠ›å’Œæ—¶é—´ï¼Œå¹¶ä¸”å¯¹äºå¤§å‹æ•°æ®é›†æ¥è¯´å¯èƒ½ä¸åˆ‡å®é™…ã€‚
- `å¤šä»»åŠ¡å­¦ä¹ `ï¼šå¤šä»»åŠ¡å­¦ä¹ æ˜¯æŒ‡åŒæ—¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹å®Œæˆå¤šä¸ªä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨è®­ç»ƒGPT/LLMæ¨¡å‹æ—¶ï¼Œå¯ä»¥è®©æ¨¡å‹åŒæ—¶å®Œæˆæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ï¼Œä»è€Œä½¿å¾—æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ›´åŠ å¤šæ ·åŒ–çš„çŸ¥è¯†ã€‚åœ¨å¤šä»»åŠ¡å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†é¢å¤–çš„çŸ¥è¯†æ·»åŠ åˆ°å…¶ä»–ä»»åŠ¡ä¸­ï¼Œä»è€Œé—´æ¥åœ°å½±å“åˆ°æ¨¡å‹åœ¨ä¸»è¦ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

ã€2023-4-22ã€‘åŸºäºllama-indexå’ŒChatGPT APIå®šåˆ¶ç§æœ‰å¯¹è¯æœºå™¨äººçš„æ–¹å¼ã€‚

æ–¹æ¡ˆ
- 1ã€fine-tuneså¾®è°ƒã€‚ç”¨å¤§é‡æ•°æ®å¯¹GPTæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°ä¸€ä¸ªç†è§£æ–‡æ¡£çš„æ¨¡å‹ã€‚
  - ä½†å¾®è°ƒéœ€è¦èŠ±è´¹å¾ˆå¤šmoneyï¼Œè€Œä¸”éœ€è¦ä¸€ä¸ªæœ‰å®ä¾‹çš„å¤§æ•°æ®é›†ã€‚ä¹Ÿä¸å¯èƒ½åœ¨æ–‡ä»¶æœ‰å˜åŒ–æ—¶æ¯æ¬¡éƒ½è¿›è¡Œå¾®è°ƒã€‚
  - å¾®è°ƒä¸å¯èƒ½è®©æ¨¡å‹ â€œçŸ¥é“â€œ æ–‡æ¡£ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œæ˜¯è¦æ•™ç»™æ¨¡å‹ä¸€ç§æ–°çš„æŠ€èƒ½ã€‚
  - å› æ­¤ï¼Œå¾®è°ƒä¸æ˜¯ä¸€ä¸ªå¥½åŠæ³•ã€‚
- 2ã€å°†ç§æœ‰æ–‡æœ¬å†…å®¹ä½œä¸ºpromptçš„ä¸Šä¸‹æ–‡ï¼Œè®¿é—®ChatGPTã€‚
  - openai apiå­˜åœ¨æœ€å¤§é•¿åº¦çš„é™åˆ¶ï¼ŒChatGPT 3.5çš„æœ€å¤§tokenæ•°ä¸º4096ï¼Œå¦‚æœè¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œä¼šç›´æ¥å¯¹æ–‡æ¡£æˆªæ–­ï¼Œå­˜åœ¨ä¸Šä¸‹æ–‡ä¸¢å¤±çš„é—®é¢˜ã€‚
  - å¹¶ä¸”apiçš„è°ƒç”¨è´¹ç”¨å’Œtokené•¿åº¦æˆæ­£æ¯”ï¼Œtokensæ•°å¤ªå¤§ï¼Œåˆ™æ¯æ¬¡è°ƒç”¨çš„æˆæœ¬ä¹Ÿä¼šå¾ˆé«˜ã€‚

### è¾“å…¥é•¿åº¦é™åˆ¶

ã€2023-7-26ã€‘[æµ…è°ˆLLMçš„é•¿åº¦å¤–æ¨](https://mp.weixin.qq.com/s/5_mBahrpeA2cHlTXylgF9w)

éšç€å¤§æ¨¡å‹åº”ç”¨çš„ä¸æ–­å‘å±•ï¼ŒçŸ¥è¯†å¤–æŒ‚å·²ç»æˆä¸ºäº†é‡è¦æ‰‹æ®µã€‚ä½†åªæ˜¯å¤–æŒ‚æ‰‹æ®µå¾€å¾€å—é™äºæ¨¡å‹æœ¬èº«**å¯æ¥å—é•¿åº¦**ï¼Œä»¥åŠæ¨¡å‹å¤–æ¨èƒ½åŠ›ã€‚

æˆªæ­¢20230724ï¼Œå¤–æ¨ç­–ç•¥ï¼šNBCEï¼Œçº¿æ€§å†…æ’ï¼ŒNTK-Aware Scaled RoPEï¼ŒDynamically Scaled RoPEï¼Œconsistent of Dynamically Scaled RoPEã€‚

#### NBCE

NBCEï¼šä½¿ç”¨æœ´ç´ è´å¶æ–¯æ‰©å±•LLMçš„Contextå¤„ç†é•¿åº¦ï¼Œ[ä»‹ç»](https://kexue.fm/archives/9617)
- è‹ç¥æœ€æ—©æå‡ºçš„æ‰©å±•LLMçš„contextæ–¹æ³•ï¼ŒåŸºäºbayeså¯å‘å¾—åˆ°çš„å…¬å¼
- åœ¨é—®ç­”ä¸‹å®æµ‹ç¡®å®ä¸é”™ï¼Œåœ¨è¾ƒé•¿contextä¸‹çš„é˜…è¯»ç†è§£è¿˜ç®—å¥½ç”¨ã€‚

å±€é™
- æ— åºæ€§ï¼Œå³æ— æ³•è¯†åˆ«Contextçš„è¾“å…¥é¡ºåºï¼Œè¿™åœ¨ç»­å†™æ•…äº‹ç­‰åœºæ™¯å¯èƒ½è¡¨ç°æ¬ ä½³ï¼Œåšä¸€äº›ä¾èµ–æ¯ä¸ªcontextç”Ÿæˆç­”æ¡ˆï¼Œæ¯”å¦‚æå–æ–‡æ¡£æ‘˜è¦ï¼Œæ•ˆæœè¾ƒå·®

```py
outputs = model(input_ids=input_ids,
                        attention_mask=attention_mask,
                        return_dict=True,
                        use_cache=True,
                        past_key_values=past_key_values
                       )
past_key_values = outputs.past_key_values
        
# ===== æ ¸å¿ƒä»£ç å¼€å§‹ =====
beta = 0.25
probas = torch.nn.functional.softmax(outputs.logits[:, -1], dim=-1)
logits = probas.log()
k = (probas * logits).sum(dim=-1)[1:].argmax() + 1
logits_max = logits[k]
logits_uncond = logits[0]
logits = (1 + beta) * logits_max - beta * logits_uncond
# ===== æ ¸å¿ƒä»£ç ç»“æŸ =====
        
# æ„å»ºåˆ†å¸ƒï¼Œé‡‡æ ·
tau = 0.01  # tau = 1æ˜¯æ ‡å‡†çš„éšæœºé‡‡æ ·ï¼Œtau->0åˆ™æ˜¯è´ªå¿ƒæœç´¢
probas = torch.nn.functional.softmax(logits[None] / tau , dim=-1)
next_tokens = torch.multinomial(probas, num_samples=1).squeeze(1)  
```

#### çº¿æ€§å†…æ’

llama åŸºäº rotary embeddingåœ¨2048é•¿åº¦ä¸Šé¢„è®­ç»ƒï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†positionå‹ç¼©åˆ°0~2048ä¹‹é—´ï¼Œä»è€Œè¾¾åˆ°é•¿åº¦å¤–æ¨çš„ç›®çš„ã€‚

longchatå°†æ¨¡å‹å¾®è°ƒä¸ºä¸Šä¸‹æ–‡é•¿åº¦å¤–æ‰©ä¸º16384ï¼Œå‹ç¼©æ¯”ä¸º 8ã€‚ä¾‹å¦‚ï¼Œposition_ids = 10000 çš„ token å˜ä¸ºposition_ids = 10000 / 8 = 1250ï¼Œç›¸é‚» token 10001 å˜ä¸º 10001 / 8 = 1250.125

è¯¥æ–¹æ³•çš„ç¼ºé™·æ˜¯éœ€è¦è¿›è¡Œä¸€å®šé‡çš„å¾®è°ƒï¼Œè®©æ¨¡å‹æ¥é€‚åº”è¿™ç§æ”¹å˜ã€‚

èµ„æ–™
- [context](https://kaiokendev.github.io/context)
- lmsys [longchat](https://lmsys.org/blog/2023-06-29-longchat/)

#### NTK-Aware Scaled RoPE

NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.
- [refer](https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/)

RoPEæ˜¯ä¸€ç§Î²è¿›åˆ¶ç¼–ç : [re](https://spaces.ac.cn/archives/9675)

RoPE çš„è¡Œä¸ºå°±åƒä¸€ä¸ªæ—¶é’Ÿã€‚12å°æ—¶æ—¶é’ŸåŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªç»´åº¦ä¸º 3ã€åº•æ•°ä¸º 60 çš„ RoPEã€‚å› æ­¤ï¼Œæ¯ç§’é’Ÿï¼Œåˆ†é’ˆè½¬åŠ¨ 1/60 åˆ†é’Ÿï¼Œæ¯åˆ†é’Ÿï¼Œæ—¶é’ˆè½¬åŠ¨ 1/60ã€‚ç°åœ¨ï¼Œå¦‚æœå°†æ—¶é—´å‡æ…¢ 4 å€ï¼Œé‚£å°±æ˜¯äºŒä½¿ç”¨çš„çº¿æ€§RoPE ç¼©æ”¾ã€‚ä¸å¹¸çš„æ˜¯ï¼Œç°åœ¨åŒºåˆ†æ¯ä¸€ç§’ï¼Œå› ä¸ºç°åœ¨ç§’é’ˆå‡ ä¹æ¯ç§’éƒ½ä¸ä¼šç§»åŠ¨ã€‚å› æ­¤ï¼Œå¦‚æœæœ‰äººç»™ä½ ä¸¤ä¸ªä¸åŒçš„æ—¶é—´ï¼Œä»…ç›¸å·®ä¸€ç§’ï¼Œä½ å°†æ— æ³•ä»è¿œå¤„åŒºåˆ†å®ƒä»¬ã€‚NTK-Aware RoPE æ‰©å±•ä¸ä¼šå‡æ…¢æ—¶é—´ã€‚ä¸€ç§’ä»ç„¶æ˜¯ä¸€ç§’ï¼Œä½†å®ƒä¼šä½¿åˆ†é’Ÿå‡æ…¢ 1.5 å€ï¼Œå°†å°æ—¶å‡æ…¢ 2 å€ã€‚è¿™æ ·ï¼Œæ‚¨å¯ä»¥å°† 90 åˆ†é’Ÿå®¹çº³åœ¨ä¸€ä¸ªå°æ—¶ä¸­ï¼Œå°† 24 å°æ—¶å®¹çº³åœ¨åŠå¤©ä¸­ã€‚æ‰€ä»¥ç°åœ¨ä½ åŸºæœ¬ä¸Šæœ‰äº†ä¸€ä¸ªå¯ä»¥æµ‹é‡ 129.6k ç§’è€Œä¸æ˜¯ 43.2k ç§’çš„æ—¶é’Ÿã€‚ç”±äºåœ¨æŸ¥çœ‹æ—¶é—´æ—¶ä¸éœ€è¦ç²¾ç¡®æµ‹é‡æ—¶é’ˆï¼Œå› æ­¤ä¸ç§’ç›¸æ¯”ï¼Œæ›´å¤§ç¨‹åº¦åœ°ç¼©æ”¾å°æ—¶è‡³å…³é‡è¦ã€‚ä¸æƒ³å¤±å»ç§’é’ˆçš„ç²¾åº¦ï¼Œä½†å¯ä»¥æ‰¿å—åˆ†é’ˆç”šè‡³æ—¶é’ˆçš„ç²¾åº¦æŸå¤±ã€‚

#### Dynamically Scaled RoPE

[dynamically_scaled_rope_further_increases](https://www.reddit.com/r/LocalLLaMA/comments/14mrgpr/dynamically_scaled_rope_further_increases/)

æ–¹æ³•äºŒã€ä¸‰ï¼Œéƒ½æ¶‰åŠåˆ°ä¸€ä¸ªè¶…å‚æ•°Î±ï¼Œç”¨äºè°ƒèŠ‚ç¼©æ”¾æ¯”ä¾‹ï¼Œè¯¥æ–¹æ³•æ˜¯é€šè¿‡åºåˆ—é•¿åº¦åŠ¨æ€é€‰æ‹©æ­£ç¡®çš„æ¯”ä¾‹å‚æ•°ï¼Œæ•ˆæœå¯ä»¥çœ‹ä¸Šå›¾ã€‚

å¯¹äºçº¿æ€§æ’å€¼ï¼Œå‰ 2k ä¸Šä¸‹æ–‡çš„ç²¾ç¡®ä½ç½®å€¼ï¼Œç„¶ååœ¨æ¨¡å‹é€ä¸ªç”Ÿæˆæ ‡è®°æ—¶é‡æ–°è®¡ç®—æ¯ä¸ªæ–°åºåˆ—é•¿åº¦çš„ä½ç½®å‘é‡ã€‚æœ¬è´¨ä¸Šï¼Œå°†æ¯”ä¾‹è®¾ç½®ä¸ºåŸå§‹æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦/å½“å‰åºåˆ—é•¿åº¦ã€‚

å¯¹äºåŠ¨æ€ NTKï¼ŒÎ± çš„ç¼©æ”¾è®¾ç½®ä¸º (Î± * å½“å‰åºåˆ—é•¿åº¦ / åŸå§‹æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦) - (Î± - 1)ã€‚éšç€åºåˆ—é•¿åº¦çš„å¢åŠ åŠ¨æ€ç¼©æ”¾è¶…å‚æ•°ã€‚

#### consistent of Dynamically Scaled RoPE

[Consistent-DynamicNTKRoPE](https://github.com/NormXU/Consistent-DynamicNTKRoPE)


### è¾“å‡ºé•¿åº¦å—é™

#### RecurrentGPTï¼ˆè¾“å‡ºä¸å—é™ï¼‰

ã€2023-5-30ã€‘[ChatGPTèƒ½å†™é•¿ç¯‡å°è¯´äº†ï¼ŒETHæå‡ºRecurrentGPTå®ç°äº¤äº’å¼è¶…é•¿æ–‡æœ¬](https://www.toutiao.com/article/7238442944003310084)
- è‹é»ä¸–è”é‚¦ç†å·¥å’Œæ³¢å½¢æ™ºèƒ½çš„å›¢é˜Ÿå‘å¸ƒäº† RecurrentGPTï¼Œä¸€ç§è®©å¤§è¯­è¨€æ¨¡å‹ (å¦‚ ChatGPT ç­‰) èƒ½å¤Ÿæ¨¡æ‹Ÿ RNN/LSTMï¼Œé€šè¿‡ Recurrent Prompting æ¥å®ç°äº¤äº’å¼**è¶…é•¿**æ–‡æœ¬ç”Ÿæˆï¼Œè®©åˆ©ç”¨ ChatGPT è¿›è¡Œé•¿ç¯‡å°è¯´åˆ›ä½œæˆä¸ºäº†å¯èƒ½ã€‚
- [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2305.13304)
- [é¡¹ç›®åœ°å€](https://github.com/aiwaves-cn/RecurrentGPT)
- åœ¨çº¿ Demo: [é•¿ç¯‡å°è¯´å†™ä½œ](https://www.aiwaves.org/recurrentgpt), [äº¤äº’å¼å°è¯´](https://www.aiwaves.org/interactivefiction)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a679b4e41e0d483bae2b1ac35ae2da63~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034283&x-signature=1GLOG8XAvQwzzXbm0v1ip16bz5Q%3D)

Transformer å¤§è¯­è¨€æ¨¡å‹æœ€æ˜æ˜¾çš„é™åˆ¶ä¹‹ä¸€: è¾“å…¥å’Œè¾“å‡ºçš„**é•¿åº¦é™åˆ¶**ã€‚
- è™½ç„¶è¾“å…¥ç«¯çš„é•¿åº¦é™åˆ¶å¯ä»¥é€šè¿‡ **VectorDB** ç­‰æ–¹å¼ç¼“è§£
- è¾“å‡ºå†…å®¹çš„é•¿åº¦é™åˆ¶å§‹ç»ˆæ˜¯é•¿å†…å®¹ç”Ÿæˆçš„å…³é”®éšœç¢ã€‚

ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¿‡å»å¾ˆå¤šç ”ç©¶è¯•å›¾ä½¿ç”¨åŸºäºå‘é‡åŒ–çš„ State æˆ– Memory æ¥è®© Transformer å¯ä»¥è¿›è¡Œ**å¾ªç¯**è®¡ç®—ã€‚è¿™æ ·çš„æ–¹æ³•è™½ç„¶åœ¨é•¿æ–‡æœ¬å»ºæ¨¡ä¸Šå±•ç°äº†ä¸€å®šçš„ä¼˜åŠ¿ï¼Œä½†æ˜¯å´è¦æ±‚ä½¿ç”¨è€…æ‹¥æœ‰å¹¶å¯ä»¥**ä¿®æ”¹æ¨¡å‹çš„ç»“æ„å’Œå‚æ•°**ï¼Œè¿™åœ¨ç›®å‰é—­æºæ¨¡å‹é¥é¥é¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ä¸­æ˜¯ä¸ç¬¦åˆå®é™…çš„ã€‚

RecurrentGPT åˆ™å¦è¾Ÿè¹Šå¾„ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œ**äº¤äº’å¼**é•¿æ–‡æœ¬ç”Ÿæˆçš„é¦–ä¸ªæˆåŠŸå®è·µã€‚å®ƒåˆ©ç”¨ ChatGPT ç­‰å¤§è¯­è¨€æ¨¡å‹ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æ¨¡æ‹Ÿäº†å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNsï¼‰çš„å¾ªç¯è®¡ç®—æœºåˆ¶ã€‚
- æ¯ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ï¼ŒRecurrentGPT ä¼šæ¥æ”¶ä¸Šä¸€ä¸ªæ—¶é—´æ­¥ç”Ÿæˆçš„å†…å®¹ã€æœ€è¿‘ç”Ÿæˆå†…å®¹çš„æ‘˜è¦ï¼ˆçŸ­æœŸè®°å¿†ï¼‰ï¼Œå†å²ç”Ÿæˆå†…å®¹ä¸­å’Œå½“å‰æ—¶é—´æ­¥æœ€ç›¸å…³çš„å†…å®¹ (é•¿æœŸè®°å¿†)ï¼Œä»¥åŠä¸€ä¸ªå¯¹ä¸‹ä¸€æ­¥ç”Ÿæˆå†…å®¹çš„æ¢—æ¦‚ã€‚RecurrentGPT æ ¹æ®è¿™äº›å†…å®¹ç”Ÿæˆä¸€æ®µå†…å®¹ï¼Œæ›´æ–°å…¶é•¿çŸ­æ—¶è®°å¿†ï¼Œå¹¶æœ€åç”Ÿæˆå‡ ä¸ªå¯¹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ç”Ÿæˆå†…å®¹çš„è§„åˆ’ï¼Œå¹¶å°†å½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ã€‚è¿™æ ·çš„å¾ªç¯è®¡ç®—æœºåˆ¶æ‰“ç ´äº†å¸¸è§„Transformer æ¨¡å‹åœ¨ç”Ÿæˆé•¿ç¯‡æ–‡æœ¬æ–¹é¢çš„é™åˆ¶ï¼Œä»è€Œå®ç°ä»»æ„é•¿åº¦æ–‡æœ¬çš„ç”Ÿæˆï¼Œè€Œä¸é—å¿˜è¿‡å»çš„ä¿¡æ¯ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/f1bd9be64d144e18914652db4ce325c8~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034283&x-signature=4WMRfq0FjPeJxmK0ujy7roS3sbA%3D)


### llama-index

ã€2023-4-23ã€‘å‚è€ƒ
- [å®šåˆ¶è‡ªå·±çš„æ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/623523968)
- [LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

æ—¢ç„¶tokensæœ‰é™åˆ¶ï¼Œé‚£ä¹ˆæœ‰æ²¡æœ‰å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œ**é¢„å¤„ç†**çš„å·¥å…·ï¼Ÿä¸è¶…è¿‡tokenæ•°é™åˆ¶ã€‚
- å€ŸåŠ©llama-indexå¯ä»¥ä»æ–‡æœ¬ä¸­åªæå–å‡ºç›¸å…³éƒ¨åˆ†ï¼Œç„¶åå°†å…¶åé¦ˆç»™promptã€‚
- [llama-index](https://gpt-index.readthedocs.io/en/latest/), [github](https://github.com/jerryjliu/llama_index)æ”¯æŒè®¸å¤šä¸åŒçš„æ•°æ®æºï¼Œå¦‚APIã€PDFã€æ–‡æ¡£ã€SQL ã€Google Docsç­‰ã€‚

[llama-index](https://gpt-index.readthedocs.io/en/latest/) Ecosystem
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼šsupport parsing a wide range of file types: .pdf, .jpg, .png, .docx, etc.
- ğŸ¡ [LlamaHub](https://llamahub.ai), åŒ…å«å„ç±»æ’ä»¶ï¼Œå¦‚ï¼šç½‘é¡µã€faissè¯­ä¹‰ç´¢å¼•ã€bç«™è§†é¢‘è„šæœ¬ã€ESã€Milvusã€æ•°æ®åº“ç­‰
- ğŸ§ª [LlamaLab](https://github.com/run-llama/llama-lab)

ã€2023-5-17ã€‘[åŸºäºChatGPTçš„è§†é¢‘æ‘˜è¦åº”ç”¨å¼€å‘](https://www.toutiao.com/article/7230786095158690362)
- å½“æ–‡æ¡£è¢«é€å…¥ LLM æ—¶ï¼Œå®ƒä¼šæ ¹æ®å…¶å¤§å°åˆ†æˆå—æˆ–èŠ‚ç‚¹ã€‚ ç„¶åå°†è¿™äº›å—è½¬æ¢ä¸ºåµŒå…¥å¹¶å­˜å‚¨ä¸ºå‘é‡ã€‚
- å½“æç¤ºç”¨æˆ·æŸ¥è¯¢æ—¶ï¼Œæ¨¡å‹å°†æœç´¢å‘é‡å­˜å‚¨ä»¥æ‰¾åˆ°æœ€ç›¸å…³çš„å—å¹¶æ ¹æ®è¿™äº›ç‰¹å®šå—ç”Ÿæˆç­”æ¡ˆã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨å¤§å‹æ–‡æ¡£ï¼ˆå¦‚ 20 åˆ†é’Ÿçš„è§†é¢‘è½¬å½•æœ¬ï¼‰ä¸ŠæŸ¥è¯¢â€œæ–‡ç« æ‘˜è¦â€ï¼Œæ¨¡å‹å¯èƒ½åªä¼šç”Ÿæˆæœ€å 5 åˆ†é’Ÿçš„æ‘˜è¦ï¼Œå› ä¸ºæœ€åä¸€å—ä¸ä¸Šä¸‹æ–‡æœ€ç›¸å…³ çš„â€œæ€»ç»“â€ã€‚
- ![image](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d0a76dbf2a11400f97220283ea233fa9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=dohd7TRWXXfBH5PRvGLj3ldXBh0%3D)

æµç¨‹å›¾
- ![flow](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/38966bfef5f641f294301647b92def7e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684911936&x-signature=Mdb8NbIuzxqhc1X9FW60XawIOK0%3D)

ä¸€ç§å…¨æ–°çš„ LlamaIndex æ•°æ®ç»“æ„ï¼š**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**ï¼Œä¸ä¼ ç»Ÿ**è¯­ä¹‰æœç´¢**ç›¸æ¯”ï¼Œæ£€ç´¢æ€§èƒ½æ›´å¥½

å¤šæ•°æ„å»º LLM æ”¯æŒçš„ QA ç³»ç»Ÿæ­¥éª¤ï¼š
- è·å–**æºæ–‡æ¡£**ï¼Œå°†æ¯ä¸ªæ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**
- å°†**æ–‡æœ¬å—**å­˜å‚¨åœ¨**å‘é‡æ•°æ®åº“**ä¸­
- æŸ¥è¯¢æ—¶ï¼Œé€šè¿‡**åµŒå…¥ç›¸ä¼¼æ€§** å’Œ/æˆ– **å…³é”®å­—è¿‡æ»¤å™¨**æ¥æ£€ç´¢æ–‡æœ¬å—ã€‚
- æ‰§è¡Œå“åº”å¹¶**æ±‡æ€»**ç­”æ¡ˆ

ç”±äºå„ç§åŸå› ï¼Œè¿™ç§æ–¹æ³•æ£€ç´¢æ€§èƒ½æœ‰é™ã€‚
- æ–‡æœ¬å—**ç¼ºä¹å…¨å±€ä¸Šä¸‹æ–‡**ã€‚é€šå¸¸queryä¸Šä¸‹æ–‡è¶…å‡ºäº†ç‰¹å®šå—ä¸­ç´¢å¼•çš„å†…å®¹ã€‚
- ä»”ç»†è°ƒæ•´ top-k / ç›¸ä¼¼åº¦åˆ†æ•°é˜ˆå€¼ã€‚
  - å‡è®¾å€¼å¤ªå°ï¼Œä½ ä¼šé”™è¿‡ä¸Šä¸‹æ–‡ã€‚
  - å‡è®¾å€¼å€¼å¤ªå¤§ï¼Œå¹¶ä¸”æˆæœ¬/å»¶è¿Ÿå¯èƒ½ä¼šéšç€æ›´å¤šä¸ç›¸å…³çš„ä¸Šä¸‹æ–‡è€Œå¢åŠ ï¼Œå™ªéŸ³å¢åŠ ã€‚
- åµŒå…¥é€‰æ‹©çš„ä¸Šä¸‹æ–‡ä¸ä¸€å®šæœ€ç›¸å…³ã€‚
  - åµŒå…¥æœ¬è´¨ä¸Šæ˜¯åœ¨æ–‡æœ¬å’Œä¸Šä¸‹æ–‡ä¹‹é—´åˆ†åˆ«ç¡®å®šçš„ã€‚

æ·»åŠ **å…³é”®å­—è¿‡æ»¤å™¨**æ˜¯å¢å¼ºæ£€ç´¢ç»“æœçš„ä¸€ç§æ–¹æ³•ã€‚
- ä½†éœ€è¦æ‰‹åŠ¨æˆ–é€šè¿‡ NLP å…³é”®å­—æå–/ä¸»é¢˜æ ‡è®°æ¨¡å‹ä¸ºæ¯ä¸ªæ–‡æ¡£å……åˆ†ç¡®å®šåˆé€‚çš„å…³é”®å­—ã€‚
- æ­¤å¤–ï¼Œè¿˜éœ€è¦ä»æŸ¥è¯¢ä¸­å……åˆ†æ¨æ–­å‡ºæ­£ç¡®çš„å…³é”®å­—ã€‚

LlamaIndexä¸­æå‡ºäº†ä¸€ä¸ªæ–°ç´¢å¼•ï¼Œä¸ºæ¯ä¸ªæ–‡æ¡£æå–/ç´¢å¼•**éç»“æ„åŒ–æ–‡æœ¬æ‘˜è¦**ã€‚
- è¯¥ç´¢å¼•å¯ä»¥æé«˜æ£€ç´¢æ€§èƒ½ï¼Œè¶…è¶Šç°æœ‰çš„æ£€ç´¢æ–¹æ³•ã€‚æœ‰åŠ©äºç´¢å¼•æ¯”å•ä¸ªæ–‡æœ¬å—æ›´å¤šçš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ¯”å…³é”®å­—æ ‡ç­¾å…·æœ‰æ›´å¤šçš„è¯­ä¹‰ã€‚

å¦‚ä½•æ„å»ºï¼Ÿ
- æå–æ¯ä¸ªæ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨ LLM ä»æ¯ä¸ªæ–‡æ¡£ä¸­æå–**æ‘˜è¦**ã€‚
- å°†æ–‡æ¡£æ‹†åˆ†ä¸º**æ–‡æœ¬å—**ï¼ˆèŠ‚ç‚¹ï¼‰ã€‚æ‘˜è¦å’ŒèŠ‚ç‚¹éƒ½å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨æŠ½è±¡ä¸­ã€‚
- ç»´æŠ¤ä»**æ‘˜è¦**åˆ°**æºæ–‡æ¡£/èŠ‚ç‚¹**çš„æ˜ å°„ã€‚

åœ¨æŸ¥è¯¢æœŸé—´ï¼Œæ ¹æ®æ‘˜è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ä»¥è¿›è¡ŒæŸ¥è¯¢ï¼š
- åŸºäº **LLM** çš„æ£€ç´¢ï¼šå‘ LLM æä¾›æ–‡æ¡£æ‘˜è¦é›†ï¼Œå¹¶è¦æ±‚ LLM ç¡®å®š: å“ªäº›æ–‡æ¡£æ˜¯ç›¸å…³çš„+ç›¸å…³æ€§åˆ†æ•°ã€‚
- åŸºäº **åµŒå…¥** çš„æ£€ç´¢ï¼šæ ¹æ®æ‘˜è¦åµŒå…¥ç›¸ä¼¼æ€§ï¼ˆä½¿ç”¨ top-k æˆªæ­¢å€¼ï¼‰æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚

æ³¨æ„
- æ£€ç´¢æ–‡æ¡£**æ‘˜è¦**çš„æ–¹æ³•ä¸åŒäºåŸºäº**åµŒå…¥**çš„æ–‡æœ¬å—æ£€ç´¢ã€‚**æ–‡æ¡£æ‘˜è¦ç´¢å¼•**æ£€ç´¢**ä»»ä½•**é€‰å®šæ–‡æ¡£çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯è¿”å›èŠ‚ç‚¹çº§åˆ«çš„ç›¸å…³å—ã€‚

å­˜å‚¨æ–‡æ¡£çš„æ‘˜è¦è¿˜å¯ä»¥å®ç°åŸºäº LLM çš„æ£€ç´¢ã€‚
- å…ˆè®© LLM æ£€æŸ¥ç®€æ˜çš„æ–‡æ¡£æ‘˜è¦ï¼Œçœ‹çœ‹æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³ï¼Œè€Œä¸æ˜¯ä¸€å¼€å§‹å°±å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLMã€‚
- è¿™åˆ©ç”¨äº† LLM çš„æ¨ç†èƒ½åŠ›ï¼Œå®ƒæ¯”åŸºäºåµŒå…¥çš„æŸ¥æ‰¾æ›´å…ˆè¿›ï¼Œä½†é¿å…äº†å°†æ•´ä¸ªæ–‡æ¡£æä¾›ç»™ LLM çš„æˆæœ¬/å»¶è¿Ÿ

å¸¦**æ‘˜è¦**çš„æ–‡æ¡£æ£€ç´¢æ˜¯**è¯­ä¹‰æœç´¢**å’Œæ‰€æœ‰æ–‡æ¡£çš„å¼ºåŠ›æ‘˜è¦ä¹‹é—´çš„â€œä¸­é—´åœ°å¸¦â€ã€‚

ç¤ºä¾‹
- æ„å»ºæ–¹æ³•è§åŸæ–‡ï¼š[LlamaIndex ï¼šé¢å‘QA ç³»ç»Ÿçš„å…¨æ–°æ–‡æ¡£æ‘˜è¦ç´¢å¼•](https://mp.weixin.qq.com/s/orODrHefDpr-gHNyjxhXmg)

```sh
pip install llama-index # install
```

```py
from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader
documents = SimpleDirectoryReader('data').load_data() # åŠ è½½æ•°æ®
index = GPTVectorStoreIndex.from_documents(documents) # åˆ›å»ºç´¢å¼•
query_engine = index.as_query_engine() # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
response = query_engine.query("What did the author do growing up?") # æ‰§è¡ŒæŸ¥è¯¢
print(response) # è¿”å›ç»“æœ
# --------- æŒä¹…åŒ–å‘é‡ç´¢å¼• ---------
from llama_index import StorageContext, load_index_from_storage
index.storage_context.persist() # æŒä¹…åŒ–å­˜å‚¨ï¼ˆé»˜è®¤æ”¾å†…å­˜ï¼‰
# rebuild storage context
storage_context = StorageContext.from_defaults(persist_dir="./storage")
# load index
index = load_index_from_storage(storage_context)
```


é«˜çº§api

```py
query_engine = doc_summary_index.as_query_engine(
  response_mode="tree_summarize", use_async=True
)
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```

åº•å±‚api

```py
# use retriever as part of a query engine
from llama_index.query_engine import RetrieverQueryEngine

# configure response synthesizer
response_synthesizer = ResponseSynthesizer.from_args()

# assemble query engine
query_engine = RetrieverQueryEngine(
    retriever=retriever,
    response_synthesizer=response_synthesizer,
)
# query
response = query_engine.query("What are the sports teams in Toronto?")
print(response)
```



å®‰è£…

```sh
pip install openai
pip install llama-index
```

è°ƒç”¨ä»£ç 
- construct_indexæ–¹æ³•ä¸­ï¼Œä½¿ç”¨llama_indexçš„ç›¸å…³æ–¹æ³•ï¼Œè¯»å–data_directory_pathè·¯å¾„ä¸‹çš„txtæ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆç´¢å¼•æ–‡ä»¶å­˜å‚¨åœ¨index_cache_pathæ–‡ä»¶ä¸­ã€‚

```py
from llama_index import SimpleDirectoryReader, GPTListIndex, GPTSimpleVectorIndex, LLMPredictor, PromptHelper,ServiceContext
from langchain import OpenAI 
import gradio as gr 
import sys 
import os 
os.environ["OPENAI_API_KEY"] = 'your openai api key'
data_directory_path = 'your txt data directory path'
index_cache_path = 'your index file path'
â€‹
#æ„å»ºç´¢å¼•
def construct_index(directory_path): 
        max_input_size = 4096 
        num_outputs = 2000 
        max_chunk_overlap = 20 
        chunk_size_limit = 500
      
        llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name="text-davinci-003", max_tokens=num_outputs))
        # æŒ‰æœ€å¤§tokenæ•°500æ¥æŠŠåŸæ–‡æ¡£åˆ‡åˆ†ä¸ºå¤šä¸ªå°çš„chunk
        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=chunk_size_limit)
        # è¯»å–directory_pathæ–‡ä»¶å¤¹ä¸‹çš„æ–‡æ¡£
        documents = SimpleDirectoryReader(directory_path).load_data() 
 
        index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)
        # ä¿å­˜ç´¢å¼•
        index.save_to_disk(index_cache_path) 
        return index 
        
def chatbot(input_text): 
        # åŠ è½½ç´¢å¼•
        index = GPTSimpleVectorIndex.load_from_disk(index_cache_path) 
        response = index.query(input_text, response_mode="compact") 
        return response.response 
        
if __name__ == "__main__":
        #ä½¿ç”¨gradioåˆ›å»ºå¯äº¤äº’ui  
        iface = gr.Interface(fn=chatbot, 
                        inputs=gr.inputs.Textbox(lines=7, label="Enter your text"), 
                        outputs="text", 
                        title="Text AI Chatbot") 
        index = construct_index(data_directory_path) 
        iface.launch(share=True)
```

llama-indexçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š
- åˆ›å»ºæ–‡æœ¬å—ç´¢å¼•
- æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æœ¬å—
- ä½¿ç”¨ç›¸å…³çš„æ–‡æœ¬å—å‘ GPT-3ï¼ˆæˆ–å…¶ä»–openaiçš„æ¨¡å‹ï¼‰ æé—®
- åœ¨è°ƒç”¨queryæ¥å£çš„æ—¶å€™ï¼Œllama-indexé»˜è®¤ä¼šæ„é€ å¦‚ä¸‹çš„prompt:

```sh
"Context information is below. \n"
    "---------------------\n"
    "{context_str}"
    "\n---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the question: {query_str}\n"
```

ä½¿ç”¨ä»¥ä¸Špromptè¯·æ±‚openai çš„æ¨¡å‹æ—¶ï¼Œæ¨¡å‹æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å’Œæå‡ºçš„é—®é¢˜ï¼Œä½¿ç”¨å…¶é€»è¾‘æ¨ç†èƒ½åŠ›å¾—åˆ°æƒ³è¦çš„ç­”æ¡ˆã€‚

![](https://pic2.zhimg.com/80/v2-9aa943fe84bc25da03b866e7f52a940d_1440w.webp)

ã€2023-4-13ã€‘[å¦‚ä½•ä¸ºGPT/LLMæ¨¡å‹æ·»åŠ é¢å¤–çŸ¥è¯†ï¼Ÿ](https://www.zhihu.com/question/591935281/answer/2979220793)


#### å¦‚ä½•åˆ†å¥

ã€2023-5-25ã€‘llama-indexçš„åˆ†å¥æ–¹æ³•ï¼šåŠ è‡ªå®šä¹‰éƒ¨åˆ†ï¼ˆå‰åç¼€ç­‰ï¼‰â†’è°ƒç”¨nltk.tokenize.punktåˆ†å¥ï¼ˆè‡ªå®šä¹‰å¥æœ«æ­£åˆ™ï¼‰â†’æŒ‰ç…§chunk_sizeæˆªæ–­â†’åˆ†å¥åˆ—è¡¨ï¼Œ[æºç ](https://github.com/jerryjliu/llama_index/blob/c5a4cc1581cc6ee8277f970e7b0b2cbbd6351eb5/llama_index/langchain_helpers/text_splitter.py#LL267C7-L267C23)



### retrieve-then-generate

1ã€retrieve-then-generateï¼šç±»ChatGPT Retrieval Pluginçš„æŠ€æœ¯æ–¹æ¡ˆ
 
æ ¸å¿ƒï¼šæ ¹æ® è¾“å…¥query æ£€ç´¢æœ¬åœ°/ç§æœ‰æ•°æ®åº“/æ–‡æ¡£ä¸­çš„æ–‡æ¡£ç‰‡æ®µï¼ˆæ£€ç´¢å¯ä»¥æ˜¯æ–‡æœ¬æ£€ç´¢æˆ–åŸºäºå‘é‡çš„æ£€ç´¢ï¼‰ï¼Œä½œä¸ºæ‰©å……çš„ä¸Šä¸‹æ–‡ contextï¼Œé€šè¿‡ prompt template ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„è¾“å…¥ï¼Œç»§è€Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆresponseã€‚

ç®€ç‰ˆå·¥ä½œæµï¼š
- chunk -> index -> retrieve -> construct input -> LLM
 
æ¨èå¼€æºå·¥å…·ï¼š
- ï¼ˆ1ï¼‰OpenAI çš„å®˜æ–¹æ’ä»¶ï¼š[ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin)
- ï¼ˆ2ï¼‰llama-indexï¼š[https://github.com/jerryjliu/llama_index](https://github.com/jerryjliu/llama_index)ï¼Œæä¾›äº†ä¸€ä¸ªæœ¬åœ°/ç§æœ‰æ•°æ®æ”¶é›†ï¼ˆingestionï¼‰å’Œæ•°æ®ç´¢å¼•ï¼ˆindexingï¼‰çš„è§£å†³æ–¹æ¡ˆï¼Œæ„å»ºèµ·å¤–éƒ¨æ•°æ®å’Œ LLM ä¹‹é—´çš„æ¥å£ã€‚

ä¸€ä¸ªåˆ©ç”¨ llama-index å®šåˆ¶ä¸ªäººè®ºæ–‡æ£€ç´¢çš„ç¤ºä¾‹ï¼š[llama_index/examples/paul_graham_essay at main Â· jerryjliu/llama_index](https://github.com/jerryjliu/llama_index/tree/main/examples/paul_graham_essay)ã€‚
 
ï¼ˆåœ¨æ²¡æœ‰OpenAI APIçš„æƒ…å†µä¸‹ï¼Œllama-index æ”¯æŒè°ƒç”¨è‡ªå®šä¹‰çš„ LLMã€‚ï¼‰
 
ï¼ˆ3ï¼‰LangChainï¼š[langchain](https://github.com/hwchase17/langchain)ï¼Œä¹Ÿæ˜¯ä¸ºäº†æ›´å¥½çš„æ„å»ºå¤–éƒ¨æ•°æ®ã€å…¶ä»–åº”ç”¨ä¸ LLM è¿›è¡Œäº¤äº’çš„æ¥å£å±‚æ¡†æ¶ã€‚

LangChainåº”ç”¨å‚è€ƒç¤ºä¾‹ï¼š[GPT-4 & LangChainâ€”â€”PDFèŠå¤©æœºå™¨äºº-åœ°è¡¨æœ€å¼ºå…¨æ–‡æœç´¢](https://www.bilibili.com/read/cv22589352)ã€‚
 
llama-index å’Œ LangChain å¯ä»¥ç»„åˆä½¿ç”¨ï¼ŒLangChain ä¸­æä¾›äº† é¢å‘ä¸åŒä»»åŠ¡çš„ prompt template å’Œ prompt chainã€‚
 
### åŸºäº fine-tuning çš„æ–¹å¼

2ã€åŸºäº fine-tuning çš„æ–¹å¼ï¼Œç›¸æ¯”äºç¬¬ä¸€ç§æ–¹æ¡ˆï¼ŒåŸºäº fine-tuning çš„æ–¹å¼éœ€è¦é¢å¤–çš„è®­ç»ƒå¼€é”€ï¼ŒåŒæ—¶è¿˜æ˜¯ä¼šå—é™äºLLMçš„æœ€å¤§é•¿åº¦é™åˆ¶ã€‚

â€œè®© LLM å…·å¤‡ç†è§£å®šåˆ¶æ•°æ®åº“çš„èƒ½åŠ›â€æ˜¯å¾ˆæœ‰æŒ‘æˆ˜çš„ç›®æ ‡ï¼ŒåŒæ—¶ä¹Ÿä¼šæœ‰å¾ˆå¤šåº”ç”¨åœºæ™¯ã€‚

ä½¿ç”¨Hugging Faceå®ç°å°†ç»´åŸºç™¾ç§‘çš„çŸ¥è¯†åº“æ·»åŠ åˆ°GPT-2æ¨¡å‹ä¸­
- ä½œè€…ï¼š[å°æ–å®æˆ˜](https://www.zhihu.com/question/591935281/answer/2960837503)

```py
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')

# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# åŠ è½½ç»´åŸºç™¾ç§‘çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°æ®é›†
dataset = TextDataset(
    tokenizer=tokenizer,
    file_path='path/to/wiki.txt',
    block_size=128
)

# åˆ›å»ºdata collator
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer, 
    mlm=False
)

# è®¾ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir='./results',          # è¾“å‡ºç›®å½•
    num_train_epochs=3,              # è®­ç»ƒçš„è½®æ•°
    per_device_train_batch_size=8,   # è®­ç»ƒæ—¶æ¯ä¸ªGPUçš„batch size
    per_device_eval_batch_size=8,    # éªŒè¯æ—¶æ¯ä¸ªGPUçš„batch size
    evaluation_strategy='steps',     # è¯„ä¼°ç­–ç•¥
    save_steps=500,                  # å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹
    save_total_limit=2,              # æœ€å¤šä¿å­˜å‡ ä¸ªæ¨¡å‹
    logging_steps=500,               # å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    learning_rate=5e-5,              # å­¦ä¹ ç‡
# åˆ›å»ºTrainerå¯¹è±¡
trainer = Trainer(
model=model,
args=training_args,
train_dataset=dataset,
data_collator=data_collator,
prediction_loss_only=True
)

# å¼€å§‹è®­ç»ƒ
trainer.train()

# ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
trainer.save_model('./fine-tuned-model')
```

### çŸ¥è¯†å›¾è°±å¢å¼º

ä½¿ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºGPT-2æ¨¡å‹çš„ç¤ºä¾‹ä»£ç ï¼š

```python
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# åŠ è½½é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹
model = GPT2LMHeadModel.from_pretrained('gpt2')
# åŠ è½½GPT-2çš„tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
# åŠ è½½çŸ¥è¯†å›¾è°±: è¡¨ç¤ºä¸€äº›å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚
knowledge_graph = {
    'John': {
        'is a': 'person',
        'born in': 'New York',
        'works at': 'Google'
    },
    'Google': {
        'is a': 'company',
        'headquartered in': 'California',
        'founded by': 'Larry Page and Sergey Brin'
    }
}

# å°†çŸ¥è¯†å›¾è°±åµŒå…¥åˆ°æ¨¡å‹ä¸­
model.resize_token_embeddings(len(tokenizer))
for entity in knowledge_graph.keys():
    entity_id = tokenizer.convert_tokens_to_ids(entity)
    entity_embedding = torch.randn(768)
    model.transformer.wte.weight.data[entity_id] = entity_embedding

# ç”Ÿæˆå¥å­
input_text = 'John works at'
input_ids = tokenizer.encode(input_text, return_tensors='pt')
output = model.generate(
    input_ids,
    max_length=50,
    do_sample=True,
    top_k=50
)
output_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(output_text)
```

## LLMåº”ç”¨

### LLMåº”ç”¨æŠ€æœ¯æ¶æ„

- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/871e57dfdaf24ba3a064e79ba0522a7b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=eQeTT9ERDeEgx00BF9U9cVyrx%2FY%3D)

å…¸å‹LLMåº”ç”¨å¼€å‘æ¶æ„å››å±‚ï¼š
- ï¼ˆ1ï¼‰`å­˜å‚¨å±‚`ï¼šä¸»è¦ä¸º`å‘é‡æ•°æ®åº“`ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰ç¼–ç åçš„ç‰¹å¾å‘é‡ï¼Œæ”¯æŒå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢ä¸åˆ†æã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨åšæ–‡æœ¬è¯­ä¹‰æ£€ç´¢æ—¶ï¼Œé€šè¿‡æ¯”è¾ƒè¾“å…¥æ–‡æœ¬çš„ç‰¹å¾å‘é‡ä¸åº•åº“æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œæ£€ç´¢ç›®æ ‡æ–‡æœ¬ï¼Œå³åˆ©ç”¨äº†å‘é‡æ•°æ®åº“ä¸­çš„ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ï¼‰ã€‚
  - ã€ä»£è¡¨æ€§æ•°æ®åº“ã€‘`Pinecone`ã€`Qdrant`ã€‚
- ï¼ˆ2ï¼‰`æ¨¡å‹å±‚`ï¼šé€‰æ‹©å¤§è¯­è¨€æ¨¡å‹ï¼Œå¦‚OpenAIçš„GPTç³»åˆ—æ¨¡å‹ã€Hugging Faceä¸­çš„å¼€æºLLMç³»åˆ—ç­‰ã€‚
  - æ¨¡å‹å±‚æä¾›æœ€æ ¸å¿ƒæ”¯æ’‘ï¼ŒåŒ…æ‹¬èŠå¤©æ¥å£ã€ä¸Šä¸‹æ–‡QAé—®ç­”æ¥å£ã€æ–‡æœ¬æ€»ç»“æ¥å£ã€æ–‡æœ¬ç¿»è¯‘æ¥å£ç­‰ã€‚
  - ã€ä»£è¡¨æ€§æ¨¡å‹ã€‘OpenAIçš„`GPT-3.5/4`ï¼ŒAnthropicçš„`Claude`ï¼ŒGoogleçš„`PaLM`ï¼ŒTHUçš„`ChatGLM`ç­‰ã€‚
- ï¼ˆ3ï¼‰`æœåŠ¡å±‚`ï¼šå°†å„ç§è¯­è¨€æ¨¡å‹æˆ–å¤–éƒ¨**èµ„æºæ•´åˆ**ï¼Œæ„å»ºå®ç”¨çš„LLMæ¨¡å‹ã€‚
  - `Langchain`æ˜¯ä¸€ä¸ªå¼€æºLLMåº”ç”¨æ¡†æ¶ï¼Œæ¦‚å¿µæ–°é¢–ï¼Œå°†LLMæ¨¡å‹ã€å‘é‡æ•°æ®åº“ã€äº¤äº’å±‚Promptã€å¤–éƒ¨çŸ¥è¯†ã€å¤–éƒ¨å·¥å…·æ•´åˆåˆ°ä¸€èµ·ï¼Œå¯è‡ªç”±æ„å»ºLLMåº”ç”¨ã€‚
  - ã€ä»£è¡¨æ€§æ¡†æ¶ã€‘ï¼š`LangChain`ï¼Œ`AutoGPT`ï¼Œ`BabyAGI`ï¼Œ`Llama-Index`ç­‰ã€‚
- ï¼ˆ4ï¼‰`äº¤äº’å±‚`ï¼šç”¨æˆ·é€šè¿‡UIä¸LLMåº”ç”¨äº¤äº’
  - `langflow`æ˜¯`langchain`çš„GUIï¼Œé€šè¿‡æ‹–æ”¾ç»„ä»¶å’ŒèŠå¤©æ¡†æ¶æä¾›ä¸€ç§è½»æ¾çš„å®éªŒå’ŒåŸå‹æµç¨‹æ–¹å¼ã€‚
  - å®ç°ä¸€ä¸ªç®€å•çš„èŠå¤©åº”ç”¨ï¼Œè¾“å…¥â€œåŸå¸‚åå­—â€ï¼ŒèŠå¤©æœºå™¨äººå›å¤â€œè¯¥åŸå¸‚çš„å¤©æ°”æƒ…å†µâ€ã€‚
  - åªéœ€è¦æ‹–åŠ¨ä¸‰ä¸ªç»„ä»¶ï¼šPromptTemplateã€OpenAIã€LLMChainã€‚å®ŒæˆPromptTemplateã€OpenAIã€LLMChainçš„ç•Œé¢åŒ–ç®€å•é…ç½®å³å¯ç”Ÿæˆåº”ç”¨ã€‚
  - ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/03233a4e108f4ffaae147afcac50d03e~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=Z9D%2Blt1IqZVkBHXAGG1QjyORqLk%3D)


### LLM åº”ç”¨

ã€2023-5-30ã€‘[ä¸‡å­—é•¿æ–‡ï¼šLLMåº”ç”¨æ„å»ºå…¨è§£æ](https://www.toutiao.com/article/7238815236906680836)


#### LLM åº”ç”¨æ€»ç»“

LLM åº”ç”¨
- 1ã€**æœ¬åœ°æ–‡æ¡£**çŸ¥è¯†é—®ç­”åŠ©ç†(chat with pdf)ï¼Œå¦‚ï¼šç§åŸŸçŸ¥è¯†é—®ç­”åŠ©ç†ï¼Œæ™ºèƒ½å®¢æœï¼Œè¯­ä¹‰æ£€ç´¢æ€»ç»“ã€è¾…åŠ©æ•™å­¦ã€‚
- 2ã€**è§†é¢‘**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with video)ï¼Œå¦‚ï¼šè§†é¢‘è‡ªåŠ¨ç¼–ç›®ã€è§†é¢‘æ£€ç´¢é—®ç­”ã€‚
- 3ã€**è¡¨æ ¼**çŸ¥è¯†æ€»ç»“é—®ç­”åŠ©ç†(chat with csv)ï¼Œå¦‚ï¼šå•†ä¸šæ•°æ®åˆ†æã€å¸‚åœºè°ƒç ”åˆ†æã€å®¢æˆ·æ•°æ®ç²¾å‡†åˆ†æç­‰

#### 1. Doc-Chat æ–‡æ¡£é—®ç­”

LangChain é¢å¯¹éæœºæ„åŒ–æ•°æ®æ—¶ï¼Œé€šè¿‡å€ŸåŠ© Embedding èƒ½åŠ›ï¼Œå¯¹PDFæ–‡ä»¶æ•°æ®è¿›è¡Œ**å‘é‡åŒ–**ï¼ŒLangChainåœ¨æ­¤åŸºç¡€ä¸Šå…è®¸ç”¨æˆ·å°†è¾“å…¥çš„æ•°æ®ä¸PDFä¸­çš„æ•°æ®è¿›è¡Œ**è¯­ä¹‰åŒ¹é…**ï¼Œä»è€Œå®ç°ç”¨æˆ·åœ¨PDFæ–‡ä»¶ä¸­çš„å†…å®¹æœç´¢ã€‚
- [refer](https://aitechtogether.com/python/105086.html)
- ![img](https://aitechtogether.com/wp-content/uploads/2023/05/952a8e3f-3f59-496f-b0e1-5fc7e12b9cef.webp)

æœ‰å¤§é‡æœ¬åœ°æ–‡æ¡£æ•°æ®ï¼Œå¸Œæœ›é€šè¿‡é—®ç­”çš„æ–¹å¼å¿«é€Ÿè·å–æƒ³è¦çš„çŸ¥è¯†æˆ–ä¿¡æ¯ï¼Œæé«˜å·¥ä½œæ•ˆç‡

è§£å†³æ–¹æ¡ˆï¼š
> langchain + llms

æœ¬åœ°åŒ–çŸ¥è¯†ä¸“å±é—®ç­”åŠ©ç†æ„å»ºè¿‡ç¨‹å¯ç®€å•æ¦‚æ‹¬å¦‚ä¸‹ï¼š
- ç¬¬ä¸€æ­¥ï¼š**æ•°æ®åŠ è½½&é¢„å¤„ç†**ï¼ˆå°†æ•°æ®æºè½¬æ¢ä¸ºtextï¼Œå¹¶åštext splitç­‰é¢„å¤„ç†ï¼‰
- ç¬¬äºŒæ­¥ï¼š**å‘é‡åŒ–**ï¼ˆå°†å¤„ç†å®Œæˆçš„æ•°æ®embeddingå¤„ç†ï¼‰
- ç¬¬ä¸‰æ­¥ï¼š**å¬å›**ï¼ˆé€šè¿‡å‘é‡æ£€ç´¢å·¥å…·Faissç­‰å¯¹queryç›¸å…³æ–‡æ¡£å¬å›ï¼‰
- ç¬¬å››æ­¥ï¼šé˜…è¯»ç†è§£ï¼Œ**æ€»ç»“ç­”æ¡ˆ**ï¼ˆå°†contextä¸queryä¼ ç»™llmsï¼Œæ€»ç»“ç­”æ¡ˆï¼‰
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a978188a6d0d4d7db75e0818e286c32c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=daelWSDLtJ1ruh29TjQfkyddRhg%3D)

##### langchaini + pinecone å®ç°


```py
from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

oader = UnstructuredPDFLoader("../data/field-guide-to-data-science.pdf")
data = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(data)

# Create embeddings of your documents to get ready for semantic search
from langchain.vectorstores import Chroma, Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone

OPENAI_API_KEY = '...'
PINECONE_API_KEY = '...'
PINECONE_API_ENV = 'us-east1-gcp'

embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# initialize pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  # find at app.pinecone.io
    environment=PINECONE_API_ENV  # next to api key in console
)
index_name = "langchaintest" # put in the name of your pinecone index here

docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)

query = "What are examples of good data science teams?"
docs = docsearch.similarity_search(query, include_metadata=True)

#. Query those docs to get your answer back
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain

llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
chain = load_qa_chain(llm, chain_type="stuff")

query = "What is the collect stage of data maturity?"
docs = docsearch.similarity_search(query, include_metadata=True)

chain.run(input_documents=docs, question=query)
#. OUTPUT: ' The collect stage of data maturity focuses on collecting internal or external datasets. Examples include gathering sales records and corresponding weather data.'
```


##### ï¼ˆ1ï¼‰æ•°æ®åŠ è½½&é¢„å¤„ç†

åŠ è½½pdfæ–‡ä»¶ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—
- æ¯ä¸ªåˆ†å—çš„æœ€å¤§é•¿åº¦ä¸º3000ä¸ªå­—ç¬¦)ã€‚è¿™ä¸ªæœ€å¤§é•¿åº¦æ ¹æ®llmçš„è¾“å…¥å¤§å°ç¡®å®šï¼Œæ¯”å¦‚gpt-3.5-turboæœ€å¤§è¾“å…¥æ˜¯4096ä¸ªtokenã€‚
- ç›¸é‚»å—ä¹‹é—´çš„é‡å éƒ¨åˆ†ä¸º400ä¸ªå­—ç¬¦ï¼Œç›®çš„æ˜¯æ¯ä¸ªç‰‡æ®µä¿ç•™ä¸€å®šçš„**ä¸Šæ–‡ä¿¡æ¯**ï¼Œåç»­å¤„ç†ä»»åŠ¡åˆ©ç”¨é‡å ä¿¡æ¯æ›´å¥½ç†è§£æ–‡æœ¬ã€‚

æ–¹æ¡ˆ
- LangChain + FAISS + OpenAI

```py
import os

openai_api_key = 'sk-F9Oxxxxxx3BlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key
from langchain.llms import OpenAI
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
from langchain import PromptTemplate

llm = OpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=openai_api_key)

# data loader
loader = PyPDFLoader("data/ZT91.pdf")
doc = loader.load()
# text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)
docs = text_splitter.split_documents(doc)
```

##### ï¼ˆ2ï¼‰å‘é‡åŒ–

è°ƒç”¨ OpenAIEmbeddingsæ¥å£å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ã€‚
- å®é™…åº”ç”¨ä¸­ï¼Œå¯ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆOpenAIEmbeddingsç”¨çš„æ˜¯ç¬¬6ä¸ªï¼‰ã€‚åŒæ—¶ï¼Œä¸­æ–‡embeddingæ•ˆæœä¼˜ç§€çš„æ¨¡å‹æœ‰ç™¾åº¦çš„ERNIEã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/495e57fd56ea4ccc9790418aab290354~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=X394ecc51Xmjra6dRr2AiK6Bwqc%3D)

```py
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
```

##### ï¼ˆ3ï¼‰å¬å›

ç”¨FAISSå·¥å…·å¯¹è¾“å…¥æ–‡æ¡£æ„å»ºFAISSç´¢å¼•ï¼Œè¿”å›æ„å»ºå¥½çš„FAISSç´¢å¼•å¯¹è±¡ã€‚

åˆ›å»ºFAISSç´¢å¼•åŒ…å«çš„å·¥ä½œæœ‰ï¼š
- ä¸ºç´¢å¼•åˆ†é…å†…å­˜ç©ºé—´ï¼›
- é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹ä¸å‚æ•°ï¼ˆæ¯”å¦‚Flat IVFFlatç­‰ï¼‰ï¼›
- å°†æ–‡æ¡£å‘é‡æ·»åŠ åˆ°ç´¢å¼•ä¸­ã€‚

```py
docsearch = FAISS.from_documents(docs, embeddings)
# docsearch.as_retriever(search_kwargs={"k": 5})è¡¨ç¤ºè¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„chunksï¼Œé»˜è®¤æ˜¯4ï¼Œå¯ä»¥ä¿®æ”¹
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})


```

##### ï¼ˆ4ï¼‰æ€»ç»“ç­”æ¡ˆ

- è¾“å…¥ï¼šquery + context
- è¾“å‡ºï¼šanswer

å…¶ä¸­ context ä¸ºé€šè¿‡faiss retrieveræ£€ç´¢å‡ºçš„ç›¸å…³æ–‡æ¡£ï¼š

ç‰¹åˆ«çš„ï¼Œä¸ºäº†è®©gptåªå›ç­”æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œåœ¨prompt_template å¢åŠ äº†çº¦æŸï¼šâ€œè¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼šâ€ã€‚å³å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç”¨æˆ·æé—®ç›¸å…³å†…å®¹ï¼Œéœ€è¦å›ç­”â€œä¸çŸ¥é“â€ï¼Œé˜²æ­¢â€œç­”éæ‰€é—®â€è¯¯å¯¼ç”¨æˆ·ã€‚

```py
prompt_template = """è¯·æ³¨æ„ï¼šè¯·è°¨æ…è¯„ä¼°queryä¸æç¤ºçš„Contextä¿¡æ¯çš„ç›¸å…³æ€§ï¼Œåªæ ¹æ®æœ¬æ®µè¾“å…¥æ–‡å­—ä¿¡æ¯çš„å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœqueryä¸æä¾›çš„ææ–™æ— å…³ï¼Œè¯·å›ç­”"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“"ï¼Œå¦å¤–ä¹Ÿä¸è¦å›ç­”æ— å…³ç­”æ¡ˆï¼š
    Context: {context}
    Question: {question}
    Answer:"""
# è¾“å…¥ï¼šquery + context
PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
query = "å®æ—¶ç”»é¢æ— æ³•æŸ¥çœ‹ï¼Œæ€æ ·è§£å†³ï¼Ÿ"
# FAISSæ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£ï¼šretriever=docsearch.as_retriever(search_kwargs={"k": 5})
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever(search_kwargs={"k": 5}), chain_type_kwargs={"prompt": PROMPT})
# queryä¸ºç”¨æˆ·è¾“å…¥çš„æé—®
qa.run(query)
```

#### 2. è§†é¢‘çŸ¥è¯†æ€»ç»“

LLM çœ‹å®Œè§†é¢‘ï¼Œå›ç­”é—®é¢˜

éœ€æ±‚æè¿°ï¼š
- youtubeç­‰è§†é¢‘ç½‘ç«™ä¸Šæ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡è§†é¢‘ï¼Œè™½ç„¶æ¨èç³»ç»ŸæŒ‰ç…§å–œå¥½è¿›è¡Œäº†æ¨èï¼Œä½†è§‚çœ‹å¤§é‡æœ‰ä»·å€¼çš„è§†é¢‘ä¾ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚æœèƒ½å¤Ÿå¿«é€Ÿäº†è§£è§†é¢‘å†…å®¹ï¼Œå¹¶å¾—åˆ°å…³æ³¨çš„ä¿¡æ¯ï¼Œå°†æå¤§æé«˜ä¿¡æ¯è·å–æ•ˆç‡ã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain + transcript + llms
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d565d76640004377abc1bcd989577fa7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=XoDjL3a6u4n%2FIC8AbQRMBoJF9zQ%3D)

ä¸pdfæ–‡æ¡£å¤„ç†æ–¹å¼ä¸åŒï¼ŒYoutubeLoaderåº“ä»youtube**è§†é¢‘é“¾æ¥**ä¸­åŠ è½½æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºæ–‡æ¡£ã€‚
- æ–‡æ¡£è·å–è¿‡ç¨‹: é€šè¿‡youtube-transcript-apiè·å–çš„è§†é¢‘çš„å­—å¹•æ–‡ä»¶ï¼Œè¿™ä¸ªå­—å¹•æ–‡ä»¶æ˜¯youtubeç”Ÿæˆçš„ã€‚å½“ç”¨æˆ·å°†è§†é¢‘ä¸Šä¼ è‡³youtubeæ—¶ï¼Œyoutubeä¼šé€šè¿‡å†…ç½®çš„è¯­éŸ³è¯†åˆ«ç®—æ³•å°†è§†é¢‘è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ã€‚å½“åŠ è½½youtubeè§†é¢‘å­—å¹•æ–‡æ¡£åï¼Œæ¥ä¸‹æ¥çš„å¤„ç†å·¥ä½œä¸ç¬¬ä¸€ä¸ªä¾‹å­ç±»ä¼¼ã€‚

LangChainæ”¯æŒå¯¹YouTubeè§†é¢‘å†…å®¹è¿›è¡Œæ‘˜è¦å†…å®¹ç”Ÿæˆï¼Œé€šè¿‡è°ƒç”¨ document_loaders æ¨¡å—ä¸­çš„ YoutubeLoade ï¼ŒåŒæ—¶ä¼ å…¥YouTubeçš„è§†é¢‘é“¾æ¥ï¼Œç„¶åå³å¯æ”¯æŒè§†é¢‘å†…å®¹çš„æ‘˜è¦æå–ã€‚
- [refer](https://aitechtogether.com/python/105086.html)
- ![img](https://aitechtogether.com/wp-content/uploads/2023/05/8d8bb508-68eb-4733-90ef-86a8bd890026.webp)

```py
from langchain.document_loaders import YoutubeLoader
from langchain.llms import OpenAI
from langchain.chains.summarize import load_summarize_chain

OPENAI_API_KEY = '...'
# åŠ è½½ youtube é¢‘é“
loader = YoutubeLoader.from_youtube_url("https://www.youtube.com/watch?v=QsYGlZkevEg", add_video_info=True)
# å°†æ•°æ®è½¬æˆ document
result = loader.load()
```

Question:
> â€œå¯¹è§†é¢‘ä¸­ä»‹ç»çš„å†…å®¹ï¼Œé€æ¡åˆ—ä¸¾ï¼Ÿâ€



#### 3. è¡¨æ ¼é—®ç­”

LLM åˆ†æå®Œ 54ä¸‡æ¡æ•°æ®ï¼Œç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œå®Œæˆäº†æ•°æ®åˆ†æå¸ˆ1å¤©çš„å·¥ä½œã€‚

éœ€æ±‚æè¿°ï¼š
- é›¶å”®å•†æœ‰å®¢æˆ·çš„äº¤æ˜“æ•°æ®ã€‚å¸Œæœ›ä»æ•°æ®ä¸­ç”Ÿæˆä¸€äº›åŸºæœ¬è§è§£ï¼Œä»¥ä¾¿è¯†åˆ«æœ€ä½³å®¢æˆ·ã€‚
- ä¾‹å¦‚ï¼šæŒ‰æ€§åˆ«å’Œå¹´é¾„ç»„åˆ’åˆ†çš„å¹³å‡æ”¯å‡ºã€æ¯ç§ç±»å‹çš„å®¢æˆ·è´­ä¹°çš„äº§å“ã€äº§å“åœ¨å“ªä¸ªåŸå¸‚å’Œå•†åº—çš„é”€å”®é¢æœ€é«˜ç­‰ç­‰
- æ•°æ®åˆ†æå¸ˆå°†è·å–æ•°æ®ï¼Œç¼–å†™ä¸€äº› SQL æˆ– Python æˆ– R ä»£ç ï¼Œç”Ÿæˆè§è§£ï¼Œæ•°æ®åˆ†æå¸ˆå¯èƒ½éœ€è¦ä¸€å¤©çš„æ—¶é—´æ¥æä¾›è¿™äº›ç»“æœã€‚

è§£å†³æ–¹æ¡ˆï¼š
- langchain+llm + agents
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/c12a12fb285e431b94a9179846dd67e8~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=pGos9u09HxT9ppxKfL4lz74LA%2F4%3D)

ä»»åŠ¡
- (1) æ˜¾ç¤ºè¡¨æ ¼ä¸­ç”¨æˆ·çš„æ•°é‡
  - éªŒè¯: agentç»™å‡ºçš„ç­”æ¡ˆå®Œå…¨æ­£ç¡®
- (2) å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´ç›¸å…³æ€§åˆ†æ
  - åˆ†æä¸‹å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§ï¼šå¹´é¾„ä¸æ¶ˆè´¹æˆæ­£ç›¸å…³ï¼Œä½†æ˜¯ç›¸å…³æ€§å¾ˆå¼±
- (3) äº§å“é”€å”®é‡ç»Ÿè®¡å¹¶ç”»å‡ºæŸ±çŠ¶å›¾
  - ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾


```py
import os
from langchain.agents import create_csv_agent
from langchain.llms import OpenAI

openai_api_key = 'sk-F9O70vxxxxxxxBlbkFJK55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key

agent = create_csv_agent(OpenAI(openai_api_key=openai_api_key, temperature=0), 'train.csv', verbose=True)
# ç»Ÿè®¡ç”¨æˆ·æ•°
agent.run("è¯·æŒ‰ç…§æ€§åˆ«å¯¹ç”¨æˆ·æ•°é‡è¿›è¡Œæ˜¾ç¤ºï¼Ÿ")
# å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢ä¹‹é—´çš„ç›¸å…³æ€§
agent.run("åœ¨è¿™ä»½è¡¨æ ¼ä¸­,å¹´é¾„ä¸æ¶ˆè´¹é‡‘é¢æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§?")
# ç»Ÿè®¡æ¯ç§äº§å“çš„é”€å”®æ€»é‡ï¼Œå¹¶ç”»æŸ±çŠ¶å›¾
agent.run("äº§å“1æ€»é‡,äº§å“2æ€»é‡,äº§å“3æ€»é‡åˆ†åˆ«æ˜¯å¤šå°‘,å°†ä¸‰ä¸ªæ€»é‡é€šè¿‡æŸ±çŠ¶å›¾ç”»å‡ºæ¥å¹¶æ˜¾ç¤º")
```




## å­˜å‚¨å±‚ï¼šæ–‡æ¡£å‘é‡åŒ–

è‡ªç ”æ¡†æ¶çš„é€‰æ‹©
- åŸºäºOpenAIEmbeddingsï¼Œå®˜æ–¹ç»™å‡ºäº†åŸºäºembeddingsæ£€ç´¢æ¥è§£å†³GPTæ— æ³•å¤„ç†é•¿æ–‡æœ¬å’Œæœ€æ–°æ•°æ®çš„é—®é¢˜çš„å®ç°æ–¹æ¡ˆã€‚[å‚è€ƒ](https://www.datalearner.com/blog/1051681543488862)
- ä¹Ÿå¯ä»¥ä½¿ç”¨ LangChain æ¡†æ¶ã€‚

å‚è€ƒ
- [ChatGPTæ€ä¹ˆå»ºç«‹ç§æœ‰çŸ¥è¯†åº“ï¼Ÿ](https://www.zhihu.com/question/596838257/answer/3004754396)
- [åˆ©ç”¨LangChainå’Œå›½äº§å¤§æ¨¡å‹ChatGLMå®ç°åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­”](https://www.zhihu.com/zvideo/1630964532179812353)

é™¤äº†ä»æ–‡æ¡£ä¸­æŠ“å–æ•°æ®ï¼Œä»æŒ‡å®šç½‘ç«™URLæŠ“å–æ•°æ®ï¼Œå®ç°æ™ºèƒ½å®¢æœå¤–éƒ¨çŸ¥è¯†åº“ï¼Œå¯ä»¥å€ŸåŠ©ChatGPTå†™Pythonä»£ç ï¼ŒPythonBeautiful Soupåº“çš„å®ç°æ–¹å¼å¾ˆæˆç†Ÿ

å¤§å‚äº§å“æˆªå›¾ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“å»ºè®¾
- ä¼ä¸šèµ„æ–™åº“ï¼Œå…³è”å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨æœç´¢
- ![a](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYAg6aFUKbz~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=5kqgHWkZX6LPdrX2H9Zq59m%2BwO0%3D)
- å¤§æ¨¡å‹æ–‡æ¡£çŸ¥è¯†æŠ½å–å’Œâ€œå³æœå³é—®â€
- ![b](https://p9-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYkN7rAGx03~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=gO%2FqHxavS7KVAfE08Mv0WayLjLQ%3D)
- ![b](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoYmX2ImA5oO~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=rlim2GCZ8zsapnPyzA47LCHJkEo%3D)


éƒ½æœ‰ChatGPTäº†ï¼Œä¸ºä»€ä¹ˆè¿˜è¦äº†è§£Embeddingè¿™ç§ã€Œä½çº§è´§ã€æŠ€æœ¯ï¼Ÿä¸¤ä¸ªåŸå› ï¼š
- æœ‰äº›é—®é¢˜ä½¿ç”¨Embeddingè§£å†³ï¼ˆæˆ–å…¶ä»–éChatGPTçš„æ–¹å¼ï¼‰ä¼šæ›´åŠ åˆç†ã€‚é€šä¿—æ¥è¯´å°±æ˜¯ã€Œæ€é¸¡ç„‰ç”¨ç‰›åˆ€ã€ã€‚
- ChatGPT**æ€§èƒ½**æ–¹é¢ä¸æ˜¯ç‰¹åˆ«å‹å¥½ï¼Œæ¯•ç«Ÿæ˜¯é€å­—ç”Ÿæˆï¼ˆä¸€ä¸ªTokenä¸€ä¸ªTokenåå‡ºæ¥çš„ï¼‰ã€‚

æ›´å¤šï¼š[ChatGPTç›¸ä¼¼åº¦åŒ¹é…ç¬”è®°](https://github.com/datawhalechina/hugging-llm/blob/main/content/ChatGPT%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E2%80%94%E2%80%94%E7%9B%B8%E4%BC%BC%E5%8C%B9%E9%85%8D.ipynb)

### æ–‡æœ¬åˆ‡åˆ†

LangChain åˆ‡åˆ†å·¥å…·
- [Text Splittersæ–‡æ¡£](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html): é€‰æ‹©å¯¹åº”çš„æ–‡æœ¬åˆ‡åˆ†å™¨ï¼Œå¦‚æœæ˜¯é€šç”¨æ–‡æœ¬çš„è¯ï¼Œå»ºè®®é€‰æ‹© `RecursiveCharacterTextSplitter`

```py
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¯¼å…¥æ–‡æœ¬
loader = UnstructuredFileLoader("./data/news_test.txt")
# å°†æ–‡æœ¬è½¬æˆ Document å¯¹è±¡
data = loader.load()
print(f'documents:{len(data)}')

# åˆå§‹åŒ–åŠ è½½å™¨
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)
# åˆ‡å‰²åŠ è½½çš„ document
split_docs = text_splitter.split_documents(data)
print("split_docs size:",len(split_docs))
```

### ç›¸ä¼¼åº¦

ç›¸ä¼¼åº¦ç´¢å¼•
- åªç”¨embeddingæ¥è®¡ç®—å¥å­çš„ç›¸ä¼¼åº¦

```py
# åˆå§‹åŒ– prompt å¯¹è±¡
question = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
# æœ€å¤šè¿”å›åŒ¹é…çš„å‰4æ¡ç›¸ä¼¼åº¦æœ€é«˜çš„å¥å­
similarDocs = db.similarity_search(question, include_metadata=True,k=4)
# [print(x) for x in similarDocs]
```

æ¥å…¥ChatGLMæ¥å¸®å¿™åšæ€»ç»“å’Œæ±‡æ€»

```py
from langchain.chains import RetrievalQA
import IPython
# æ›´æ¢ LLM
qa = RetrievalQA.from_chain_type(llm=ChatGLM(temperature=0.1), chain_type="stuff", retriever=retriever)
# è¿›è¡Œé—®ç­”
query = "2022å¹´è…¾è®¯è¥æ”¶å¤šå°‘"
print(qa.run(query))
```

### å‘é‡åŒ–æ–¹æ¡ˆ

#### OpenAIEmbeddings

OpenAIå®˜æ–¹çš„embeddingæœåŠ¡

OpenAIEmbeddingsï¼š
- ä½¿ç”¨ç®€å•ï¼Œå¹¶ä¸”æ•ˆæœæ¯”è¾ƒå¥½ï¼›

##### OpenAIçš„EmbeddingæœåŠ¡

ç›´æ¥ä½¿ç”¨openaiçš„embeddingæœåŠ¡

```py
import os
import openai

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
# OPENAI_API_KEY = "å¡«å…¥ä¸“å±çš„API key"
openai.api_key = OPENAI_API_KEY

text = "æˆ‘å–œæ¬¢ä½ "
model = "text-embedding-ada-002"
emb_req = openai.Embedding.create(input=[text], model=model)
emb = emb_req.data[0].embedding
len(emb), type(emb)
# ç›¸ä¼¼åº¦è®¡ç®—
from openai.embeddings_utils import get_embedding, cosine_similarity

# æ³¨æ„å®ƒé»˜è®¤çš„æ¨¡å‹æ˜¯text-similarity-davinci-001ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ¢æˆtext-embedding-ada-002
text1 = "æˆ‘å–œæ¬¢ä½ "
text2 = "æˆ‘é’Ÿæ„ä½ "
text3 = "æˆ‘ä¸å–œæ¬¢ä½ "
emb1 = get_embedding(text1)
emb1 = get_embedding(text1, "text-embedding-ada-002") # æŒ‡å®šæ¨¡å‹
emb2 = get_embedding(text2)
emb3 = get_embedding(text3)
cosine_similarity(emb1, emb2) # 0.9246855139297101
cosine_similarity(emb1, emb3) # 0.8578009661644189
```

é—®é¢˜
- ä¼šæ¶ˆè€—openaiçš„tokenï¼Œç‰¹åˆ«æ˜¯å¤§æ®µæ–‡æœ¬æ—¶ï¼Œ**æ¶ˆè€—çš„token**è¿˜ä¸å°‘ï¼Œå¦‚æœçŸ¥è¯†åº“æ˜¯æ¯”è¾ƒå›ºå®šçš„ï¼Œå¯ä»¥è€ƒè™‘å°†æ¯æ¬¡ç”Ÿæˆçš„embeddingåšæŒä¹…åŒ–ï¼Œè¿™æ ·å°±ä¸éœ€è¦å†è°ƒç”¨openaiäº†ï¼Œå¯ä»¥å¤§å¤§èŠ‚çº¦tokençš„æ¶ˆè€—ï¼›
- å¯èƒ½ä¼šæœ‰**æ•°æ®æ³„éœ²**çš„é£é™©ï¼Œå¦‚æœæ˜¯ä¸€äº›é«˜åº¦ç§å¯†çš„æ•°æ®ï¼Œä¸å»ºè®®ç›´æ¥è°ƒç”¨ã€‚

##### LangChainè°ƒç”¨OpenAI

```py
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import VectorDBQA
from langchain.document_loaders import UnstructuredMarkdownLoader
from langchain.embeddings.openai import OpenAIEmbeddings
import IPython
import os
from dotenv import load_dotenv
load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_BASE"] = os.getenv("OPENAI_API_BASE")

embeddings = OpenAIEmbeddings()

# ---- ç®€æ´ç‰ˆ -------
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
```

#### HuggingFaceEmbeddings

HuggingFaceEmbeddingsï¼š

å¯ä»¥åœ¨HuggingFaceä¸Šé¢é€‰æ‹©å„ç§sentence-similarityæ¨¡å‹æ¥è¿›è¡Œå®éªŒï¼Œæ•°æ®éƒ½æ˜¯åœ¨æœ¬æœºä¸Šè¿›è¡Œè®¡ç®—
éœ€è¦ä¸€å®šçš„ç¡¬ä»¶æ”¯æŒï¼Œæœ€å¥½æ˜¯æœ‰GPUæ”¯æŒï¼Œä¸ç„¶ç”Ÿæˆæ•°æ®å¯èƒ½ä¼šéå¸¸æ…¢
ç”Ÿæˆçš„å‘é‡æ•ˆæœå¯èƒ½ä¸æ˜¯å¾ˆå¥½ï¼Œå¹¶ä¸”HuggingFaceä¸Šçš„ä¸­æ–‡å‘é‡æ¨¡å‹ä¸æ˜¯å¾ˆå¤šã€‚

```py
from langchain.vectorstores import Chroma
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
import IPython
import sentence_transformers

embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "GanymedeNil/text2vec-large-chinese",
    "text2vec2":"uer/sbert-base-chinese-nli",
    "text2vec3":"shibing624/text2vec-base-chinese",
}

EMBEDDING_MODEL = "text2vec3"
# åˆå§‹åŒ– hugginFace çš„ embeddings å¯¹è±¡
embeddings = HuggingFaceEmbeddings(model_name=embedding_model_dict[EMBEDDING_MODEL], )
embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='mps')
```

#### M3E

ã€2023-7-14ã€‘[ç ”ç©¶äººå‘˜å¼€æºä¸­æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œå¡«è¡¥ä¸­æ–‡å‘é‡æ–‡æœ¬æ£€ç´¢é¢†åŸŸçš„ç©ºç™½](https://www.toutiao.com/article/7254900867097625127)

ç”±äº GPT ä½¿ç”¨çš„ Transformer æ¨¡å‹çš„è‡ªèº«ç‰¹æ€§ï¼Œå¯¼è‡´æ¨¡å‹åªèƒ½ä»å›ºå®šé•¿åº¦çš„ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆæ–‡æœ¬ã€‚é‚£ä¹ˆï¼Œå½“è¦æ¨¡å‹æ„ŸçŸ¥æ›´å¹¿é˜”çš„ä¸Šä¸‹æ–‡æ—¶ï¼Œè¯¥æ€ä¹ˆåšå‘¢ï¼Ÿ

é¢†åŸŸå†…é€šç”¨çš„è§£å†³æ–¹æ¡ˆ: å°†å†å²å¯¹è¯æˆ–è€…é¢†åŸŸè¯­æ–™ä¸­çš„ç›¸å…³çŸ¥è¯†é€šè¿‡å‘é‡æ£€ç´¢ï¼Œå†è¡¥å……åˆ° GPT æ¨¡å‹çš„ä¸Šä¸‹æ–‡ä¸­ã€‚

è¿™æ ·ï¼ŒGPT æ¨¡å‹å°±ä¸éœ€è¦æ„ŸçŸ¥å…¨éƒ¨æ–‡æœ¬ï¼Œè€Œæ˜¯æœ‰é‡ç‚¹ã€æœ‰ç›®çš„åœ°åªå…³å¿ƒé‚£äº›ç›¸å…³çš„éƒ¨åˆ†ï¼Œè¿™å’Œ Transformer å†…éƒ¨çš„ Attention æœºåˆ¶åŸç†ç›¸ä¼¼ï¼Œä½¿å¾—æ–‡æœ¬åµŒå…¥æ¨¡å‹å˜æˆäº† GPT æ¨¡å‹çš„è®°å¿†æ£€ç´¢æ¨¡å—ã€‚

ä½†æ˜¯é•¿æœŸä»¥æ¥ï¼Œé¢†åŸŸå†…ä¸€ç›´ç¼ºå°‘å¼€æºã€å¯ç”¨çš„**ä¸­æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹**ä½œä¸ºæ–‡æœ¬æ£€ç´¢ã€‚
- ä¸­æ–‡å¼€æºæ–‡æœ¬åµŒå…¥æ¨¡å‹ä¸­æœ€è¢«å¹¿æ³›ä½¿ç”¨çš„ `text2vec` ä¸»è¦æ˜¯åœ¨ä¸­æ–‡è‡ªç„¶è¯­è¨€æ¨ç†æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚
- OpenAI å‡ºå“çš„ `text-embedding-ada-002` æ¨¡å‹è¢«å¹¿æ³›ä½¿ç”¨ ï¼Œè™½ç„¶è¯¥æ¨¡å‹æ•ˆæœè¾ƒå¥½ï¼Œä½†æ­¤æ¨¡å‹ä¸å¼€æºã€ä¹Ÿä¸å…è´¹ï¼ŒåŒæ—¶è¿˜æœ‰æ•°æ®**éšç§**å’Œæ•°æ®**å‡ºå¢ƒ**ç­‰é—®é¢˜ã€‚

##### MokaHR å¼€æº M3E

æœ€è¿‘ï¼Œ`MokaHR` å›¢é˜Ÿå¼€å‘äº†ä¸€ç§åä¸º `M3E` çš„æ¨¡å‹ï¼Œè¿™ä¸€æ¨¡å‹å¼¥è¡¥äº†ä¸­æ–‡å‘é‡æ–‡æœ¬æ£€ç´¢é¢†åŸŸçš„ç©ºç™½ï¼Œ `M3E` æ¨¡å‹åœ¨ä¸­æ–‡åŒè´¨æ–‡æœ¬ S2S ä»»åŠ¡ä¸Šåœ¨ 6 ä¸ªæ•°æ®é›†çš„å¹³å‡è¡¨ç°å¥½äº `text2vec` å’Œ `text-embedding-ada-002` ï¼Œåœ¨ä¸­æ–‡æ£€ç´¢ä»»åŠ¡ä¸Šä¹Ÿä¼˜äºäºŒè€…ã€‚
- huggingface: [m3e-base](https://huggingface.co/moka-ai/m3e-base)

M3E æ˜¯ Moka Massive Mixed Embedding çš„ç¼©å†™
- Mokaï¼Œæ­¤æ¨¡å‹ç”± MokaAI è®­ç»ƒï¼Œå¼€æºå’Œè¯„æµ‹ï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ uniem ï¼Œè¯„æµ‹ BenchMark ä½¿ç”¨ MTEB-zh
- Massiveï¼Œæ­¤æ¨¡å‹é€šè¿‡åƒä¸‡çº§ (2200w+) çš„ä¸­æ–‡å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
- Mixedï¼Œæ­¤æ¨¡å‹æ”¯æŒä¸­è‹±åŒè¯­çš„åŒè´¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¼‚è´¨æ–‡æœ¬æ£€ç´¢ç­‰åŠŸèƒ½ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢
- Embeddingï¼Œæ­¤æ¨¡å‹æ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œå¯ä»¥å°†è‡ªç„¶è¯­è¨€è½¬æ¢æˆç¨ å¯†çš„å‘é‡

Tips:
- ä½¿ç”¨åœºæ™¯ä¸»è¦æ˜¯ä¸­æ–‡ï¼Œå°‘é‡è‹±æ–‡çš„æƒ…å†µï¼Œå»ºè®®ä½¿ç”¨ m3e ç³»åˆ—çš„æ¨¡å‹
- å¤šè¯­è¨€ä½¿ç”¨åœºæ™¯ï¼Œå¹¶ä¸”ä¸ä»‹æ„æ•°æ®éšç§çš„è¯ï¼Œæˆ‘å»ºè®®ä½¿ç”¨ openai text-embedding-ada-002
- ä»£ç æ£€ç´¢åœºæ™¯ï¼Œæ¨èä½¿ç”¨ openai text-embedding-ada-002
- æ–‡æœ¬æ£€ç´¢åœºæ™¯ï¼Œè¯·ä½¿ç”¨å…·å¤‡æ–‡æœ¬æ£€ç´¢èƒ½åŠ›çš„æ¨¡å‹ï¼Œåªåœ¨ S2S ä¸Šè®­ç»ƒçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œæ²¡æœ‰åŠæ³•å®Œæˆæ–‡æœ¬æ£€ç´¢ä»»åŠ¡

M3E æ¨¡å‹ä¸­ä½¿ç”¨çš„æ•°æ®é›†ã€è®­ç»ƒè„šæœ¬ã€è®­ç»ƒå¥½çš„æ¨¡å‹ã€è¯„æµ‹æ•°æ®é›†ä»¥åŠè¯„æµ‹è„šæœ¬éƒ½å·²å¼€æºï¼Œç”¨æˆ·å¯ä»¥è‡ªç”±åœ°è®¿é—®å’Œä½¿ç”¨ç›¸å…³èµ„æºã€‚è¯¥é¡¹ç›®ä¸»è¦ä½œè€…ã€MokaHR è‡ªç„¶è¯­è¨€å¤„ç†å·¥ç¨‹å¸ˆç‹å®‡æ˜•è¡¨ç¤ºï¼š
> â€œæˆ‘ç›¸ä¿¡ M3E æ¨¡å‹å°†æˆä¸ºä¸­æ–‡æ–‡æœ¬å‘é‡æ£€ç´¢ä¸­ä¸€ä¸ªé‡è¦çš„é‡Œç¨‹ç¢‘ï¼Œæœªæ¥ç›¸å…³é¢†åŸŸçš„å·¥ä½œï¼Œéƒ½å¯èƒ½ä»è¿™äº›å¼€æºçš„èµ„æºä¸­æ”¶ç›Šã€‚â€

M3E ä½¿ç”¨ in-batch è´Ÿé‡‡æ ·çš„å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼åœ¨å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä¸ºäº†ä¿è¯ in-batch è´Ÿé‡‡æ ·çš„æ•ˆæœï¼Œæˆ‘ä»¬ä½¿ç”¨ A100 80G æ¥æœ€å¤§åŒ– batch-sizeï¼Œå¹¶åœ¨å…±è®¡ 2200W+ çš„å¥å¯¹æ•°æ®é›†ä¸Šè®­ç»ƒäº† 1 epochã€‚è®­ç»ƒè„šæœ¬ä½¿ç”¨ [uniem](https://github.com/wangyuxinwhy/uniem/blob/main/scripts/train_m3e.py)

##### ç›´æ¥ä½¿ç”¨

```py
# pip install -U sentence-transformers
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('moka-ai/m3e-base')

#Our sentences we like to encode
sentences = [
    '* Moka æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹ç”± MokaAI è®­ç»ƒå¹¶å¼€æºï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ uniem',
    '* Massive æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹é€šè¿‡**åƒä¸‡çº§**çš„ä¸­æ–‡å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒ',
    '* Mixed æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹æ”¯æŒä¸­è‹±åŒè¯­çš„åŒè´¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¼‚è´¨æ–‡æœ¬æ£€ç´¢ç­‰åŠŸèƒ½ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢ï¼ŒALL in one'
]

#Sentences are encoded by calling model.encode()
embeddings = model.encode(sentences)

#Print the embeddings
for sentence, embedding in zip(sentences, embeddings):
    print("Sentence:", sentence)
    print("Embedding:", embedding)
    print("")

```

##### å¾®è°ƒ

uniem æä¾›äº†éå¸¸æ˜“ç”¨çš„ finetune æ¥å£ï¼Œå‡ è¡Œä»£ç ï¼Œå³åˆ»é€‚é…ï¼

```py
from datasets import load_dataset

from uniem.finetuner import FineTuner

dataset = load_dataset('shibing624/nli_zh', 'STS-B')
# æŒ‡å®šè®­ç»ƒçš„æ¨¡å‹ä¸º m3e-small
finetuner = FineTuner.from_pretrained('moka-ai/m3e-small', dataset=dataset)
finetuner.run(epochs=1)
```

è¯¦è§ [uniem å¾®è°ƒæ•™ç¨‹](https://github.com/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb)


## å‘é‡æ•°æ®åº“

å‘é‡æ•°æ®åº“ï¼ˆVectorstoresï¼‰ç”¨äºå­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰ç¼–ç åçš„**ç‰¹å¾å‘é‡**ï¼Œæ”¯æŒå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢ä¸åˆ†æã€‚
- æ–‡æœ¬è¯­ä¹‰æ£€ç´¢ï¼Œé€šè¿‡æ¯”è¾ƒè¾“å…¥æ–‡æœ¬çš„ç‰¹å¾å‘é‡ä¸åº•åº“æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œæ£€ç´¢ç›®æ ‡æ–‡æœ¬ï¼Œå³åˆ©ç”¨äº†å‘é‡æ•°æ®åº“ä¸­çš„ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ï¼‰ã€‚

å› ä¸ºæ•°æ®ç›¸å…³æ€§æœç´¢å…¶å®æ˜¯å‘é‡è¿ç®—ã€‚æ‰€ä»¥ï¼Œä¸ç®¡ä½¿ç”¨ openai api embedding åŠŸèƒ½è¿˜æ˜¯ç›´æ¥é€šè¿‡ å‘é‡æ•°æ®åº“ ç›´æ¥æŸ¥è¯¢ï¼Œéƒ½éœ€è¦å°†åŠ è½½è¿›æ¥çš„æ•°æ® Document è¿›è¡Œ**å‘é‡åŒ–**ï¼Œæ‰èƒ½è¿›è¡Œå‘é‡è¿ç®—æœç´¢ã€‚

è½¬æ¢æˆå‘é‡ä¹Ÿå¾ˆç®€å•ï¼Œåªéœ€è¦æŠŠæ•°æ®å­˜å‚¨åˆ°å¯¹åº”çš„å‘é‡æ•°æ®åº“ä¸­å³å¯å®Œæˆå‘é‡çš„è½¬æ¢ã€‚

å®˜æ–¹ä¹Ÿæä¾›äº†å¾ˆå¤šçš„å‘é‡æ•°æ®åº“ä¾›æˆ‘ä»¬ä½¿ç”¨ï¼ŒåŒ…æ‹¬ï¼š
- Annoy
- Chroma
- ElasticSearch
- FAISS
- Milvus
- PGVector
- Pinecone
- Redis

ä»£è¡¨æ€§æ•°æ®åº“
- Chromaã€Pineconeã€Qdrand

æ›´å¤šæ”¯æŒçš„å‘é‡æ•°æ®åº“ä½¿ç”¨æ–¹æ³•ï¼Œå¯è½¬è‡³é“¾æ¥ã€‚

### Faiss


```py
from langchain.vectorstores import FAISS

db = FAISS.from_documents(split_docs, embeddings)
db.save_local("./faiss/news_test")
# åŠ è½½æŒä¹…åŒ–å‘é‡
db = FAISS.load_local("./faiss/news_test",embeddings=embeddings)
# ====== æˆ– ========
vs_path = "./vector_store"
if vs_path and os.path.isdir(vs_path):
    vector_store = FAISS.load_local(vs_path, embeddings)
    vector_store.add_documents(docs)
else:
    if not vs_path:
        vs_path = f"""{VS_ROOT_PATH}{os.path.splitext(file)[0]}_FAISS_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}"""
    vector_store = FAISS.from_documents(docs, embeddings)

vector_store.save_local(vs_path)
docs = vector_store.similarity_search(query)
docs_and_scores = vector_store.similarity_search_with_score(query)
```


### Mulvus


```py
vector_db = Milvus.from_documents(
    docs,
    embeddings,
    connection_args={"host": "127.0.0.1", "port": "19530"},
)
docs = vector_db.similarity_search(query)
docs[0]
```


### Chroma

Chroma æ¯”è¾ƒè½»é‡ï¼Œç›´æ¥å®‰è£…åº“

```py
from langchain.vectorstores import Chroma
# åˆå§‹åŒ–åŠ è½½å™¨
db = Chroma.from_documents(split_docs, embeddings,persist_directory="./chroma/openai/news_test")
# æŒä¹…åŒ–
db.persist()
# æŒä¹…åŒ–åï¼Œå¯ä»¥ç›´æ¥é€‰æ‹©ä»æŒä¹…åŒ–æ–‡ä»¶ä¸­åŠ è½½ï¼Œä¸éœ€è¦å†é‡æ–°å°±å¯ä½¿ç”¨äº†
db = Chroma(persist_directory="./chroma/news_test", embedding_function=embeddings)
```

```py
# pip install chromadb
# åŠ è½½ç´¢å¼•
from langchain.vectorstores import Chroma
vectordb = Chroma(persist_directory="./vector_store", embedding_function=embeddings)
# å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
query = "æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—"
docs = vectordb.similarity_search(query)
docs2 = vectordb.similarity_search_with_score(query)
print(docs[0].page_content)
# åœ¨æ£€ç´¢å™¨æ¥å£ä¸­å…¬å¼€è¯¥ç´¢å¼•
retriever = vectordb.as_retriever(search_type="mmr")
docs = retriever.get_relevant_documents(query)[0]
print(docs.page_content)
```

### Pinecone

```py
import pinecone 

# Connecting to Pinecone
pinecone.deinit()
pinecone.init(
    api_key="YOUR_API_KEY",  # find at app.pinecone.io
    environment="YOUR_ENV"  # next to api key in console
)

# similarity_search
docsearch = Pinecone.from_documents(docs, embeddings, index_name="langchain-demo")
docs = docsearch.similarity_search(query)
print(docs[0].page_content)

# Create a Pinecone Service
pinecone_service = pinecone.Service()

# Create an Embedding Model
from langchain.embeddings.openai import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()

# Create a Vectorstore
from langchain.vectorstores import Chroma
vectorstore = Chroma(embeddings, pinecone_service)

# Upload documents to Pinecone Vectorstore
from langchain.vectorstores import Chroma
docsearch = Chroma.from_documents(texts, embeddings, collection_name="collection_name")
```

### PGVector

```py
from langchain.vectorstores.pgvector import PGVector
import os
CONNECTION_STRING = PGVector.connection_string_from_db_params(
    driver=os.environ.get("PGVECTOR_DRIVER", "psycopg2"),
    host=os.environ.get("PGVECTOR_HOST", "localhost"),
    port=int(os.environ.get("PGVECTOR_PORT", "5432")),
    database=os.environ.get("PGVECTOR_DATABASE", "postgres"),
    user=os.environ.get("PGVECTOR_USER", "postgres"),
    password=os.environ.get("PGVECTOR_PASSWORD", "postgres"),
)
db = PGVector.from_documents(
    embedding=embeddings,
    documents=docs,
    collection_name="state_of_the_union",
    connection_string=CONNECTION_STRING,
)

query = "What did the president say about Ketanji Brown Jackson"
docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)
for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print(doc.page_content)
    print("-" * 80)
```


## æœåŠ¡å±‚ï¼šLLMæ¡†æ¶

LLMså°±åƒæ˜¯C++çš„ç¼–è¯‘å™¨ï¼ŒPythonçš„è§£é‡Šå™¨ä¸€æ ·ï¼š

| è¯­è¨€ç±»å‹	| æ‰§è¡ŒåŸç† |
| ---	| --- |
| C++è¯­è¨€	| C++è¯­è¨€ â†’ ç¼–è¯‘å™¨/é“¾æ¥å™¨ â†’ æ—¢å®šä»»åŠ¡ |
| Javaè¯­è¨€	| Javaè¯­è¨€ â†’ ç¼–è¯‘å™¨/è™šæ‹Ÿæœº â†’ æ—¢å®šä»»åŠ¡ |
| Pythonè¯­è¨€	| Pythonè¯­è¨€ â†’ è§£é‡Šå™¨ â†’ æ—¢å®šä»»åŠ¡ |
| äººç±»è‡ªç„¶è¯­è¨€	| äººç±»è‡ªç„¶è¯­è¨€ â†’ LLMs â†’ å„ç§åç«¯ç»„ä»¶ â†’ æ—¢å®šä»»åŠ¡ |

å°†è¯­è¨€æ¨¡å‹ä¸å…¶ä»–æ•°æ®æºç›¸è¿æ¥ï¼Œå¹¶å…è®¸è¯­è¨€æ¨¡å‹ä¸ç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œæä¾›äº†ä¸°å¯Œçš„API
- ä¸ LLM äº¤äº’
- LLM è¿æ¥å¤–éƒ¨æ•°æ®æº

AGIçš„åŸºç¡€å·¥å…·æ¨¡å—åº“ï¼Œç±»ä¼¼æ¨¡å—åº“è¿˜æœ‰ mavinã€‚
-  LangChain provides an amazing suite of tools for everything around LLMs. 
- Itâ€™s kind of like HuggingFace but specialized for LLMs

### æ–°å…´ LLM æŠ€æœ¯æ ˆ

å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯æ ˆç”±å››ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼š
- `æ•°æ®é¢„å¤„ç†æµç¨‹`ï¼ˆdata preprocessing pipelineï¼‰: 
  - ä¸æ•°æ®æºè¿æ¥çš„è¿æ¥å™¨ï¼ˆä¾‹å¦‚S3å­˜å‚¨æ¡¶æˆ–CRMï¼‰ã€æ•°æ®è½¬æ¢å±‚ä»¥åŠä¸‹æ¸¸è¿æ¥å™¨ï¼ˆä¾‹å¦‚å‘çŸ¢é‡æ•°æ®åº“ï¼‰
  - é€šå¸¸ï¼Œè¾“å…¥åˆ°LLMä¸­çš„æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ä¹Ÿæ˜¯æœ€éš¾å¤„ç†çš„ï¼ˆå¦‚PDFã€PPTXã€HTMLç­‰ï¼‰ï¼Œä½†åŒæ—¶ï¼Œæ˜“äºè®¿é—®æ–‡æœ¬çš„æ–‡æ¡£ï¼ˆä¾‹å¦‚.DOCXï¼‰ä¸­ä¹ŸåŒ…å«ç”¨æˆ·ä¸å¸Œæœ›å‘é€åˆ°æ¨ç†ç»ˆç«¯çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚å¹¿å‘Šã€æ³•å¾‹æ¡æ¬¾ç­‰ï¼‰ã€‚
- `åµŒå…¥ç«¯ç‚¹`ï¼ˆembeddings endpoint ï¼‰+`å‘é‡å­˜å‚¨`ï¼ˆvector storeï¼‰
  - åµŒå…¥ç«¯ç‚¹ï¼ˆç”¨äºç”Ÿæˆå’Œè¿”å›è¯¸å¦‚è¯å‘é‡ã€æ–‡æ¡£å‘é‡ç­‰åµŒå…¥å‘é‡çš„ API ç«¯ç‚¹ï¼‰å’Œå‘é‡å­˜å‚¨ï¼ˆç”¨äºå­˜å‚¨å’Œæ£€ç´¢å‘é‡çš„æ•°æ®åº“æˆ–æ•°æ®å­˜å‚¨ç³»ç»Ÿï¼‰ä»£è¡¨äº†æ•°æ®å­˜å‚¨å’Œè®¿é—®æ–¹å¼çš„é‡å¤§æ¼”å˜ã€‚
  - ä»¥å‰ï¼ŒåµŒå…¥ä¸»è¦ç”¨äºè¯¸å¦‚**æ–‡æ¡£èšç±»**ä¹‹ç±»çš„ç‰¹å®šä»»åŠ¡
  - åœ¨æ–°æ¶æ„ä¸­ï¼Œå°†æ–‡æ¡£åŠå…¶åµŒå…¥å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œå¯ä»¥é€šè¿‡LLMç«¯ç‚¹å®ç°å…³é”®çš„äº¤äº’æ¨¡å¼ã€‚
  - ç›´æ¥å­˜å‚¨åŸå§‹åµŒå…¥ï¼Œæ„å‘³ç€æ•°æ®å¯ä»¥ä»¥å…¶è‡ªç„¶æ ¼å¼å­˜å‚¨ï¼Œä»è€Œå®ç°æ›´å¿«çš„å¤„ç†æ—¶é—´å’Œæ›´é«˜æ•ˆçš„æ•°æ®æ£€ç´¢ã€‚
  - æ­¤å¤–ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥æ›´å®¹æ˜“åœ°å¤„ç†å¤§å‹æ•°æ®é›†ï¼Œå› ä¸ºå®ƒå¯ä»¥å‡å°‘è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­éœ€è¦å¤„ç†çš„æ•°æ®é‡ã€‚
- `LLM ç»ˆç«¯`ï¼ˆLLM endpointsï¼‰
  - æ¥æ”¶è¾“å…¥æ•°æ®å¹¶ç”ŸæˆLLMè¾“å‡ºçš„ç»ˆç«¯ã€‚LLMç»ˆç«¯è´Ÿè´£ç®¡ç†æ¨¡å‹çš„èµ„æºï¼ŒåŒ…æ‹¬å†…å­˜å’Œè®¡ç®—èµ„æºï¼Œå¹¶æä¾›å¯æ‰©å±•å’Œå®¹é”™çš„æ¥å£ï¼Œç”¨äºå‘ä¸‹æ¸¸åº”ç”¨ç¨‹åºæä¾›LLMè¾“å‡ºã€‚
- `LLM ç¼–ç¨‹æ¡†æ¶`ï¼ˆLLM programming frameworkï¼‰
  - ä¸€å¥—å·¥å…·å’ŒæŠ½è±¡ï¼Œç”¨äºä½¿ç”¨è¯­è¨€æ¨¡å‹æ„å»ºåº”ç”¨ç¨‹åºã€‚åœ¨ç°ä»£æŠ€æœ¯æ ˆä¸­å‡ºç°äº†å„ç§ç±»å‹çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼šLLMæä¾›å•†ã€åµŒå…¥æ¨¡å‹ã€å‘é‡å­˜å‚¨ã€æ–‡æ¡£åŠ è½½å™¨ã€å…¶ä»–å¤–éƒ¨å·¥å…·ï¼ˆè°·æ­Œæœç´¢ç­‰ï¼‰ï¼Œè¿™äº›æ¡†æ¶çš„ä¸€ä¸ªé‡è¦åŠŸèƒ½æ˜¯åè°ƒå„ç§ç»„ä»¶ã€‚

å›¾è§£
- ![img](https://pic2.zhimg.com/80/v2-06c1d00721f768055a329539694c3529_720w.webp)


### LLaMA-Index

å¾…è¡¥å……

### LangChain

LangChain, è¯­è¨€é“¾æ¡ï¼Œä¹Ÿç§°ï¼š`å…°é“¾`ï¼ŒHarrison Chase 2022å¹´10æœˆåˆ›å»ºçš„ä¸€ä¸ª Python åº“ï¼Œä¸€ç§LLMè¯­è¨€å¤§æ¨¡å‹å¼€å‘å·¥å…·
- LangChainç›®å‰æœ‰ä¸¤ä¸ªè¯­è¨€çš„å®ç°ï¼špythonå’Œnodejs
- å‡ åˆ†é’Ÿå†…æ„å»º GPT é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚

LangChain å¯ä»¥å¸®åŠ©å¼€å‘è€…å°†LLMä¸å…¶ä»–è®¡ç®—æˆ–çŸ¥è¯†æºç»“åˆèµ·æ¥ï¼Œåˆ›å»ºæ›´å¼ºå¤§çš„åº”ç”¨ç¨‹åºã€‚
- ![img](https://aitechtogether.com/wp-content/uploads/2023/05/c8538d73-3b21-4a6e-8e83-845477d3f275.webp)
- ![](https://picx.zhimg.com/v2-b048e039fd396b131767f58b9c97a37b_1440w.jpg?source=172ae18b)

è®ºæ–‡ã€Š[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)ã€‹çš„å®ç°ï¼š
- è¯¥è®ºæ–‡å±•ç¤ºäº†ä¸€ç§**æç¤º**æŠ€æœ¯ï¼Œå…è®¸æ¨¡å‹ã€Œæ¨ç†ã€ï¼ˆé€šè¿‡æ€ç»´é“¾ï¼‰å’Œã€Œè¡ŒåŠ¨ã€ï¼ˆé€šè¿‡èƒ½å¤Ÿä½¿ç”¨é¢„å®šä¹‰å·¥å…·é›†ä¸­çš„å·¥å…·ï¼Œä¾‹å¦‚èƒ½å¤Ÿæœç´¢äº’è”ç½‘ï¼‰ã€‚

LangChain åœ¨æ²¡æœ‰ä»»ä½•æ”¶å…¥ä¹Ÿæ²¡æœ‰ä»»ä½•æ˜æ˜¾çš„åˆ›æ”¶è®¡åˆ’çš„æƒ…å†µä¸‹ï¼Œè·å¾—äº† 1000 ä¸‡ç¾å…ƒçš„ç§å­è½®èèµ„å’Œ 2000-2500 ä¸‡ç¾å…ƒçš„ A è½®èèµ„ï¼Œä¼°å€¼è¾¾åˆ° 2 äº¿ç¾å…ƒå·¦å³ã€‚

LangChain æ„å»ºçš„æœ‰è¶£åº”ç”¨ç¨‹åºåŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰ï¼š
- èŠå¤©æœºå™¨äºº
- ç‰¹å®šé¢†åŸŸçš„æ€»ç»“å’Œé—®ç­”
- æŸ¥è¯¢æ•°æ®åº“ä»¥è·å–ä¿¡æ¯ç„¶åå¤„ç†å®ƒä»¬çš„åº”ç”¨ç¨‹åº
- è§£å†³ç‰¹å®šé—®é¢˜çš„ä»£ç†ï¼Œä¾‹å¦‚æ•°å­¦å’Œæ¨ç†éš¾é¢˜

#### æ–‡æ¡£ä»‹ç»

- [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/en/latest/index.html)
- [GPTå¼€å‘åˆ©å™¨LangChainæŒ‡åŒ—](https://mp.weixin.qq.com/s/VGtjETMC-hRTAiL6hp5gyg)
- Github: [pythonç‰ˆæœ¬](https://github.com/hwchase17/langchain )(å·²ç»æœ‰4Wå¤šçš„star), [goè¯­è¨€ç‰ˆ](https://github.com/tmc/langchaingo)
- [åŸºäºLangChainä»é›¶å®ç°Auto-GPTå®Œå…¨æŒ‡å—](https://aitechtogether.com/python/105086.html)


#### LangFlow å¯è§†åŒ–

ã€2023-7-4ã€‘[LangFlow](https://logspace.ai/) æ˜¯ `LangChain` çš„ä¸€ç§å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆ`GUI`ï¼‰ï¼Œå®ƒä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›äº†æ˜“ç”¨çš„**å®éªŒå’ŒåŸå‹è®¾è®¡**å·¥å…·ã€‚é€šè¿‡ä½¿ç”¨ LangFlowï¼Œç”¨æˆ·å¯ä»¥åˆ©ç”¨ react-flow è½»æ¾æ„å»ºLLMåº”ç”¨ã€‚

[LangFlow](https://logspace.ai/) [github](https://github.com/logspace-ai/langflow) çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
- æä¾›å¤šç§ LangChain ç»„ä»¶ä»¥ä¾›é€‰æ‹©ï¼Œå¦‚è¯­è¨€æ¨¡å‹ã€æç¤ºåºåˆ—åŒ–å™¨ã€ä»£ç†å’Œé“¾ç­‰ã€‚
- é€šè¿‡ç¼–è¾‘æç¤ºå‚æ•°ã€é“¾æ¥é“¾å’Œä»£ç†ï¼Œä»¥åŠè·Ÿè¸ªä»£ç†çš„æ€è€ƒè¿‡ç¨‹ï¼Œç”¨æˆ·å¯ä»¥æ¢ç´¢è¿™äº›ç»„ä»¶çš„åŠŸèƒ½ã€‚
- ä½¿ç”¨ LangFlowï¼Œç”¨æˆ·å¯ä»¥å°†æµç¨‹å¯¼å‡ºä¸º JSON æ–‡ä»¶ï¼Œç„¶ååœ¨ LangChain ä¸­ä½¿ç”¨ã€‚
- LangFlow çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æä¾›äº†ä¸€ç§ç›´è§‚çš„æ–¹å¼æ¥è¿›è¡Œæµç¨‹å®éªŒå’ŒåŸå‹å¼€å‘ï¼ŒåŒ…æ‹¬æ‹–æ”¾ç»„ä»¶å’ŒèŠå¤©æ¡†
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/3985851583544f95acce1c6c2399147a~tplv-obj:1280:640.image?_iz=97245&from=post&x-expires=1696204800&x-signature=d4gBt5CjT3X6m6%2FF9sTfMLy1x6o%3D)

```sh
pip install langflow # å®‰è£…
langflow # å¯åŠ¨
python -m langflow # ä¸Šé¢å‘½ä»¤ä¸ç®¡ç”¨æ—¶ç”¨è¿™ä¸ª
```

è‡ªåŠ¨å¼¹å‡ºæœ¬åœ°webé¡µé¢: http://127.0.0.1:7860/, é…ç½®å¯å¯¼å‡ºä¸ºjsonæ ¼å¼

jsonæ ¼å¼å¯¼å…¥ flow

```py
from langflow import load_flow_from_json

flow = load_flow_from_json("path/to/flow.json")
# Now you can use it like any chain
flow("Hey, have you heard of LangFlow?")
```


#### LangChain è§‚ç‚¹

ã€2023-7-23ã€‘[æˆ‘ä¸ºä»€ä¹ˆæ”¾å¼ƒäº† LangChainï¼Ÿ](https://zhuanlan.zhihu.com/p/645345926)

ç”± LangChain æ¨å¹¿çš„ ReAct å·¥ä½œæµåœ¨ InstructGPT/text-davinci-003 ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œä½†æˆæœ¬å¾ˆé«˜ï¼Œè€Œä¸”å¯¹äºå°å‹é¡¹ç›®æ¥è¯´å¹¶ä¸å®¹æ˜“ä½¿ç”¨ã€‚

ã€ŒLangChain æ˜¯ RAG æœ€å—æ¬¢è¿çš„å·¥å…·ï¼Œæ‰€ä»¥æˆ‘æƒ³è¿™æ˜¯å­¦ä¹ å®ƒçš„æœ€ä½³æ—¶æœºã€‚æˆ‘èŠ±äº†ä¸€äº›æ—¶é—´é˜…è¯» LangChain çš„å…¨é¢æ–‡æ¡£ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å¦‚ä½•æœ€å¥½åœ°åˆ©ç”¨å®ƒã€‚ã€

ç»è¿‡ä¸€å‘¨çš„ç ”ç©¶ï¼Œæˆ‘ä¸€æ— æ‰€è·ã€‚è¿è¡Œ LangChain çš„ demo ç¤ºä¾‹ç¡®å®å¯ä»¥å·¥ä½œï¼Œä½†æ˜¯ä»»ä½•è°ƒæ•´å®ƒä»¬ä»¥é€‚åº”é£Ÿè°±èŠå¤©æœºå™¨äººçº¦æŸçš„å°è¯•éƒ½ä¼šå¤±è´¥ã€‚åœ¨è§£å†³äº†è¿™äº› bug ä¹‹åï¼ŒèŠå¤©å¯¹è¯çš„æ•´ä½“è´¨é‡å¾ˆå·®ï¼Œè€Œä¸”æ¯«æ— è¶£å‘³ã€‚ç»è¿‡ç´§å¼ çš„è°ƒè¯•ä¹‹åï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§£å†³æ–¹æ¡ˆã€‚ç”¨å›äº†ä½çº§åˆ«çš„ ReAct æµç¨‹ï¼Œå®ƒç«‹å³åœ¨å¯¹è¯è´¨é‡å’Œå‡†ç¡®æ€§ä¸Šè¶…è¿‡äº†æˆ‘çš„ LangChain å®ç°

LangChain çš„é—®é¢˜åœ¨äºå®ƒè®©ç®€å•çš„äº‹æƒ…å˜å¾—ç›¸å¯¹å¤æ‚ï¼Œè€Œè¿™ç§ä¸å¿…è¦çš„å¤æ‚æ€§é€ æˆäº†ä¸€ç§ã€Œéƒ¨è½ä¸»ä¹‰ã€ï¼ŒæŸå®³äº†æ•´ä¸ªæ–°å…´çš„äººå·¥æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿã€‚
- LangChain ä½¿ç”¨çš„ä»£ç é‡ä¸ä»…ä½¿ç”¨å®˜æ–¹ openai åº“çš„ä»£ç é‡å¤§è‡´ç›¸åŒï¼Œä¼°è®¡ LangChain åˆå¹¶äº†æ›´å¤šå¯¹è±¡ç±»ï¼Œä½†ä»£ç ä¼˜åŠ¿å¹¶ä¸æ˜æ˜¾ã€‚
- LangChain å¹å˜˜çš„æç¤ºå·¥ç¨‹åªæ˜¯ f-stringsï¼Œä¸€ä¸ªå­˜åœ¨äºæ¯ä¸ª Python å®‰è£…ä¸­çš„åŠŸèƒ½ï¼Œä½†æ˜¯æœ‰é¢å¤–çš„æ­¥éª¤ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ä½¿ç”¨è¿™äº› PromptTemplates æ¥åšåŒæ ·çš„äº‹æƒ…å‘¢ï¼Ÿ
- çœŸæ­£æƒ³åšçš„æ˜¯ï¼šå¦‚ä½•åˆ›å»º Agentï¼Œç»“åˆäº†è¿«åˆ‡æƒ³è¦çš„ ReAct å·¥ä½œæµã€‚è€ŒLangChainç¤ºä¾‹é‡Œæ¯ä¸ªæ€æƒ³ / è¡ŒåŠ¨ / è§‚å¯Ÿä¸­éƒ½ä½¿ç”¨äº†è‡ªå·±çš„ API è°ƒç”¨ OpenAIï¼Œæ‰€ä»¥é“¾æ¡æ¯”ä½ æƒ³è±¡çš„è¦æ…¢ã€‚
- LangChain å¦‚ä½•å­˜å‚¨åˆ°ç›®å‰ä¸ºæ­¢çš„å¯¹è¯?

åˆ¶ä½œè‡ªå·±çš„ Python è½¯ä»¶åŒ…è¦æ¯”è®© LangChain æ¥æ»¡è¶³è‡ªå·±çš„éœ€æ±‚å®¹æ˜“å¾—å¤š

LangChain ç¡®å®ä¹Ÿæœ‰å¾ˆå¤šå®ç”¨åŠŸèƒ½ï¼Œæ¯”å¦‚æ–‡æœ¬åˆ†å‰²å™¨å’Œé›†æˆå‘é‡å­˜å‚¨ï¼Œè¿™ä¸¤ç§åŠŸèƒ½éƒ½æ˜¯ã€Œç”¨ PDF / ä»£ç èŠå¤©ã€æ¼”ç¤ºä¸å¯æˆ–ç¼ºçš„ï¼ˆåœ¨æˆ‘çœ‹æ¥è¿™åªæ˜¯ä¸€ä¸ªå™±å¤´ï¼‰ã€‚

#### LangChain ç»„ä»¶

LangChainåŒ…å«å…­éƒ¨åˆ†ç»„ä»¶
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/f101b9ecf540489280e7f95017243fb9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=j8hpvldp7FTdOSIGCFjEyUEmbhs%3D)
- Modelsã€Promptsã€Indexesã€Memoryã€Chainsã€Agentsã€‚

LangChainä¸»è¦æ”¯æŒ6ç§ç»„ä»¶ï¼š
- `Models`ï¼šæ¨¡å‹ï¼Œå„ç§ç±»å‹çš„æ¨¡å‹å’Œæ¨¡å‹é›†æˆï¼Œæ¯”å¦‚GPT-4
- `Prompts`ï¼šæç¤ºï¼ŒåŒ…æ‹¬æç¤ºç®¡ç†ã€æç¤ºä¼˜åŒ–å’Œæç¤ºåºåˆ—åŒ–
- `Memory`ï¼šè®°å¿†ï¼Œç”¨æ¥ä¿å­˜å’Œæ¨¡å‹äº¤äº’æ—¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€
- `Indexes`ï¼šç´¢å¼•ï¼Œç”¨æ¥ç»“æ„åŒ–æ–‡æ¡£ï¼Œä»¥ä¾¿å’Œæ¨¡å‹äº¤äº’
- `Chains`ï¼šé“¾ï¼Œä¸€ç³»åˆ—å¯¹å„ç§ç»„ä»¶çš„è°ƒç”¨
- `Agents`ï¼šä»£ç†ï¼Œå†³å®šæ¨¡å‹é‡‡å–å“ªäº›è¡ŒåŠ¨ï¼Œæ‰§è¡Œå¹¶ä¸”è§‚å¯Ÿæµç¨‹ï¼Œç›´åˆ°å®Œæˆä¸ºæ­¢

##### æ¡†æ¶

LangChain æ¡†æ¶ç¤ºæ„å›¾

<div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2023-07-19T14:21:54.356Z\&quot; agent=\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\&quot; etag=\&quot;-aOkMyNOUPzSYAY1Qx6N\&quot; version=\&quot;21.6.3\&quot;&gt;\n  &lt;diagram name=\&quot;ç¬¬ 1 é¡µ\&quot; id=\&quot;YUrH7kkdw6S7EPocWAtV\&quot;&gt;\n    &lt;mxGraphModel dx=\&quot;1434\&quot; dy=\&quot;771\&quot; grid=\&quot;1\&quot; gridSize=\&quot;10\&quot; guides=\&quot;1\&quot; tooltips=\&quot;1\&quot; connect=\&quot;1\&quot; arrows=\&quot;1\&quot; fold=\&quot;1\&quot; page=\&quot;1\&quot; pageScale=\&quot;1\&quot; pageWidth=\&quot;827\&quot; pageHeight=\&quot;1169\&quot; math=\&quot;0\&quot; shadow=\&quot;0\&quot;&gt;\n      &lt;root&gt;\n        &lt;mxCell id=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;1\&quot; parent=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-64\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;587\&quot; y=\&quot;226\&quot; width=\&quot;123.75\&quot; height=\&quot;135\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-15\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;70\&quot; y=\&quot;153.75\&quot; width=\&quot;270\&quot; height=\&quot;67.5\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;CRyWcW9bKPYmjVe2kgWn-25\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;800\&quot; y=\&quot;215\&quot; width=\&quot;110\&quot; height=\&quot;150\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;CRyWcW9bKPYmjVe2kgWn-2\&quot; value=\&quot;LangChainç»„ä»¶\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=0;fontSize=22;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;310.13\&quot; y=\&quot;10\&quot; width=\&quot;170\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-3\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-2\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-5\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-4\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-6\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-2\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; value=\&quot;LangChain&amp;lt;br&amp;gt;å…°é“¾\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#B3B3B3;strokeColor=#314354;fontStyle=1;fontSize=17;fontColor=#ffffff;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;225.44\&quot; y=\&quot;267.5\&quot; width=\&quot;109.62\&quot; height=\&quot;45\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-24\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-60\&quot; target=\&quot;CRyWcW9bKPYmjVe2kgWn-25\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;630.75\&quot; y=\&quot;290\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-57\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;exitX=0.5;exitY=0;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeColor=#FF6666;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-10\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-56\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-2\&quot; value=\&quot;Models&amp;lt;br&amp;gt;æ¨¡å‹\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#d80073;strokeColor=none;rounded=1;fontStyle=1;fontSize=14;fontColor=#ffffff;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;430.25\&quot; y=\&quot;272.5\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-16\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#FF9999;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-4\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-10\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-4\&quot; value=\&quot;Chains&amp;lt;br&amp;gt;é“¾\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#f8cecc;strokeColor=none;rounded=1;fontStyle=1;fontSize=14;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;237.5\&quot; y=\&quot;170\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-17\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#FF9999;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-7\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-2\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-7\&quot; value=\&quot;Prompts&amp;lt;br&amp;gt;æç¤º\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;rounded=1;fontStyle=1;fontSize=14;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;430.25\&quot; y=\&quot;340\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-32\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-8\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-25\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;282\&quot; y=\&quot;515\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-8\&quot; value=\&quot;Document Loader &amp;amp;amp; Utils\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=1\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;206.82\&quot; y=\&quot;450\&quot; width=\&quot;149.38\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-9\&quot; value=\&quot;Memory&amp;lt;br&amp;gt;è®°å¿†\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#60a917;strokeColor=none;rounded=1;fontColor=#ffffff;fontStyle=1;fontSize=14;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;80\&quot; y=\&quot;272.5\&quot; width=\&quot;107.75\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-10\&quot; value=\&quot;Agents&amp;lt;br&amp;gt;ä»£ç†\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#1ba1e2;strokeColor=none;rounded=1;fontColor=#ffffff;fontStyle=1;fontSize=14;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;80\&quot; y=\&quot;170\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-11\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=1;entryY=1;entryDx=0;entryDy=0;exitX=0;exitY=0;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-10\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;297.5\&quot; y=\&quot;285\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;330.5\&quot; y=\&quot;215\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-12\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-9\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;220\&quot; y=\&quot;290\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;182.5\&quot; y=\&quot;245\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-13\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-33\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-8\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;260.5\&quot; y=\&quot;303\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;192.5\&quot; y=\&quot;255\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-14\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=0;entryY=0;entryDx=0;entryDy=0;exitX=1;exitY=1;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-7\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;270.5\&quot; y=\&quot;313\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;202.5\&quot; y=\&quot;265\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-19\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-18\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-9\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-48\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.409;entryY=0;entryDx=0;entryDy=0;entryPerimeter=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-18\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-41\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-18\&quot; value=\&quot;Vectorstores\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=1\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;80\&quot; y=\&quot;450\&quot; width=\&quot;107.75\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-20\&quot; value=\&quot;GPT 3.5\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;rounded=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;816.13\&quot; y=\&quot;225\&quot; width=\&quot;73.87\&quot; height=\&quot;25\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-21\&quot; value=\&quot;GPT 4\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;rounded=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;816.13\&quot; y=\&quot;255\&quot; width=\&quot;73.87\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-22\&quot; value=\&quot;Claude\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;rounded=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;816.13\&quot; y=\&quot;285\&quot; width=\&quot;73.87\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-23\&quot; value=\&quot;ChatGLM\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;rounded=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;816.13\&quot; y=\&quot;322.5\&quot; width=\&quot;73.87\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-25\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;414\&quot; y=\&quot;435\&quot; width=\&quot;222.25\&quot; height=\&quot;65\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-26\&quot; value=\&quot;Text\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;426.25\&quot; y=\&quot;443\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-27\&quot; value=\&quot;Image\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;496.38\&quot; y=\&quot;443\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-28\&quot; value=\&quot;Word\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;426.25\&quot; y=\&quot;473\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-29\&quot; value=\&quot;PDF\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;496.38\&quot; y=\&quot;473\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-30\&quot; value=\&quot;Video\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;566.25\&quot; y=\&quot;443\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-31\&quot; value=\&quot;Url\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;566.25\&quot; y=\&quot;473\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-35\&quot; value=\&quot;è®°å¿†ç±»å‹&amp;lt;br&amp;gt;â‘  short term: buffer&amp;lt;br&amp;gt;â‘¡ long term: Entity&amp;lt;br&amp;gt;ç»„ä»¶ç±»å‹&amp;lt;br&amp;gt;â‘  å…¨éƒ¨å¯¹è¯å†…å®¹&amp;lt;br&amp;gt;â‘¡ æœ€è¿‘kè½®&amp;lt;br&amp;gt;â‘¢ å†…å®¹æ‘˜è¦&amp;lt;br&amp;gt;â‘£ åŒ¹é…æœ€ç›¸ä¼¼çš„kç»„\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;20.25\&quot; y=\&quot;292.5\&quot; width=\&quot;130\&quot; height=\&quot;130\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-36\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-1\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-33\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;280\&quot; y=\&quot;313\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;280\&quot; y=\&quot;450\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-33\&quot; value=\&quot;Indexes&amp;lt;br&amp;gt;ç´¢å¼•\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#e1d5e7;strokeColor=none;rounded=1;fontStyle=1;fontSize=14;shadow=1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;239.26\&quot; y=\&quot;375\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-37\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#999999;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-33\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-18\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;292\&quot; y=\&quot;420\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;292\&quot; y=\&quot;460\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-38\&quot; value=\&quot;ç»„ä»¶&amp;lt;br&amp;gt;â‘  Document Loader&amp;lt;br&amp;gt;â‘¡ Vector Stores&amp;lt;br&amp;gt;â‘¢ Text Splitters&amp;lt;br&amp;gt;â‘£ Retrievers\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;330.13\&quot; y=\&quot;353\&quot; width=\&quot;130\&quot; height=\&quot;90\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-39\&quot; value=\&quot;ä»»åŠ¡é“¾&amp;lt;br&amp;gt;â‘  Simple Chainï¼ˆæ¨¡æ¿ï¼‰&amp;lt;br&amp;gt;â‘¡ Sequential Chain&amp;lt;br&amp;gt;â‘¢ ä¸å¤–éƒ¨æ•°æ®&amp;lt;br&amp;gt;â‘£ ä¸é•¿æœŸè®°å¿†\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;245\&quot; y=\&quot;80\&quot; width=\&quot;160\&quot; height=\&quot;90\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-40\&quot; value=\&quot;Autonomus Chains&amp;lt;br&amp;gt;â‘  Tools + Agents&amp;lt;br&amp;gt;â‘¡ BabyAGI, AutoGPT\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;47.74999999999999\&quot; y=\&quot;200\&quot; width=\&quot;140\&quot; height=\&quot;60\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-41\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;43\&quot; y=\&quot;520\&quot; width=\&quot;222.25\&quot; height=\&quot;65\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-42\&quot; value=\&quot;FAISS\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;55.25\&quot; y=\&quot;528\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-43\&quot; value=\&quot;ES\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;125.38\&quot; y=\&quot;528\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-44\&quot; value=\&quot;Pinecone\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;55.25\&quot; y=\&quot;558\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-45\&quot; value=\&quot;Chroma\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;125.38\&quot; y=\&quot;558\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-46\&quot; value=\&quot;Milvus\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;195.25\&quot; y=\&quot;528\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-47\&quot; value=\&quot;PGVector\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;195.25\&quot; y=\&quot;558\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-49\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;dashed=1;dashPattern=1 1;fillColor=#E6E6E6;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;514.75\&quot; y=\&quot;123.75\&quot; width=\&quot;222.25\&quot; height=\&quot;65\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-50\&quot; value=\&quot;Google\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;527\&quot; y=\&quot;131.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-51\&quot; value=\&quot;Wolfram\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;597.13\&quot; y=\&quot;131.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-52\&quot; value=\&quot;Wikipedia\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;527\&quot; y=\&quot;161.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-53\&quot; value=\&quot;API\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;597.13\&quot; y=\&quot;161.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-54\&quot; value=\&quot;Youtube\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;667\&quot; y=\&quot;131.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-55\&quot; value=\&quot;Web\&quot; style=\&quot;whiteSpace=wrap;html=1;rounded=1;dashed=1;dashPattern=1 2;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;667\&quot; y=\&quot;161.75\&quot; width=\&quot;60\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-56\&quot; value=\&quot;Tools\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=0;fontSize=14;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;375.63\&quot; y=\&quot;138.75\&quot; width=\&quot;84.5\&quot; height=\&quot;35\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-58\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-56\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-49\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;483\&quot; y=\&quot;283\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;483\&quot; y=\&quot;245\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-59\&quot; value=\&quot;å…­å¤§ç»„ä»¶ï¼šModelsã€Promptsã€Indexesã€Memoryã€Chainsã€Agents\&quot; style=\&quot;text;fontColor=default;labelBackgroundColor=none;fontSize=12;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;500\&quot; y=\&quot;80\&quot; width=\&quot;366.24\&quot; height=\&quot;20\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-61\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;RI6usgfjZI69E3hADuvV-2\&quot; target=\&quot;RI6usgfjZI69E3hADuvV-60\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;515\&quot; y=\&quot;290\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;626\&quot; y=\&quot;290\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-60\&quot; value=\&quot;LLMs\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=0;fontSize=14;shadow=0;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;600.75\&quot; y=\&quot;276.5\&quot; width=\&quot;60.63\&quot; height=\&quot;27.5\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-62\&quot; value=\&quot;Chat Models\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=0;fontSize=14;shadow=0;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;597\&quot; y=\&quot;235\&quot; width=\&quot;90\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-63\&quot; value=\&quot;Text Embedding\&quot; style=\&quot;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;rounded=1;fontStyle=0;fontSize=14;shadow=0;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;597\&quot; y=\&quot;318.75\&quot; width=\&quot;110\&quot; height=\&quot;27.5\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-65\&quot; value=\&quot;é¡ºåºç¡®å®š\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontColor=#FF0000;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;300\&quot; y=\&quot;200\&quot; width=\&quot;70\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-66\&quot; value=\&quot;æ”¹è¿›ï¼šä¸å®š\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontColor=#FF0000;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;165\&quot; y=\&quot;158.75\&quot; width=\&quot;80\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-67\&quot; value=\&quot;ç»„æˆ&amp;lt;br&amp;gt;â‘  Actionæ‰§è¡Œæ“ä½œ&amp;lt;br&amp;gt;â‘¡ Observation æ”¶åˆ°çš„ä¿¡æ¯&amp;lt;br&amp;gt;â‘¢ Decision å†³ç­–\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;25.25\&quot; y=\&quot;68.75\&quot; width=\&quot;170\&quot; height=\&quot;70\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;RI6usgfjZI69E3hADuvV-68\&quot; value=\&quot;wangqiwen&amp;#xa;2023-7-19\&quot; style=\&quot;text;fontColor=default;labelBackgroundColor=none;fontSize=12;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;476.5\&quot; y=\&quot;533.75\&quot; width=\&quot;69.75\&quot; height=\&quot;37.5\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n      &lt;/root&gt;\n    &lt;/mxGraphModel&gt;\n  &lt;/diagram&gt;\n&lt;/mxfile&gt;\n&quot;}"></div>
<script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script>


##### Document Loaders and Utils

LangChain çš„ Document Loaders å’Œ Utils æ¨¡å—åˆ†åˆ«ç”¨äº**è¿æ¥åˆ°æ•°æ®æº**å’Œ**è®¡ç®—æº**ã€‚

å½“ä½¿ç”¨loaderåŠ è½½å™¨è¯»å–åˆ°æ•°æ®æºåï¼Œæ•°æ®æºéœ€è¦è½¬æ¢æˆ Document å¯¹è±¡åï¼Œåç»­æ‰èƒ½è¿›è¡Œä½¿ç”¨ã€‚

Document Loaders çš„Unstructured å¯ä»¥å°†è¿™äº›åŸå§‹æ•°æ®æºè½¬æ¢ä¸ºå¯å¤„ç†çš„æ–‡æœ¬ã€‚

The following document loaders are provided:
- CSV Loader CSVæ–‡ä»¶
- DataFrame Loader ä» pandas æ•°æ®å¸§åŠ è½½æ•°æ®
- Diffbot ä» URL åˆ—è¡¨ä¸­æå– HTML æ–‡æ¡£ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„æ–‡æ¡£æ ¼å¼
- Directory Loader åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
- EverNote å°è±¡ç¬”è®°
- Git ä» Git å­˜å‚¨åº“åŠ è½½æ–‡æœ¬æ–‡ä»¶
- Google Drive Googleç½‘ç›˜
- HTML HTML æ–‡æ¡£
- Markdown
- Notebook å°† .ipynb ç¬”è®°æœ¬ä¸­çš„æ•°æ®åŠ è½½ä¸ºé€‚åˆ LangChain çš„æ ¼å¼
- Notion
- PDF
- PowerPoint
- Unstructured File Loader ä½¿ç”¨UnstructuredåŠ è½½å¤šç§ç±»å‹çš„æ–‡ä»¶ï¼Œç›®å‰æ”¯æŒåŠ è½½æ–‡æœ¬æ–‡ä»¶ã€powerpointsã€htmlã€pdfã€å›¾åƒç­‰
- URL åŠ è½½ URL åˆ—è¡¨ä¸­çš„ HTML æ–‡æ¡£å†…å®¹
- Word Documents

##### Text Spltters

æ–‡æœ¬åˆ†å‰²å°±æ˜¯ç”¨æ¥åˆ†å‰²æ–‡æœ¬çš„ã€‚

ä¸ºä»€ä¹ˆéœ€è¦åˆ†å‰²æ–‡æœ¬ï¼Ÿ
- å› ä¸ºæ¯æ¬¡ä¸ç®¡æŠŠæ–‡æœ¬å½“ä½œ prompt å‘ç»™ openai api ï¼Œè¿˜æ˜¯ä½¿ç”¨ embedding åŠŸèƒ½, éƒ½æ˜¯æœ‰å­—ç¬¦é™åˆ¶çš„ã€‚

æ¯”å¦‚å°†ä¸€ä»½300é¡µçš„ pdf å‘ç»™ openai apiï¼Œè¿›è¡Œæ€»ç»“ï¼Œè‚¯å®šä¼šæŠ¥è¶…è¿‡æœ€å¤§ Token é”™ã€‚æ‰€ä»¥è¿™é‡Œå°±éœ€è¦ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨å»åˆ†å‰² loader è¿›æ¥çš„ Documentã€‚
- é»˜è®¤æ¨èçš„æ–‡æœ¬æ‹†åˆ†å™¨æ˜¯ RecursiveCharacterTextSplitterã€‚
- é»˜è®¤æƒ…å†µä»¥ [â€œ\n\nâ€, â€œ\nâ€, â€œ â€œ, â€œâ€] å­—ç¬¦è¿›è¡Œæ‹†åˆ†ã€‚
- å…¶å®ƒå‚æ•°è¯´æ˜ï¼š
  - length_function å¦‚ä½•è®¡ç®—å—çš„é•¿åº¦ã€‚é»˜è®¤åªè®¡ç®—å­—ç¬¦æ•°ï¼Œä½†åœ¨è¿™é‡Œä¼ é€’ä»¤ç‰Œè®¡æ•°å™¨æ˜¯å¾ˆå¸¸è§çš„ã€‚
  - chunk_sizeï¼šå—çš„æœ€å¤§å¤§å°ï¼ˆç”±é•¿åº¦å‡½æ•°æµ‹é‡ï¼‰ã€‚
  - chunk_overlapï¼šå—ä¹‹é—´çš„æœ€å¤§é‡å ã€‚æœ‰ä¸€äº›é‡å å¯ä»¥å¾ˆå¥½åœ°ä¿æŒå—ä¹‹é—´çš„ä¸€äº›è¿ç»­æ€§ï¼ˆä¾‹å¦‚ï¼Œåšä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼‰
- CharacterTextSplitter é»˜è®¤æƒ…å†µä¸‹ä»¥ separator="\n\n"è¿›è¡Œæ‹†åˆ†
- TiktokenText Splitter ä½¿ç”¨OpenAI çš„å¼€æºåˆ†è¯å™¨åŒ…æ¥ä¼°è®¡ä½¿ç”¨çš„ä»¤ç‰Œ

```py
# This is a long document we can split up.
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()
from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(        
    separator = "\n\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)
metadatas = [{"document": 1}, {"document": 2}]
documents = text_splitter.create_documents([state_of_the_union, state_of_the_union], metadatas=metadatas)
print(texts[0])
```

```py
# This is a long document we can split up.
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()
from langchain.text_splitter import TokenTextSplitter
text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)
texts = text_splitter.split_text(state_of_the_union)
print(texts[0])
```

##### LangChain Embedding

æ¨¡å‹æ‹‰åˆ°æœ¬åœ°ä½¿ç”¨çš„å¥½å¤„ï¼š
- è®­ç»ƒæ¨¡å‹
- å¯ä»¥ä½¿ç”¨æœ¬åœ°çš„ GPU
- æœ‰äº›æ¨¡å‹æ— æ³•åœ¨ HuggingFace è¿è¡Œ

LangChain Embeddingç¤ºä¾‹
- HuggingFace

```py
from langchain.embeddings import HuggingFaceEmbeddings 

embeddings = HuggingFaceEmbeddings() 
text = "This is a test document." 
query_result = embeddings.embed_query(text) 
doc_result = embeddings.embed_documents([text])
```

- llama-cpp

```py
# !pip install llama-cpp-python
from langchain.embeddings import LlamaCppEmbeddings

llama = LlamaCppEmbeddings(model_path="/path/to/model/ggml-model-q4_0.bin")
text = "This is a test document."
query_result = llama.embed_query(text)
doc_result = llama.embed_documents([text])
```

- OpenAI

```py
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text = "This is a test document."
query_result = embeddings.embed_query(text)
doc_result = embeddings.embed_documents([text])
```


##### ï¼ˆ1ï¼‰Modelsï¼ˆæ¨¡å‹ï¼‰ï¼šLLMé€‰æ‹©

ï¼ˆ1ï¼‰`Models`ï¼ˆæ¨¡å‹ï¼‰: å¯é€‰æ‹©ä¸åŒçš„LLMä¸Embeddingæ¨¡å‹ã€‚å¯ä»¥ç›´æ¥è°ƒç”¨ API å·¥ä½œï¼Œä¹Ÿå¯ä»¥è¿è¡Œæœ¬åœ°æ¨¡å‹ã€‚
- `LLMs`ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰: æ¥æ”¶æ–‡æœ¬å­—ç¬¦ä½œä¸ºè¾“å…¥ï¼Œè¿”å›çš„ä¹Ÿæ˜¯æ–‡æœ¬å­—ç¬¦
- `Chat Models` èŠå¤©æ¨¡å‹
  - èŠå¤©æ¨¡å‹åŸºäºLLMsï¼Œä¸åŒçš„æ˜¯å®ƒæ¥æ”¶èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œè¿”å›çš„ä¹Ÿæ˜¯èŠå¤©æ¶ˆæ¯
  - èŠå¤©æ¶ˆæ¯æ˜¯ä¸€ç§ç‰¹å®šæ ¼å¼çš„æ•°æ®ï¼ŒLangChainä¸­æ”¯æŒå››ç§æ¶ˆæ¯: `AIMessage`,`Â HumanMessage`,`Â SystemMessage` ,`ChatMessage` ï¼Œéœ€è¦æŒ‰ç…§è§’è‰²æŠŠæ•°æ®ä¼ é€’ç»™æ¨¡å‹ï¼Œè¿™éƒ¨åˆ†åœ¨åé¢æ–‡ç« é‡Œå†è¯¦ç»†è§£é‡Šã€‚
- `Text Embedding`ï¼šç”¨äºæ–‡æœ¬çš„å‘é‡åŒ–è¡¨ç¤ºã€‚æ–‡æœ¬åµŒå…¥æ¨¡å‹æ¥æ”¶æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œè¿”å›çš„æ˜¯æµ®ç‚¹æ•°åˆ—è¡¨. è®¾è®¡ç”¨äºä¸åµŒå…¥äº¤äº’çš„ç±»
  - ç”¨äºå®ç°åŸºäºçŸ¥è¯†åº“çš„é—®ç­”å’Œsemantic searchï¼Œç›¸æ¯” fine-tuning æœ€å¤§çš„ä¼˜åŠ¿ï¼šä¸ç”¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”å¯ä»¥å®æ—¶æ·»åŠ æ–°çš„å†…å®¹ï¼Œè€Œä¸ç”¨åŠ ä¸€æ¬¡æ–°çš„å†…å®¹å°±è®­ç»ƒä¸€æ¬¡ï¼Œå¹¶ä¸”å„æ–¹é¢æˆæœ¬è¦æ¯” fine-tuning ä½å¾ˆå¤šã€‚
  - ä¾‹å¦‚ï¼Œå¯è°ƒç”¨OpenAIã€Cohereã€HuggingFaceç­‰Embeddingæ ‡å‡†æ¥å£ï¼Œå¯¹æ–‡æœ¬å‘é‡åŒ–ã€‚
  - ä¸¤ä¸ªæ–¹æ³•ï¼š`embed_documents` å’Œ `embed_query`ã€‚æœ€å¤§åŒºåˆ«åœ¨äºæ¥å£ä¸åŒï¼šä¸€ç§å¤„ç†**å¤š**ä¸ªæ–‡æ¡£ï¼Œè€Œå¦ä¸€ç§å¤„ç†**å•**ä¸ªæ–‡æ¡£ã€‚
  - æ–‡æœ¬åµŒå…¥æ¨¡å‹é›†æˆäº†å¦‚ä¸‹çš„æºï¼šAzureOpenAIã€Hugging Face Hubã€InstructEmbeddingsã€Llama-cppã€OpenAI ç­‰
- HuggingFace Models

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯Modelsçš„æ ¸å¿ƒï¼Œä¹Ÿæ˜¯LangChainçš„åŸºç¡€ç»„æˆéƒ¨åˆ†ï¼ŒLLMsæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ…è£…å™¨ï¼Œé€šè¿‡è¯¥æ¥å£ä¸å„ç§å¤§æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚
- è¿™äº›æ¨¡å‹åŒ…æ‹¬OpenAIçš„GPT-3.5/4ã€è°·æ­Œçš„LaMDA/PaLMï¼ŒMeta AIçš„LLaMAç­‰ã€‚

LLMs ç±»çš„åŠŸèƒ½å¦‚ä¸‹ï¼š
- æ”¯æŒå¤šç§æ¨¡å‹æ¥å£ï¼Œå¦‚ OpenAIã€Hugging Face Hubã€Anthropicã€Azure OpenAIã€GPT4Allã€Llama-cppâ€¦
- Fake LLMï¼Œç”¨äºæµ‹è¯•
- ç¼“å­˜çš„æ”¯æŒï¼Œæ¯”å¦‚ in-memï¼ˆå†…å­˜ï¼‰ã€SQLiteã€Redisã€SQL
- ç”¨é‡è®°å½•
- æ”¯æŒæµæ¨¡å¼ï¼ˆå°±æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—çš„è¿”å›ï¼Œç±»ä¼¼æ‰“å­—æ•ˆæœï¼‰

LangChainè°ƒç”¨OpenAIçš„gpt-3.5-turboå¤§è¯­è¨€æ¨¡å‹çš„ç®€å•ç¤ºä¾‹

```py
import os
from langchain.llms import OpenAI

openai_api_key = 'sk-******'
os.environ['OPENAI_API_KEY'] = openai_api_key

llm = OpenAI(model_name="gpt-3.5-turbo")
# llm = OpenAI(model_name="text-davinci-003", n=2, best_of=2)
print(llm("è®²ä¸ªç¬‘è¯ï¼Œå¾ˆå†·çš„ç¬‘è¯"))
# ä¸ºä»€ä¹ˆé¸Ÿå„¿ä¼šæˆä¸ºæ¸¸æ³³é«˜æ‰‹ï¼Ÿå› ä¸ºå®ƒä»¬æœ‰ä¸€åªè„šæ¯”å¦ä¸€åªè„šæ›´é•¿ï¼Œæ‰€ä»¥æ¸¸èµ·æ³³æ¥ä¸è´¹åŠ›ï¼ï¼ˆç¬‘ï¼‰
llm_result = llm.generate(["Tell me a joke", "Tell me a poem"])
llm_result.llm_output    # è¿”å› tokens ä½¿ç”¨é‡
```

###### æµå¼è¾“å‡º

æµå¼è¾“å‡º
- LangChainåœ¨æ”¯æŒä»£ç†å°è£…ChatGPTæ¥å£çš„åŸºç¡€ä¸Šï¼Œä¹ŸåŒæ ·åœ°æŠŠChatGPT APIæ¥å£çš„æµå¼æ•°æ®è¿”å›é›†æˆäº†è¿›æ¥

```py
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI, ChatAnthropic
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler # æµå¼
from langchain.schema import HumanMessage
# streaming
llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)
resp = llm("Write me a song about sparkling water.")
```

###### ç¼“å­˜

ç¼“å­˜LLMçš„ç»“æœ
- è°ƒç”¨ChatGPTçš„APIæ¥å£å¾€å¾€ä¼šå­˜åœ¨ç½‘ç»œå»¶æ—¶çš„æƒ…å†µ
- ä¸ºäº†æ›´ä¼˜é›…çš„å®ç°LLMè¯­è¨€ç”Ÿæˆæ¨¡å‹ï¼ŒLangChainåŒæ—¶æä¾›äº†æ•°æ®ç¼“å­˜çš„æ¥å£å¦‚æœç”¨æˆ·é—®äº†**åŒæ ·çš„é—®é¢˜**ï¼ŒLangChainæ”¯æŒç›´æ¥å°†æ‰€ç¼“å­˜çš„æ•°æ®ç›´æ¥å“åº”

```py
import langchain
from langchain.cache import InMemoryCache # å¯åŠ¨ç¼“å­˜
langchain.llm_cache = InMemoryCache()

# To make the caching really obvious, lets use a slower model.
llm = OpenAI(model_name="text-davinci-002", n=2, best_of=2)
```

###### å¼‚æ­¥è¿”å›

å¼‚æ­¥è¿”å›
- æ„å»ºå¤æ‚çš„LLMæ¨¡å‹è°ƒç”¨é“¾æ—¶ï¼Œå¾€å¾€å­˜åœ¨æ¥å£çš„**å¤šæ¬¡è°ƒç”¨**ï¼Œè€Œä¸”å¹¶ä¸èƒ½ä¿è¯æ¥å£çš„å®æ—¶æ€§è¿”å›
- è¿™æ—¶å¯ä»¥ä½¿ç”¨æ¥å£**å¼‚æ­¥è¿”å›**çš„æ¨¡å‹æ¥æå‡åŠŸèƒ½çš„æœåŠ¡è´¨é‡ï¼Œç³»ç»Ÿçš„æ€§èƒ½

```py
import time
import asyncio # å¼‚æ­¥

from langchain.llms import OpenAI

def generate_serially():
    llm = OpenAI(temperature=0.9)
    for _ in range(10):
        resp = llm.generate(["Hello, how are you?"])
        print(resp.generations[0][0].text)

async def async_generate(llm):
    resp = await llm.agenerate(["Hello, how are you?"])
    print(resp.generations[0][0].text)

async def generate_concurrently():
    llm = OpenAI(temperature=0.9)
    tasks = [async_generate(llm) for _ in range(10)]
    await asyncio.gather(*tasks)


s = time.perf_counter()
# If running this outside of Jupyter, use asyncio.run(generate_concurrently())
await generate_concurrently()
elapsed = time.perf_counter() - s
print('\033[1m' + f"Concurrent executed in {elapsed:0.2f} seconds." + '\033[0m')

s = time.perf_counter()
generate_serially()
elapsed = time.perf_counter() - s
print('\033[1m' + f"Serial executed in {elapsed:0.2f} seconds." + '\033[0m')
```

###### å¤šæ¨¡å‹èåˆ

æ•´åˆå¤šä¸ªæ¨¡å‹
- ä½œä¸ºLangChainä¸­çš„æ ¸å¿ƒæ¨¡å—ï¼ŒLangChainä¸æ­¢æ”¯æŒç®€å•çš„LLMï¼Œä»ç®€å•çš„æ–‡æœ¬ç”ŸæˆåŠŸèƒ½ã€ä¼šè¯èŠå¤©åŠŸèƒ½ä»¥åŠæ–‡æœ¬å‘é‡åŒ–åŠŸèƒ½å‡é›†æˆï¼Œå¹¶ä¸”å°†å…¶å°è£…æˆä¸€ä¸ªä¸€ä¸ªçš„é“¾æ¡èŠ‚ç‚¹
- ï¼ˆ1ï¼‰å¤§è¯­è¨€æ¨¡å‹
- ï¼ˆ2ï¼‰èŠå¤©æ¨¡å‹: OpenAIæ‰€æä¾›çš„å¤šè§’è‰²èŠå¤©ï¼Œå…è®¸ç”¨æˆ·è®¾å®šä¿¡æ¯å½’å±ä¸åŒçš„è§’è‰²ï¼Œä»è€Œä¸°å¯Œç”¨æˆ·çš„èŠå¤©èƒŒæ™¯ï¼Œæ„é€ å‡ºæ›´åŠ æ‹ŸäººåŒ–çš„èŠå¤©æ•ˆæœ
- ï¼ˆ3ï¼‰è¯­è¨€å‘é‡åŒ–æ¨¡å‹

OpenAI

```py
import os
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
from langchain.llms import OpenAI
from langchain import PromptTemplate, LLMChain

template = """Question: {question}
Answer: Let's think step by step."""
prompt = PromptTemplate(template=template, input_variables=["question"])
llm = OpenAI()
llm_chain = LLMChain(prompt=prompt, llm=llm)
question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"
llm_chain.run(question)
```

è§’è‰²è®¾ç½®

```py
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)

chat = ChatOpenAI(temperature=0)

messages = [
    SystemMessage(content="You are a helpful assistant that translates English to French."),
    HumanMessage(content="Translate this sentence from English to French. I love programming.")
]
chat(messages)
```

æ¨¡æ¿åŒ–ç¼–æ’

```py
template="You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

# get a chat completion from the formatted messages
chat(chat_prompt.format_prompt(input_language="English", output_language="French", text="I love programming.").to_messages())
```

Azure OpenAI

```py
import os
os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_VERSION"] = "2022-12-01"
os.environ["OPENAI_API_BASE"] = "..."
os.environ["OPENAI_API_KEY"] = "..."
# Import Azure OpenAI
from langchain.llms import AzureOpenAI
# Create an instance of Azure OpenAI
# Replace the deployment name with your own
llm = AzureOpenAI(
    deployment_name="td2",
    model_name="text-davinci-002",
)
# Run the LLM
llm("Tell me a joke")
```

Hugging Face Hub

```py
import os
os.environ["HUGGINGFACEHUB_API_TOKEN"] = HUGGINGFACEHUB_API_TOKEN

from langchain import HuggingFaceHub

repo_id = "google/flan-t5-xl" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options
llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={"temperature":0, "max_length":64})

from langchain import PromptTemplate, LLMChain

template = """Question: {question}
Answer: Let's think step by step."""
prompt = PromptTemplate(template=template, input_variables=["question"])
llm_chain = LLMChain(prompt=prompt, llm=llm)
question = "Who won the FIFA World Cup in the year 1994? "
print(llm_chain.run(question))
```


##### ï¼ˆ2ï¼‰Promptsï¼ˆæç¤ºè¯­ï¼‰: æ¨¡æ¿åŒ–

é€šå¸¸ä½œä¸ºè¾“å…¥ä¼ é€’ç»™æ¨¡å‹çš„ä¿¡æ¯è¢«ç§°ä¸º`æç¤º`
- æç¤ºå¯ä»¥æ˜¯**æ–‡æœ¬å­—ç¬¦**ï¼Œä¹Ÿå¯ä»¥æ˜¯**æ–‡ä»¶**ã€**å›¾ç‰‡**ç”šè‡³**è§†é¢‘**
- LangChainç›®å‰åªæ”¯æŒå­—ç¬¦å½¢å¼çš„æç¤ºã€‚

æç¤ºä¸€èˆ¬ä¸æ˜¯**ç¡¬ç¼–ç **çš„å½¢å¼å†™åœ¨ä»£ç é‡Œï¼Œè€Œæ˜¯ç”±`æ¨¡æ¿`å’Œ`ç”¨æˆ·è¾“å…¥`æ¥ç”Ÿæˆï¼ŒLangChainæä¾›å¤šä¸ªç±»å’Œæ–¹æ³•æ¥æ„å»ºæç¤ºã€‚
- `æç¤ºæ¨¡æ¿`
  - æç¤ºæ¨¡æ¿æ˜¯ä¸€ç§ç”Ÿæˆæç¤ºçš„æ–¹å¼ï¼ŒåŒ…å«ä¸€ä¸ªå¸¦æœ‰å¯æ›¿æ¢å†…å®¹çš„æ¨¡æ¿ï¼Œä»ç”¨æˆ·é‚£è·å–ä¸€ç»„å‚æ•°å¹¶ç”Ÿæˆæç¤º
  - æç¤ºæ¨¡æ¿ç”¨æ¥ç”ŸæˆLLMsçš„æç¤ºï¼Œæœ€ç®€å•çš„ä½¿ç”¨åœºæ™¯ï¼Œæ¯”å¦‚â€œæˆ‘å¸Œæœ›ä½ æ‰®æ¼”ä¸€ä¸ªä»£ç ä¸“å®¶çš„è§’è‰²ï¼Œå‘Šè¯‰æˆ‘è¿™ä¸ªæ–¹æ³•çš„åŸç†{code}â€ã€‚
- `èŠå¤©æç¤ºæ¨¡æ¿`
  - èŠå¤©æ¨¡å‹æ¥æ”¶èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå†æ¬¡å¼ºè°ƒèŠå¤©æ¶ˆæ¯å’Œæ™®é€šå­—ç¬¦æ˜¯ä¸ä¸€æ ·çš„ï¼ŒèŠå¤©æç¤ºæ¨¡æ¿çš„ä½œç”¨å°±æ˜¯ä¸ºèŠå¤©æ¨¡å‹ç”Ÿæˆæç¤º
- `ç¤ºä¾‹é€‰æ‹©å™¨`
  - ç¤ºä¾‹é€‰æ‹©å™¨æ˜¯ä¸€ä¸ªé«˜çº§ç‰ˆçš„æ•°æ®ç­›é€‰å™¨
- `è¾“å‡ºè§£æå™¨`
  - ç”±äºæ¨¡å‹è¿”å›çš„æ˜¯æ–‡æœ¬å­—ç¬¦ï¼Œè¾“å‡ºè§£æå™¨å¯ä»¥æŠŠæ–‡æœ¬è½¬æ¢æˆç»“æ„åŒ–æ•°æ®

Promptsï¼ˆæç¤ºè¯­ï¼‰: ç®¡ç†LLMè¾“å…¥
- PromptTemplate è´Ÿè´£æ„å»ºæ­¤è¾“å…¥
- LangChain æä¾›äº†å¯ç”¨äºæ ¼å¼åŒ–è¾“å…¥å’Œè®¸å¤šå…¶ä»–å®ç”¨ç¨‹åºçš„æç¤ºæ¨¡æ¿ã€‚

å½“ç”¨æˆ·ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹è¯æ—¶ï¼Œç”¨æˆ·å†…å®¹å³Promptï¼ˆæç¤ºè¯­ï¼‰ã€‚
- å¦‚æœç”¨æˆ·æ¯æ¬¡è¾“å…¥çš„Promptä¸­åŒ…å«å¤§é‡çš„é‡å¤å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ª**Promptæ¨¡æ¿**ï¼Œå°†é€šç”¨éƒ¨åˆ†æå–å‡ºæ¥ï¼Œç”¨æˆ·è¾“å…¥è¾“å…¥éƒ¨åˆ†ä½œä¸ºå˜é‡ã€‚

Promptæ¨¡æ¿ååˆ†æœ‰ç”¨
- åˆ©ç”¨langchainæ„å»ºä¸“å±**å®¢æœåŠ©ç†**ï¼Œå¹¶ä¸”æ˜ç¡®å‘Šè¯‰å…¶åªå›ç­”**çŸ¥è¯†åº“**ï¼ˆäº§å“ä»‹ç»ã€è´­ä¹°æµç¨‹ç­‰ï¼‰é‡Œé¢çš„çŸ¥è¯†ï¼Œå…¶ä»–æ— å…³çš„è¯¢é—®ï¼Œåªå›ç­”â€œæˆ‘è¿˜æ²¡æœ‰å­¦ä¹ åˆ°ç›¸å…³çŸ¥è¯†â€ã€‚
- è¿™æ—¶å¯åˆ©ç”¨Promptæ¨¡æ¿å¯¹llmè¿›è¡Œçº¦æŸã€‚

è°ƒç”¨LangChainçš„PromptTemplate

```py
from langchain import PromptTemplate

# ã€æ— å˜é‡æ¨¡æ¿ã€‘An example prompt with no input variables
no_input_prompt = PromptTemplate(input_variables=[], template="Tell me a joke.")
no_input_prompt.format()
# -> "Tell me a joke."
# ã€æœ‰å˜é‡æ¨¡æ¿ã€‘
name_template = """
æˆ‘æƒ³è®©ä½ æˆä¸ºä¸€ä¸ªèµ·åå­—çš„ä¸“å®¶ã€‚ç»™æˆ‘è¿”å›ä¸€ä¸ªåå­—çš„åå•. åå­—å¯“æ„ç¾å¥½ï¼Œç®€å•æ˜“è®°ï¼Œæœ—æœ—ä¸Šå£.
å…³äº{name_description},å¥½å¬çš„åå­—æœ‰å“ªäº›?
"""
# åˆ›å»ºä¸€ä¸ªpromptæ¨¡æ¿
prompt_template = PromptTemplate(input_variables=["name_description"], template=name_template)
description = "ç”·å­©åå­—"
print(prompt_template.format(name_description=description))
# æˆ‘æƒ³è®©ä½ æˆä¸ºä¸€ä¸ªèµ·åå­—çš„ä¸“å®¶ã€‚ç»™æˆ‘è¿”å›ä¸€ä¸ªåå­—çš„åå•. åå­—å¯“æ„ç¾å¥½ï¼Œç®€å•æ˜“è®°ï¼Œæœ—æœ—ä¸Šå£.å…³äºç”·å­©åå­—,å¥½å¬çš„åå­—æœ‰å“ªäº›?
# ã€å¤šå˜é‡æ¨¡æ¿ã€‘
# An example prompt with multiple input variables
multiple_input_prompt = PromptTemplate(
    input_variables=["adjective", "content"],
    template="Tell me a {adjective} joke about {content}."
)
multiple_input_prompt.format(adjective="funny", content="chickens")
# -> "Tell me a funny joke about chickens."
```

FewShot PromptTemplate
- æ¨¡æ¿å¯ä»¥æ ¹æ®è¯­æ–™åº“ä¸­çš„å†…å®¹è¿›è¡ŒåŒ¹é…ï¼Œæœ€ç»ˆå¯æŒ‰ç…§ç‰¹å®šçš„æ ¼å¼åŒ¹é…å‡º**æ ·ä¾‹**ä¸­çš„å†…å®¹ã€‚

```py
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain.prompts.prompt import PromptTemplate

examples = [
  {
    "question": "Who lived longer, Muhammad Ali or Alan Turing?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: How old was Muhammad Ali when he died?
Intermediate answer: Muhammad Ali was 74 years old when he died.
Follow up: How old was Alan Turing when he died?
Intermediate answer: Alan Turing was 41 years old when he died.
So the final answer is: Muhammad Ali
"""
  },
  {
    "question": "When was the founder of craigslist born?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: Who was the founder of craigslist?
Intermediate answer: Craigslist was founded by Craig Newmark.
Follow up: When was Craig Newmark born?
Intermediate answer: Craig Newmark was born on December 6, 1952.
So the final answer is: December 6, 1952
"""
  }
]

example_prompt = PromptTemplate(input_variables=["question", "answer"], template="Question: {question}\n{answer}")
print(example_prompt.format(**examples[0]))
```

```s
=========================
Question: Who lived longer, Muhammad Ali or Alan Turing?

Are follow up questions needed here: Yes.
Follow up: How old was Muhammad Ali when he died?
Intermediate answer: Muhammad Ali was 74 years old when he died.
Follow up: How old was Alan Turing when he died?
Intermediate answer: Alan Turing was 41 years old when he died.
So the final answer is: Muhammad Ali
```


##### ï¼ˆ3ï¼‰Indexesï¼ˆç´¢å¼•ï¼‰ï¼šæ–‡æ¡£ç»“æ„åŒ–

Indexesï¼ˆç´¢å¼•ï¼‰ï¼šæ–‡æ¡£ç»“æ„åŒ–æ–¹å¼, ä»¥ä¾¿LLMæ›´å¥½çš„äº¤äº’
- ç´¢å¼•æ˜¯æŒ‡å¯¹æ–‡æ¡£è¿›è¡Œç»“æ„åŒ–çš„æ–¹æ³•ï¼Œä»¥ä¾¿LLMèƒ½å¤Ÿæ›´å¥½çš„ä¸ä¹‹äº¤äº’ã€‚

æœ€å¸¸è§çš„ä½¿ç”¨åœºæ™¯æ˜¯æ–‡æ¡£æ£€ç´¢ï¼Œæ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚
- æ³¨æ„: ç´¢å¼•ä¹Ÿèƒ½ç”¨åœ¨é™¤äº†æ£€ç´¢å¤–çš„å…¶ä»–åœºæ™¯ï¼ŒåŒæ ·æ£€ç´¢é™¤äº†ç´¢å¼•å¤–ä¹Ÿæœ‰å…¶ä»–çš„å®ç°æ–¹å¼ã€‚

ç´¢å¼•ä¸€èˆ¬å’Œæ£€ç´¢**éç»“æ„åŒ–æ•°æ®**ï¼ˆæ¯”å¦‚æ–‡æœ¬æ–‡æ¡£ï¼‰ç›¸å…³ï¼ŒLangChainæ”¯æŒçš„ä¸»è¦ç´¢å¼•ç±»å‹å¦‚ä¸‹ï¼Œéƒ½æ˜¯å›´ç»•ç€**å‘é‡æ•°æ®åº“**çš„ã€‚

è¯¥ç»„ä»¶ä¸»è¦åŒ…æ‹¬ï¼šDocument Loadersï¼ˆ`æ–‡æ¡£åŠ è½½å™¨`ï¼‰ã€Text Splittersï¼ˆ`æ–‡æœ¬æ‹†åˆ†å™¨`ï¼‰ã€VectorStoresï¼ˆ`å‘é‡å­˜å‚¨å™¨`ï¼‰ä»¥åŠRetrieversï¼ˆ`æ£€ç´¢å™¨`ï¼‰ã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/5078c23e1fea4bee99746ebec0847be5~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=Uzl65uwWtcvNhfi1OHpX8u%2BGzko%3D)
- `æ–‡æœ¬æ£€ç´¢å™¨`ï¼šå°†ç‰¹å®šæ ¼å¼æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬ã€‚è¾“å…¥å¯ä»¥æ˜¯ pdfã€wordã€csvã€images ç­‰ã€‚
- `æ–‡æœ¬æ‹†åˆ†å™¨`ï¼šå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå°çš„**æ–‡æœ¬å—**ï¼Œä¾¿äºLLMæ¨¡å‹å¤„ç†ã€‚
  - ç”±äºæ¨¡å‹å¤„ç†æ•°æ®æ—¶ï¼Œå¯¹è¾“å…¥é•¿åº¦æœ‰é™åˆ¶ï¼Œå› æ­¤éœ€è¦å¯¹é•¿æ–‡æœ¬è¿›è¡Œ**åˆ†å—**ã€‚
  - ä¸åŒè¯­è¨€æ¨¡å‹å¯¹å—çš„å¤§å°å®šä¹‰ä¸åŒï¼Œæ¯”å¦‚OpenAIçš„GPTå¯¹åˆ†å—çš„é•¿åº¦é€šè¿‡tokenå¤§å°æ¥é™åˆ¶ï¼Œæ¯”å¦‚GPT-3.5æ˜¯**4096**ï¼Œå³è¿™ä¸ªåˆ†å—æ‰€åŒ…å«çš„Tokenæ•°é‡ä¸èƒ½è¶…è¿‡4096ã€‚
  - ä¸€èˆ¬çš„åˆ†å—æ–¹æ³•ï¼šé¦–å…ˆï¼Œå¯¹é•¿æ–‡æœ¬è¿›è¡Œ**æ–­å¥**ï¼Œå³åˆ†æˆä¸€å¥ä¸€å¥è¯ã€‚ç„¶åï¼Œè®¡ç®—æ¯å¥è¯åŒ…å«çš„tokenæ•°é‡ï¼Œå¹¶ä»ç¬¬ä¸€å¥è¯å¼€å§‹å¾€åä¾æ¬¡ç´¯åŠ ï¼Œç›´åˆ°è¾¾åˆ°æŒ‡å®šæ•°é‡ï¼Œç»„æˆä¸º1ä¸ªåˆ†å—ã€‚ä¾æ¬¡é‡å¤ä¸Šè¿°æ“ä½œã€‚æ¯”å¦‚æŒ‰ç…§**å­—æ¯**åˆ‡åˆ†çš„`Character`ï¼ŒæŒ‰ç…§**token**åˆ‡åˆ†çš„`Tiktoken`ç­‰ã€‚
- `å‘é‡å­˜å‚¨å™¨`ï¼šå­˜å‚¨æå–çš„æ–‡æœ¬å‘é‡ï¼ŒåŒ…æ‹¬Faissã€Milvusã€Pineconeã€Chromaç­‰ã€‚
- `å‘é‡æ£€ç´¢å™¨`ï¼šé€šè¿‡ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œæ£€ç´¢å™¨è´Ÿè´£ä»åº•åº“ä¸­æ£€ç´¢å‡ºç‰¹å®šç›¸å…³åº¦çš„æ–‡æ¡£ã€‚åº¦é‡å‡†åˆ™åŒ…æ‹¬ä½™å¼¦è·ç¦»ã€æ¬§å¼è·ç¦»ç­‰ã€‚


æ•°æ®æºåŠ è½½

```py
# ğŸ¨ åŠ è½½Bç«™ï¼ˆBiliBiliï¼‰è§†é¢‘æ•°æ®
#!pip install bilibili-api
from langchain.document_loaders.bilibili import BiliBiliLoader
loader = BiliBiliLoader(
    ["https://www.bilibili.com/video/BV1xt411o7Xu/"]
)
loader.load()

# ğŸ¨ åŠ è½½CSVæ•°æ®
from langchain.document_loaders.csv_loader import CSVLoader

loader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')

data = loader.load()

# ğŸ¨ åŠ è½½Emailæ•°æ®
#!pip install unstructured
from langchain.document_loaders import UnstructuredEmailLoader
loader = UnstructuredEmailLoader('example_data/fake-email.eml')
data = loader.load()

# ğŸ¨ åŠ è½½ç”µå­ä¹¦Epubæ•°æ®
#!pip install pandocs
from langchain.document_loaders import UnstructuredEPubLoader
loader = UnstructuredEPubLoader("winter-sports.epub", mode="elements")
data = loader.load()

# ğŸ¨ åŠ è½½Gitæ•°æ®
# !pip install GitPython

from git import Repo
repo = Repo.clone_from(
    "https://github.com/hwchase17/langchain", to_path="./example_data/test_repo1"
)
branch = repo.head.reference

from langchain.document_loaders import GitLoader
loader = GitLoader(repo_path="./example_data/test_repo1/", branch=branch)
data = loader.load()

# ğŸ¨ åŠ è½½HTMLæ•°æ®
from langchain.document_loaders import UnstructuredHTMLLoader

loader = UnstructuredHTMLLoader("example_data/fake-content.html")

data = loader.load()

# ğŸ¨ åŠ è½½Imageå›¾ç‰‡æ•°æ®
#!pip install pdfminer

from langchain.document_loaders.image import UnstructuredImageLoader
loader = UnstructuredImageLoader("layout-parser-paper-fast.jpg")
data = loader.load()

# ğŸ¨ åŠ è½½Wordæ–‡æ¡£æ•°æ®
from langchain.document_loaders import Docx2txtLoader
loader = Docx2txtLoader("example_data/fake.docx")

data = loader.load()
# [Document(page_content='Lorem ipsum dolor sit amet.', metadata={'source': 'example_data/fake.docx'})]

# ğŸ¨ åŠ è½½PDFæ–‡ä»¶æ•°æ®
# !pip install pypdf

from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("example_data/layout-parser-paper.pdf")
pages = loader.load_and_split()
pages[0]
```

ç¤ºä¾‹

```py
# pip install chromadb
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
# æŒ‡å®šè¦ä½¿ç”¨çš„æ–‡æ¡£åŠ è½½å™¨
from langchain.document_loaders import TextLoader
documents = TextLoader('../state_of_the_union.txt', encoding='utf8')
# æ¥ä¸‹æ¥å°†æ–‡æ¡£æ‹†åˆ†æˆå—ã€‚
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
# ç„¶åæˆ‘ä»¬å°†é€‰æ‹©æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„åµŒå…¥ã€‚
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
# æˆ‘ä»¬ç°åœ¨åˆ›å»º vectorstore ç”¨ä½œç´¢å¼•ã€‚
from langchain.vectorstores import Chroma
db = Chroma.from_documents(texts, embeddings)
# è¿™å°±æ˜¯åˆ›å»ºç´¢å¼•ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨æ£€ç´¢å™¨æ¥å£ä¸­å…¬å¼€è¯¥ç´¢å¼•ã€‚
retriever = db.as_retriever()
# åˆ›å»ºä¸€ä¸ªé“¾å¹¶ç”¨å®ƒæ¥å›ç­”é—®é¢˜ï¼
qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=retriever)
query = "What did the president say about Ketanji Brown Jackson"
qa.run(query)
```

**Retrievers**

æ£€ç´¢å™¨æ¥å£æ˜¯ä¸€ä¸ªé€šç”¨æ¥å£ï¼Œå¯ä»¥è½»æ¾åœ°å°†æ–‡æ¡£ä¸è¯­è¨€æ¨¡å‹ç»“åˆèµ·æ¥ã€‚
- æ­¤æ¥å£å…¬å¼€äº†ä¸€ä¸ª get_relevant_documents æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªæŸ¥è¯¢ï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰å¹¶è¿”å›ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œç”¨çš„éƒ½æ˜¯ VectorStore Retrieverã€‚
- æ­¤æ£€ç´¢å™¨ç”± VectorStore å¤§åŠ›æ”¯æŒã€‚ä¸€æ—¦ä½ æ„é€ äº†ä¸€ä¸ª VectorStoreï¼Œæ„é€ ä¸€ä¸ªæ£€ç´¢å™¨å°±å¾ˆå®¹æ˜“äº†ã€‚

```py
# # pip install faiss-cpu
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.document_loaders import DirectoryLoader
# åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰txtç±»å‹çš„æ–‡ä»¶ï¼Œå¹¶è½¬æˆ document å¯¹è±¡
loader = DirectoryLoader('./data/', glob='**/*.txt')
documents = loader.load()
# æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ–‡æ¡£æ‹†åˆ†æˆå—ã€‚
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
# ç„¶åæˆ‘ä»¬å°†é€‰æ‹©æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„åµŒå…¥ã€‚
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()
from langchain.vectorstores import FAISS
db = FAISS.from_documents(texts, embeddings)
query = "æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—"
docs = db.similarity_search(query)
docs_and_scores = db.similarity_search_with_score(query)
print(docs)

retriever = db.as_retriever()	# æœ€å¤§è¾¹é™…ç›¸å…³æ€§æœç´¢ mmr
# retriever = db.as_retriever(search_kwargs={"k": 1})	# æœç´¢å…³é”®å­—
docs = retriever.get_relevant_documents("æœªå…¥èŒåŒäº‹å¯ä»¥å‡ºå·®å—")
print(len(docs))

# db.save_local("faiss_index")
# new_db = FAISS.load_local("faiss_index", embeddings)
# docs = new_db.similarity_search(query)
# docs[0]
```


##### ï¼ˆ4ï¼‰Chainsï¼ˆé“¾æ¡ï¼‰ï¼šç»„åˆé“¾è·¯

Chainsï¼ˆé“¾æ¡ï¼‰ï¼šå°†LLMä¸å…¶ä»–ç»„ä»¶ç»“åˆ, é“¾å…è®¸å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„åº”ç”¨ç¨‹åºã€‚
- æŠŠä¸€ä¸ªä¸ªç‹¬ç«‹çš„ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼ŒLangChainåå­—çš„ç”±æ¥
- Chain å¯ç†è§£ä¸ºä»»åŠ¡ã€‚ä¸€ä¸ª Chain å°±æ˜¯ä¸€ä¸ªä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥åƒé“¾æ¡ä¸€æ ·ï¼Œé€ä¸ªæ‰§è¡Œå¤šä¸ªé“¾

Chainæä¾›äº†ä¸€ç§å°†å„ç§ç»„ä»¶ç»Ÿä¸€åˆ°åº”ç”¨ç¨‹åºä¸­çš„æ–¹æ³•ã€‚
- ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ªChainï¼Œæ¥å—æ¥è‡ªç”¨æˆ·çš„è¾“å…¥ï¼Œå¹¶é€šè¿‡PromptTemplateå°†å…¶æ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–çš„è¾“å‡ºä¼ å…¥åˆ°LLMæ¨¡å‹ä¸­ã€‚
- é€šè¿‡å¤šä¸ªChainä¸å…¶ä»–éƒ¨ä»¶ç»“åˆï¼Œå¯ç”Ÿæˆå¤æ‚çš„é“¾ï¼Œå®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚
- ![Chainsç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/4d5ba1c00889406fb3bc7c86fbb9660f~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=pLKYIarzSV1QkVxKv%2Blc0t8lDrE%3D)

LangChainä¸­ï¼Œä¸»è¦æœ‰ä¸‹é¢å‡ ç§é“¾ï¼Œå…¶ä¸­æœ€å¸¸ç”¨çš„æ˜¯LLMChainã€‚
- `LLMChain`
  - LLMChainç”± **PromptTemplate**ã€**æ¨¡å‹**å’Œå¯é€‰çš„**è¾“å‡ºè§£æå™¨**ç»„æˆã€‚
  - é“¾æ¥æ”¶å¤šä¸ªè¾“å…¥å˜é‡ï¼Œä½¿ç”¨PromptTemplateç”Ÿæˆæç¤ºï¼Œä¼ é€’ç»™æ¨¡å‹ï¼Œæœ€åä½¿ç”¨è¾“å‡ºè§£æå™¨æŠŠæ¨¡å‹è¿”å›å€¼è½¬æ¢æˆæœ€ç»ˆæ ¼å¼ã€‚
- `ç´¢å¼•ç›¸å…³é“¾`
  - å’Œç´¢å¼•äº¤äº’ï¼ŒæŠŠè‡ªå·±çš„æ•°æ®å’ŒLLMsç»“åˆèµ·æ¥ï¼Œæœ€å¸¸è§çš„ä¾‹å­æ˜¯æ ¹æ®æ–‡æ¡£æ¥å›ç­”é—®é¢˜ã€‚
- `æç¤ºé€‰æ‹©å™¨`
  - ä¸ºä¸åŒæ¨¡å‹ç”Ÿæˆä¸åŒçš„æç¤º


LLMä¸å…¶ä»–ç»„ä»¶ç»“åˆï¼Œåˆ›å»ºä¸åŒåº”ç”¨ï¼Œä¸€äº›ä¾‹å­ï¼š
- å°†LLMä¸**æç¤ºæ¨¡æ¿**ç›¸ç»“åˆ
- ç¬¬ä¸€ä¸ª LLM çš„è¾“å‡ºä½œä¸ºç¬¬äºŒä¸ª LLM çš„è¾“å…¥, **é¡ºåºç»„åˆ**å¤šä¸ª LLM
- LLMä¸**å¤–éƒ¨æ•°æ®**ç»“åˆï¼Œæ¯”å¦‚ï¼Œé€šè¿‡langchainè·å–youtubeè§†é¢‘é“¾æ¥ï¼Œé€šè¿‡LLMè§†é¢‘é—®ç­”
- LLMä¸**é•¿æœŸè®°å¿†**ç»“åˆï¼Œæ¯”å¦‚èŠå¤©æœºå™¨äºº

```py
from langchain import LLMChain

llm_chain = LLMChain(prompt=prompt, llm=llm)
question = "Can Barack Obama have a conversation with George Washington?"
print(llm_chain.run(question))
```

LLMChainæ˜¯ä¸€ä¸ªç®€å•çš„é“¾ï¼Œå®ƒæ¥å—ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨ç”¨æˆ·è¾“å…¥æ ¼å¼åŒ–å®ƒå¹¶è¿”å›æ¥è‡ª LLM çš„å“åº”ã€‚

```py
from langchain.llms import OpenAI
from langchain.docstore.document import Document
import requests
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
import pathlib
import subprocess
import tempfile
"""
ç”Ÿæˆå¯¹ä»¥å‰æ’°å†™çš„åšå®¢æ–‡ç« æœ‰ç†è§£çš„åšå®¢æ–‡ç« ï¼Œæˆ–è€…å¯ä»¥å‚è€ƒäº§å“æ–‡æ¡£çš„äº§å“æ•™ç¨‹
"""

source_chunks = ""
search_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings())

from langchain.chains import LLMChain
prompt_template = """Use the context below to write a 400 word blog post about the topic below:
    Context: {context}
    Topic: {topic}
    Blog post:"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "topic"]
)

llm = OpenAI(temperature=0)

chain = LLMChain(llm=llm, prompt=PROMPT)

def generate_blog_post(topic):
    docs = search_index.similarity_search(topic, k=4)
    inputs = [{"context": doc.page_content, "topic": topic} for doc in docs]
    print(chain.apply(inputs))

generate_blog_post("environment variables")
```

æ‰§è¡Œå¤šä¸ªchain
- é¡ºåºé“¾æ˜¯æŒ‰é¢„å®šä¹‰é¡ºåºæ‰§è¡Œå…¶é“¾æ¥çš„é“¾ã€‚
- ä½¿ç”¨SimpleSequentialChainï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ä¸€ä¸ªè¾“å…¥/è¾“å‡ºï¼Œä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºæ˜¯ä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚

```py
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

# location é“¾
llm = OpenAI(temperature=1)
template = """Your job is to come up with a classic dish from the area that the users suggests.
% USER LOCATION
{user_location}

YOUR RESPONSE:
"""
prompt_template = PromptTemplate(input_variables=["user_location"], template=template)
location_chain = LLMChain(llm=llm, prompt=prompt_template)

# meal é“¾
template = """Given a meal, give a short and simple recipe on how to make that dish at home.
% MEAL
{user_meal}

YOUR RESPONSE:
"""
prompt_template = PromptTemplate(input_variables=["user_meal"], template=template)
meal_chain = LLMChain(llm=llm, prompt=prompt_template)

# é€šè¿‡ SimpleSequentialChain ä¸²è”èµ·æ¥ï¼Œç¬¬ä¸€ä¸ªç­”æ¡ˆä¼šè¢«æ›¿æ¢ç¬¬äºŒä¸ªä¸­çš„user_mealï¼Œç„¶åå†è¿›è¡Œè¯¢é—®
overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)
review = overall_chain.run("Rome")
```

##### ï¼ˆ5ï¼‰Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰ï¼šå…¶ä»–å·¥å…·

â€œé“¾â€å¯ä»¥å¸®åŠ©å°†ä¸€ç³»åˆ— LLM è°ƒç”¨é“¾æ¥åœ¨ä¸€èµ·ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼Œè°ƒç”¨é¡ºåºé€šå¸¸æ˜¯**ä¸ç¡®å®š**çš„ã€‚
- æœ‰äº›åº”ç”¨å¹¶ä¸æ˜¯ä¸€å¼€å§‹å°±ç¡®å®šè°ƒç”¨å“ªäº›æ¨¡å‹ï¼Œè€Œæ˜¯ä¾èµ–äºç”¨æˆ·è¾“å…¥

LangChain åº“æä¾›äº†ä»£ç†â€œAgentsâ€ï¼Œæ ¹æ®**æœªçŸ¥**è¾“å…¥è€Œä¸æ˜¯**ç¡¬ç¼–ç **æ¥å†³å®šä¸‹ä¸€æ­¥é‡‡å–çš„è¡ŒåŠ¨ã€‚ 

Agentsé€šå¸¸ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼š`Action`ã€`Observation`å’Œ`Decision`ã€‚
- `Action`æ˜¯ä»£ç†æ‰§è¡Œçš„æ“ä½œ
- `Observation`æ˜¯ä»£ç†æ¥æ”¶åˆ°çš„ä¿¡æ¯
- `Decision`æ˜¯ä»£ç†åŸºäº`Action`å’Œ`Observation`åšå‡ºçš„å†³ç­–ã€‚

Agent ä½¿ç”¨LLMæ¥ç¡®å®šè¦é‡‡å–å“ªäº›è¡ŒåŠ¨ä»¥åŠæŒ‰ä»€ä¹ˆé¡ºåºé‡‡å–çš„è¡ŒåŠ¨ã€‚æ“ä½œå¯ä»¥ä½¿ç”¨å·¥å…·å¹¶è§‚å¯Ÿå…¶è¾“å‡ºï¼Œä¹Ÿå¯ä»¥è¿”å›ç”¨æˆ·ã€‚åˆ›å»ºagentæ—¶çš„å‚æ•°ï¼š
- `LLM`ï¼šä¸ºä»£ç†æä¾›åŠ¨åŠ›çš„è¯­è¨€æ¨¡å‹ã€‚
- `å·¥å…·`ï¼šæ‰§è¡Œç‰¹å®šèŒè´£çš„åŠŸèƒ½, æ–¹ä¾¿æ¨¡å‹å’Œå…¶ä»–èµ„æºäº¤äº’
  - æ¯”å¦‚ï¼šGoogleæœç´¢ï¼Œæ•°æ®åº“æŸ¥æ‰¾ï¼ŒPython Replã€‚å·¥å…·çš„æ¥å£å½“å‰æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå°†å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œå­—ç¬¦ä¸²ä½œä¸ºè¾“å‡ºã€‚
- `å·¥å…·é›†`
  - è§£å†³ç‰¹å®šé—®é¢˜çš„å·¥å…·é›†åˆ
- `ä»£ç†`ï¼šhighest level APIã€custom agent. è¦ä½¿ç”¨çš„ä»£ç†ã€‚å›´ç»•æ¨¡å‹çš„åŒ…è£…å™¨ï¼Œæ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œå†³å®šæ¨¡å‹çš„è¡Œä¸º
- `ä»£ç†æ‰§è¡Œå™¨`
  - ä»£ç†å’Œä¸€ç»„å·¥å…·ï¼Œè°ƒç”¨ä»£ç†

```py
# Create RetrievalQA Chain
from langchain.chains import RetrievalQA
retrieval_qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever())

# Create an Agent
from langchain.agents import initialize_agent, Tool
tools = [
    Tool(
        name="Example QA System",
        func=retrieval_qa.run,
        description="Example description of the tool."
    ),
]
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)

# Use Agent
agent.run("Ask a question related to the documents")
```

Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰ï¼šè®¿é—®å…¶ä»–å·¥å…·

Agentsæ˜¯LLMä¸å·¥å…·ä¹‹é—´çš„**æ¥å£**ï¼ŒAgentsç”¨æ¥ç¡®å®šä»»åŠ¡ä¸å·¥å…·ã€‚

ä¸€èˆ¬çš„Agentsæ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ï¼š
- a. é¦–å…ˆï¼Œæ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œå¹¶è½¬åŒ–ä¸ºPromptTemplate
- b. å…¶æ¬¡ï¼ŒAgentsé€šè¿‡è°ƒç”¨LLMè¾“å‡ºactionï¼Œå¹¶å†³å®šä½¿ç”¨å“ªç§å·¥å…·æ‰§è¡Œaction
- c. æœ€åï¼ŒAgentsè°ƒç”¨å·¥å…·å®Œæˆactionä»»åŠ¡
- ![agentç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/b53d13fc3ceb4d5fa43081721e2b97b9~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=HzMa7h7l78O8xFoMDsdNIx%2Bf0yg%3D)

Agentså¯ä»¥è°ƒç”¨é‚£äº›å·¥å…·å®Œæˆä»»åŠ¡ï¼Ÿ

| å·¥å…· | æè¿° | 
| --- | --- | 
| æœç´¢ | è°ƒç”¨è°·æ­Œæµè§ˆå™¨æˆ–å…¶ä»–æµè§ˆå™¨æœç´¢æŒ‡å®šå†…å®¹ |
| ç»ˆç«¯ | åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå‘½ä»¤ï¼Œè¾“å…¥åº”è¯¥æ˜¯æœ‰æ•ˆçš„å‘½ä»¤ï¼Œè¾“å‡ºå°†æ˜¯è¿è¡Œè¯¥å‘½ä»¤çš„ä»»ä½•è¾“å‡º |
| Wikipedia | ä»ç»´åŸºç™¾ç§‘ç”Ÿæˆç»“æœ |
| Wolfram-Alpha | WA æœç´¢æ’ä»¶â€”â€”å¯ä»¥å›ç­”å¤æ‚çš„æ•°å­¦ã€ç‰©ç†æˆ–ä»»ä½•æŸ¥è¯¢ï¼Œå°†æœç´¢æŸ¥è¯¢ä½œä¸ºè¾“å…¥ã€‚ |
| Python REPL | ç”¨äºè¯„ä¼°å’Œæ‰§è¡Œ Python å‘½ä»¤çš„ Python shellã€‚å®ƒä»¥ python ä»£ç ä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºç»“æœã€‚è¾“å…¥çš„ python ä»£ç å¯ä»¥ä» LangChain ä¸­çš„å¦ä¸€ä¸ªå·¥å…·ç”Ÿæˆ |


Agenté€šè¿‡è°ƒç”¨wikipediaå·¥å…·ï¼Œå¯¹ç”¨æˆ·æå‡ºçš„é—®é¢˜å›ç­”ã€‚å°½ç®¡gpt-3.5åŠŸèƒ½å¼ºå¤§ï¼Œä½†æ˜¯å…¶çŸ¥è¯†åº“æˆªæ­¢åˆ°2021å¹´9æœˆï¼Œå› æ­¤ï¼Œagentè°ƒç”¨wikipediaå¤–éƒ¨çŸ¥è¯†åº“å¯¹ç”¨æˆ·é—®é¢˜å›ç­”ã€‚å›ç­”è¿‡ç¨‹å¦‚ä¸‹ï¼š
- a. åˆ†æç”¨æˆ·è¾“å…¥é—®é¢˜ï¼Œé‡‡å–çš„Actionä¸ºé€šè¿‡Wikipediaå®ç°ï¼Œå¹¶ç»™å‡ºäº†Actionçš„è¾“å…¥
- b. æ ¹æ®åˆ†æå¾—åˆ°äº†æœ€ç›¸å…³çš„ä¸¤é¡µï¼Œå¹¶è¿›è¡Œäº†æ€»ç»“
- c. å¯¹æœ€åçš„å†…å®¹è¿›ä¸€æ­¥æç‚¼ï¼Œå¾—åˆ°æœ€ç»ˆç­”æ¡ˆ

```py
import os
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.llms import OpenAI

openai_api_key = 'sk-F9xxxxxxx55q8YgXb6s5dJ1A4LjA'
os.environ['OPENAI_API_KEY'] = openai_api_key
llm = OpenAI(temperature=0)
tools = load_tools(["wikipedia","llm-math"], llm=llm)
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)
print(agent.run("åˆ—ä¸¾spaceXæ˜Ÿèˆ°åœ¨2022å¹´åçš„å‘å°„è®°å½•?"))
```

##### ï¼ˆ6ï¼‰Memoryï¼ˆè®°å¿†ï¼‰ï¼š

æ¨¡å‹æ˜¯æ— çŠ¶æ€çš„ï¼Œä¸ä¿å­˜ä¸Šä¸€æ¬¡äº¤äº’æ—¶çš„æ•°æ®
- OpenAIçš„APIæœåŠ¡æ²¡æœ‰ä¸Šä¸‹æ–‡æ¦‚å¿µï¼Œè€ŒchatGPTæ˜¯é¢å¤–å®ç°äº†ä¸Šä¸‹æ–‡åŠŸèƒ½ã€‚

ä¸ºäº†æä¾›ä¸Šä¸‹æ–‡çš„åŠŸèƒ½ï¼ŒLangChainæä¾›äº†è®°å¿†ç»„ä»¶ï¼Œç”¨æ¥åœ¨å¯¹è¯è¿‡ç¨‹ä¸­å­˜å‚¨æ•°æ®ã€‚

å¯¹äºåƒèŠå¤©æœºå™¨äººè¿™æ ·çš„åº”ç”¨ç¨‹åºï¼Œéœ€è¦è®°ä½ä»¥å‰çš„å¯¹è¯å†…å®¹ã€‚
- ä½†é»˜è®¤æƒ…å†µä¸‹ï¼ŒLLMå¯¹å†å²å†…å®¹**æ²¡æœ‰è®°å¿†åŠŸèƒ½**ã€‚LLMçš„è¾“å‡ºåªé’ˆå¯¹ç”¨æˆ·å½“å‰çš„æé—®å†…å®¹å›ç­”ã€‚
- ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒLangchainæä¾›äº†**è®°å¿†ç»„ä»¶**ï¼Œç”¨æ¥ç®¡ç†ä¸ç»´æŠ¤å†å²å¯¹è¯å†…å®¹ã€‚
- ![memoryç¤ºæ„å›¾](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/c64ff3021d1a4ba68c3a6a5dd470cdc6~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=M2fWwrITBkva%2BXT%2BiQINk6VD54M%3D)

langchainæä¾›ä¸åŒçš„Memoryç»„ä»¶å®Œæˆå†…å®¹è®°å¿†ï¼Œä¸‹é¢åˆ—ä¸¾å››ç§ï¼š
- `ConversationBufferMemory`ï¼šè®°ä½**å…¨éƒ¨å¯¹è¯å†…å®¹**ã€‚è¿™æ˜¯æœ€ç®€å•çš„å†…å­˜è®°å¿†ç»„ä»¶ï¼Œå®ƒçš„åŠŸèƒ½æ˜¯ç›´æ¥å°†ç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„èŠå¤©å†…å®¹è®°å½•åœ¨å†…å­˜ä¸­ã€‚[img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/8b04d8cc8c8f462bafa21bc473066efc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=ljnOnmukL7V9UH5OzY4l%2BpwkfpU%3D)
- `ConversationBufferWindowMemory`ï¼šè®°ä½**æœ€è¿‘kè½®**çš„èŠå¤©å†…å®¹ã€‚ä¸ä¹‹å‰çš„ConversationBufferMemoryç»„ä»¶çš„å·®åˆ«æ˜¯å®ƒå¢åŠ äº†ä¸€ä¸ªçª—å£å‚æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯å¯ä»¥æŒ‡å®šä¿å­˜å¤šè½®å¯¹è¯çš„æ•°é‡ã€‚[img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a830075b33094ef38f3aea87010fdd58~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=BbNKPeRu0j9knJWw02kEPUOu1uI%3D)
  - â€‹åœ¨è¯¥ä¾‹å­ä¸­è®¾ç½®äº†å¯¹è¯è½®æ•°k=2ï¼Œå³åªèƒ½è®°ä½å‰ä¸¤è½®çš„å†…å®¹ï¼Œâ€œæˆ‘çš„åå­—â€æ˜¯åœ¨å‰3è½®ä¸­çš„Answerä¸­å›ç­”çš„ï¼Œå› æ­¤å…¶æ²¡æœ‰å¯¹å…¶è¿›è¡Œè®°å¿†ï¼Œæ‰€ä»¥æ— æ³•å›ç­”å‡ºæ­£ç¡®ç­”æ¡ˆã€‚
- `ConversationSummaryMemory`ï¼šConversationSummaryMemoryå®ƒä¸ä¼šå°†ç”¨æˆ·å’Œæœºå™¨äººä¹‹å‰çš„æ‰€æœ‰å¯¹è¯éƒ½å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚å®ƒåªä¼šå­˜å‚¨ä¸€ä¸ªç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„**èŠå¤©å†…å®¹çš„æ‘˜è¦**ï¼Œè¿™æ ·åšçš„ç›®çš„å¯èƒ½æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜å¼€é”€å’Œtokençš„æ•°é‡ã€‚
  - ConversationSummaryMemory[ç¬¬ä¸€è½®å¯¹è¯](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/6b3c8f69e31440af9cb954bc903fd65d~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=X8kxNoQQtJqKKBIufAI5%2BGTprxo%3D): ä½ å¥½ï¼Œæˆ‘æ˜¯ç‹è€å…­
  - ConversationSummaryMemory[ç¬¬äºŒè½®å¯¹è¯](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/ab4fbe8ad6cb4286a1e8f9e10141d2ef~noop.image?_iz=58558&from=article.pc_detail&x-expires=1686034275&x-signature=tf%2FsfV5MF%2BIK7yWow48%2BvO%2FV%2BqY%3D): ä½ å«ä»€ä¹ˆåå­—
  - åœ¨ç¬¬ä¸€è½®å¯¹è¯å®Œæˆåï¼ŒMemoryå¯¹ç¬¬ä¸€è½®å¯¹è¯çš„å†…å®¹è¿›è¡Œäº†æ€»ç»“ï¼Œæ”¾åˆ°äº†æ‘˜è¦ä¸­ã€‚åœ¨ç¬¬äºŒè½®å¯¹è¯ä¸­ï¼ŒLLMåŸºäºæ‘˜è¦ä¸è¯¥è½®çš„é—®é¢˜è¿›è¡Œå›ç­”ã€‚
- `VectorStored-Backed Memory`: å°†æ‰€æœ‰ä¹‹å‰çš„å¯¹è¯é€šè¿‡**å‘é‡**çš„æ–¹å¼å­˜å‚¨åˆ°VectorDBï¼ˆå‘é‡æ•°æ®åº“ï¼‰ä¸­ï¼Œåœ¨æ¯ä¸€è½®æ–°çš„å¯¹è¯ä¸­ï¼Œä¼šæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ä¿¡æ¯ï¼ŒåŒ¹é…å‘é‡æ•°æ®åº“ä¸­**æœ€ç›¸ä¼¼çš„Kç»„**å¯¹è¯ã€‚





å›½å†…ä¸å°‘LLmå›¢é˜Ÿé‡‡ç”¨langChainï¼Œé›†æˆllmæœ¬åœ°åŒ–çŸ¥è¯†åº“

langChainï¼ŒbabyAGI æƒ³åšAGIç”Ÿæ€ï¼Œè¿™ä¸ªå°±æœ‰äº›åŠ›ä¸ä»å¿ƒäº†ã€‚autoGPTå¥½ä¸€ç‚¹ï¼Œç›¸å¯¹ç®€å•ã€‚

langChainï¼ŒbabyAGIçš„å­æ¨¡å—ï¼Œéƒ½æ˜¯å‡ ç™¾ä¸ªã€‚ç‰¹åˆ«æ˜¯langChainï¼Œæ¨¡å—åº“å±…ç„¶æœ‰600å¤šå¼ å­æ¨¡å—mapæ¶æ„å›¾

[æ— éœ€OpenAI API Keyï¼Œæ„å»ºä¸ªäººåŒ–çŸ¥è¯†åº“çš„ç»ˆææŒ‡å—](https://mp.weixin.qq.com/s/ponKZ1OaHXX2nzuSxXg8-Q)

æ„å»ºçŸ¥è¯†åº“çš„ä¸»è¦æµç¨‹ï¼š
1. åŠ è½½æ–‡æ¡£
2. æ–‡æœ¬åˆ†å‰²
3. æ„å»ºçŸ¢é‡æ•°æ®åº“
4. å¼•å…¥LLM
5. åˆ›å»ºqa_chainï¼Œå¼€å§‹æé—®


####  LangChain + Milvus

```py
from langchain.embeddings.openai import OpenAIEmbeddings # openai
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI  # openai
import os

os.environ["OPENAI_API_KEY"] = "OPENAI_API_KEY"

# Question Answering Chain
# â‘  åŠ è½½æ–‡æ¡£
with open("../test.txt") as f:
    state_of_the_union = f.read()
# â‘¡ æ–‡æœ¬åˆ†å‰²
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0) # æŒ‡å®šåˆ†å‰²å™¨
texts = text_splitter.split_text(state_of_the_union) # åˆ†å‰²æ–‡æœ¬
embeddings = OpenAIEmbeddings() # ä½¿ç”¨OpenAIçš„embeddingæœåŠ¡
# â‘¢ æ„å»ºé€‚é‡æ•°æ®åº“
docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{"source": str(i)} for i in range(len(texts))]).as_retriever()
query = "What did the president say about Justice Breyer"
docs = docsearch.get_relevant_documents(query)
# â‘£ å¼•å…¥LLMï¼Œåˆ›å»ºqa_chain
chain = load_qa_chain(OpenAI(temperature=0), chain_type="stuff")
# â‘¤ å¼€å§‹æé—®
answer = chain.run(input_documents=docs, question=query)
print(answer)
```

ä»¥ä¸Šæ„å»ºä¾èµ–OpenAIï¼Œæœ‰ç¬¬ä¸‰æ–¹å…è´¹æœåŠ¡å—ï¼Ÿ
- [transformers-course](Githubï¼šhttps://github.com/Liu-Shihao/transformers-course)

Huggingfaceå¼€æºAIæ¨¡å‹æ„å»ºæœ¬åœ°çŸ¥è¯†åº“
- å¼€æºçš„google/flan-t5-xlAIæ¨¡å‹

```py
from langchain import HuggingFacePipeline
from langchain.chains import RetrievalQA
from langchain.chains.question_answering import load_qa_chain
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms.base import LLM
import os

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

os.environ["HUGGINGFACEHUB_API_TOKEN"] = 'HUGGINGFACEHUB_API_TOKEN'

# Document Loaders
loader = TextLoader('../example_data/test.txt', encoding='utf8')
documents = loader.load()

# Text Splitters
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# select embeddings
embeddings = HuggingFaceEmbeddings()

# create vectorstores
db = Chroma.from_documents(texts, embeddings)

# Retriever
retriever = db.as_retriever(search_kwargs={"k": 2})

query = "what is embeddings?"
docs = retriever.get_relevant_documents(query)

for item in docs:
    print("page_content:")
    print(item.page_content)
    print("source:")
    print(item.metadata['source'])
    print("---------------------------")


tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-xl")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-xl")
pipe = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_length=512,
    temperature=0,
    top_p=0.95,
    repetition_penalty=1.15
)

llm = HuggingFacePipeline(pipeline=pipe)

chain = load_qa_chain(llm, chain_type="stuff")
llm_response = chain.run(input_documents=docs, question=query)
print(llm_response)
print("done.")
```

é›†æˆäº† Milvus å’Œ LangChainï¼š[å‚è€ƒ](https://mp.weixin.qq.com/s/tgQ-SOoc0h-hqDZy9N3rfg)

```py
class VectorStore(ABC):
    """Interface for vector stores."""    @abstractmethoddef add_texts(
        self,
        texts: Iterable[str],
        metadatas: Optional[List[dict]] = None,
kwargs:Any,
    ) ->List[str]:
"""Run more texts through the embeddings and add to the vectorstore."""    @abstractmethoddefsimilarity_search(
        self, query:str, k:int =4,kwargs: Any) -> List[Document]:
        """Return docs most similar to query."""def max_marginal_relevance_search(
        self, query: str, k: int = 4, fetch_k: int = 20) -> List[Document]:
        """Return docs selected using the maximal marginal relevance."""raise NotImplementedError

    @classmethod    @abstractmethoddef from_texts(
        cls: Type[VST],
        texts: List[str],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        **kwargs: Any,
    ) -> VST:
        """Return VectorStore initialized from texts and embeddings."""
```                


å°† Milvus é›†æˆåˆ° LangChain ä¸­ï¼Œå®ç°å‡ ä¸ªå…³é”®å‡½æ•°ï¼šadd_texts()ã€similarity_search()ã€max_marginal_relevance_search()å’Œ from_text()

å°† Milvus é›†æˆåˆ° LangChain ä¸­çš„ç¡®å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œæœ€ä¸»è¦çš„æ˜¯ Milvus æ— æ³•å¤„ç† JSON æ–‡ä»¶ã€‚ç›®å‰ï¼Œåªæœ‰ä¸¤ç§è§£å†³æ–¹æ³•ï¼š
- ç°æœ‰çš„ Milvus collection ä¸Šåˆ›å»ºä¸€ä¸ª VectorStoreã€‚
- åŸºäºä¸Šä¼ è‡³ Milvus çš„ç¬¬ä¸€ä¸ªæ–‡æ¡£åˆ›å»ºä¸€ä¸ª VectorStoreã€‚

#### LangChain + Faiss + Ray å®è·µ

ã€2023-5-29ã€‘[Building an LLM open source search engine in 100 lines using LangChain and Ray](https://www.anyscale.com/blog/llm-open-source-search-engine-langchain-ray)
- Building the index: Build a document index easily with Ray and Langchain
- ![](https://images.ctfassets.net/xjan103pcp94/4OzISThpksdKgjZ0gVJUiB/85bb7fccdfef1df3d061c57e9af1062a/index-langchain.jpg)
- Build a document index 4-8x faster with Ray
- ![](https://images.ctfassets.net/xjan103pcp94/7tDpD5Q7nxtRyX9lgDvbkI/6209fbd875c5cd379c2289ef6f6554f0/Screen_Shot_2023-04-16_at_6.20.10_PM.png)
- Serving: Serve search queries with Ray and Langchain
- ![](https://images.ctfassets.net/xjan103pcp94/1g6zBePU72Rmz5MBH2reaB/db400e9bbbc445d7214d45658f81992f/Screen_Shot_2023-04-16_at_9.42.46_PM.png)


#### LangChain+ChatGLM æœ¬åœ°é—®ç­”

[LangChain+ChatGLM å®ç°æœ¬åœ°é—®ç­”](https://juejin.cn/post/7236028062873550908)

ChatGLM-6B apiéƒ¨ç½²ï¼š[ChatGLM é›†æˆè¿›LangChainå·¥å…·](https://juejin.cn/post/7226157821708681277)
- [api.py](https://github.com/THUDM/ChatGLM-6B/blob/main/api.py#L53:5)
- é»˜è®¤æœ¬åœ°çš„ 8000 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨

```sh
pip install fastapi uvicorn
python api.py
```

æ•ˆæœ

```sh
curl -X POST "http://{your_host}:8000" \
     -H 'Content-Type: application/json' \
     -d '{"prompt": "ä½ å¥½", "history": []}'
# ç»“æœ
{
  "response":"ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚",
  "history":[["ä½ å¥½","ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"]],
  "status":200,
  "time":"2023-03-23 21:38:40"
}
```

å°è£… ChatGLM APIåˆ°LangChainä¸­

```py
from langchain.llms.base import LLM
from langchain.llms.utils import enforce_stop_tokens
from typing import Dict, List, Optional, Tuple, Union

import requests
import json

class ChatGLM(LLM):
    max_token: int = 10000
    temperature: float = 0.1
    top_p = 0.9
    history = []

    def __init__(self):
        super().__init__()

    @property
    def _llm_type(self) -> str:
        return "ChatGLM"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        # headersä¸­æ·»åŠ ä¸Šcontent-typeè¿™ä¸ªå‚æ•°ï¼ŒæŒ‡å®šä¸ºjsonæ ¼å¼
        headers = {'Content-Type': 'application/json'}
        data=json.dumps({
          'prompt':prompt,
          'temperature':self.temperature,
          'history':self.history,
          'max_length':self.max_token
        })
        # print("ChatGLM prompt:",prompt)
        # è°ƒç”¨api
        response = requests.post("{your_host}/api",headers=headers,data=data)
		# print("ChatGLM resp:",response)
        if response.status_code!=200:
          return "æŸ¥è¯¢ç»“æœé”™è¯¯"
        resp = response.json()
        if stop is not None:
            response = enforce_stop_tokens(response, stop)
        self.history = self.history+[[None, resp['response']]]
        return resp['response']
# è°ƒç”¨
llm = ChatGLM()
print(llm("ä½ ä¼šåšä»€ä¹ˆ"))
# ChatGLM prompt: ä½ ä¼šåšä»€ä¹ˆ
# æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¢«è®­ç»ƒæ¥å›ç­”äººç±»æå‡ºçš„é—®é¢˜ã€‚æˆ‘ä¸èƒ½åšä»»ä½•å®é™…çš„äº‹æƒ…ï¼Œåªèƒ½é€šè¿‡æ–‡å­—å›ç­”é—®é¢˜ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ã€‚

```


### å¾®è½¯guidanceï¼ˆLangChainç®€åŒ–ï¼‰

ã€2023-5-26ã€‘[å¾®è½¯å‘å¸ƒlangChainæ€æ‰‹ï¼šguidanceæ¶æ„å›¾å…¨çƒé¦–å‘](https://mp.weixin.qq.com/s/tdN5KXSXfM9dKDMWbXV2WA)

å¾®è½¯å‘å¸ƒguidanceæ¨¡å—åº“ï¼Œå¹¶è¿…é€Ÿç™»ä¸Šgithubç½‘ç«™TOPæ¦œé¦–ï¼š
- guidanceï¼Œä¼ ç»Ÿæç¤ºæˆ–é“¾æ¥æ›´æœ‰æ•ˆã€æ›´é«˜æ•ˆåœ°æ§åˆ¶æ–°å¼è¯­è¨€æ¨¡å‹ã€‚
- ååŠ©ç”¨æˆ·å°†ç”Ÿæˆã€æç¤ºå’Œé€»è¾‘æ§åˆ¶äº¤é”™åˆ°å•ä¸ªè¿ç»­æµä¸­ï¼Œä»¥åŒ¹é…è¯­è¨€æ¨¡å‹å®é™…å¤„ç†æ–‡æœ¬çš„æ–¹å¼ã€‚
- ç®€å•çš„è¾“å‡ºç»“æ„ï¼Œå¦‚æ€ç»´é“¾åŠå…¶è®¸å¤šå˜ä½“ï¼ˆä¾‹å¦‚ARTï¼ŒAuto-CoTç­‰ï¼‰å·²è¢«è¯æ˜å¯ä»¥æé«˜LLMçš„æ€§èƒ½ã€‚
- åƒGPT-4è¿™æ ·æ›´å¼ºå¤§çš„LLMçš„å‡ºç°å…è®¸æ›´ä¸°å¯Œçš„ç»“æ„ï¼Œå¹¶ä½¿è¯¥ç»“æ„æ›´å®¹æ˜“ï¼Œæ›´ä¾¿å®œã€‚

ç®€å•æ¥è¯´ï¼Œå¾®è½¯guidanceæ¨¡å—åº“ï¼Œæ˜¯langChainæ¨¡å—åº“çš„**ç®€åŒ–ç‰ˆ**ï¼Œæˆ–è€…è¯´ï¼šlangChainæ€æ‰‹ã€‚

### ChatGLM QA

ã€2023-5-22ã€‘
- [åŸºäºchatglmæ­å»ºæ–‡æ¡£é—®ç­”æœºå™¨äºº](https://zhuanlan.zhihu.com/p/622418308): é“è·¯äº¤é€šå®‰å…¨æ³•é¢†åŸŸï¼Œä¸åˆ°100è¡Œçš„pythonæ–‡ä»¶
  - åŸºäºlangchain/llama-indexå·²ç»å¯ä»¥å¿«é€Ÿå®Œæˆç±»ä¼¼çš„åŠŸèƒ½ï¼Œä½†ä»£ç é‡å¤§ï¼Œå­¦ä¹ é—¨æ§›é«˜
- [chatglm-qabot-v2: ä»q-dåŒ¹é…åˆ°q-qåŒ¹é…](https://github.com/xinsblog/chatglm-qabot)
- [chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)
- [Chinese-LangChain](https://github.com/yanqiangmiffy/Chinese-LangChain)ï¼šä¸­æ–‡langchainé¡¹ç›®ï¼ŒåŸºäºChatGLM-6b+langchainå®ç°æœ¬åœ°åŒ–çŸ¥è¯†åº“æ£€ç´¢ä¸æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ
  - ![img](https://github.com/yanqiangmiffy/Chinese-LangChain/raw/master/images/web_demos/v3.png)

ä¸€äº›å…³é”®ç»„ä»¶çš„é…ç½®ï¼š
- LLMä½¿ç”¨çš„æ˜¯æ¸…åçš„chatglm-6b
- è®¡ç®—embeddingç”¨çš„æ˜¯è‹ç¥çš„**simbertV2**
- æ²¡åšembeddingçš„ç´¢å¼•ä¼˜åŒ–ï¼Œç›´æ¥æ”¾listé‡Œæš´åŠ›æŸ¥æ‰¾
- æ¯æ¬¡é»˜è®¤æŸ¥æ‰¾top3ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µç”¨äºæ„é€ prompt
- æ„é€ promptçš„æ¨¡æ¿è§ä»£ç 
- ç”Ÿæˆç­”æ¡ˆçš„é•¿åº¦æ²¡åšé™åˆ¶ï¼Œè¦åšçš„è¯åœ¨ä»£ç ä¸­åŠ è¯·æ±‚chatglmçš„å‚æ•°å³å¯

```py
import sys

# åˆå§‹åŒ–é—®ç­”æœºå™¨äºº
qabot = QaBot(doc_path="data/ä¸­åäººæ°‘å…±å’Œå›½é“è·¯äº¤é€šå®‰å…¨æ³•.txt", chatglm_api_url=sys.argv[1])
# æ ¹æ®æ–‡æ¡£å›ç­”é—®é¢˜
answer, _ = qabot.query('é…’åé©¾é©¶ä¼šåç‰¢å—')
```

åˆå§‹åŒ–çš„ä»£ç å¦‚ä¸‹

```py
def __init__(self, doc_path: str, chatglm_api_url: str):
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨äºå°†æ–‡æ¡£è½¬ä¸ºembedding
    pretrained_model = "junnyu/roformer_chinese_sim_char_small"
    self.tokenizer = RoFormerTokenizer.from_pretrained(pretrained_model)
    self.model = RoFormerForCausalLM.from_pretrained(pretrained_model)
    # åŠ è½½æ–‡æ¡£ï¼Œé¢„å…ˆè®¡ç®—æ¯ä¸ªchunkçš„embedding
    self.chunks, self.index = self._build_index(doc_path)
    # chatglmçš„apiåœ°å€
    self.chatglm_api_url = chatglm_api_url
```

æ¯æ¬¡é—®ç­”çš„ä»£ç å¦‚ä¸‹

```py
def query(self, question: str) -> Tuple[str, str]:
    # è®¡ç®—questionçš„embedding
    query_embedding = self._encode_text(question)
    # æ ¹æ®questionçš„embeddingï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„3ä¸ªchunk
    relevant_chunks = self._search_index(query_embedding, topk=3)
    # æ ¹æ®questionå’Œæœ€ç›¸å…³çš„3ä¸ªchunkï¼Œæ„é€ prompt
    prompt = self._generate_prompt(question, relevant_chunks)
    # è¯·æ±‚chatglmçš„apiè·å¾—ç­”æ¡ˆ
    answer = self._ask_chatglm(prompt)
    # åŒæ—¶è¿”å›ç­”æ¡ˆå’Œprompt
    return answer, prompt
```

æ•ˆæœ
- ![](https://pic3.zhimg.com/80/v2-f263dca70c9ae78e85f2284f1f66685e_1440w.webp)
- ![](https://pic1.zhimg.com/80/v2-70c79cadf68c65c30160dedf8ef17b34_1440w.webp)
- ![](https://pic4.zhimg.com/80/v2-c323e0e63b47f2cb006dddba14ef57ab_1440w.webp)

åŸºäºchatglmåšæ–‡æ¡£é—®ç­”ï¼Œé€šå¸¸çš„åšæ³•æ˜¯"å…ˆæ£€ç´¢å†æ•´åˆ"ï¼Œå¤§è‡´æ€è·¯
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†æ¯ä¸ªchunkè½¬ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“
- å½“ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªchunk
- å°†é—®é¢˜å’Œchunkåˆå¹¶é‡å†™ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

å°†ç”¨æˆ·è¯·æ±‚çš„queryå’ŒdocumentåšåŒ¹é…ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„`q-dåŒ¹é…`ã€‚

q-dåŒ¹é…çš„é—®é¢˜
- queryå’Œdocumentåœ¨**è¡¨è¾¾æ–¹å¼å­˜åœ¨è¾ƒå¤§å·®å¼‚**ï¼Œé€šå¸¸queryæ˜¯ä»¥**ç–‘é—®å¥**ä¸ºä¸»ï¼Œè€Œdocumentåˆ™ä»¥**é™ˆè¿°è¯´æ˜**ä¸ºä¸»ï¼Œè¿™ç§å·®å¼‚å¯èƒ½ä¼šå½±å“æœ€ç»ˆåŒ¹é…çš„æ•ˆæœã€‚
- ä¸€ç§æ”¹è¿›çš„æ–¹æ³•æ˜¯ä¸åš`q-dåŒ¹é…`ï¼Œè€Œæ˜¯å…ˆé€šè¿‡documentç”Ÿæˆä¸€æ‰¹å€™é€‰çš„questionï¼Œå½“ç”¨æˆ·å‘æ¥è¯·æ±‚çš„æ—¶å€™ï¼Œé¦–å…ˆæ˜¯æŠŠqueryå’Œå€™é€‰çš„questionåšåŒ¹é…ï¼Œè¿›è€Œæ‰¾åˆ°ç›¸å…³çš„documentç‰‡æ®µ
- å¦ä¸€ä¸ªæ€è·¯é€šè¿‡HyDEå»ä¼˜åŒ–
  - ä¸ºqueryå…ˆç”Ÿæˆä¸€ä¸ªå‡ç­”æ¡ˆï¼Œç„¶åé€šè¿‡å‡ç­”æ¡ˆå»æ£€ç´¢ï¼Œè¿™æ ·å¯ä»¥çœå»ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆé—®é¢˜çš„è¿‡ç¨‹ï¼Œä»£ä»·ç›¸å¯¹è¾ƒå°

ç¬¬ä¸€ç§æ–¹æ³•å°±æ˜¯'`q-qåŒ¹é…`'ï¼Œå…·ä½“æ€è·¯å¦‚ä¸‹ï¼š
- é¦–å…ˆå‡†å¤‡å¥½æ–‡æ¡£ï¼Œå¹¶æ•´ç†ä¸ºçº¯æ–‡æœ¬çš„æ ¼å¼ã€‚æŠŠæ¯ä¸ªæ–‡æ¡£åˆ‡æˆè‹¥å¹²ä¸ªå°çš„chunks
- éƒ¨ç½²chatglmçš„apiï¼Œ[éƒ¨ç½²æ–¹æ³•](https://github.com/THUDM/ChatGLM-6B#api%E9%83%A8%E7%BD%B2)
- è°ƒapiï¼Œæ ¹æ®æ¯ä¸ªchunkç”Ÿæˆ5ä¸ªå€™é€‰çš„questionï¼Œä½¿ç”¨çš„promptæ ¼å¼ä¸º'è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ç”Ÿæˆ5ä¸ªé—®é¢˜: ...'ï¼Œç”Ÿæˆæ•ˆæœè§ä¸‹å›¾ï¼š
  - ![](https://pic2.zhimg.com/80/v2-7790ad31e0621bff9e10233b448100f1_1440w.jpg)
- è°ƒç”¨æ–‡æœ¬è½¬å‘é‡çš„æ¥å£ï¼Œå°†ç”Ÿæˆçš„questionè½¬ä¸ºå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œå¹¶è®°å½•questionå’ŒåŸå§‹chunkçš„å¯¹åº”å…³ç³»
- ç”¨æˆ·å‘æ¥ä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå°†é—®é¢˜åŒæ ·è½¬ä¸ºå‘é‡ï¼Œå¹¶æ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œå¾—åˆ°ç›¸å…³æ€§æœ€é«˜çš„ä¸€ä¸ªquestionï¼Œè¿›è€Œæ‰¾åˆ°å¯¹åº”çš„chunk
- å°†é—®é¢˜å’Œchunk**åˆå¹¶é‡å†™**ä¸ºä¸€ä¸ªæ–°çš„è¯·æ±‚å‘ç»™chatglmçš„api

[chatglm-qabot](https://github.com/xinsblog/chatglm-qabot)
- qabot_v1.pyå®ç°äº†q-dåŒ¹é…æ–¹æ³•
- qabot_v2.pyå®ç°äº†q-qåŒ¹é…æ–¹æ³•

`q-dåŒ¹é…`å’Œ`q-qåŒ¹é…`çš„ä»£ç å·®å¼‚
- åˆå§‹åŒ–æ„å»ºç´¢å¼•çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic1.zhimg.com/80/v2-e3e8a1922e93fe67a6432866882b4490_1440w.webp)
- æŸ¥è¯¢ç´¢å¼•æ—¶çš„å·®å¼‚å¦‚ä¸‹ï¼š
  - ![](https://pic2.zhimg.com/80/v2-273d529bbcd4577f55003cd6fe508fa5_1440w.webp)

æµ‹è¯•é—®é¢˜ä¸ºè¡Œé©¶è¯çš„å¼æ ·ç”±è°æ¥ç›‘åˆ¶ï¼Œv1å’Œv2çš„æ•ˆæœå¯¹æ¯”å¦‚ä¸‹ï¼š
- ![](https://pic2.zhimg.com/80/v2-14832aaedad809d62ce0d9157c770c69_1440w.webp)

åœ¨æ„å»ºç´¢å¼•é˜¶æ®µï¼Œv2èŠ±è´¹çš„æ—¶é—´æ˜¯è¿œè¶…è¿‡v1çš„ï¼š

```sh
# è®¡ç®—chunksçš„embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00, 7.81it/s]
# ç”Ÿæˆquestionå¹¶è®¡ç®—embedding: 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [07:24<00:00, 22.24s/it]
```


## å®šåˆ¶çŸ¥è¯†åº“

ã€2023-5-24ã€‘
- [åŸºäº ChatGLM-6B æ­å»ºä¸ªäººä¸“å±çŸ¥è¯†åº“](https://www.toutiao.com/article/7236562318920876596)
- [å¦‚ä½•ä½¿ç”¨LangChainï¼‹LLM æ¥æ„å»ºæœ¬åœ°çŸ¥è¯†åº“](https://mp.weixin.qq.com/s/ponKZ1OaHXX2nzuSxXg8-Q)

### ä¸šåŠ¡åœºæ™¯

è°ƒæ•´ promptï¼ŒåŒ¹é…ä¸åŒçš„çŸ¥è¯†åº“ï¼Œè®© LLM æ‰®æ¼”ä¸åŒçš„è§’è‰²
- â€¢ ä¸Šä¼ å…¬å¸è´¢æŠ¥ï¼Œå……å½“è´¢åŠ¡åˆ†æå¸ˆ
- â€¢ ä¸Šä¼ å®¢æœèŠå¤©è®°å½•ï¼Œå……å½“æ™ºèƒ½å®¢æœ
- â€¢ ä¸Šä¼ ç»å…¸Caseï¼Œå……å½“å¾‹å¸ˆåŠ©æ‰‹
- â€¢ ä¸Šä¼ åŒ»é™¢ç™¾ç§‘å…¨ä¹¦ï¼Œå……å½“åœ¨çº¿é—®è¯ŠåŒ»ç”Ÿ

### é—®é¢˜

å¾®è°ƒçš„ç“¶é¢ˆ
- éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œå¾ˆå¤šè®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œä»¥ä¾¿åœ¨ä¸åŒè¶…å‚æ•°è®¾ç½®è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œå¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ª
- åŠ¨æ€æ‰©å±•æ¯”è¾ƒå·®ï¼Œæ–°å¢å’Œä¿®æ”¹åŸæœ‰çš„æ•°æ®éƒ½è¦é‡æ–°å¾®è°ƒä¸€æ¬¡ã€‚

æ€»ä¹‹ï¼Œå¾®è°ƒå¯¹éä¸“ä¸šäººå‘˜ä¸å‹å¥½ã€‚

å¦‚ä½•ä¸ç”¨å¾®è°ƒå°±èƒ½å®ç°å‚ç›´é¢†åŸŸçš„ä¸“ä¸šé—®ç­”ï¼Ÿ
- æ–¹æ¡ˆï¼šChatGLM-6B + langchain å®ç°ä¸ªäººä¸“å±çŸ¥è¯†åº“

### æŠ€æœ¯åŸç†

æŠ€æœ¯åŸç†
- åŠ è½½æ–‡ä»¶ -> è¯»å–æ–‡æœ¬ -> æ–‡æœ¬åˆ†å‰² -> æ–‡æœ¬å‘é‡åŒ– -> é—®å¥å‘é‡åŒ– -> åœ¨æ–‡æœ¬å‘é‡ä¸­åŒ¹é…å‡ºä¸é—®å¥å‘é‡æœ€ç›¸ä¼¼çš„top kä¸ª -> åŒ¹é…å‡ºçš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æ·»åŠ åˆ° prompt ä¸­ -> æäº¤ç»™ LLM ç”Ÿæˆå›ç­”ã€‚
- [img1](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/0d835cc528ba470d8e0e000f950780c7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=5lntZ3rovTBKBRNYBptf8gdfeOM%3D)
- [img2](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/ddc11018f9324f6cae76611a7486894b~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=O88KtsSqlFFGJqlLUTLF4IzYYhs%3D)

æ ¸å¿ƒæŠ€æœ¯æ˜¯: å‘é‡ embedding
- å°†ç”¨æˆ·çŸ¥è¯†åº“å†…å®¹ç»è¿‡ embedding å­˜å…¥å‘é‡çŸ¥è¯†åº“ï¼Œç„¶åç”¨æˆ·æ¯ä¸€æ¬¡æé—®ä¹Ÿä¼šç»è¿‡ embeddingï¼Œåˆ©ç”¨å‘é‡ç›¸å…³æ€§ç®—æ³•ï¼ˆä¾‹å¦‚ä½™å¼¦ç®—æ³•ï¼‰æ‰¾åˆ°æœ€åŒ¹é…çš„å‡ ä¸ªçŸ¥è¯†åº“ç‰‡æ®µï¼Œå°†è¿™äº›çŸ¥è¯†åº“ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·ä½œä¸º prompt æäº¤ç»™ LLM å›ç­”

å…¸å‹çš„prompt

```json
å·²çŸ¥ä¿¡æ¯ï¼š
{context} 
æ ¹æ®ä¸Šè¿°å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´å’Œä¸“ä¸šçš„æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ— æ³•ä»ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·è¯´ â€œæ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜â€ æˆ– â€œæ²¡æœ‰æä¾›è¶³å¤Ÿçš„ç›¸å…³ä¿¡æ¯â€ï¼Œä¸å…è®¸åœ¨ç­”æ¡ˆä¸­æ·»åŠ ç¼–é€ æˆåˆ†ï¼Œç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚ 
é—®é¢˜æ˜¯ï¼š{question}
```

### å®ç°

```sh
# ä¸‹è½½æºç 
git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git
# å®‰è£…ä¾èµ–
cd langchain-ChatGLM
pip install -r requirements.txt
# ä¸‹è½½æ¨¡å‹

# å®‰è£… git lfs
git lfs install
# ä¸‹è½½ LLM æ¨¡å‹
git clone https://huggingface.co/THUDM/chatglm-6b /your_path/chatglm-6b
# ä¸‹è½½ Embedding æ¨¡å‹
git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese /your_path/text2vec
# æ¨¡å‹éœ€è¦æ›´æ–°æ—¶ï¼Œå¯æ‰“å¼€æ¨¡å‹æ‰€åœ¨æ–‡ä»¶å¤¹åæ‹‰å–æœ€æ–°æ¨¡å‹æ–‡ä»¶/ä»£ç 
git pull
```

æ¨¡å‹ä¸‹è½½å®Œæˆåï¼Œè¯·åœ¨ configs/model_config.py æ–‡ä»¶ä¸­ï¼Œå¯¹embedding_model_dictå’Œllm_model_dictå‚æ•°è¿›è¡Œä¿®æ”¹ã€‚

```py
embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "/your_path/text2vec"
}
llm_model_dict = {
    "chatyuan": "ClueAI/ChatYuan-large-v2",
    "chatglm-6b-int4-qe": "THUDM/chatglm-6b-int4-qe",
    "chatglm-6b-int4": "THUDM/chatglm-6b-int4",
    "chatglm-6b-int8": "THUDM/chatglm-6b-int8",
    "chatglm-6b": "/your_path/chatglm-6b",
}
```

å¯åŠ¨æœåŠ¡

```py
# Web æ¨¡å¼å¯åŠ¨
pip install gradio
python webui.py
# API æ¨¡å¼å¯åŠ¨
python api.py
# å‘½ä»¤è¡Œæ¨¡å¼å¯åŠ¨
python cli_demo.py
```

### æ•ˆæœ

gradioé¡µé¢
- [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/558af5fd53d34b5a859afddbc82a331c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=N%2FKm%2FGcW8WSiFxrAAD04P3klhig%3D)

Chatgpt-Next-Web é¡¹ç›®åŸºç¡€ä¸Šè¿›è¡Œäº†é€‚é…ä¿®æ”¹ï¼Œæ‰“é€ äº†ä¸€æ¬¾é¢å‘ç”¨æˆ·ä½¿ç”¨çš„æœ¬åœ°çŸ¥è¯†åº“å‰ç«¯ã€‚
- [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/55d11a03e5a742ce9c201aa355b38e3c~noop.image?_iz=58558&from=article.pc_detail&x-expires=1685601997&x-signature=fYTBeLwxkicrZBzWsYQusCVfiJk%3D)


### FastGPT

ã€2023-5-17ã€‘[FastGPT](https://github.com/c121914yu/FastGPT), è°ƒç”¨ gpt-3.5 å’Œ embedding æ„å»ºè‡ªå·±çš„çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“æ„å»ºåŸç†
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/KBProcess.jpg?raw=true)

æ•ˆæœ
- ![img](https://github.com/c121914yu/FastGPT/raw/main/docs/imgs/demo.png?raw=true)



åœ¨çº¿ä½“éªŒ
- ğŸ‰ [fastgpt.run](https://fastgpt.run/) ï¼ˆå›½å†…ç‰ˆï¼‰
- ğŸ‰ [ai.fastgpt.run](https://ai.fastgpt.run/) ï¼ˆæµ·å¤–ç‰ˆï¼‰



## ä¸šç•Œæ¡ˆä¾‹

### New Bing

- ä¼˜åŠ¿ï¼šå…è´¹ï¼Œå¿«æ·ï¼Œå¯ä»¥è”ç½‘ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥é˜…è¯»æœ¬åœ°PDFå’Œç½‘ç»œè®ºæ–‡ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’
- ç¼ºç‚¹ï¼šä¸ç¨³å®šï¼Œè¯†åˆ«å†…å®¹æœ‰é™ï¼Œç”šè‡³äºä¿¡æ¯é‡ä½äºæ‘˜è¦çš„å†…å®¹ã€‚ç»å¸¸ä¼šè¾“å‡ºä¸€åŠå°±æ–­äº†ã€‚

### chatpdf

[ChatPDF](https://www.chatpdf.com) ç•Œé¢å¹²å‡€ï¼Œä¸Šä¼ pdfåï¼Œç›´æ¥å¯¹è¯ã€‚
- ä¸Šä¼ é€Ÿåº¦å¾ˆå¿«ï¼Œå¯¹è¯å“åº”ä¹Ÿéå¸¸çš„å¿«ã€‚
- å¯¹æ–‡æ¡£å†…å®¹çš„è§£æå¾ˆå‡†ç¡®ï¼ŒåŒ…æ‹¬ä¸€äº›éšè—åœ¨å†…éƒ¨çš„çŸ¥è¯†ç‚¹ä¹Ÿå¯ä»¥å¿«é€Ÿæœç´¢æ‰¾åˆ°
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY88FTkaxGc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=A9yfB6gzbQrwWdUHuBZ2o0bRZzM%3D)

ä¼˜åŠ¿ï¼š
- äº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ç¼ºç‚¹ï¼šå…¨æ–‡æ€»ç»“ä¿¡æ¯é‡è¾ƒä½ï¼Œé—®ç­”æ¨¡å¼åå‘äºå…³é”®è¯å®šä½ï¼Œç„¶åä¸Šä¸‹æ–‡ç¿»è¯‘ï¼Œä¸”å·²ç»æ”¶è´¹ï¼Œæ¯æœˆ5åˆ€ã€‚åªæ”¯æŒæœ¬åœ°PDFæ–‡æ¡£ä¸Šä¼ ã€‚

### scispace

- ä¼˜åŠ¿ï¼šäº¤äº’æ–¹ä¾¿ï¼Œå®¹æ˜“ä¸Šæ‰‹ï¼Œå¯ä»¥æŒç»­é—®ç­”äº¤äº’ï¼Œæ”¯æŒæœ¬åœ°è®ºæ–‡ä¸Šä¼ ï¼Œå¯ä»¥å…¬å¼æˆªå›¾è§£æï¼Œå¯ä»¥è§£é‡Šä¼ªä»£ç 
- ç¼ºç‚¹ï¼šå¯¹ä¸­æ–‡æ”¯æŒè¾ƒå·®ï¼Œå…¨æ–‡æ€»ç»“æ•ˆæœè¾ƒå·®ã€‚

### aminer.cn

æ¸…åå”æ°è€å¸ˆä»–ä»¬ç»„çš„å·¥ä½œï¼
- ![](https://pic1.zhimg.com/80/v2-33843cf159df1ca9e4a28fa32a15a759_1440w.webp?source=1940ef5c)
- ![](https://pic1.zhimg.com/80/v2-765efacd5340b65de02e79087ee91a07_1440w.webp?source=1940ef5c)

- ä¼˜åŠ¿ï¼šæœ‰çƒ­ç‚¹è®ºæ–‡æ¨é€ï¼æœ‰è®ºæ–‡æ‰“åˆ†ï¼Œå’Œåˆ«äººçš„æé—®è®°å½•
- ç¼ºç‚¹ï¼šè¯­ä¹‰ç†è§£æœ‰é™

### ChatPaper å¼€æº

ä¸­ç§‘å¤§å‡ºå“ï¼šChatPaper, Use ChatGPT to summarize the arXiv papers. å…¨æµç¨‹åŠ é€Ÿç§‘ç ”ï¼Œåˆ©ç”¨chatgptè¿›è¡Œè®ºæ–‡æ€»ç»“+æ¶¦è‰²+å®¡ç¨¿+å®¡ç¨¿å›å¤
- åŠŸèƒ½ï¼šè®ºæ–‡ï¼ˆç¦»çº¿/åœ¨çº¿ï¼‰æ€»ç»“+è®ºæ–‡æ¶¦è‰²+AIå®¡ç¨¿+AIå®¡ç¨¿å›å¤ç­‰åŠŸèƒ½ã€‚
- [github](https://github.com/kaixindelele/chatpaper), [demo](https://chatpaper.org/)

é—®é¢˜ï¼š
- å‰é¢å‡ æ¬¾å·¥å…·éƒ½é¢ä¸´ä¸€ä¸ªé—®é¢˜ï¼Œå…¨æ–‡æ€»ç»“çš„ä¿¡æ¯é‡è¾ƒä½ï¼Œå› ä¸ºGPTsçš„è¾“å…¥tokenæ˜¯**è¿œä½äº**è®ºæ–‡çš„å…¨æ–‡æ–‡æœ¬çš„ï¼Œè€Œç®€å•çš„ç¿»è¯‘æ€»ç»“æ‘˜è¦ï¼Œåˆæ‹¿ä¸åˆ°å¤šå°‘æœ‰æ•ˆä¿¡æ¯

æ–¹æ¡ˆï¼š
- å°†abstractå’Œintroductionè¿›è¡Œå‹ç¼©ï¼Œç„¶åè¾“å…¥ç»™chatè¿›è¡Œæ€»ç»“

æ•ˆæœ
- æ¯ç¯‡æ–‡ç« ï¼Œè°ƒç”¨äº”æ¬¡chatï¼Œå¯ä»¥è·å¾—7åˆ°8æˆçš„ä¿¡æ¯é‡ï¼Œå¹¶ä¸”æ ¼å¼åŒ–è¾“å‡ºæˆä¸­å›½äººå®¹æ˜“çœ‹æ‡‚çš„æ–‡æœ¬ï¼Œæå¤§çš„é™ä½äº†å¤§å®¶çš„é˜…è¯»é—¨æ§›ã€‚å‡ ä¹å¯ä»¥è¾¾åˆ°ï¼ŒAIèŠ±ä¸€åˆ†é’Ÿæ€»ç»“ï¼ŒäººèŠ±ä¸€åˆ†é’Ÿçœ‹æ€»ç»“ï¼Œå°±å¯ä»¥åˆ¤æ–­è¿™ç¯‡æ–‡ç« æ˜¯å¦éœ€è¦ç²¾è¯»çš„æ•ˆæœã€‚
- å¦‚æœéœ€è¦**ç²¾è¯»**ï¼Œåˆ™å¯ä»¥è°ƒç”¨ä¸Šé¢çš„å„ç§å·¥å…·ï¼Œå°¤å…¶æ¨èscispaceå’Œaminer.


### PandasGPT

[PandaGPT](https://www.pandagpt.io/), è®¿é—®é€Ÿåº¦åæ…¢ï¼ŒUIå¯¹è¯æ ·å¼ä¸€è¨€éš¾å°½ï¼Œæ²¡æœ‰ä¸€ä¸ªç‰ˆå—ä¸æ˜¯äº’ç›¸é®æŒ¡çš„
- å·²æœ‰3wä¸ªæ–‡æ¡£ï¼Œ10wä¸ªé—®é¢˜
- ä¸Šä¼ æ–‡æ¡£ï¼Œç›´æ¥é’ˆå¯¹æ–‡æ¡£é—®ç­”; è¿˜èƒ½ç”ŸæˆçŸ¥è¯†å›¾è°±ï¼ŒGenerate Knowledge Graph
- ![](https://uploads-ssl.webflow.com/6405047c9d73416a60b878b4/6405068dec8bf7442171f160_Screenshot%202023-03-05%20at%204.15.30%20PM.png)

- é—®é¢˜å›ç­”åŸºæœ¬åˆ°ä½ï¼Œç›¸æ¯”ChatPDFï¼Œç•¥æ˜¾å•°å—¦
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY8iElGGYks~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=BO6bt9JW5V%2Fsitc%2F%2FKWe6sBmUHY%3D)

ç±»ä¼¼çš„ï¼Œè¿˜æœ‰ AMiner ä¸Šçš„åæ™ºå†°

### ChatDOC

ã€2023-3-28ã€‘[ChatDOC](https://chatdoc.com/)æ–‡æ¡£é˜…è¯»å·¥å…·ï¼Œæ”¯æŒä¸­æ–‡ï¼åˆå¿«åˆå…è´¹ï¼ä½¿ç”¨ ChatGPT é˜…è¯»æ–‡ä»¶çš„AIé—®ç­”æœºå™¨äºº
- åŸºäº ChatGPT çš„æ–‡ä»¶é˜…è¯»åŠ©æ‰‹ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¯ä»¥å¿«é€Ÿä»ä¸Šä¼ ç ”ç©¶è®ºæ–‡ã€ä¹¦ç±ã€æ‰‹å†Œç­‰æ–‡ä»¶ä¸­æå–ã€å®šä½å’Œæ±‡æ€»æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶é€šè¿‡èŠå¤©çš„æ–¹å¼åœ¨å‡ ç§’é’Ÿå†…ç»™å‡ºé—®é¢˜çš„ç­”æ¡ˆã€‚
- ChatDOC è¿˜å¯ä»¥ç†è§£æ–‡æ¡£ä¸­çš„è¡¨æ ¼æˆ–æ–‡å­—ï¼Œä¼˜åŒ–å…¶æ•°æ®åˆ†ææ€§èƒ½ï¼Œå¹¶ä¸ºæ¯ä¸ªå›ç­”æä¾›ç›´æ¥å¼•ç”¨çš„æ¥æºï¼Œæ–¹ä¾¿æ ¸å®AIçš„è§£è¯»å‡†ç¡®æ€§ã€‚
- ChatDOC ç›®å‰å…è´¹ï¼Œæ–‡ä»¶å¤§å°é™åˆ¶ä¸º 200 é¡µï¼Œæœ€å¤šå¯ä»¥ä¸Šä¼  5 ä¸ªæ–‡æ¡£ã€‚åœ¨å³å°†æ›´æ–°çš„ç‰ˆæœ¬ä¸­ï¼Œè¿˜æ”¯æŒè·¨å¤šä¸ªæ–‡æ¡£çš„ç»¼åˆæŸ¥è¯¢å’Œé—®ç­”ã€‚
- ![](https://pic2.zhimg.com/80/v2-c73f17ecea423a82aad0ac7c110bd625_720w.webp)


### typeset

[typeset](https://typeset.io)
- ä¸»æ‰“è®ºæ–‡æ£€ç´¢ï¼Œä¹Ÿæ”¯æŒpdfæ–‡æ¡£è§£è¯»ã€‚
- ä¸Šä¼ ã€å¯¹è¯å“åº”éƒ½ååˆ†ç¼“æ…¢ï¼Œå¯¹è¯çš„æ•ˆæœå·®ï¼Œå¾ˆå¤šçŸ¥è¯†ç‚¹æ— æ³•è§£è¯»ï¼Œä¸€å¾‹å›å¤æ— æ³•æ‰¾åˆ°è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TdjoY9mB4FVHsf~noop.image?_iz=58558&from=article.pc_detail&x-expires=1684219771&x-signature=DjAXODUMrVrnilF7CAXPLSUT0qs%3D)

### privateGPT (æœ¬åœ°ã€ç¦»çº¿)

ã€2023-5-17ã€‘å¼€æºçš„ [privateGPT](https://www.privategpt.io/), [privateGPTä»£ç ](https://github.com/imartinez/privateGPT)ï¼Œå®ƒä½¿ç”¨GPTçš„å¼ºå¤§åŠŸèƒ½ï¼Œå¯ä»¥åœ¨100%ç§å¯†çš„æƒ…å†µä¸‹ä¸æœ¬åœ°æ–‡æ¡£è¿›è¡Œç§å¯†äº¤äº’ï¼Œä¸ä¼šæœ‰ä»»ä½•æ•°æ®æ³„æ¼ã€‚
- ä½¿ç”¨LLaMaã€LangChainå’ŒGPT4Allæ„å»ºã€‚
- [Demo](https://docs.boosterframework.com/)

The supported extensions are:
- .csv: CSV,
- .docx: Word Document,
- .enex: EverNote,
- .eml: Email,
- .epub: EPub,
- .html: HTML File,
- .md: Markdown,
- .msg: Outlook Message,
- .odt: Open Document Text,
- .pdf: Portable Document Format (PDF),
- .pptx : PowerPoint Document,
- .txt: Text file (UTF-8)


### ChatBase

ã€2023-5-28ã€‘[ChatGPT é€ å¯Œâ€œç¥è¯â€ï¼šå¤§å››å­¦ç”Ÿæ”¾å¼ƒå¤§å‚å»åˆ›ä¸šï¼ŒåŠå¹´åæœˆæ”¶å…¥45ä¸‡](https://mp.weixin.qq.com/s/IS5NvCAzs0q4Xi5ABfszFQ)

åŸƒåŠå¤§å­¦ç”Ÿ[Yasser](https://twitter.com/yasser_elsaid_)åœ¨ Meta å’Œ Tesla ç­‰å¤§å‚å®ä¹ åŠå¹´åï¼Œå…¶åˆ›åŠçš„èŠå¤©æœºå™¨äººå…¬å¸å°±å·²ç»ç¨³å®šæœˆæ”¶ 6.4 ä¸‡ç¾å…ƒï¼ˆçº¦åˆ 45 ä¸‡äººæ°‘å¸ï¼‰ï¼Œè€Œä¸”è‡ªé¦–æ¬¡ä¸Šçº¿ä»¥æ¥ï¼Œä¸šåŠ¡æµé‡ä»æœªä¸‹æ»‘ç¼©æ°´ã€‚
- Chatbase å¸‚åœºå®šä½å¹¶ä¸å¤æ‚ï¼Œä¹Ÿæ²¡åšè¿‡éªŒè¯æˆ–è€…å•†ä¸šè°ƒæŸ¥ã€‚æ¯•ç«Ÿ AI è¿™ä¸ªé¢†åŸŸæ‰åˆšåˆšè¯ç”Ÿï¼Œå¯¹æˆ‘æ¥è¯´â€˜ç”¨ ChatGPT å¤„ç†æ•°æ®â€™è‚¯å®šæœ‰æå¤´ï¼Œèƒ½å¸®åŠ©è®¸è®¸å¤šå¤šç”¨æˆ·è§£å†³å®é™…éœ€æ±‚
- Chatbase æœ€åˆå…¶å®æ˜¯æƒ³åšæˆä¸€æ¬¾å¤„ç† PDF çš„ ChatGPT å·¥å…·ï¼Œè¿™æ˜¯ Yasser å½“æ—¶æƒ³åˆ°çš„æœ€ç›´è§‚çš„ç”¨ä¾‹ã€‚æ¯”å¦‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä¸€ä»½ PDFï¼Œç„¶åè®© ChatGPT æ€»ç»“ä¸€ä¸‹å…¶ä¸­çš„å†…å®¹ã€‚
- ç¬¬ä¸€ä¸ªç‰ˆæœ¬èŠ±äº†ä¸¤ä¸ªæœˆæ—¶é—´ï¼Œ2023 å¹´ 2 æœˆ 2 å·ï¼ŒYasser å‘å¸ƒç»™äº† Twitter ä¸Šçš„å…¨éƒ¨ 16 ä¸ªå…³æ³¨è€…ï¼Œç»“æœä¸€ä¸‹å­å°±ç«äº†ï¼Œå·¨å¤§çš„å•†æœºï¼ŒYasser é©¬ä¸Šä¸­æ­¢äº†åœ¨æ ¡è¯¾ä¸šï¼ŒæŠŠæ‰€æœ‰æ—¶é—´å’Œç²¾åŠ›éƒ½é›†ä¸­åœ¨ Chatbase ä¸Š

[Chatbase.co](https://www.chatbase.co/) æ˜¯ä¸€æ¬¾ä¸ºç½‘ç«™æ„å»ºè‡ªå®šä¹‰ ChatGPT ç•Œé¢çš„å·¥å…·ï¼Œç”¨æˆ·åªéœ€ä¸Šä¼ **æ–‡æ¡£**æˆ–æ·»åŠ åˆ°**ç½‘ç«™é“¾æ¥**ï¼Œå°±å¯ä»¥è·å¾—ä¸€ä¸ªç±»ä¼¼ ChatGPT çš„èŠå¤©æœºå™¨äººï¼Œå¹¶å°†å®ƒä½œä¸ºå°ç»„ä»¶æ·»åŠ åˆ°ç½‘ç«™ä¸Šã€‚

Yasser ç”¨ Reactã€Next.js å’Œ Supabase æ¥æ„ web åº”ç”¨ã€‚Yasser è¿˜åœ¨åº”ç”¨çš„ AI éƒ¨åˆ†ä½¿ç”¨äº† OpenAI çš„ APIã€Langchain è¿˜æœ‰ Pineconeã€‚ä»˜æ¬¾éƒ¨åˆ†ç”¨çš„æ˜¯ Stripeã€‚ç›®å‰è¿™å¥—æŠ€æœ¯æ ˆè¿è¡Œå¾—ä¸é”™ï¼Œä½†åç»­ Yasser å¯èƒ½éœ€è¦åšäº›è°ƒæ•´æ¥æ§åˆ¶æˆæœ¬ï¼Œæ¯”å¦‚å°è¯•ä¸åŒçš„ Vector æ•°æ®åº“æˆ–è€…æ‰˜ç®¡é€‰é¡¹

å¯é›†æˆåˆ°è‡ªå·±çš„ç½‘ç«™, å®˜æ–¹æä¾›[çœ‹æ¿é…ç½®](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX/dashboard)
- ç¤ºä¾‹ï¼š[test](https://www.chatbase.co/chatbot/zNSQTQvqYJYf0rb0V-wYX)
- å›½å¤–ä»‹ç»ï¼š[How a college student reached $64,000/mo in 6 months by being an AI first mover](https://www.indiehackers.com/post/how-a-college-student-reached-64-000-mo-in-6-months-by-being-an-ai-first-mover-ba7981f6e1)


# ç»“æŸ