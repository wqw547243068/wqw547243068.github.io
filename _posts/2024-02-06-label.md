---
layout: post
title:  数据标注专题笔记
date:   2024-02-06 17:20:00
categories: 大模型
tags: ChatGPT 标注
excerpt: 数据标注流程介绍，大模型时代如何提升数据标注效率？
mathjax: true
permalink: /label
---

* content
{:toc}

# 数据标注



## 标注范式


【2023-10-22】[为标注员的LLM（五）：3种标注范式以及思考](https://zhuanlan.zhihu.com/p/662285150?utm_psn=1699572009640701952)

标注的本质以及LLM的作用
- `标注` = `常识` + `标注规则`
- 常识对应先验知识。有了常识能力，可以在仅提供类别名称、而未提供标注规则的情况下进行标注。这也是零样本NLP模型（如Siamese-uniNLU[8]、paddleNLP[9]）的核心。
- 标注规则帮助标注员明确任务、区分边界。需要做的工作包括：任务定义、类别定义、边界处理逻辑等。

而将LLM引入标注，意味着什么呢？
- 有了一个具备相当**常识**的标注员。就算不提供细则，也能有良好的效果（范式1）；
- 有了一个能**听懂人话**、**高效**的标注员。标注规则通过自然语言表达，也通过自然语言修改，成本低、速度快、且人类可以理解（范式2、范式3）。

### LLM 标注

归纳出使用LLM标注的3种范式：炼丹式、工具式、智能式。
- `炼丹式`：范式的特点在于：
  - 重心不在于调整prompt中的标注规则部分，而在于调参数、应用prompt技术（如Self-Consistency[2]、Chain-of-Thought[3]、Bias Calibration[4])、Few-Shot Prompting等）；
  - 目标是最大化dev set上的任务指标。
  - 本质是炼丹，和传统的ML过程是一样的：在dev set上，通过调整超参、应用prompt技术，以得到能带来最佳效果的prompt。
  - ![](https://pic2.zhimg.com/80/v2-d3a0ca04b31efd23022c4a5b531b17a1_1440w.webp)
  - 优点：整个过程可以高度自动化；
  - 缺点：难以针对badcase进行迭代；
  - 适用场景：Cold-Start。在没有业务经验的时候，可以快速得到第一版标注结果。
- `工具式`(局部使用)
  - 代表是Snorkel的论文：Language Models in the Loop: Incorporating Prompting into Weak Supervision[5], 特点是：
  - 把LLM当作**局部**的**子标注器**，例如判断这段话里是否有联系方式；
  - 人类负责把大的标注任务拆解为多个LLM子标注器的组合。拆解和组合方式，取决于数据分析和业务理解。
  - 这一范式的本质是Programmatic Weak Supervision思路的扩展。
  - ![](https://pic2.zhimg.com/80/v2-fe07128fec9088bd190b2e39ae578e39_1440w.webp)
  - 优点：人类掌控全局，因此更可控；对LLM的依赖性和要求较低，可以用较弱的LLM；支持迭代，迭代的思路是新增LLM标注器、或者修改原有的LLM标注器；
  - 缺点：框架相对复杂，人类使用者需要学习如何分析数据、设计子标注器；
  - 适用场景：通用
- `智能式`(智能体迭代)
  - 代表: OpenAI使用GPT-4来标注的Blog[6]。此范式的特点如下：
  - **所有**的标注要求都通过prompt来表达，包括标签定义、标注边界情况的划分（例：如果XXXX，则标注XXX）；
  - 支持**迭代**，迭代Loop是 LLM标注 -> 找到标注错误 -> 让LLM解释标注原因 -> 迭代标注规则，迭代目标是让让标注规则越来越精准。
  - 本质是把LLM当作智能体，人类则聚焦到标注的核心：让标注规则更清晰、准确。
  - ![](https://pic1.zhimg.com/80/v2-f68d33a4b08a29fa7a34aeae9fc0e568_1440w.webp)
  - 优点：迭代只需修改标注规则，无需代码，且对比范式2，标注规则更加具体、完整、可理解、可复用（范式2是将标注规则抽象为 子标注器+逻辑关系）；
  - 缺点：对LLM要求高，尤其是对复杂指令的理解能力，因为标注规则会包含划分边界的if-else逻辑、对标签的详细定义等；
  - 适用场景：通用。

各范式间的关系
- 智能式和炼丹式，都是用一个全局性的LLM来完成标注任务；而工具式里，LLM的作用是局部性的；
- 智能式和工具式，核心是迭代标注规则；而炼丹式的核心是迭代与业务无关的变量（参数、prompt技术等）；
- 炼丹式可以结合在智能式、工具式当中，以进一步提升效果；

![](https://pic2.zhimg.com/80/v2-c688bca456452bb24fecc785273ec801_1440w.webp)

### ChatGPT 超过人工标注

【2023-3-29】ChatGPT超过人工标注
- [ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks](https://arxiv.org/abs/2303.15056?fbclid=IwAR2j7nL9y2pvxkHHkbZtbWbfEGuyaqiQ6NYVO39WkpUK5NGkBGZLjiMx0ho)
- Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.

苏黎世大学：
> ChatGPT标注数据比人类便宜**20倍**，**80%**任务上占优势

在ChatGPT面前，无论成本还是效率，人类可以说是毫无优势：
- 成本上，ChatGPT平均每个标注成本低于0.003美元，比众包平台便宜20倍；何况AI还能24*7无休。
- 效率上，在相关性、立场、主题等任务中，ChatGPT也是以4:1的优势“碾压”人类。

`MTurk` 是专门进行数据标注的一个众包平台。
- 在MTurk这类众包平台内部，还会有更加精细的分工，比如说会有经过专业训练的数据标注者以及众包工作者。
- 前者在产出高质量数据上具有优势，但自然成本也更高，而后者虽然更便宜但质量也会随任务难度波动。

于是, 研究大语言模型（LLM）在这方面的潜力，并且对比了没有额外训练（zero-shot）的ChatGPT（基于GPT-3.5）和MTurk在数据标注上的性能。这项对比基于研究团队此前收集到的2382条推文样本。

ChatGPT和MTurk分别将推文以“相关性、立场、主题、政策、实用性”这五种任务进行标注。

“生成训练数据需要人工”的说法已经成为过去式

### ChatGPT NER Demo

ChatGPT 用于 人工标注的 Web系统：[Weak Labeling Tool using ChatGPT](https://github.com/ainbr/chatgpt-weak-labeler-web-ui), [代码](https://github.com/ainbr/chatgpt-weak-labeler-web-ui/blob/master/app.py)
- ![](https://github.com/ainbr/chatgpt-weak-labeler-web-ui/raw/master/misc/screenshot1.png)

```sh
git clone https://github.com/ainbr/chatgpt-weak-labeler-webui.git
pip install -r requirements.txt
gradio app.py
```

填入OpenAI Key即可启动NER任务

【2023-6-18】[无需人力标注！悉尼大学华人团队提出"GPT自监督标注范式](https://www.toutiao.com/article/7245196537557549623)

业界和学界面临数据标注任务：成本较高、存在偏见、难以评估，以及标注难度等问题。

悉尼大学研究团队提出了一种通过大语言模型**自监督生成标注**的框架。首次利用基于**生成-还原**循环标注的GPT自监督方法，解决了上述问题
- davinci，text-curie-001，text-davinci-003，gpt-3.5-turbo在不同评估标准下标注数据质量的得分
- [论文链接](https://arxiv.org/pdf/2306.04349.pdf)

核心思想: 利用大语言模型作为一个**黑盒优化优器**，构造了一个循环：
- 模版质量越高，生成的数据-标注对质量越高；
- 生成的数据标注对质量越高，用当前质量更高的数据对替换上一轮的模版。
- 以此往复迭代，滚雪球式循环提升标注质量。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/2f0cd7e8bebb47218672ba0a28b98008~noop.image)

标注方法包含了**one-shot阶段**和**生成阶段**。
- one-shot阶段的目标：迭代寻找**最优**的 \{数据-标注\}数据对 作为模板。

迭代过程：
- 初始化一个简单数据对作为初始模版，利用GPT生成标注，生成的标注和原始数据形成一个新的数据对。
- 然后，通过比较从标注中还原出来的数据和原始数据，评估这个新数据对作为模板的潜力。
- 如果还原数据与原数据的相似度得分有所提高，就用当前新数据对直接作为新的模板进行一轮数据生成。

因此，这种**自我对齐机制**会迭代调整one-shot模板，为下一轮生成做好准备。one-shot阶段搜索到的最优模板随后用于对数据集进行标注。

通过调整不同的预训练奖励模型来评估标注的质量，并引入不同的评价指标来间接评估摘要的还原能力。

### Autolabel

【2023-6-19】[GPT-4终结人工标注！AI标注比人类标注效率高100倍，成本仅1/7](https://www.toutiao.com/article/7280051689963635212)

数据标注需要找到一个新方法，避免大量使用人工标注带来的包括道德风险在内的其他潜在麻烦。所以，包括谷歌/Anthropic在内的AI巨头和大型独角兽，都在进行数据标注自动化的探索。
- 谷歌最近的研究，开发了一个和人类标注能力相近的AI标注工具
  - 论文: [RLAIF:Scaling Reinforcement Learning from Human Feedback with AI Feedback]()
- Anthropic采用了Constitutional AI来处理数据，也获得了很好的对齐效果
  - 论文: [Constitutional Al: Harmlessness from AI Feeedback]()

初创公司refuel，也上线了一个AI标注数据的开源处理工具：`Autolabel`。用AI标注数据，效率最高提升100倍. [introducing-autolabel](https://www.refuel.ai/blog-posts/introducing-autolabel)
- 按照使用成本最高的GPT-4来算，采用`Autolabel`标注的成本只有使用人工标注的1/7，而如果使用其他更便宜的模型，成本还能进一步降低

![](https://accesspath-com-1252517293.cos.ap-nanjing.myqcloud.com/2023/09/8619824325141295306.png?imageMogr2/format/webp)

要点
- 1、开源工具Autolabel能用LLM代替人工高效标注数据，效率提升100倍，成本仅1/7。
- 2、Autolabel支持主流LLM，可快速标注NLP数据集，准确率高达88.4%，超过人工标注。
- 3、Autolabel可估计标注置信度，不同LLM可平衡成本与质量，大幅降低标注门槛。

Autolabel安装

```sh
# 安装所有必要的库
pip install 'refuel-autolabel[openai]'
```

```py
from autolabel import get_data
get_data('civil_comments')
```

自动标签贴标分为三个步骤:
- 首先，指定一个标签配置(参见下面的config对象)并创建一个LabelingAgent。
- 接下来，通过运行agent.plan，使用config中指定的LLM对的数据集进行一次标注
- 最后，使用agent.run运行标签


### LabelFast

【2023-11-3】[LabelFast：基于LLM的NLP任务自动标注开源工具，Demo发布「AI小作坊」](https://zhuanlan.zhihu.com/p/664879079?utm_psn=1703869814744084481)
- [LabelFast](https://github.com/duanyu/LabelFast) 用LLM技术，识别并快速标注简单文本数据的开源工具
- [demo](https://modelscope.cn/studios/duanyu/LabelFast/summary)
- 标注员只需关注那些**少量而关键**的难样本，达到降本增效

特点如下：
- 开箱即用。无需微调和Prompt工程，提供 标注任务 + 样本，马上开始标注；
- 诚实可信。在提供标注结果的同时，还提供Confidence信息，以表示模型对标注结果的信心程度，便于使用者确定何时信任模型结果；
- 完全开源。LabelFast源于开源的模型和技术，因此也将回馈开源社区。

LabelFast的核心理念是：
- 用最快的速度，完成简单样本的标注，让人类聚焦于关键的难样本。

常见使用场景
- 单条样本标注: 将单条样本填入文本框 -> 执行标注 -> 得到标注结果；
- 批量样本标注: 将多条样本，按格式做成xlsx/csv文件 -> 上传文件 -> 执行标注 -> 得到批量标注结果；
- 批量样本标注 + 选择confidence threshold: 将多条样本 + 真实标签，按格式做成xlsx/csv文件 -> 上传文件 -> 执行标注 -> 得到批量标注结果 + 各confidence threshold下的任务表现(output2) -> 根据任务表现，确定confidence threshold，高于此值的自动标注结果可直接使用，低于此值的通过其他方式标注

### 图片标注

【2024-1-8】[告别逐一标注，一个提示实现批量图片分割，高效又准确](https://www.toutiao.com/article/7321625929854222859)

Segment Anything Model (SAM) 在图像分割领域引起了巨大的关注，其卓越的泛化性能引发了广泛的兴趣。然而，尽管如此，SAM 仍然面临一个无法回避的问题：
- 为了使 SAM 能够准确地分割出目标物体的位置，每张图片都需要手动提供一个独特的**视觉提示**。

目前的一些方法，如 SEEM 和 AV-SAM，通过提供更多模态的输入信息来引导模型更好地理解要分割的物体是什么。然而，尽管输入信息变得更加具体和多样化，但在实际场景中，每个无标注样本仍然需要一个独特的提示来作为指导，这是一种不切实际的需求。

伦敦大学玛丽女王学院的研究者们提出了一种无需训练的分割方法 GenSAM ，能够在只提供一个任务通用的文本提示的条件下，将任务下的所有无标注样本进行有效地分割。
- 论文链接：[paper](https://arxiv.org/pdf/2312.07374.pdf)
- 项目链接：[GenSAM](https://lwpyh.github.io/GenSAM/)
- 代码链接：[GenSAM](https://github.com/jyLin8100/GenSAM/)

Generalizable SAM（GenSAM）模型旨在摆脱像 SAM 这类提示分割方法对样本特定提示的依赖。

作者提出了一个**跨模态思维链**（Cross-modal Chains of Thought Prompting，CCTP）的概念，将一个任务通用的文本提示映射到该任务下的所有图片上，生成个性化的感兴趣物体和其背景的共识热力图，从而获得可靠的视觉提示来引导分割。此外，为了实现测试时自适应，作者进一步提出了一个**渐进掩膜生成**（Progressive Mask Generation，PMG）框架，通过迭代地将生成的热力图重新加权到原图上，引导模型对可能的目标区域进行从粗到细的聚焦。值得注意的是，GenSAM 无需训练，所有的优化都是在实时推理时实现的。

图见原文


# 结束