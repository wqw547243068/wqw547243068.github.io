---
layout: post
title:  æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰ä¸“é¢˜
date:   2023-11-10 16:52:00
categories: å¤§æ¨¡å‹
tags: gpt moe ä¸“å®¶ llama
excerpt: æ··åˆä¸“å®¶æ¨¡å‹ï¼ŒMoEç³»åˆ—
mathjax: true
permalink: /moe
---

* content
{:toc}


# MoE æ··åˆä¸“å®¶æ¨¡å‹


## ä»€ä¹ˆæ˜¯ MoE

ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆMoEï¼‰æŠŠå¤æ‚çš„ä»»åŠ¡åˆ†å‰²æˆä¸€ç³»åˆ—æ›´å°ã€æ›´å®¹æ˜“å¤„ç†çš„**å­ä»»åŠ¡**ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç”±ä¸€ä¸ªç‰¹å®šé¢†åŸŸçš„ã€Œä¸“å®¶ã€è´Ÿè´£ã€‚
1. `ä¸“å®¶å±‚`ï¼šä¸“é—¨è®­ç»ƒçš„å°å‹ç¥ç»ç½‘ç»œï¼Œæ¯ä¸ªç½‘ç»œéƒ½åœ¨å…¶æ“…é•¿çš„é¢†åŸŸæœ‰ç€å“è¶Šçš„è¡¨ç°ã€‚
2. `é—¨æ§ç½‘ç»œ`ï¼šMoEæ¶æ„ä¸­çš„**å†³ç­–æ ¸å¿ƒ**ã€‚å®ƒè´Ÿè´£åˆ¤æ–­å“ªä¸ªä¸“å®¶æœ€é€‚åˆå¤„ç†æŸä¸ªç‰¹å®šçš„è¾“å…¥æ•°æ®ã€‚é—¨æ§ç½‘ç»œä¼šè®¡ç®—è¾“å…¥æ•°æ®ä¸æ¯ä¸ªä¸“å®¶çš„å…¼å®¹æ€§å¾—åˆ†ï¼Œç„¶åä¾æ®è¿™äº›å¾—åˆ†å†³å®šæ¯ä¸ªä¸“å®¶åœ¨å¤„ç†ä»»åŠ¡ä¸­çš„ä½œç”¨ã€‚

è¿™äº›ç»„ä»¶å…±åŒä½œç”¨ï¼Œç¡®ä¿é€‚åˆçš„ä»»åŠ¡ç”±åˆé€‚çš„ä¸“å®¶æ¥å¤„ç†ã€‚é—¨æ§ç½‘ç»œæœ‰æ•ˆåœ°å°†è¾“å…¥æ•°æ®å¼•å¯¼è‡³æœ€åˆé€‚çš„ä¸“å®¶ï¼Œè€Œä¸“å®¶ä»¬åˆ™ä¸“æ³¨äºè‡ªå·±æ“…é•¿çš„é¢†åŸŸã€‚è¿™ç§åˆä½œæ€§è®­ç»ƒä½¿å¾—æ•´ä½“æ¨¡å‹å˜å¾—æ›´åŠ å¤šåŠŸèƒ½å’Œå¼ºå¤§ã€‚

## å®ç°æ¡ˆä¾‹


### GPT-4

[GPT-4æ··åˆå¤§æ¨¡å‹ï¼Ÿç ”ç©¶è¯æ˜MoE+æŒ‡ä»¤è°ƒä¼˜ç¡®å®è®©å¤§æ¨¡å‹æ€§èƒ½è¶…ç¾¤](https://www.toutiao.com/article/7253055129237422626)
- 6æœˆ, ã€Œå¤©æ‰é»‘å®¢ã€ä¹”æ²»ãƒ»éœå…¹ï¼ˆGeorge Hotzï¼‰åœ¨æ¥å—ä¸€å®¶åä¸º Latent Space çš„ AI æŠ€æœ¯æ’­å®¢çš„é‡‡è®¿æ—¶æåˆ°äº† GPT-4ï¼Œå¹¶ç§°: GPT-4 å…¶å®æ˜¯ä¸€ä¸ª**æ··åˆ**æ¨¡å‹ã€‚
- GPT-4 é‡‡ç”¨ç”± 8 ä¸ªä¸“å®¶æ¨¡å‹ç»„æˆçš„é›†æˆç³»ç»Ÿï¼Œæ¯ä¸ªä¸“å®¶æ¨¡å‹éƒ½æœ‰ 2200 äº¿ä¸ªå‚æ•°ï¼ˆæ¯” GPT-3 çš„ 1750 äº¿å‚æ•°é‡ç•¥å¤šä¸€äº›ï¼‰ï¼Œå¹¶ä¸”è¿™äº›æ¨¡å‹ç»è¿‡äº†é’ˆå¯¹ä¸åŒæ•°æ®å’Œä»»åŠ¡åˆ†å¸ƒçš„è®­ç»ƒã€‚

è°·æ­Œã€UC ä¼¯å…‹åˆ©ç­‰è¯æ˜ MoE + æŒ‡ä»¤è°ƒä¼˜èµ·åˆ°äº† 1 + 1 > 2 çš„æ•ˆæœã€‚[è®ºæ–‡](https://arxiv.org/pdf/2305.14705.pdf)
- è°·æ­Œã€UC ä¼¯å…‹åˆ©ã€MIT ç­‰æœºæ„çš„ç ”ç©¶è€…è”åˆå‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡è¯å®ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰ä¸æŒ‡ä»¤è°ƒä¼˜çš„ç»“åˆèƒ½å¤Ÿè®©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½å¤§å¹…æå‡ã€‚

MoEæ˜¯ä¸‹ä¸€ä»£LLMæ¶æ„ï¼Œå®ç°
- [moduleformer](https://github.com/ibm/moduleformer)

### Megatron-LM MoE

ã€2023-11-15ã€‘[Megatron-LM MoE ä»£ç è§£æ](https://zhuanlan.zhihu.com/p/666653126?utm_psn=1708124942137335808)

æ–°ç‰ˆæœ¬çš„ Megatron-LM ä¸­ï¼ŒNvidia ä¹Ÿé‡Šå‡ºäº† MoE çš„é…å¥—å®ç°ã€‚è™½ç„¶æ˜¯ token droplessï¼ŒåŸç”Ÿæ”¯æŒ Megatron çš„ 3D å¹¶è¡Œå’Œ Expert Parallelism

arguments.py ä¸­åŠ å…¥äº† MoE ç›¸å…³çš„å‚æ•°é€‰é¡¹
- --num-experts: Expert çš„æ•°é‡
- --expert-parallel: å¼€å¯ Expert Parallelism
- --expert-model-parallel-size: Expert Parallelism çš„ degreeï¼Œå› ä¸º Expert Parallelism (EP) è¢«æ”¾åœ¨äº† Data Parallelism (DP) é‚£ä¸€ç»´ï¼Œå› æ­¤åœ¨è®¾ç½®æ—¶è¦æ±‚ DP éœ€è¦èƒ½å¤Ÿè¢« EP æ•´é™¤ï¼ˆå¯ä»¥è¿™æ ·ç†è§£ï¼Œåœ¨ä¸è€ƒè™‘ EP çš„æƒ…å†µä¸‹ï¼Œä¸ç®¡ TP å’Œ PP å¦‚ä½•è®¾ç½®ï¼ŒDP çš„å¤§å°å§‹ç»ˆå¯¹åº”æœ‰å¤šå°‘ä»½ model copy åœ¨å¹¶è¡Œè®­ç»ƒï¼ŒExpert Parallelism ç›¸å½“äºæŠŠæ‰€æœ‰çš„ Experts åˆ‡åˆ†åˆ° EP ä»½è¿™æ ·çš„ model copy ä¸Šï¼Œå› æ­¤ DP å¿…é¡»èƒ½è¢« EP æ•´é™¤ï¼Œå¦åˆ™æ ¹æœ¬æ²¡æ³•åˆ‡ï¼‰ã€‚åŸåˆ™ä¸Šæ¯å¼  GPU ä¸Šå¯ä»¥æ”¾å¤šä¸ª Expertï¼Œæ¯ä¸ª Expert ä¹Ÿå¯ä»¥è¢«åˆ‡åˆ†åˆ°å¤šå¼  GPU ä¸Šã€‚å¦‚æœå›ºå®šæ¯å¼  GPU å¯¹åº”ä¸€ä¸ª Expertï¼Œé‚£ä¹ˆå¯¹äºä¸€ä¸ª Expert=16 çš„ MoE æ¨¡å‹ï¼ŒEP=16ï¼ŒDP ä¹Ÿè‡³å°‘æ˜¯16ï¼Œæ‰€ä»¥å¯¹èµ„æºçš„è¦æ±‚è¿˜æ˜¯å¾ˆé«˜çš„ã€‚

æ¨¡å‹å®ç°ä¸Šåªæ˜¯åœ¨ ParallelTransformerLayer åˆå§‹åŒ–æ—¶å°† ParallelMLP æ›¿æ¢æˆäº† SwitchMLP, ä»£ç å®ç°è§[åŸæ–‡](https://zhuanlan.zhihu.com/p/666653126?utm_psn=1708124942137335808)


### ã€2023-11-22ã€‘LM-Cocktail

é—®é¢˜
- LLM finetuneæ–¹å¼ä¼šå¯¼è‡´ç›®æ ‡ä»»åŠ¡ä¹‹å¤–çš„ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œæ€§èƒ½ä¸¥é‡è¡°å‡ï¼ˆperformance degenerationï¼‰

- è®ºæ–‡ï¼š[LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://arxiv.org/pdf/2311.13534.pdf)
- ä»£ç ï¼š[FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding)

BAAIå’Œä¸­ç§‘é™¢å‘å¸ƒ LM-Cocktailï¼Œä½¿ç”¨æ¨¡å‹èåˆï¼ˆmodel mergingï¼‰æ–¹å¼
- å°† finetuneæ¨¡å‹èå…¥ pre-trainæ¨¡å‹ä¸­
- æˆ– ä¸¤è€…åŒç­‰é‡è¦ï¼ŒåŠ æƒ

BAAIæ›´å¤šå·¥ä½œ
-   11/23/2023: Release [LM-Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail), ä¸€ç§é€šè¿‡æ¨¡å‹èåˆåœ¨å¾®è°ƒæ—¶ä¿æŒåŸæœ‰æ¨¡å‹é€šç”¨èƒ½åŠ›çš„æ–¹æ³•. [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2311.13534) ğŸ”¥
-   10/12/2023: å‘å¸ƒ [LLM-Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder), ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹**å„ç§æ£€ç´¢å¢å¼ºä»»åŠ¡è®¾è®¡**çš„è‹±æ–‡å‘é‡æ¨¡å‹ã€‚[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2310.07554.pdf)
-   09/15/2023: å‘å¸ƒ [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.07597.pdf) å’Œ [æ•°æ®é›†](https://data.baai.ac.cn/details/BAAI-MTP).
-   09/12/2023: æ›´æ–°ï¼š
    -   **æ–°å¢é‡æ’æ¨¡å‹**ï¼šå¼€æºäº¤å‰ç¼–ç å™¨æ¨¡å‹bge-rerankerï¼Œå…·æœ‰æ¯”å‘é‡æ¨¡å‹æ›´å¼ºå¤§çš„æ’åºèƒ½åŠ›ã€‚éå¸¸å»ºè®®ä½¿ç”¨æˆ–è€…å¾®è°ƒå®ƒæ¥é‡æ–°æ’åºå‘é‡æ¨¡å‹è¿”å›çš„top-kæ–‡æ¡£ï¼Œæé«˜æœ€ç»ˆç»“æœçš„ç›¸å…³æ€§ã€‚
    -   **æ›´æ–°å‘é‡æ¨¡å‹**ï¼šå‘å¸ƒbge-\*-v1.5å‘é‡æ¨¡å‹ï¼Œç¼“è§£ç›¸ä¼¼åº¦åˆ†å¸ƒé—®é¢˜ï¼Œæå‡æ— æŒ‡ä»¤æƒ…å†µä¸‹çš„æ£€ç´¢èƒ½åŠ›ï¼ˆä½†æ£€ç´¢ä»»åŠ¡ä»å»ºè®®ä½¿ç”¨æŒ‡ä»¤ï¼‰
-   09/07/2023: æ›´æ–°[å¾®è°ƒä»£ç ](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md): å¢åŠ éš¾è´Ÿæ ·æœ¬æŒ–æ˜è„šæœ¬ï¼Œå¢åŠ æŒ‡ä»¤å‚æ•°æ–¹ä¾¿åœ¨å¾®è°ƒä¸­æ·»åŠ æŒ‡ä»¤.
-   08/09/2023: BGEæ¨¡å‹æ•´åˆå…¥Langchain, å¯ä»¥åœ¨langchainä¸­éå¸¸ç®€å•çš„[ä½¿ç”¨å®ƒ](https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md#using-langchain); C-MTEBä¸­æ–‡æ¦œå•å·²[åœ¨çº¿æ›´æ–°](https://huggingface.co/spaces/mteb/leaderboard).
-   08/05/2023: å‘å¸ƒæ›´å°çš„æ¨¡å‹(base, small), **åœ¨åŒå°ºå¯¸æ¨¡å‹ä¸­å–å¾—æœ€å¥½çš„æ€§èƒ½ï¼ ğŸ¤—**
-   08/02/2023: :tada: :tada: å‘å¸ƒä¸­è‹±æ–‡å‘é‡æ¨¡å‹BGE(BAAI General Embeddingçš„ç¼©å†™), **åœ¨MTEBå’ŒC-MTEBæ¦œå•ä¸Šå–å¾—æœ€å¥½çš„æ€§èƒ½**
-   08/01/2023: å‘å¸ƒå¤§è§„æ¨¡ä¸­æ–‡æ–‡æœ¬å‘é‡[è¯„æµ‹æ¦œå•](https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB) (**C-MTEB**), å…¶åŒ…æ‹¬31ä¸ªæµ‹è¯•ä»»åŠ¡.



æ•ˆæœ
- å¾®è°ƒçš„Llamaå’ŒBGEæ¨¡å‹
- FLAN, MMLU, MTEB ä¸ŠéªŒè¯äº† LM-Cocktail çš„æœ‰æ•ˆæ€§ã€‚



### ã€2023-12-11ã€‘Mistral-MoE

ã€2023-12-11ã€‘å¼€æºMoEæ¨¡å‹ï¼š[8x7Bå¼€æºMoEå‡»è´¥Llama 2é€¼è¿‘GPT-4ï¼æ¬§ç‰ˆOpenAIéœ‡æƒŠAIç•Œï¼Œ22äººå…¬å¸åŠå¹´ä¼°å€¼20äº¿](https://mistral.ai/news/mixtral-of-experts/)

æ³•å›½çš„AIåˆåˆ›å…¬å¸ [Mistral AI](https://mistral.ai/news/mixtral-of-experts/) å‘å¸ƒäº†é¦–ä¸ªå¼€æºMoEå¤§æ¨¡å‹ã€‚87GBçš„ç§å­ï¼Œ8x7Bçš„MoEæ¶æ„ï¼Œåƒä¸€æ¬¾miniç‰ˆã€Œå¼€æºGPT-4ã€
- 2023å¹´6æœˆï¼Œ[Mistral AI](https://mistral.ai/news/mixtral-of-experts/)ä¸Šçº¿ã€‚7é¡µPPTï¼Œè·å¾—æ¬§æ´²å†å²ä¸Šæœ€å¤§çš„ç§å­è½®èèµ„, 1.13äº¿ç¾å…ƒã€‚
- 2023å¹´9æœˆï¼ŒMistral 7Bå‘å¸ƒï¼Œå·ç§°æ˜¯å½“æ—¶æœ€å¼ºçš„70äº¿å‚æ•°å¼€æºæ¨¡å‹ã€‚
- 2023å¹´12æœˆï¼Œç±»GPT-4æ¶æ„çš„å¼€æºç‰ˆæœ¬Mistral 8x7Bå‘å¸ƒã€‚å‡ å¤©åï¼Œå¤–åª’é‡‘èæ—¶æŠ¥å…¬å¸ƒMistral AIæœ€æ–°ä¸€è½®èèµ„4.15äº¿ç¾å…ƒï¼Œä¼°å€¼é«˜è¾¾20äº¿ç¾å…ƒï¼Œç¿»äº†8å€ã€‚

- è®ºæ–‡ [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf), ä½œè€…ä¸­ä¸¤äººæ˜¯ [Mistral AI](https://mistral.ai/news/mixtral-of-experts/) åˆ›å§‹äºº
- [æ–‡æ¡£](https://docs.mistral.ai/)
- [api](https://docs.mistral.ai/api/), æä¾›ä¸‰ç§æ¥å£: Chat, Embedding, Models

huggingfaceï¼š [mistralai](https://huggingface.co/mistralai)
- [mistralai/Mixtral-8x7B-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
- [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)
- [mistralai/Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
- [mistralai/Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)


8*7B å°æ¨¡å‹ç›´æ¥ç¢¾å‹äº† `Llama 2 70B`

Mistral 8x7B åœ¨æ¯ä¸ªtokençš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œåªä½¿ç”¨äº†2ä¸ªä¸“å®¶ã€‚

ä»æ¨¡å‹å…ƒæ•°æ®ä¸­æå–çš„ä¿¡æ¯ï¼š

```json
{"dim": 4096, "n_layers": 32, "head_dim": 128, "hidden_dim": 14336, "n_heads": 32, "n_kv_heads": 8, "norm_eps": 1e-05, "vocab_size": 32000, "moe": {"num_experts_per_tok": 2, "num_experts": 8}
```

ä¸GPT-4ï¼ˆç½‘ä¼ ç‰ˆï¼‰ç›¸æ¯”ï¼ŒMistral 8x7B å…·æœ‰ç±»ä¼¼çš„æ¶æ„ï¼Œä½†åœ¨è§„æ¨¡ä¸Šæœ‰æ‰€ç¼©å‡ï¼š
- ä¸“å®¶æ•°é‡ä¸º**8ä¸ª**ï¼Œè€Œä¸æ˜¯16ä¸ªï¼ˆå‡å°‘äº†ä¸€åŠï¼‰
- æ¯ä¸ªä¸“å®¶æ‹¥æœ‰**70äº¿**å‚æ•°ï¼Œè€Œä¸æ˜¯1660äº¿ï¼ˆå‡å°‘äº†çº¦24å€ï¼‰
- æ€»è®¡420äº¿å‚æ•°ï¼ˆä¼°è®¡å€¼ï¼‰ï¼Œè€Œä¸æ˜¯1.8ä¸‡äº¿ï¼ˆå‡å°‘äº†çº¦42å€ï¼‰
- ä¸åŸå§‹GPT-4ç›¸åŒçš„32Kä¸Šä¸‹æ–‡çª—å£

å·²ç»æœ‰ä¸å°‘å¼€æºæ¨¡å‹å¹³å°ä¸Šçº¿äº†Mistral 8Ã—7B
- [Perplexity Labs](https://labs.perplexity.ai)

Mistralæ”¾å‡ºè¿™ä¸ªå¼€æºçš„7BÃ—8Eçš„MoEä¹‹å‰ï¼Œè‹±ä¼Ÿè¾¾å’Œè°·æ­Œä¹Ÿæ”¾å‡ºè¿‡å…¶ä»–å®Œå…¨å¼€æºçš„MoE



# ç»“æŸ