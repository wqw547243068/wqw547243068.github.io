---
layout: post
title:  "机器学习模型评估方法-The-Evaluation-of-Machine Learning"
date:   2020-08-05 14:56:00
categories: 机器学习
tags: 机器学习 AUC PR 混淆矩阵 NCE 评分卡 评价 互联网金融 损失函数 kappa 马修斯 mcc 指标 mae elo 竞技 博弈
author : 鹤啸九天
excerpt: 机器学习项目开始前的核心问题：如何设置指标，评价模型效果？
mathjax: true
permalink: /eva
---

* content
{:toc}

# 总结


- [Scikit-Learn的模型评估指标](https://www.biaodianfu.com/scikit-learn-metrics.html)

sklearn 提供大量评估函数 [机器学习方法选择](https://www.biaodianfu.com/wp-content/uploads/2023/11/sklearn.png)
- ![](https://www.biaodianfu.com/wp-content/uploads/2023/11/sklearn.png)
- 也可以用 sklearn.metrics.make_scorer 打包供scoring参数调用。

## 机器学习问题类型

常见几类机器学习问题
- 分类
- 聚类
- 回归

损失函数见站内专题: [机器学习: 损失函数](loss)


## 回归MSE/分类CE？

回归、分类损失函数：
- **回归**问题常用`mse`作为损失函数，隐含的预设是**数据误差**符合`高斯分布`。
- **分类**问题常用`交叉熵`则是以数据分布服从`多项式分布`为前提。离散数据

回归问题能用交叉熵吗
- 可以，虽然交叉熵用在回归问题看起来有些越俎代庖，「狗拿耗子多管闲事」，但「黑猫白猫能捉老鼠就是好猫」，搞清楚数据特点、使用场景，loss选择就能更贴合实际，最终的效果才是硬道理。

本质上回归应该**用什么样的损失函数取决于数据分布**。损失函数的选择本身也是一种先验偏好，选择mse意味着认为数据误差符合**高斯分布**，选择交叉熵则表示你倾向于认为数据接近**多项式分布**。如果你的先验直觉比较准确，符合实际情况，那模型效果应该会更好一些。 多项式分布一般和**离散数据**相关，但如果连续数据分桶后接近多项式分布，那选用mse可能就不合时宜了。

本质上，损失函数的选择是取决于对数据分布假设，不同的loss形式隐式地有对数据分布的要求，需要仔细分析数据特点进行判断。至于为什么A分布对应甲损失函数，B分布却对应乙损失函数，这也是一个值得展开的话题，简单来说这是最大熵原理约束下的选择。如对于高斯噪音分布，选择mse是满足最大熵要求的，它没有在高斯分布的假设之外增加额外的先验偏好。

[知乎](https://zhuanlan.zhihu.com/p/362496849)

【2022-8-20】[为什么回归问题用 MSE？](https://mp.weixin.qq.com/s/ddIPuYHkZD4PBykNkf7qLg)
- 解答1：回归时，数据的残差有正有负，取平方求和后可以很简单的衡量模型的好坏。同时因为平方后容易求导数，比取绝对值还要分情况讨论好用 —— 经验主导，没有指出本质
- [解答2](https://zhuanlan.zhihu.com/p/45790146)：MSE对于偏差比较大的数据惩罚得比较多，但是会被outlier影响，同时MSE的优化目标是**平均值**，而MAE的优化目标是**中位数**。即如果我们的数据集足够大，对于同一个x会有多个y，MSE的目标是尽可能让预测值接近这些y的平均值。同时在做gradient descent的时候，MSE的梯度可以在越接近最小值的地方越平缓，这样不容易步子扯大了。而MAE的梯度一直不变，得手动调整learning rate。
- [解答3](https://www.zhihu.com/question/426901520)：根据中心极限定理，误差服从**正态分布**，此时使得样本**似然函数最大**等价于使得**MSE最小**——Ian的《Deep Learning》


# 聚类指标


[聚类算法评估指标](https://www.biaodianfu.com/cluster-score.html)

<table>
  <tbody>
    <tr><td>Scoring</td><td>Function</td><td>Comment</td></tr>
    <tr><td></td><td></td><td></td></tr>
    <tr><td>‘adjusted_mutual_info_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score">metrics.adjusted_mutual_info_score</a></td><td></td></tr>
    <tr><td>‘adjusted_rand_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score">metrics.adjusted_rand_score</a></td><td></td></tr>
    <tr><td>‘completeness_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score">metrics.completeness_score</a></td><td></td></tr>
    <tr><td>‘fowlkes_mallows_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score">metrics.fowlkes_mallows_score</a></td><td></td></tr><tr><td>‘homogeneity_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score">metrics.homogeneity_score</a></td><td></td></tr><tr><td>‘mutual_info_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score">metrics.mutual_info_score</a></td><td></td></tr><tr><td>‘normalized_mutual_info_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score">metrics.normalized_mutual_info_score</a></td><td></td></tr><tr><td>‘rand_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score">metrics.rand_score</a></td><td></td></tr><tr><td>‘v_measure_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score">metrics.v_measure_score</a></td><td></td></tr></tbody></table>


# 回归指标


常见指标
- 回归方差(反应自变量与因变量之间的相关程度)
- 平均绝对误差

整理的[回归模型评估指标](https://www.biaodianfu.com/regression-metrics.html)。

<table><tbody><tr><td></td></tr><tr><td>Scoring</td><td>Function</td><td>Comment</td></tr><tr><td></td><td></td><td></td></tr><tr><td>‘explained_variance’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score">metrics.explained_variance_score</a></td><td>可解释方差</td></tr><tr><td>‘max_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error">metrics.max_error</a></td><td>最大误差值</td></tr><tr><td>‘neg_mean_absolute_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error">metrics.mean_absolute_error</a></td><td></td></tr><tr><td>‘neg_mean_squared_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error">metrics.mean_squared_error</a></td><td></td></tr><tr><td>‘neg_root_mean_squared_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error">metrics.mean_squared_error</a></td><td></td></tr><tr><td>‘neg_mean_squared_log_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error">metrics.mean_squared_log_error</a></td><td></td></tr><tr><td>‘neg_median_absolute_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error">metrics.median_absolute_error</a></td><td></td></tr><tr><td>‘r2’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score">metrics.r2_score</a></td><td>决定系数</td></tr><tr><td>‘neg_mean_poisson_deviance’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance">metrics.mean_poisson_deviance</a></td><td></td></tr><tr><td>‘neg_mean_gamma_deviance’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance">metrics.mean_gamma_deviance</a></td><td></td></tr><tr><td>‘neg_mean_absolute_percentage_error’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error">metrics.mean_absolute_percentage_error</a></td><td></td></tr><tr><td>‘d2_absolute_error_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score">metrics.d2_absolute_error_score</a></td><td></td></tr><tr><td>‘d2_pinball_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_pinball_score.html#sklearn.metrics.d2_pinball_score">metrics.d2_pinball_score</a></td><td></td></tr><tr><td>‘d2_tweedie_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_tweedie_score.html#sklearn.metrics.d2_tweedie_score">metrics.d2_tweedie_score</a></td><td></td></tr></tbody></table>


## 回归方差(反应自变量与因变量之间的相关程度)

explained_variance_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')
 

## 平均绝对误差

mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')

 

## 均方差

mean_squared_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')

 

## 中值绝对误差

median_absolute_error(y_true, y_pred)


# 分类指标

- 参考：[深入理解AUC](https://tracholar.github.io/machine-learning/2018/01/26/auc.html)
- 在机器学习的评估指标中，AUC是一个最常见也是最常用的指标之一。
- AUC 基于几何，但是其意义十分重要，应用十分广泛。


## 总结

准确率accuracy、精确率precision，召回率recall等指标

[分类算法评估指标](https://www.biaodianfu.com/classification-score.html)
- Confusion Matrix 混淆矩阵
- Classification Report
- 精确度 precision ＆召回率 Recall
- F1值: 平衡 precision 和 Recall 效果
- ROC曲线 和 AUC值: 仅适用于**二分类**

<table><tbody><tr><td>Scoring</td><td>Function</td><td width="257">Comment</td></tr><tr><td></td><td></td><td width="257"></td></tr><tr><td>‘accuracy’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score">metrics.accuracy_score</a></td><td width="257">准确率</td></tr><tr><td>‘balanced_accuracy’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score">metrics.balanced_accuracy_score</a></td><td width="257">平衡准确率</td></tr><tr><td>‘top_k_accuracy’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score">metrics.top_k_accuracy_score</a></td><td width="257">Top_K准确率</td></tr><tr><td>‘average_precision’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score">metrics.average_precision_score</a></td><td width="257">平均精确率</td></tr><tr><td>‘neg_brier_score’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss">metrics.brier_score_loss</a></td><td width="257"></td></tr><tr><td>‘f1’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">metrics.f1_score</a></td><td width="257"></td></tr><tr><td>‘f1_micro’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">metrics.f1_score</a></td><td width="257">micro-averaged</td></tr><tr><td>‘f1_macro’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">metrics.f1_score</a></td><td width="257">macro-averaged</td></tr><tr><td>‘f1_weighted’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">metrics.f1_score</a></td><td width="257">weighted average</td></tr><tr><td>‘f1_samples’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">metrics.f1_score</a></td><td width="257">by multilabel sample</td></tr><tr><td>‘neg_log_loss’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss">metrics.log_loss</a></td><td width="257">requires predict_proba support</td></tr><tr><td>‘precision’ etc.</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score">metrics.precision_score</a></td><td width="257">精确率</td></tr><tr><td>‘recall’ etc.</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score">metrics.recall_score</a></td><td width="257">召回率</td></tr><tr><td>‘jaccard’ etc.</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score">metrics.jaccard_score</a></td><td width="257">suffixes apply as with ‘f1’</td></tr><tr><td>‘roc_auc’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">metrics.roc_auc_score</a></td><td width="257"></td></tr><tr><td>‘roc_auc_ovr’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">metrics.roc_auc_score</a></td><td width="257"></td></tr><tr><td>‘roc_auc_ovo’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">metrics.roc_auc_score</a></td><td width="257"></td></tr><tr><td>‘roc_auc_ovr_weighted’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">metrics.roc_auc_score</a></td><td width="257"></td></tr><tr><td>‘roc_auc_ovo_weighted’</td><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">metrics.roc_auc_score</a></td></tr></tbody></table>


### 二分类

- auc 只能用于 二分类 评价
- 分类器只需要计算出预测概率分数，不需要自己设置threshold。 一个threshold会算出一个点，一般会自动尝试所有threshold，最后形成一个曲线。以下就不考虑threshold。
- Auc 变化其实等价于左上角的面积（绿色部分）变化。 这个面积和两类数据的概率分布的重叠面积成正比 （容易分错类的部分）。 根各数据分布的重叠部分成正比。（这个数据不一定是原始数据，而是通过特征工程和模型高纬投影后的，各类数据分布）好的分类器，把两类分的很开，概率分布重叠小，左上面积小，auc大。最坏的情况是随机，概率分布完全重叠，auc是直线。
- ![](https://pic3.zhimg.com/80/v2-ee0d1b124bae822d1e9bb5784d63e051_720w.jpg)
- 转自：知乎[xixihaha912](https://www.zhihu.com/question/39840928/answer/342874215)

可用指标


### 多分类



## 分类报告

分类评估指标报告 包含: `precision`, `recall`, `f1-score`, `support` 四个指标，基本包括了分类需要看到的指标。

### classification_report

classification_report 显示主要分类指标的文本报告

对应函数：

```py
sklearn.metrics.classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False)
```

参数
- `y_true`: 1维数组，或标签指示器数组/稀疏矩阵，**标签值**。 
- `y_pred`: 1维数组，或标签指示器数组/稀疏矩阵，分类器**预测值**。
- `labels`: array，shape = `[n_labels]`，报表中包含的标签索引的可选列表。
- `target_names`: 字符串列表，与标签匹配的可选显示名称（相同顺序）。
- `sample_weight`: 类似于shape = `[n_samples]` 数组，可选项，样本权重。
- `digits`: int，输出浮点值的位数。
 

### 实现


```py
# -*- coding: utf-8 -*-

from sklearn.metrics import classification_report

y_true = ['北京', '上海', '成都', '成都', '上海', '北京', '上海', '成都', '北京', '上海']
y_pred = ['北京', '上海', '成都', '上海', '成都', '成都', '上海', '成都', '北京', '上海']

res = classification_report(y_true, y_pred, target_names=['北京', '上海', '成都']) # 字符串形式
print('字符串形式: ', res)
res = classification_report(y_true, y_pred, target_names=['北京', '上海', '成都'], output_dict=True)
print('字典形式: ', res)
```

输出结果

```sh
字符串形式:
               precision    recall  f1-score   support

          北京       0.75      0.75      0.75         4
          上海       1.00      0.67      0.80         3
          成都       0.50      0.67      0.57         3

    accuracy                           0.70        10
   macro avg       0.75      0.69      0.71        10
weighted avg       0.75      0.70      0.71        10

字典形式:
 {'北京': {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 4.0}, '上海': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3.0}, '成都': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1-score': 0.5714285714285715, 'support': 3.0}, 'accuracy': 0.7, 'macro avg': {'precision': 0.75, 'recall': 0.6944444444444443, 'f1-score': 0.7071428571428572, 'support': 10.0}, 'weighted avg': {'precision': 0.75, 'recall': 0.7, 'f1-score': 0.7114285714285715, 'support': 10.0}}
```

confusion_matrix 方法可输出该多分类问题的混淆矩阵

## 混淆矩阵

混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵

将预测结果和真实结果用混淆矩阵展示，可以用于二分类与多分类。


### Confusion Matrix

`混淆矩阵`（Confusion Matrix），又称为`可能性矩阵`或`错误矩阵`。

混淆矩阵是可视化工具，特别用于监督学习，在无监督学习一般叫做`匹配矩阵`。
- 图像精度评价中，主要用于**比较分类结果和实际测得值**，可以把分类结果的精度显示在一个混淆矩阵里面。

混淆矩阵要表达的含义：
- 混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；
- 每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目；每一列中的数值表示真实数据被预测为该类的数目。

混淆矩阵：

| pred_label/true_label | Positive | Negative |
|:---:|:---:|:---:|
|Positive|TP|FP|
|Negtive|FN|TN|

如上表所示，行表示预测的label值，列表示真实label值。

TP，FP，FN，TN分别表示如下意思：
- `TP`（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；
- `FP`（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；
- `FN`（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；
- `TN`（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.
根据以上几个指标，可以分别计算出Accuracy、Precision、Recall（Sensitivity，SN），Specificity（SP）, [img](https://ask.qcloudimg.com/http-save/yehe-5020298/lf7xwsxhsx.png?imageView2/2/w/1620)
- `Accuracy`：表示预测结果的精确度，预测正确的样本数除以总样本数。
  - $Accuracy＝(TP+TN)/(TP+FP+FN+TN)$
- `Precision`，准确率，表示预测结果中，预测为正样本的样本中，正确预测为正样本的概率；
  - $Precision=TP/(TP+FP)$
- `Recall`，召回率，表示在原始样本的正样本中，最后被正确预测为正样本的概率；
  - $Recall＝TP/(TP+FN)$
- `Specificity`，常常称作特异性，它研究的样本集是原始样本中的负样本，表示的是在这些负样本中最后被正确预测为负样本的概率。

![](https://ask.qcloudimg.com/http-save/yehe-5020298/lf7xwsxhsx.png?imageView2/2/w/1620)

实际中，往往希望得到的 precision和recall都比较高，比如当FN和FP等于0的时候，他们的值都等于1。但是，它们往往在某种情况下是互斥的，比如这种情况，50个正样本，50个负样本，结果全部预测为正，那么它的precision为1而recall却为0.5.所以需要一种折衷的方式，因此就有了F1-score。
- F1-score表示的是precision和recall的调和平均评估指标
  - ![](https://ask.qcloudimg.com/http-save/yehe-5020298/58joe37gx9.png?imageView2/2/w/1620)
- 类似的还有MCC
  - ![](https://ask.qcloudimg.com/http-save/yehe-5020298/qg4ywi3bnj.png?imageView2/2/w/1620)

一张图总结：[img](https://img-blog.csdnimg.cn/20200721143338327.png)
- ![](https://img-blog.csdnimg.cn/20200721143338327.png)

[img](https://pic1.zhimg.com/80/v2-763b2bc2e358ead002eca8d94e104db4_720w.jpg)![](https://pic1.zhimg.com/80/v2-763b2bc2e358ead002eca8d94e104db4_720w.jpg)


[图解](https://www.biaodianfu.com/wp-content/uploads/2020/09/PN.png)
- ![](https://www.biaodianfu.com/wp-content/uploads/2020/09/PN.png)


### sklearn 实现

confusion_matrix 方法可输出该多分类问题的混淆矩阵

对应函数：

```py
sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)
```

参数
- `y_true`: 1维数组，或标签指示器数组/稀疏矩阵，目标值。 
- `y_pred`: 1维数组，或标签指示器数组/稀疏矩阵，分类器返回的估计值。
- `labels`: array，shape = `[n_labels]`，报表中包含的标签索引的可选列表。
- `sample_weight`: 样本权重。

样本不均衡时，如 0占80%，1和-1各占10%，每个类数量差距很大，可选择加入 `sample_weight` 调整样本。
- sample 针对**多标签**分类， 每个样本/实例分别计算p,r,f, 然后求平均。
- [compute_sample_weight 官方介绍](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_sample_weight.html)

```py
from sklearn.metrics import confusion_matrix

y_true = ['北京', '上海', '成都', '成都', '上海', '北京', '上海', '成都', '北京', '上海']
y_pred = ['北京', '上海', '成都', '上海', '成都', '成都', '上海', '成都', '北京', '上海']
res = confusion_matrix(y_true, y_pred, labels = ['北京', '上海', '成都']) # 输出字符串形式
print('混淆矩阵(默认): \n', res)
#  [[2 0 1]
#  [0 3 1]
#  [0 1 2]]

# sklearn compute_sample_weight 函数计算 sample_weight：
from sklearn.utils.class_weight import compute_sample_weight
sw = compute_sample_weight(class_weight='balanced',y=y_true)
print('不均衡权重:\n', sw)
#  [1.11111111 0.83333333 1.11111111 1.11111111 0.83333333 1.11111111
#  0.83333333 1.11111111 1.11111111 0.83333333]

# sw 和 ytrue 同 shape，每个数代表该样本所在的sample_weight。
# 具体计算方法是总样本数/（类数*每个类的个数），比如一个值为-1的样本，它的sample_weight就是300 / (3 * 30)。
cm =confusion_matrix(y_true, y_pred, sample_weight=sw)
print('混淆矩阵(不均衡)\n', cm)
#  [[2.5        0.         0.83333333]
#  [0.         2.22222222 1.11111111]
#  [1.11111111 0.         2.22222222]]
```

进一步把混淆矩阵变成图片

```py
# -*- coding: utf-8 -*-
# author: Jclian91
# place: Daxing Beijing
# time: 2019-11-14 21:52

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import matplotlib as mpl

# 支持中文字体显示, 使用于Mac系统
zhfont=mpl.font_manager.FontProperties(fname="/System/Library/Fonts/STHeiti Light.ttc")

y_true = ['北京', '上海', '成都', '成都', '上海', '北京', '上海', '成都', '北京', '上海']
y_pred = ['北京', '上海', '成都', '上海', '成都', '成都', '上海', '成都', '北京', '上海']

classes = ['北京', '上海', '成都']
confusion = confusion_matrix(y_true, y_pred)

# 绘制热度图
plt.imshow(confusion, cmap=plt.cm.Greens)
indices = range(len(confusion))
plt.xticks(indices, classes, fontproperties=zhfont)
plt.yticks(indices, classes, fontproperties=zhfont)
plt.colorbar()
plt.xlabel('y_pred')
plt.ylabel('y_true')

# 显示数据
for first_index in range(len(confusion)):
  for second_index in range(len(confusion[first_index])):
    plt.text(first_index, second_index, confusion[first_index][second_index])
# 显示图片
plt.show()
```

更多总结

```py
from sklearn.metrics import confusion_matrix
import numpy as np

# 输入示例1: list
y_true=[1,1,0,1,1,0]
y_pred=[0,0,0,0,0,0]
# 输入示例2: np.array
y_true=np.array([1,1,0,1,1,0])
y_pred=np.array([0,0,0,0,0,0])
# 统计数值
print(min(y_pred), max(y_pred), y_pred.min()) # 0 0 0
print(np.unique(y_true)) # [0 1]
print(np.unique(y_pred)) # [0]
print(np.unique(y_pred).size) # 1

print('count: ', np.bincount(y_true)) # count:  [2 4]

C = confusion_matrix(y_true, y_pred)
# 返回 np.array 结构
print(type(C),'\n', C)
# <class 'numpy.ndarray'> 
#  [[2 0]
#  [4 0]]

#------- 另一种导入方式 ---------
from sklearn import metrics

labels1_all_valid = [1,0,0,1]
predict1_all_valid = [1,0,1,1]
confusion_matrix = metrics.confusion_matrix(labels1_all_valid, predict1_all_valid)
print('python list: ', confusion_matrix)

# 字符串类型的标签, 默认按照字母顺序依次编号0~n-1
y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]
y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]
print(set(y_true))
# 设置顺序
C = confusion_matrix(y_true, y_pred, labels=["bird", "cat", "ant"])
print('string + 调整label顺序: ', C)
```

#### 问题

【2024-7-18】报错
- 维度不一致导致错误

```sh
C = confusion_matrix([1,1], [1,1,0])

ValueError: Found input variables with inconsistent numbers of samples: [6, 7]
```

## precision 准确率


precision_score, recall_score, f1_score 有共同参数，以precision为例：

### precision_score

对应函数：

```py
sklearn.metrics.precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)
```

- `y_true`：1维数组，或标签指示器数组/稀疏矩阵，目标值。 
- `y_pred`：1维数组，或标签指示器数组/稀疏矩阵，分类器返回的估计值。
- `labels`：array，shape = `[n_labels]`，报表中包含的标签索引的可选列表。
- `pos_label`：对二分类有用，一般不用管。
- `average`：可选 None, ‘binary’ (default), ‘micro’, ‘macro’, ‘samples’, ‘weighted’。
  - 'binary' 为二分类； 
  - ‘micro’, ‘macro’, ‘weighted’ 可用于多分类
  - `micro`: 所有的类放在一起算，具体到precision，就是把所有类的TP加和，再除以所有类的TP和FN的加和
    - micro 下, precision 和 recall 都等于accuracy
  - `macro`: 先分别求出每个类的precision再算术平均。
  - `weighted`: `macro` 改良版，不再是取算术平均、乘以固定weight（1/3）了，而是乘以该类占比。



### 代码实现

```py
from sklearn.metrics import precision_score,recall_score,f1_score

y_true=['a','b','c','a','b']
y_pre=['b','b','c','a','b']

target_names=['class_a','class_b','class_c']

from sklearn.metrics import precision_score
precision_score(y_true, y_pred, average="micro") # 0.6333333333333333
precision_score(y_true, y_pred, average="macro") # 0.46060606060606063
precision_score(y_true, y_pred, average="weighted") # 0.7781818181818182

print(precision_score(y_true,y_pre))
print(recall_score(y_true,y_pre))
print(f1_score(y_true,y_pre))

'''
结果：
[[1 1 0]
 [0 2 0]
 [0 0 1]]
'''
```

## recall 召回率


## PR曲线

P-R曲线中，P为[图](https://img-blog.csdn.net/20180715110420551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxOTk0MDA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)中precision，即精准度，R为图中recall，即召回率。

![](https://img-blog.csdn.net/20180715110420551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxOTk0MDA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

AP的计算，此处参考的是PASCAL  VOC  CHALLENGE的2010年之前计算方法。首先设定一组阈值，[0, 0.1, 0.2, …, 1]。然后对于recall大于每一个阈值（比如recall>0.3），我们都会得到一个对应的最大precision。这样，我们就计算出了11个precision。AP即为这11个precision的平均值。这种方法英文叫做11-point interpolated average precision。​

## AP/mAP

[原文链接](https://blog.csdn.net/qq_41994006/article/details/81051150)

【2023-4-11】[目标检测中的“神奇指南”——平均精度（mAP）](https://baijiahao.baidu.com/s?id=1762496869648133227&wfr=spider&for=pc)

`AP`值的计算需要一系列指标做铺垫，涉及的名词：
- （1）IOU：IOU是一个比值，是预测框与实际框的相交部分与两者全部面积的比值；
- （2）TP：被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数；
- （3）FP：被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；
- （4）FN：被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；
- （5）TN：被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。

IOU是预测边界框和参考边界框的交集和并集之间的比率，利用这个比值，可以知晓每个检测结果的正确性。
- 将IOU与阈值进行比较，最常用的阈值是0.5，如果 IoU > 0.5，那么认为这是一个正确检测，否则认为这是一错误的检测。

`mAP`作为预测目标位置及类别类算法的性能度量指标，对评估目标定位模型、目标检测模型以及实例分割模型非常有用。
- 计算出所有检测框的IOU值，求解其P与R，最终得出mAP值，利用这些平均精度值，便可以轻松地判断模型对任何给定类别的性能。


## F 指标

Fbeta-measure 是一种可配置的单分指标，用于根据对正类的预测来评估二元分类模型

### F1

P和R同等重要

```sh
F-Measure = ((1 + 1^2) * Precision * Recall) / (1^2 * Precision + Recall)
F-Measure = (2 * Precision * Recall) / (Precision + Recall)
```

代码计算方式

```py
from sklearn.metrics import fbeta_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# perfect precision, 50% recall
y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
p = precision_score(y_true, y_pred)
r = recall_score(y_true, y_pred)
f = fbeta_score(y_true, y_pred, beta=0.5)
print('Result: p=%.3f, r=%.3f, f=%.3f' % (p, r, f))
```


### F_beta

Fbeta 是 F 的抽象，**调和均值计算**中的精度和召回率的平衡, 由beta系数控制。

```sh
Fbeta = ((1 + beta^2) * Precision * Recall) / (beta^2 * Precision + Recall)
```

beta 参数用于 Fbeta-measure。
- beta=2, 称为 F2-measure 或 F2-score。
- beta=1, 称为 F1-measure 或 F1-score

beta 参数的三个常见值：
- `F0.5-Measure` (beta=0.5)：精度上的权重更大，召回的权重更小。
- `F1-Measure` (beta=1.0)：平衡准确率和召回率的权重。
- `F2-Measure` (beta=2.0)：精度权重较小，召回权重较大

```py
from sklearn.metrics import fbeta_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# perfect precision, 50% recall
y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
p = precision_score(y_true, y_pred)
r = recall_score(y_true, y_pred)
f = fbeta_score(y_true, y_pred, beta=1.0) # beta=1
f = fbeta_score(y_true, y_pred, beta=2.0) # beta=2
print('Result: p=%.3f, r=%.3f, f=%.3f' % (p, r, f))
```


## AUC


## 多分类

- 【2021-8-6】[多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨](https://zhuanlan.zhihu.com/p/147663370)
- 具体场景（如不均衡多分类）中到底应该以哪种指标为主要参考呢？
- 多分类模型和二分类模型的评价指标有啥区别？
- 多分类问题中
  - 为什么 Accuracy = micro precision = micro recall = micro F1-score? 
  - 什么时候用 macro, weighted, micro precision/ recall/ F1-score?

Accuracy 是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，对于**不平衡**数据集而言，Accuracy并不是一个好指标。如100张图片中91张图片是「狗」，5张是「猫」，4张是「猪」，训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是**大多数**类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score（如91%）。此时，虽然Accuracy Score很高，但是**意义不大**。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。因此需要引入`Precision` （精准度），`Recall` （召回率）和`F1-score`评估指标。考虑到二分类和多分类模型中，评估指标的计算方法略有不同

在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。
- ![](https://pic4.zhimg.com/80/v2-e1cf922d05b7e1bf266620577e6fd253_720w.jpg)
- 混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要**单独**计算其Precision和Recall。

如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（也可参考[scikit-learn官网](https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)）


### 总结

[How to avoid machine learning pitfalls: a guide for academic researchers](https://arxiv.org/abs/2108.02497)
- 不要对不平衡的数据集使用准确度（accuracy）指标。这个指标常用于分类模型，不平衡数据集应采用**kappa系数**或**马修斯相关系数**（MCC）指标。

### kappa系数

【2021-9-13】[kappa系数简介](https://zhuanlan.zhihu.com/p/67844308)

Kappa系数是一个用于一致性检验的指标，也可以用于衡量分类的效果。因为对于分类问题，所谓一致性就是模型预测结果和实际分类结果是否一致。kappa系数的计算是基于混淆矩阵的，取值为-1到1之间,通常大于0。可分为五组来表示不同级别的一致性：
- 0.0~0.20 **极低**的一致性(slight)
- 0.21~0.40 **一般**的一致性(fair)
- 0.41~0.60 **中等**的一致性(moderate)
- 0.61~0.80 **高度**的一致性(substantial)
- 0.81~1 几乎**完全一致**(almost perfect)

基于混淆矩阵的kappa系数计算公式如下：
- ![](https://www.zhihu.com/equation?tex=kappa+%3D+%5Cfrac%7Bp_o-p_e%7D%7B1-p_e%7D+)
- 其中，p0=对角线元素之和/矩阵所有元素之和，及acc，pe是所有类别分别对应的“实际与预测数量的乘积”之总和，除以“样本总数的平方”

对于不均衡数据集，acc失灵，所以用kappa系数，惩罚模型“偏向性”的指标来代替acc。而根据kappa的计算公式，越不平衡的混淆矩阵，pe越高，kappa值就越低，正好能够给“偏向性”强的模型打低分。



代码：
```python
import numpy as np
 
# 计算混淆矩阵的kappa
def kappa(confusion_matrix):
    pe_rows = np.sum(confusion_matrix, axis=0)
    pe_cols = np.sum(confusion_matrix, axis=1)
    sum_total = sum(pe_cols)
    pe = np.dot(pe_rows, pe_cols) / float(sum_total ** 2)
    po = np.trace(confusion_matrix) / float(sum_total)
    return (po - pe) / (1 - pe)
# 无偏向的混淆矩阵
balance_matrix = np.array(
    [
        [2,  1,  1],
        [1,  2,  1],
        [1,  1,  2]
    ]
)
# 有偏向的混淆矩阵
unbalance_matrix = np.array(
    [
        [0,  0,  3],
        [0,  0,  3],
        [0,  0,  6]
    ]
)
kappa_balance = kappa(balance_matrix)
print("kappa for balance matrix: %s" % kappa_balance)

kappa_unbalance = kappa(unbalance_matrix)
print("kappa for unbalance matrix: %s" % kappa_unbalance)
kappa for balance matrix: 0.25
kappa for unbalance matrix: 0.0

# --------- sklearn ----------
#sklearn计算kappa
from sklearn.metrics import cohen_kappa_score
y_true = [2, 0, 2, 2, 0, 1]
y_pred = [0, 0, 2, 2, 0, 2]
kappa_value = cohen_kappa_score(y_true, y_pred)
print("kappa值为 %f" % kappa_value)
# kappa值为 0.428571
# --------- tensorflow ------------
# tensorflow计算kappa
import tensorflow as tf

y_t = tf.constant(y_true)
y_p = tf.constant(y_pred)
kappa, update = tf.contrib.metrics.cohen_kappa(y_t, y_p, 3)
with tf.Session() as sess:
    sess.run(tf.local_variables_initializer())
    print(kappa.eval(), update.eval())
    print(kappa.eval(), update.eval())

```

### MCC系数

马修斯相关系数（MCC）是机器学习中衡量二分类的分类性能的指标。该指标考虑了真阳性、真阴性和假阳性和假阴性，通常认为该指标是一个比较均衡的指标，即使是在两类别的样本失衡时，也可以应用它。MCC本质上是一个描述实际分类与预测分类之间的相关系数，它的取值范围为
- 1时表示对受试对象的完美预测
- 0时表示预测的结果还不如随机预测的结果
- -1是指预测分类和实际分类完全不一致

[MCC介绍](https://blog.csdn.net/gaomeihong1993/article/details/96979986)

代码：

```python
import pandas as pd
from math import sqrt

def get_data():
    df = pd.read_csv('data.csv')
    TP = df.iloc[0]["zero"]
    FP = df.iloc[1]["zero"]
    FN = df.iloc[0]["one"]
    TN = df.iloc[1]["one"]
    return TP,FP,FN,TN

def calculate_data(TP,FP,FN,TN):
    numerator = (TP * TN) - (FP * FN) #马修斯相关系数公式分子部分
    denominator = sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) #马修斯相关系数公式分母部分
    result = numerator/denominator
    return result

if __name__ == '__main__':
  # ----- 自定义 -------
  TP,FP,FN,TN = get_data()
  result = calculate_data(TP,FP,FN,TN)
  print(result) #打印出结果
  # ------- sklearn --------
  from sklearn.metrics import matthews_corrcoef
  y_true = [+1, +1, +1, -1]
  y_pred = [+1, -1, +1, +1]
  matthews_corrcoef(y_true, y_pred)
```


### Macro-average方法
    
 
该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求**平均**，给所有类别**相同权重**。该方法能够平等看待每个类别，但是它的值会受稀有类别影响。
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Precision%7D+%3D+%5Cfrac%7B%7BP%7D_%7Bcat%7D+%2BP_%7Bdog%7D++%2BP_%7Bpig%7D+%7D%7B3%7D+%3D+0.5194)
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Recall%7D+%3D+%5Cfrac%7BR_%7Bcat%7D+%2B+R_%7Bdog%7D++%2BR_%7Bpig%7D+%7D%7B3%7D+%3D+0.5898)
 
### Weighted-average方法
 
该方法给不同类别**不同权重**（权重根据该类别的**真实分布**比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BW%7D_%7Bcat%7D+%3A+%5Ctext%7BW%7D_%7Bdog%7D+%3A+%5Ctext%7BW%7D_%7Bpig%7D+%3D+%5Ctext%7BN%7D_%7Bcat%7D+%3A+%5Ctext%7BN%7D_%7Bdog%7D+%3A%5Ctext%7BN%7D_%7Bpig%7D++%3D+%5Cfrac%7B7%7D%7B26%7D+%3A+%5Cfrac%7B16%7D%7B26%7D%3A+%5Cfrac%7B3%7D%7B26%7D) (W代表权重，N代表样本在该类别下的真实数目)
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Precision%7D+%3D+%7BP%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BP%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BP%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.6314)
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Recall%7D+%3D+%7BR%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BR%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BR%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.5577)
 
### Micro-average方法
 
该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFP%7D_%7Bcat%7D+%2B+%7BFP%7D_%7Bdog%7D+%2B+%7BFP%7D_%7Bpig%7D%7D+%3D+0.5577+)
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Recall%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFN%7D_%7Bcat%7D+%2B+%7BFN%7D_%7Bdog%7D+%2B+%7BFN%7D_%7Bpig%7D%7D%3D0.5577)

其中，特别有意思的是，**Micro-precision和Micro-recall竟然始终相同**！这是为啥呢？
 
这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-**precision**和Micro-**recall**的数值都等于**Accuracy**，因为它们计算了对角线样本数和总样本数的比值，总结就是：
- ![[公式]](https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Ctext%7BMicro-Recall%7D+%3D+%5Ctext%7BMicro-F1+score%7D+%3D+%5Ctext%7BAccuracy%7D+)

代码

```python
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score

# create confusion matrix
y_true = np.array([-1]*70 + [0]*160 + [1]*30)
y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + 
                  [-1]*30 + [0]*80 + [1]*30 + 
                  [-1]*5 + [0]*15 + [1]*20)
cm = confusion_matrix(y_true, y_pred)
conf_matrix = pd.DataFrame(cm, index=['Cat','Dog','Pig'], columns=['Cat','Dog','Pig'])

# plot size setting
fig, ax = plt.subplots(figsize = (4.5,3.5))
sns.heatmap(conf_matrix, annot=True, annot_kws={"size": 19}, cmap="Blues")
plt.ylabel('True label', fontsize=18)
plt.xlabel('Predicted label', fontsize=18)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.savefig('confusion.pdf', bbox_inches='tight')
plt.show()
```


# 评分方法

## Elo机制

【2023-5-26】[什么才是真正的Elo机制](https://zhuanlan.zhihu.com/p/447810763)

### 什么是Elo？

`Elo` Rating System 是由匈牙利裔美国物理学家 `Arpad Elo` 创建的一个衡量各类**对弈活动**水平的评价方法，是当今对弈水平评估的公认的权威方法。
- 被广泛用于`博弈类`比赛，`国际象棋`、`围棋`、`足球`、`篮球`等运动。网络游戏`英雄联盟`、`魔兽世界`内的竞技对战系统也采用此分级制度。
- 电影 《社交网络》中 , 创办了 Facebook 的 `Mark Zuckerberg` 和 `Eduardo Saverin` 在 Harvard 读大二时， 一夜间搭建了网站 `Facemash`。这个网站每次会展示两张不同女生的照片，用户选择自己认为更好看的一张。每次选择后，便进入下一组女生照片的评选。最终， Facemash 将计算出全校女生的长相排名。这其中所用的算法，就是 `Elo Rating System`。

Elo不是游戏首创，在体育竞技中十分常见。篮球、乒乓球、围棋、国际象棋等等，都会使用Elo来衡量运动员的水平。
- 系统基于统计学, 只是一种参考，并不能**绝对**衡量出运动员实力。
  - 体育竞技本身就是一种十分复杂的游戏，一场比赛的输赢受到许多因素的影响，运动员的状态、运气、心理素质、场地氛围等等，都可能左右一场比赛。
- 设计之初，Elo Rating System 仅是一个国际象棋选手的排名系统。
  - Elo 成为公认最权威的方法，是因为<span style='color:blue'>比之前所有评分系统都先进</span>，更容易准确反应一个选手的真实水平。
  - 1970年，国际棋联正式开始使用这个评分系统。
  - Elo遭1V1对抗时用的最多，预测多人对抗游戏并不是它的强项

### Elo 原理

Elo评级系统是如何运行的呢？

Elo 用一个**数字**来衡量运动员的水平，每场比赛结束后，**赢家**会从**输家**那里获得积分。两名运动员之间的**积分差异**决定一场比赛后，获得或者失去的积分。
- 如果评分**高**的运动员获胜，那么只会从评分低的运动员那里，获得**一点点**积分。
- 相反 如果评分**低**的运动员爆冷，就会抢走评分高的运动员**大量**积分。
- 如果平局，评分**低**的运动员，同样会抢走评分低的运动员**一定**的积分。

注意
- <span style='color:blue'>只要运动员的场次**足够多**，Elo就会真实地反应出运动员的真实水平</span>。

如何实现对象的评价和排名 
- Elo假设每个玩家在每盘游戏中的表现是一个`正态分布`的随机变量
- 尽管选手在不同的游戏中发挥可能差异很大，但每位选手在一段时间内表现的平均值变化很小。
- Elo用随机变量的平均值来代表选手的真正水平。
- 简单的说：每个选手在每盘游戏中的发挥都是不稳定的，80的实力可能发挥出85，或者发挥出75， 但是随着比赛的不断进行，可以越来越多的趋近80这个真实水准。而ELO是用这个平均值来作为真实水准

假设: [ELO算法的原理及应用](https://zhuanlan.zhihu.com/p/57480433)
> 一名选手当前实力受各种因素的影响, 在一定范围内波动，某个时刻用来描述其实力的函数应当符合`正态分布`

两名选手进行对战时的预期胜率
- ![](https://abcdxyzk.github.io/images/alg/20220828-12.png)
- D为两者的分差。

利用了最小二乘法，得到与它的函数图向相近的另外的一个函数
- ![](https://abcdxyzk.github.io/images/alg/20220828-13.png)

当玩家A与玩家B的分差为D时，玩家A对玩家B的期望胜率为P(D)
- ![](https://abcdxyzk.github.io/images/alg/20220828-14.jpg)
- 玩家分数相同时，对战预期胜率为50%，分差越大，玩家之间的胜率差距也就越大，当分差大于400时，低分玩家的预期胜率将不足10%。
- ![](https://abcdxyzk.github.io/images/alg/20220828-17.jpg)
- 取K=32时，玩家结束一场比赛后的实际得分数如图所示。可以看到玩家战胜比自己低800分的选手后（有近100%的胜率）基本不得分。

Elo 用一个数字衡量运动员水平，每场比赛结束后，赢家会从输家那里获得积分。
- 两名运动员之间的积分差异，决定一场比赛后，获得或者失去的积分。
- 如果评分高的运动员获胜，那么只会从评分低的运动员那里，获得**一点点积分**。
- 相反，如果评分低的运动员**爆冷**，就会**抢走**评分高的运动员大量积分。
- 如果平局，评分低的运动员，同样会抢走评分低的运动员一定的积分。

只要运动员的场次足够多，Elo就会真实地反应出运动员的真实水平。

```sh
Ra: A选手当前分数
Rb: B选手当前分数

# Ea: 预期A选手的胜负值
Ea = 1/(1+10^[(Rb-Ra)/400])

# Eb: 预期B选手的胜负值
Eb = 1/(1+10^[(Ra-Rb)/400])

E值也是预估的双方胜率，所以 Ea + Eb = 1

Sa: 实际胜负值，胜 = 1， 平 = 0.5， 负 = 0
K： 每场比赛能得到的最大分数，魔兽里 k=32 

R'a: A选手一场比赛之后的积分
R'a = Ra + K(Sa-Ea)

R'b: B选手一场比赛之后的积分
R'b = Rb + K(Sa-Eb)
```

举例

```
A队1500分，B队1600分，则
预估A队的胜负值 Ea = 1/(1+10^[(1600-1500)/400]) = 0.36
预估B队的胜负值 Eb = 1/(1+10^[(1500-1600)/400]) = 0.64

假设A队赢了，
A队最终得分为 R'a = 1500 + 32*(1-0.36) = 1500+20.5 = 1520, 赢20分，B队输20分。
假设B队赢了，
B队最终得分为 R'b = 1600 + 32*(1-0.64) = 1600 + 11.52 = 1612, 赢12分，A队输12分。

这就是为什么你赢高分队分数多，输给低分的输的也多，赢低分的分数很少。
其实K值就是这个方程的极限，所以理论上你最多可以赢一个队伍32分，实际上29-30已经差不多了，赢了不得分也是有可能的。
```

但是，Elo评分系统基于统计学，只是一种参考，并不能绝对衡量出运动员的实力。
- 体育竞技本身就是一种十分复杂的游戏，一场比赛的输赢受到许多因素的影响，运动员的状态、运气、心理素质、场地氛围等等，都可能左右一场比赛。
- 电竞是Elo应用最广泛的领域. CSGO、守望先锋、魔兽世界都采用Elo机制，或者Elo机制的升级版-Glicko-2

Elo之所以能成为公认**最权威**的方法，是因为它比之前所有的评分系统都**先进**，更容易更准确反应一个选手的真实水平。
- 1970年，国际棋联正式开始使用这个评分系统。

Elo遭1V1对抗时用的最多，预测**多人对抗**游戏并不是强项。

Elo 会赋予每位玩家一个相同的**初始积分**，并进行以下计算：
1. 根据**积分差**计算双方获胜概率； 
2. 每位玩家根据对方积分和游戏结果所表现出的水平分；
3. 得出游戏后的积分变化。

Elo 工作模式总结：
1. Elo 会给出玩家一场对局的获胜概率。Elo 积分相差越大，积分高的一方获胜概率就越大；
2. 每场对局后，对阵双方都会进行一部分积分交换，胜者得分，败者失分；
3. 如果两名玩家的积分相差很大，代表高分方获胜的概率极大，因此 即便赢了也涨不了多少分，败方也掉不了多少分。但倘若被低分方爆出冷门，那高分 方将失去大量分数。

### Elo缺点

Elo Rating System 的缺点

任何算法系统都有优缺点，Elo 也不例外。
- 初期的盲目性
  - Elo 积分在达到合理（趋近真实）水平之前需要一个过程。比如一个 2000 分的玩家玩小号，遇到的对手大概都是 1400 分水平，这时候 Elo 积分是不能准 确反映他的实力的。经过几局对战，这名玩家的积分会逐渐达到合理水平。这个 过程就是 Elo 积分的收敛过程。
- 对时间不敏感
  - Elo 积分不会随着时间变化，当一位玩家很长时间没有游戏的时候，他的水 平可能会上下浮动，但他的 Elo 积分并不会随之改变。尤其对于顶尖玩家而言， 这时候的积分排名未必能反映玩家间真实的实力排名。


### Elo 改进

Elo本来是一个好东西，但是游戏厂家一般都会对Elo进行魔改，这也是不同游戏，玩家对elo感知不同的原因。改得不好，简直就是一场灾难。

Elo 初次进入玩家视野，是王者荣耀策划 Donny 2018年在微博上发的一条关于匹配机制的解释。
- ![](https://pic4.zhimg.com/80/v2-552f4bfd98743edf87e63b88dc9a76ab_1440w.webp)

关键点：
1. 段位和Elo值共同决定匹配对手和队友；
2. 如果等待时间过长，则放大Elo的寻找范围；
3. 利用勇者积分机制，让玩家快速达到真实实力所在段位；

这些都是体育竞技中的Elo所没有的。因为这些特别的规则，玩家一些现象很容易解释，比如：
- 王者荣耀中，为什么王者局，可以匹配到星耀2（星耀晋级后是王者段位）的玩家，这时因为这名星耀2玩家的Elo太高，已经达到了最强王者段位的水平。反之，最强王者匹配到星耀局，说明 Elo太低了。
- 如此一来，又会出现一些问题。星耀2玩家因为Elo分数高去打王者局，在其他玩家实力大致相当的前提下，如果这名玩家实力是荣耀王者（最强王者50星），那么对手很容易被碾压。如果这名玩家是靠运气连胜导致Elo分数太高，又会成为队伍的累赘。

事实证明，<span style='color:green'>双方实力大致相当的对局非常少</span>。因为这名玩家需要足够多的场次，Elo值才能真实反应他的水平，而且即便如此，也不能排除他心情好，练一把英雄的情况……

再比如强行将**匹配时长**加入Elo机制中。
- 玩家匹配等待时间过长，则放大Elo的寻找范围。

换句话说，假设9名最强王者玩家的Elo值都是1500分左右，但此时死活就是找不到一个1500分左右的最强王者玩家，那么系统就会扩大范围，强行匹配一个Elo 1600分，或者Elo 1400分的玩家。毫无疑问，出现这种情况，对局本身就不是公平的，更没有50%的胜率可言。

电竞中的Elo算法最大的问题是: 不能保证双方玩家的水平相当。
- 对方70%能赢，己方30%能赢，结果阵容怎么好，英雄理解怎么到位，操作怎么溜，就是有一个坑货，怎么都赢不了。

关于Elo的错误认识。
- 强行50%胜率
- 拿败方MVP下把容易输
- 隐藏分很高，下局逆风局
- 连胜后必定连跪

换一种算法，是否能避免这种现象的出现？
- 答案是不能，但可能减少。不能避免，是因为你总有达到属于自己实力段位的时候，总有运气爆棚连胜的时候，也会有运气差的时候。只要有一种算法，能保证双方在选阵容前，胜率是50%，双方水平相当，这种现象就会减少。

[让我来告诉你，什么才是真正的Elo机制](https://zhuanlan.zhihu.com/p/447810763)

### Elo 实践

【2023-8-4】Elo Python实践代码
- [gpt_prompt_engineer.ipynb](https://github.com/mshumer/gpt-prompt-engineer/blob/main/gpt_prompt_engineer.ipynb)

```py
def expected_score(r1, r2):
    return 1 / (1 + 10**((r2 - r1) / 400))

def update_elo(r1, r2, score1):
    e1 = expected_score(r1, r2)
    e2 = expected_score(r2, r1)
    return r1 + K * (score1 - e1), r2 + K * ((1 - score1) - e2)

# K is a constant factor that determines how much ratings change
K = 32
# Convert scores to numeric values
score1 = 1 if score1 == 'A' else 0 if score1 == 'B' else 0.5
score2 = 1 if score2 == 'B' else 0 if score2 == 'A' else 0.5

# Average the scores
score = (score1 + score2) / 2

# Update ELO ratings
r1, r2 = prompt_ratings[prompt1], prompt_ratings[prompt2]
r1, r2 = update_elo(r1, r2, score)
```


## 评分卡

- KDD的2019年会上，俄罗斯联邦储蓄银行（Sberbank）发布的论文《[E.T.-RNN: Applying Deep Learning to Credit Loan Applications](https://www.kdd.org/kdd2019/accepted-papers/view/e.t.-rnn-applying-deep-learning-to-credit-loan-applications)》，这是一篇将深度学习应用于风控领域的一个不错的探索
  - 传统**评分卡**方法: 信用评分是银行业务基础指标，经典的信用评分方法基于用户的申请单信息，用户的信用历史和其他关联的金融信息。传统的评分卡多采用经典的机器学习算法比如逻辑回归，GBDT，LighgtGBM等算法预测用户的贷后表现。
  - 尽管经典机器学习算法广泛应用且效果不错，但有以下不足：
    - 需要大量的特征工程工作和行业领域知识
    - 对于白户（无信用历史）的用户，很难给定评分
    - 传统算法模型没有充分利用用户数据
  - 论文提出了一种基于深度学习的评分卡算法，该方法基于到户交易数据利用RNN模型预测申请贷款用户的信用分。算法名称**ETRNN**全称Embedding Transactional Recurrent Neural Network，主要是利用用户的借记卡和信用卡的交易数据，只要用户有信用卡或者借记卡，就可以利用该方法。与传统的信用评分方法相比，ETRNN算法有以下有点：
    - 首先该方法效果超过了传统的方法。
    - 该方法基于用户的交易数据，不需要大量的特征工程方法和领域知识。
    - 该方法并部需要申请人除交易数据之外的其他数据，这意味着可以快速授信，改善用户体验。
    - 用户交易数据很难仿造。
    - 即使白户也可以利用交易数据评分。
  - 传统的评分卡方法，往往是对用户的交易流水历史做一些聚合，得到一些特征；而深度学习方法直接利用用户的交易流水数据，更好的利用用户消费的时序信息。

### 什么是信用评分卡模型？

- 【2021-7-27】[风险控制：信用评分卡模型](https://www.biaodianfu.com/credit-score.html)

**评分卡模型**又叫做**信用评分卡模型**，最早由美国信用评分巨头**FICO公司**于20世纪60年代推出，在信用风险评估以及金融风险控制领域中广泛使用。银行利用评分卡模型对客户的信用历史数据的多个特征进行打分，得到不同等级的信用评分，从而判断客户的优质程度，据此决定是否准予授信以及授信的额度和利率。相较资深从业人员依靠自身的经验设置的专家规则，评分卡模型的使用具有很明显的优点：
- 判断快速：系统只需要按照评分卡逐项打分，最后通过相应的公式计算出总分，即可准确判断出是否为客户授信以及额度和利率。
- 客观透明：评分卡模型的标准是统一的，无论是客户还是风险审核人员，都可以通过评分卡一眼看出评分结果和评判依据。
- 应用范围广：由于评分卡的评分项是客观计算，其得出的分数具有广泛的参考性和适用性。例如，生活中常见的支付宝芝麻信用分，就是依据评分卡模型计算得出。

[图](https://www.biaodianfu.com/wp-content/uploads/2021/01/credit-score.png)

![](https://www.biaodianfu.com/wp-content/uploads/2021/01/credit-score.png)

评分卡模型在银行不同的业务阶段体现的方式和功能也不一样。按照借贷用户的借贷时间，评分卡模型可以划分为以下三种：
- **贷前**：**申请**评分卡（Application score card），又称为`A卡`
  - 更准确地评估申请人的未来表现(违约率)，降低坏帐率
  - 加快(自动化)审批流程, 降低营运成本
  - 增加审批决策的客观性和一致性，提高客户满意度
- **贷中**：**行为**评分卡（Behavior score card），又称为`B卡`
  - 更好的客户管理策略, 提高赢利
  - 减少好客户的流失
  - 对可能拖欠的客户，提早预警
- **贷后**：**催收**评分卡（Collection score card），又称为`C卡`
  - 优化催收策略，提高欠帐的回收率
  - 减少不必要的催收行为，降低营运成本

评分卡模型示例： [图](https://www.biaodianfu.com/wp-content/uploads/2021/01/credit-score-example.png)
![](https://www.biaodianfu.com/wp-content/uploads/2021/01/credit-score-example.png)

一个用户总的评分等于基准分加上对客户各个属性的评分。举个例子某客户年龄为27岁，性别为男，婚姻状况为已婚，学历为本科，月收入为10000，那么他的评分为：223+8+4+8+8+13=264


### 评分效果评估

专家训练场的评估分为三段：房源自述、小贝问答、推荐房源。最终的评分结果根据上述三个部分加权得到，现阶段没有完整数据可以标注，需要对各个阶段先进行评估，确保各阶段的评估合理。其中，推荐房源可以根据经纪人推荐的房源和系统候选房源进行对比，这个指标不需要评估，另外两个指标涉及意图识别及加权策略，需要进行评估。

评估使用基于pair-wise的方式，通过分析对比结果与评分之间的关系得出评估是否合理：
- 如果相对好的数据评分相对高，则评价合理
- 如果相对好的数据评分相对低，则评价不合理

文本为VR带看经纪人训练场中经纪人的文本，标注目标为标注文本A相对于文本B的好坏程度，数字的含义如下：
- -2（很差），-1（较差），0（差不多），1（较好），2（很好）

标注的数据有两个部分：
- （1）房源自述，对应的title为narrate，比较的时候参考以下标准：
  - 基础素质（讲解房源、小区、配套等）
- （2）小贝问答，对应的title为show，比较的时候参考以下标准：
  - 服务态度（标注开场白、结束语等）
  - 需求理解与挖掘（理解客户需求，挖掘客户需求，比如购房意愿、金额等）

评分结果的验证分为以下几个方面：
- （1）分数**分布**验证，检验是否为正态分布。如VR带看里，房源自述+小贝问答两种语料，检查概率分布
- （2）**一致性**检验，即**定性**检验，检查标注的好坏是否与分差保持一致
  - 例如：文本A相对于文本B是1，文本A的分数是90，文本B是80，因为90 > 80，所以这条数据是通过一致性检验的。
  - 房源自述和小贝问答的一致率均大于 90%，说明一致率很高，简单理解评分的好坏准确率为90%以上。
- （3）**分值**检验，即**定量**检验，检查标注的好坏程度是否与分差保持正比关系
  - 如果标注结果与**分差**正相关，那么打分的结果是比较合理的。
  - 例如：标注结果为文本A1相对于文本B1是1，实际分差为10分，标注结果为文本A2相对于文本B2是2，实际分差为20分，标注结果与分差是正相关的，说明评分的分数合理。

- [参考](https://wiki.lianjia.com/pages/viewpage.action?pageId=711844107)


### 评分卡模型

如何搭信用评分卡模型？有了上面的评分卡示例，接下来需要考虑的是如何生成类似上面的表格：
- 变量特征是如何选取的？
  - 剔除跟目标变量不太相关的特征, 涉及：变量两两**相关性**分析, 变量的**多重共线性**分析
  - 消除由于线性相关的变量，避免特征冗余
  - 减轻后期验证、部署、监控的负担
  - 保证变量的可解释性
- 特征的变量范围是如何进行划分的？对变量进行分箱来实现变量的分段
  - 分箱的定义：①对连续变量进行分段离散化②将多状态的离散变量进行合并，减少离散变量的状态数
  - 常见的分箱类型：
    - ①无监督分箱。 无监督分箱仅仅考虑了各个变量自身的数据结构，并没有考虑自变量与目标变量之间的关系，因此无监督分箱不一定会带来模型性能的提升。
      - 等频分箱：把自变量按从小到大的顺序排列，根据自变量的个数等分为k部分，每部分作为一个分箱。
      - 等距分箱：把自变量按从小到大的顺序排列，将自变量的取值范围分为k个等距的区间，每个区间作为一个分箱。
      - 聚类分箱：用k-means聚类法将自变量聚为k类，但在聚类过程中需要保证分箱的有序性。
    - ②有监督分箱，包括 Split 分箱和 Merge 分箱
      - Split 分箱是一种自上而下(即基于分裂)的数据分段方法。Split 分箱和决策树比较相似，切分点的选择指标主要有 Entropy，Gini 指数和 IV 值等。
      - Merge 分箱，是一种自底向上(即基于合并)的数据离散化方法。Merge 分箱常见的类型为Chimerge分箱。
    - ③ChiMerge 分箱
      - ChiMerge 分箱是目前最流行的分箱方式之一，其基本思想是如果两个相邻的区间具有类似的类分布，则这两个区间合并；否则，它们应保持分开。Chimerge通常采用卡方值来衡量两相邻区间的类分布情况。
- 每个字段的分值是如何设定的？

变量选择方法: 更多方法请参考：[机器学习之特征选择方法](https://www.biaodianfu.com/feature-selection.html) [图](https://www.biaodianfu.com/wp-content/uploads/2021/01/features-768x775.png)
![](https://www.biaodianfu.com/wp-content/uploads/2021/01/features-768x775.png)

- 【2021-7-27】[风险控制：信用评分卡模型](https://www.biaodianfu.com/credit-score.html)

- 【2021-3-21】[深入浅出评分卡的逻辑回归原理](https://zhuanlan.zhihu.com/p/104599677)
- 信贷评分卡的建模过程中，使用最多的算法就是逻辑回归（logistics regression）函数。下面，我们将围绕下面几点详细地讲述逻辑回归的数学来源和业务用途：
  - 什么是逻辑回归函数?
    - ![](https://pic1.zhimg.com/80/v2-036cc92debe28b75c8d4f5d093a9a8e0_1440w.jpg)
  - 为什么评分卡要使用逻辑回归函数？
  - 经济意义下逻辑回归函数的由来？（从金融角度揭示）
  - 怎么产生标准评分卡？（评分卡分数的线性转换）
    - 模型最终的产出还得是分数，上述的 s(x) 为对数比率分数，想要转化为千分制的分数还必须进行分数线性转化：![](https://www.zhihu.com/equation?tex=S_%7Bscale%7D%3Da%2Bb%2AS_%7BlogOdds%7D)
    - 以下2个假设用于定义分数刻度：
      - log 比率为 1:1的时候，分数为500分；![](https://www.zhihu.com/equation?tex=500%3Da%2Bb%2Aln%281%29)
      - 好坏比（odds)每增加一倍，分数增加20分。![](https://www.zhihu.com/equation?tex=520%3Da%2Bb%2Aln%282%29)
    - 解出![](https://www.zhihu.com/equation?tex=a%3D500%2Cb%3D20%2Fln2)，所以![](https://www.zhihu.com/equation?tex=S_%7Bscale%7D%3D500%2B%2820%2Fln2%29%2AS_%7BlogOdds%7D)![](https://www.zhihu.com/equation?tex=%5CRightarrow+S_%7Bscale%7D%3D500%2B%2820%2Fln2%29%2A%28a%2B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bw%28x_%7Bi%7D%29%7D%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5Cfrac%7B500%7D%7Bn%7D%2B%5Cfrac%7B20%7D%7Bln2%7Dw%28x_%7Bi%7D%29%7D)
    - 分数输出: 经过特征筛选、证据权重的计算、系数的回归，对每个特征分组都计算出一个分数，得出如下标准评分卡格式
  - 逻辑回归-标准评分卡的实操。
- 银行决定是否给个人或企业贷款的关键因素是对未来违约概率的预测，逻辑回归函数能提供此技术支持。假设某银行挑选了 n 个特征进入评分卡给客户进行准入评分，且这 n 个特征包含了能判断客户是好还是坏的充分信息![](https://www.zhihu.com/equation?tex=X%3D%28x_%7B1%7D%2Cx_%7B2%7D%2C...%2Cx_%7Bn%7D%29)，若是想预测某个客户在将来违约的概率，那么只需要收集该客户的n个特征信息，代入公式![](https://www.zhihu.com/equation?tex=p%28z%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D)，就得到一个介于(0,1)之间的值，称为好客户的概率。
- 在逻辑回归函数的作用下，可以将客户的特征信息（如婚姻、年龄、历史以往信贷表现等）综合起来并转化为一个概率值，该值给银行预测客户好坏提供了一个直观依据。即 p(z) 值越大，证明该客户在将来违约的概率越小。


### 基本流程

- （1）是否有label，如果有，需要先做特征分析，剔除无关特征
  - 正式建模之前，一般会对特征工程挖掘到的特征集进行筛选，以选择相关性高、稳定性强的特征，作为入模变量。
  - 常用特征筛选一般会考虑如下几方面：
    - 1）特征**覆盖率**(cover rate)，选取覆盖率达到一定阈值的特征；
    - 2）特征**相关性**：如根据特征本身的KS值、IV或卡方值，选择与建模label相关性高的特征；
    - 3）特征**稳定性**：比如通过衡量特征的PSI，选择随时间波动性尽可能小的特征。
    - 此外，还可以通过VIF、相关性系数等指标，排除特征之间的共线性。
- （2）特征重要度数值+专家经验，制定组合方式，得到初步分数
- （3）全局分布调整，转换到正太分布N（u，σ），u＜及格线，保证分数具备区分度
- （4）打分反馈闭环，根据用户反馈，补充到label中，回到（1）

无监督评分卡也有些方法，如基于专家经验的层次分析法，熵权法等


### 评分卡建模

- [机器学习在信用评分卡中的应用](https://zhuanlan.zhihu.com/p/49818814)
- 特征和样本标签准备好后，评分卡建模的过程则比较自然。虽然深度学习等技术在互联网领域已大行其道，在信用评分卡建模中，逻辑回归或GBDT等仍然是目前主流的建模算法。一方面是金融领域对特征的可解释性要求会更高，通过LR或GBDT建模，比较容易直观得到每个特征在模型结果中的权重，并根据业务经验解释权重系数的合理性。另一方面，实际评分卡建模中，一般入模特征维度并不高。在低维度建模中，LR和GBDT已经可以取得比较可观的效果。

### 模型评估

- 模型建立后，需要对模型的预测能力、稳定性进行评估。信用评分模型常用的评估指标为KS、AUC等。 考虑到金融业务反馈周期长的特点，除了划分训练集、测试集外，通常会预留一段训练样本时间段之外的数据集，作为OOT（跨时间）集合，以测量模型在时间上的稳定性。
- 评分分布图的区分度
  - 如果通过评分能将**好坏用户完全区隔**开来，那是理想中最好的评分卡模型，但实际情况中好坏用户的评分会有一定程度的重叠，我们要做的就是尽量减小重叠程度。
  - 好坏用户的得分分布最好都是**正态分布**，如果呈双峰或多峰分布，那么很有可能是某个变量的得分过高导致，这样对评分卡的稳定性会有影响。
  - ![](https://pic1.zhimg.com/80/v2-4819c26a5036036ce54e9f602327b564_1440w.jpg)
  - 摘自：[评分卡模型的评估方法论](https://zhuanlan.zhihu.com/p/56738542), [github 代码](https://github.com/taenggu0309/Scorecard--Assessment)
- [一文读懂评分卡的IV、KS、AUC、GINI指标](https://zhuanlan.zhihu.com/p/119282743)
- 当一张评分卡构建完成时，筛选出一组特征生成了分数，我们会想要知道这个分数是否靠谱，即是否可以依赖这个分数将好坏客户区分开来，这个时候就需要评判评分卡有效性的指标。
- 测量评分卡好坏区分能力的指标有许多，本文就为大家介绍几个常用的定量指标：
  - ① **散度**（分数为连续函数）与**信息比率**（IV);
  - ② **KS值**
  - ③ ROC曲线、AUROC值与GINI系数。

#### 散度与信息比率

- 散度为信息比率的连续版本。而评分卡分数是基于有限样本计算出的分数分布，并不一定是完全连续函数，所以就衍生出了离散版本的散度----信息比率IV。
- 在实际应用当中，IV值通常用来筛选变量，IV值越大，该变量的好坏区分能力越强。在评分卡建模的过程中，利用IV值筛选变量也是非常重要的一个环节。
- 从IV值的公式中，易得变量的分组越多，IV值越大。但是分组分的太多，就会使得每个分组的数据量变少，导致细项分组的分布不稳定。所以，我们在使用IV值筛选变量的时候，不能为了提高IV值一味地将分箱的数目提高，也要兼顾变量的业务含义和分布的稳定性。

#### KS值

- KS值是一个衡量好坏客户分数距离的上限值，具体做法为将对于各个分数区间对应的好坏客户累计占比进行相减，取最大值。
- ![](https://pic2.zhimg.com/80/v2-d1afba6dc7f1d022a722d3c55d4f23a9_1440w.jpg)
  - 为什么F(s\|B)为凹函数、F(s\|G)为凸函数？
  - 为什么F(s\|B)-F(s\|G)存在极大值（最大值）？
  - 为什么F(s\|B)曲线在F(s\|G)曲线之上？
- ![](https://pic1.zhimg.com/80/v2-4c73cebb1eb9cf2497993b98e10042f8_1440w.jpg)



#### ROC曲线与AUROC值

- ROC曲线也是评分卡度量指标中常用的指标工具，在介绍KS统计量的时候，其分布函数是由好客户和坏客户对应的累计概率密度函数F(s\|B)与F(s\|G)随着分数s变化的图形，而ROC曲线是好客户的累计概率密度相对于坏客户的累计概率密度函数的图形
  - ![](https://pic4.zhimg.com/80/v2-1e5953e490b27a7f1f225b83850a6f4f_1440w.jpg)
- 根据上文的分析，得出越接近B点的曲线，好坏客户的区分能力越强，这个时候，ROC曲线与X轴围成的面积就越大。由此，衍生出ROC曲线关于X轴面积的指标AUROC（Area under the ROC curve)。

#### GINI曲线

- AUROC值是ROC曲线和X轴的面积，GINI系数定义为ROC曲线和对角线AC之间的面积占对角线AC曲线围成面积比，即 ![](https://pic1.zhimg.com/80/v2-b808e5dc8bbb7400944eac704d797bd8_1440w.jpg) 。
  - 如果该评分系统异常完美，AUC曲线过点B(0,1)，这个时候GINI=1；
  - 如果评分卡毫无区分度，那么AUC曲线即为AC曲线，这时GINI=0;
- 所以，GINI系数是一个介于(0,1)之间的函数，该值越大，模型的区分能力越强。


### 实战

- [Python实现的半自动评分](https://zhuanlan.zhihu.com/p/92916332)，[github地址](https://github.com/taenggu0309/Semi-auto-modeling)，整个脚本的大概流程是：
  - PSI预筛选 --> 特征分箱 --> IV筛选特征 --> 相关性/多重共线性筛选 --> woe单调调整 -- > 显著性筛选 --> 系数一致筛选 --> 建模 --> 模型评估 --> 标准评分转换



# 结束
















