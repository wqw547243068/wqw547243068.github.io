---
layout: post
title:  "神经网络训练可视化"
date:   2019-05-11 17:25:00
categories: 编程语言
tags: Tensorflow Python 深度学习 可视化 wandb
excerpt: 如何将训练过程可视化？tensorboard 和 wandb
author: 鹤啸九天
mathjax: true
permalink: /train_vis
---

* content
{:toc}


# 训练可视化


## TensorBoard

TensorFlow自带的一个强大的可视化工具

查看模型训练过程中各个参数的变化情况（例如损失函数 loss 的值）。虽然可以通过命令行输出来查看，但有时显得不够直观。而 TensorBoard 就是一个能够帮助我们将训练过程可视化的工具。
原理
- 在运行过程中，记录结构化的数据
- 运行一个本地服务器，监听6006端口
- 请求时，分析记录的数据，绘制

### TensorBoard 使用方法

操作方法
- 每运行一次 tf.summary.scalar() ，记录器就会向记录文件中写入一条记录。除了最简单的标量（scalar）以外，TensorBoard 还可以对其他类型的数据（如图像，音频等）进行可视化
- 代码目录打开终端: tensorboard --logdir=./tensorboard
- 默认情况下，TensorBoard 每 30 秒更新一次数据。不过也可以点击右上角的刷新按钮手动刷新。
- ![](https://tf.wiki/_images/tensorboard.png)

TensorFlow在MNIST实验数据上得到Tensorboard结果
- Event: 展示训练过程中的统计数据（最值，均值等）变化情况
- Image: 展示训练过程中记录的图像
- Audio: 展示训练过程中记录的音频
- Histogram: 展示训练过程中记录的数据的分布图

注意事项：
- 如果需要重新训练，需要删除掉记录文件夹内的信息并重启 TensorBoard（或者建立一个新的记录文件夹并开启 TensorBoard， --logdir 参数设置为新建立的文件夹）；
- 记录文件夹目录保持全英文。

```python
import tensorflow as tf
from zh.model.mnist.mlp import MLP
from zh.model.utils import MNISTLoader

num_batches = 1000
batch_size = 50
learning_rate = 0.001
log_dir = 'tensorboard' # 记录文件所保存的目录

model = MLP()
data_loader = MNISTLoader()
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
summary_writer = tf.summary.create_file_writer(log_dir)     # 实例化记录器
#tf.summary.trace_on(profiler=True)  # 开启Trace（可选）
tf.summary.trace_on(graph=True, profiler=True)  # 开启Trace，可以记录图结构和profile信息；如果使用了 tf.function 建立了计算图，也可以点击 “Graphs” 查看图结构。

for batch_index in range(num_batches):
    X, y = data_loader.get_batch(batch_size)
    with tf.GradientTape() as tape:
        y_pred = model(X)
        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)
        loss = tf.reduce_mean(loss)
        print("batch %d: loss %f" % (batch_index, loss.numpy()))
        with summary_writer.as_default():                           # 指定记录器
            tf.summary.scalar("loss", loss, step=batch_index)       # 将当前损失函数的值写入记录器
    grads = tape.gradient(loss, model.variables)
    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))
with summary_writer.as_default():
    tf.summary.trace_export(name="model_trace", step=0, profiler_outdir=log_dir)    # 保存Trace信息到文件（可选）
```

### Tensorboard使用

- 理解训练过程、调试和优化TensorFlow程序，TensorFlow团队开发了一套名为TensorBoard的可视化工具，它是一套可以通过浏览器运行的Web应用程序。TensorBoard可用于可视化TensorFlow计算图，绘制有关计算图运行结果的量化指标，并显示其他数据（如通过它的图像）
- ![](https://p3-tt.byteimg.com/origin/pgc-image/45b05322178c442f99b39199e17c1d55?from=pc)

- 5个步骤

```python
# (1) From TF graph, decide which tensors you want to log
w2_hist = tf.summary.histogram("weights2", W2)
cost_summ = tf.summary.scalar("cost", cost)
# (2) Merge all summaries
summary = tf.summary.merge_all()
# Create writer and add graph
# (3) Create summary writer
writer = tf.summary.FileWriter(‘./logs’)
writer.add_graph(sess.graph)
# (4) Run summary merge and add_summary
s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)
writer.add_summary(s, global_step=global_step)
# (5) Launch TensorBoard
tensorboard --logdir=./logs
# 端口映射，远程server调用本地日志
#ssh -L local_port:127.0.0.1:remote_port username@server.com
ssh -L 7007:121.0.0.0:6006 hunkim@server.com # local
tensorboard —logdir=./logs/xor_logs # server
# 访问：http://127.0.0.1:7007

```

- TensorBoard 常用API
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/12d38976fa274af69a66f711541398b8?from=pc)
- tensorboard可视化: 通过 TensorFlow 程序运行过程中输出的日志文件可视化 TenorFlow 程序的运行状态d
  - ![](https://p1-tt.byteimg.com/origin/pgc-image/28ff3eb0d23347b89c3b51ce7062a231?from=pc)


## PyTorch 可视化

### 总结

tensorflow的模型结构可视化方法：[参考文章](https://blog.csdn.net/qq_27825451/article/details/96856217)
- （1）使用自带的tensorboard（不直观）
- （2）使用netron工具打开（.pd 或者是.meta文件）
- （3）第三方库CNNGraph（  https://github.com/huachao1001/CNNGraph）
- （4）tensorspace.js （这个比较高级，没用过）
- （5）高层API中keras的可视化

pytorch的模型结构可视化方法：
- （1）使用tensorboardX（不太直观）
- （2）使用graphviz加上torchviz （依赖于graphviz和GitHub第三方库torchviz）
- （3）使用微软的tensorwatch （只能在jupyter notebook中使用，个人最喜欢这种方式）
- （4）使用netron可视化工具（.pt 或者是 .pth 文件）

### 网络示例

[Pytorch可视化](https://zhuanlan.zhihu.com/p/220403674)

示例代码

```python
import torch
import torch.nn as nn
 
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()

        self.conv1 = nn.Sequential(
            nn.Conv2d(1, 16, 3, 1, 1),
            nn.ReLU(),
            nn.AvgPool2d(2, 2)
        )

        self.conv2 = nn.Sequential(
            nn.Conv2d(16, 32, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )

        self.fc = nn.Sequential(
            nn.Linear(32 * 7 * 7, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU()
        )

        self.out = nn.Linear(64, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        output = self.out(x)
        return output

# 输出网络结构
MyConvNet = ConvNet()
print(MyConvNet)

```

有了基本的神经网络后，分别通过HiddenLayer和PyTorchViz库来可视化上述的卷积层神经网络。

### 网络结构可视化

#### HiddenLayer可视化

安装库

```shell
pip install hiddenlayer
```

可视化

```python
import hiddenlayer as h
vis_graph = h.build_graph(MyConvNet, torch.zeros([1 ,1, 28, 28]))   # 获取绘制图像的对象
vis_graph.theme = h.graph.THEMES["blue"].copy()     # 指定主题颜色
vis_graph.save("./demo1.png")   # 保存图像的路径
```

可视化训练过程
- HiddenLayer 适用于小网络可视化，其它建议使用更复杂的 tensorboardX
- 不同于tensorboard，hiddenlayer会在程序运行的过程中动态生成图像，而不是模型训练完后

```python
import hiddenlayer as hl
import time

# 记录训练过程的指标
history = hl.History()
# 使用canvas进行可视化
canvas = hl.Canvas()

# 获取优化器和损失函数
optimizer = torch.optim.Adam(MyConvNet.parameters(), lr=3e-4)
loss_func = nn.CrossEntropyLoss()
log_step_interval = 100      # 记录的步数间隔

for epoch in range(5):
    print("epoch:", epoch)
    # 每一轮都遍历一遍数据加载器
    for step, (x, y) in enumerate(train_loader):
        # 前向计算->计算损失函数->(从损失函数)反向传播->更新网络
        predict = MyConvNet(x)
        loss = loss_func(predict, y)
        optimizer.zero_grad()   # 清空梯度（可以不写）
        loss.backward()     # 反向传播计算梯度
        optimizer.step()    # 更新网络
        global_iter_num = epoch * len(train_loader) + step + 1  # 计算当前是从训练开始时的第几步(全迭代次数)
        if global_iter_num % log_step_interval == 0:
            # 控制台输出一下
            print("global_step:{}, loss:{:.2}".format(global_iter_num, loss.item()))
            # 在测试集上预测并计算正确率
            test_predict = MyConvNet(test_data_x)
            _, predict_idx = torch.max(test_predict, 1)  # 计算softmax后的最大值的索引，即预测结果
            acc = accuracy_score(test_data_y, predict_idx)

            # 以epoch和step为索引，创建日志字典
            history.log((epoch, step),
                        train_loss=loss,
                        test_acc=acc,
                        hidden_weight=MyConvNet.fc[2].weight)

            # 可视化
            with canvas:
                canvas.draw_plot(history["train_loss"])
                canvas.draw_plot(history["test_acc"])
                canvas.draw_image(history["hidden_weight"])
```

效果
- ![img](https://pic1.zhimg.com/80/v2-961ce1b437e3f50be2c0993a0473cf60_1440w.webp)


#### PyTorchViz可视化

安装

```shell
pip install torchviz
```

只使用可视化函数make_dot()来获取绘图对象，基本使用和HiddenLayer差不多，不同的地方在于PyTorch绘图之前可以指定一个网络的输入值和预测值。

```python
from torchviz import make_dot
x = torch.randn(1, 1, 28, 28).requires_grad_(True)  # 定义一个网络的输入值
y = MyConvNet(x)    # 获取网络的预测值
 
MyConvNetVis = make_dot(y, params=dict(list(MyConvNet.named_parameters()) + [('x', x)]))
MyConvNetVis.format = "png"
# 指定文件生成的文件夹
MyConvNetVis.directory = "data"
# 生成文件
MyConvNetVis.view()
```

打开与上述代码相同根目录下的data文件夹，里面会有一个.gv文件和一个.png文件，其中的.gv文件是Graphviz工具生成图片的脚本代码，.png是.gv文件编译生成的图片，直接打开.png文件就行。
- 默认情况下，上述程序运行后会自动打开.png文件
- ![](https://pic1.zhimg.com/80/v2-5df5777fbbd000d62257364b39a9151c_1440w.webp)

### 训练过程可视化

#### tensorboardX 可视化

数据集准备

```python
import torchvision
import torch.utils.data as Data
# 准备训练用的MNIST数据集
train_data = torchvision.datasets.MNIST(
    root = "./data/MNIST",  # 提取数据的路径
    train=True, # 使用MNIST内的训练数据
    transform=torchvision.transforms.ToTensor(),    # 转换成torch.tensor
    download=False   # 如果是第一次运行的话，置为True，表示下载数据集到root目录
)

# 定义loader
train_loader = Data.DataLoader(
    dataset=train_data,
    batch_size=128,
    shuffle=True,
    num_workers=0
)

test_data = torchvision.datasets.MNIST(
    root="./data/MNIST",
    train=False,    # 使用测试数据
    download=False
)

# 将测试数据压缩到0-1
test_data_x = test_data.data.type(torch.FloatTensor) / 255.0
test_data_x = torch.unsqueeze(test_data_x, dim=1)
test_data_y = test_data.targets

# 打印一下测试数据和训练数据的shape
print("test_data_x.shape:", test_data_x.shape)
print("test_data_y.shape:", test_data_y.shape)

for x, y in train_loader:
    print(x.shape)
    print(y.shape)
    break
```

tensorboardX可视化训练过程
- `tensorboard` 是谷歌开发的深度学习框架tensorflow的一套深度学习可视化神器，pytorch团队开发出了 `tensorboardX` 来让pytorch的玩家也能享受tensorboard的福利。

先安装相关的库：

```shell
pip install tensorboardX
pip install tensorboard
```

并将tensorboard.exe所在的文件夹路径加入环境变量path中

tensorboardX的使用过程。
- 基本使用为，先通过tensorboardX下的SummaryWriter类获取一个日志编写器对象。
- 然后通过这个对象的一组方法往日志中添加事件，即生成相应的图片，最后启动前端服务器，在localhost中就可以看到最终的结果了。

```python
from tensorboardX import SummaryWriter

logger = SummaryWriter(log_dir="data/log")

# 获取优化器和损失函数
optimizer = torch.optim.Adam(MyConvNet.parameters(), lr=3e-4)
loss_func = nn.CrossEntropyLoss()
log_step_interval = 100      # 记录的步数间隔

for epoch in range(5):
    print("epoch:", epoch)
    # 每一轮都遍历一遍数据加载器
    for step, (x, y) in enumerate(train_loader):
        # 前向计算->计算损失函数->(从损失函数)反向传播->更新网络
        predict = MyConvNet(x)
        loss = loss_func(predict, y)
        optimizer.zero_grad()   # 清空梯度（可以不写）
        loss.backward()     # 反向传播计算梯度
        optimizer.step()    # 更新网络
        global_iter_num = epoch * len(train_loader) + step + 1  # 计算当前是从训练开始时的第几步(全迭代次数)
        if global_iter_num % log_step_interval == 0:
            # 控制台输出一下
            print("global_step:{}, loss:{:.2}".format(global_iter_num, loss.item()))
            # 添加的第一条日志：损失函数-全局迭代次数
            logger.add_scalar("train loss", loss.item() ,global_step=global_iter_num)
            # 在测试集上预测并计算正确率
            test_predict = MyConvNet(test_data_x)
            _, predict_idx = torch.max(test_predict, 1)     # 计算softmax后的最大值的索引，即预测结果
            acc = accuracy_score(test_data_y, predict_idx)
            # 添加第二条日志：正确率-全局迭代次数
            logger.add_scalar("test accuary", acc.item(), global_step=global_iter_num)
            # 添加第三条日志：这个batch下的128张图像
            img = vutils.make_grid(x, nrow=12)
            logger.add_image("train image sample", img, global_step=global_iter_num)
            # 添加第三条日志：网络中的参数分布直方图
            for name, param in MyConvNet.named_parameters():
                logger.add_histogram(name, param.data.numpy(), global_step=global_iter_num)
```

代码同一级的目录,输入指令，启动服务器
- tensorboard --logdir="./data/log"
- 浏览器中访问红框框中的url，便可得到可视化界面，点击上面的页面控件
- ![](https://pic4.zhimg.com/80/v2-8e88b0f96042ad6ca8da7034afd5bdcb_1440w.webp)

#### HiddenLayer

tensorboard的图像很华丽，但是使用过程相较于其他的工具包较为繁琐，所以小网络一般没必要使用tensorboard。
- 不同于tensorboard，hiddenlayer会在程序运行的过程中动态生成图像，而不是模型训练完后
- ![](https://pic4.zhimg.com/80/v2-0816802722a880fb2c261552476604ab_1440w.webp)

```py
 import hiddenlayer as hl
 import time
 ​
 # 记录训练过程的指标
 history = hl.History()
 # 使用canvas进行可视化
 canvas = hl.Canvas()
 ​
 # 获取优化器和损失函数
 optimizer = torch.optim.Adam(MyConvNet.parameters(), lr=3e-4)
 loss_func = nn.CrossEntropyLoss()
 log_step_interval = 100      # 记录的步数间隔
 ​
 for epoch in range(5):
     print("epoch:", epoch)
     # 每一轮都遍历一遍数据加载器
     for step, (x, y) in enumerate(train_loader):
         # 前向计算->计算损失函数->(从损失函数)反向传播->更新网络
         predict = MyConvNet(x)
         loss = loss_func(predict, y)
         optimizer.zero_grad()   # 清空梯度（可以不写）
         loss.backward()     # 反向传播计算梯度
         optimizer.step()    # 更新网络
         global_iter_num = epoch * len(train_loader) + step + 1  # 计算当前是从训练开始时的第几步(全局迭代次数)
         if global_iter_num % log_step_interval == 0:
             # 控制台输出一下
             print("global_step:{}, loss:{:.2}".format(global_iter_num, loss.item()))
             # 在测试集上预测并计算正确率
             test_predict = MyConvNet(test_data_x)
             _, predict_idx = torch.max(test_predict, 1)  # 计算softmax后的最大值的索引，即预测结果
             acc = accuracy_score(test_data_y, predict_idx)
 ​
             # 以epoch和step为索引，创建日志字典
             history.log((epoch, step),
                         train_loss=loss,
                         test_acc=acc,
                         hidden_weight=MyConvNet.fc[2].weight)
 ​
             # 可视化
             with canvas:
                 canvas.draw_plot(history["train_loss"])
                 canvas.draw_plot(history["test_acc"])
                 canvas.draw_image(history["hidden_weight"])
```

### Visdom进行可视化

Visdom是Facebook为pytorch开发的一块可视化工具。类似于tensorboard，visdom也是通过在本地启动前端服务器来实现可视化的，而在具体操作上，visdom又类似于matplotlib.pyplot。所以使用起来很灵活。



```python
from visdom import Visdom
from sklearn.datasets import  load_iris
import torch
import numpy as np
from PIL import Image

# 绘制图像需要的数据
iris_x, iris_y = load_iris(return_X_y=True)

# 获取绘图对象，相当于plt
vis = Visdom()

# ===== 添加折线图 =======
x = torch.linspace(-6, 6, 100).view([-1, 1])
sigmoid = torch.nn.Sigmoid()
sigmoid_y = sigmoid(x)
tanh = torch.nn.Tanh()
tanh_y = tanh(x)
relu = torch.nn.ReLU()
relu_y = relu(x)
# 连接三个张量
plot_x = torch.cat([x, x, x], dim=1)
plot_y = torch.cat([sigmoid_y, tanh_y, relu_y], dim=1)
# 绘制线性图
vis.line(X=plot_x, Y=plot_y, win="line plot", env="main",
         opts={
             "dash" : np.array(["solid", "dash", "dashdot"]),
             "legend" : ["Sigmoid", "Tanh", "ReLU"]
         })
# ====== 绘制2D和3D散点图 ========
# 参数Y用来指定点的分布，win指定图像的窗口名称，env指定图像所在的环境，opts通过字典来指定一些样式
vis.scatter(iris_x[ : , 0 : 2], Y=iris_y+1, win="windows1", env="main")
vis.scatter(iris_x[ : , 0 : 3], Y=iris_y+1, win="3D scatter", env="main",
            opts={
                "markersize" : 4,   # 点的大小
                "xlabel" : "特征1",
                "ylabel" : "特征2"
            })
# ==== 添加茎叶图 ======
x = torch.linspace(-6, 6, 100).view([-1, 1])
y1 = torch.sin(x)
y2 = torch.cos(x)

# 连接张量
plot_x = torch.cat([x, x], dim=1)
plot_y = torch.cat([y1, y2], dim=1)
# 绘制茎叶图
vis.stem(X=plot_x, Y=plot_y, win="stem plot", env="main",
         opts={
             "legend" : ["sin", "cos"],
             "title" : "茎叶图"
         })

# 计算鸢尾花数据集特征向量的相关系数矩阵
iris_corr = torch.from_numpy(np.corrcoef(iris_x, rowvar=False))
# ==== 绘制热力图 =====
vis.heatmap(iris_corr, win="heatmap", env="main",
            opts={
                "rownames" : ["x1", "x2", "x3", "x4"],
                "columnnames" : ["x1", "x2", "x3", "x4"],
                "title" : "热力图"
            })

# ==== 可视化图片 =====
img_Image = Image.open("./example.jpg")
img_array = np.array(img_Image.convert("L"), dtype=np.float32)
img_tensor = torch.from_numpy(img_array)
print(img_tensor.shape)

# 这次env自定义
vis.image(img_tensor, win="one image", env="MyPlotEnv",
          opts={
              "title" : "一张图像"
          })

# ==== 可视化文本 =====
text = "hello world"
vis.text(text=text, win="text plot", env="MyPlotEnv",
         opts={
             "title" : "可视化文本"
         })
```

运行上述代码，再
- 在终端中启动服务器
  - python3 -m visdom.server
- 然后根据终端返回的URL，在谷歌浏览器中访问这个URL，就可以看到图像了
- 在Environment中输入不同的env参数可以看到我们在不同环境下绘制的图片。对于分类图集特别有用
- ![](https://pic4.zhimg.com/80/v2-81414cc7ab91f73e1d58ffa87c7b149b_1440w.webp)

注意：
- 如果前端服务器停掉了，那么所有的图片都会丢失，因为此时的图像的数据都是驻留在内存中，而并没有dump到本地磁盘。
- 那么如何保存当前visdom中的可视化结果，并在将来复用呢？点击Manage Views → 点击fork->save




## wandb

【2023-4-10】[wandb使用教程(一)：基础用法](https://zhuanlan.zhihu.com/p/493093033)

wandb是一个免费、用于记录实验数据的工具。
- wandb相比于tensorboard之类的工具，有更加丰富的**用户管理，团队管理**功能，更加方便团队协作。

wandb 是 Weight & Bias 缩写，与Tensorboard类似的参数可视化平台。

不过，相比较TensorBoard而言，Wandb更加的强大，主要体现在以下的几个方面：
- 复现模型：Wandb更有利于复现模型。Wandb不仅记录指标，还会记录**超参数**和**代码**版本。
- 自动上传云端：
  - 把项目交给同事或者要去度假，Wandb可以便捷地查看所有模型，不必花费大量时间来重新运行旧实验。
- 快速、灵活的集成：
  - 只需5分钟即可把Wandb加到项目。
  - 下载Wandb免费的开源Python包，然后在代码中插入几行，以后每次运行模型都会得到记录完备的指标和记录。
- 集中式指示板：
  - Wandb提供同样的集中式指示板。不管在哪里训练模型，不管是在本地机器、实验室集群还是在云端实例；不必花时间从别的机器上复制TensorBoard文件。
- 强大的表格：
  - 对不同模型的结果进行搜索、筛选、分类和分组。
  - 轻而易举地查看成千上万个模型版本，并找到不同任务的最佳模型。

使用wandb，首先要在网站上创建team，然后在team下创建project，然后project下会记录每个实验的详细数据。

### wandb 安装

wandb是一个Python库，所以可以直接通过pip来安装：
 
```sh
pip install wandb
```

然后在[wandb官网](https://wandb.ai/)注册一个账号，然后获取该账号的[私钥](https://wandb.ai/authorize)。然后在命令行执行：
 
```sh
wandb login
```

根据提示输入私钥即可。
 
以本教程中的代码为例，我们创建一个叫做tmarl的team，然后创建了一个叫做wandb_usage的project:
- ![](https://pic4.zhimg.com/80/v2-99fe7d414e63332bca36bed98f5e7bd7_1440w.jpg)
- wandb界面展示
 
然后在代码里面只要指定该team和project，便可以把数据传输到对应的project下：
 
```py
import wandb

config = dict (
  learning_rate = 0.01,
  momentum = 0.2,
  architecture = "CNN",
  dataset_id = "peds-0192",
  infra = "AWS",
)

test = wandb.init(
    project='wqw', # 项目名称wqw，运行时会创建 wqw 目录
    entity=your_team_name,
    notes=socket.gethostname(),
    name='test', # 任务名,不设置时，系统会自动拼接两个单词作为名称，如 green-wood-250
    dir=run_dir,
    job_type="training",
    reinit=True,
    resume="allow",  #  是否可恢复, 防止意外中断, 默认None
    config=config) # 实验参数配置, 保存训练配置，这些配置包含超参数、数据集名称或模型类型等输入设置
# 运行中途可以更新config信息
wandb.config.update({'a':10})
test.config.update(dict(epoch=args.epochs, lr=args.lr, batch_size=args.batch_size))
# 补充观测数据
wandb.log({'loss': loss, 'epoch': epoch, 'learning rate': cur_lr，
           'images': wandb.Image(images.float()),
           'masks': {'true': wandb.Image(targets.float()),
                     'pred': wandb.Image(pred.float())}
          })
wandb.Image() # 用于图像的显示，numpy格式的数组或者PIL实例转化为PNG，从而在网页上直接显示出来。
```

### 示例

【2023-11-24】实践通过

专属api key启动

```sh
wandb login 666efa48cc...
```

执行训练脚本

```py
import wandb
import random

# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 0.02,
    "architecture": "CNN",
    "dataset": "CIFAR-100",
    "epochs": 10,
    }
)

# simulate training
epochs = 10
offset = random.random() / 5
for epoch in range(2, epochs):
    acc = 1 - 2 ** -epoch - random.random() / epoch - offset
    loss = 2 ** -epoch + random.random() / epoch + offset
    
    # log metrics to wandb
    wandb.log({"acc": acc, "loss": loss})

# [optional] finish the wandb run, necessary in notebooks
wandb.finish()
```

【2024-3-20】wandb 报错

```sh
wandb.sdk.lib.config_util.ConfigError: Attempted to change value of key "batch_size" from 32 to 256
If you really want to do this, pass allow_val_change=True to config.update()
```

改进

```py
import wandb

wandb.init() # allow_val_change=True 放 init 不管用
wandb.config.update({"allow_val_change":True})

```

### 使用方法

wandb的基础功能就是跟踪训练过程，然后在wandb网站上查看训练数据。

wandb通过通用的log()函数，可以展示丰富的数据类型，包括训练`曲线`，`图片`，`视频`，`表格`，`html`，`matplotlib图像`等。

详细教程见：[wandb使用教程(一)：基础用法](https://zhuanlan.zhihu.com/p/493093033)，[本地部署](https://zhuanlan.zhihu.com/p/521663928)
*   展示训练曲线示例: [test_curves.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_curves.sh)
*   展示图片示例: [test_images.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_images.sh)
*   展示视频示例: [test_videos.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_videos.sh)
*   展示matplotlib画图示例：[test_matplot.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_matplot.sh)
*   展示表格示例: [test_tables.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_tables.sh)
*   展示多进程group示例: [test\_multi\_process.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_multi_process.sh)
*   展示html示例: [test_html.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_html.sh)
*   PyTorch集成示例: [test_pytorch.sh](https://github.com/huangshiyu13/wandb_tutorial/blob/main/basic/test_pytorch.sh)


### 问题



【2024-3-19】执行

```py
import wandb
# 不设置 project 时，会默认创建 wandb 目录
wandb.init()
# 设置 project
wandb.init(project="wqw")
```

报错：
- [[AttributeError] module 'wandb' has no attribute 'init'](https://github.com/wandb/wandb/issues/5950)

分析
- 本地有 `wandb` 目录(包含 `__init__.py` )、`wandb.py` 文件

My guess is that you have either:
- wandb directory that contains an `__init__.py`, or `wandb.py` file in your working directory.

实情
- 公司内定制了wandb包，将默认包做了修改

解决方法
- 卸载 


# 结束


