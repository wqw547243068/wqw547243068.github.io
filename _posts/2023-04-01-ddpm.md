---
layout: post
title:  "æ‰©æ•£æ¨¡å‹-DDPM"
date:   2023-04-01 08:01:00
categories: è®¡ç®—æœºè§†è§‰ å¤§æ¨¡å‹
tags: sd æ‰©æ•£ lora vae unet å¤šæ¨¡æ€ è§†é¢‘ç”Ÿæˆ
excerpt: æ‰©æ•£ç”Ÿæˆæ¨¡å‹åŸç†
mathjax: true
permalink: /ddpm
---

* content
{:toc}

# æ‰©æ•£æ¨¡å‹ DDPM


æ‰©æ•£æ¨¡å‹
- ![](https://pic1.zhimg.com/80/v2-ee822b476d8c4c54667b8ee59b036828_1440w.webp)

æ ‡å‡†çš„**æ‰©æ•£æ¨¡å‹**åˆ†ä¸ºä¸¤ä¸ªä¸»è¦è¿‡ç¨‹:`æ­£å‘è¿‡ç¨‹`ï¼ˆæ‰©æ•£ï¼‰å’Œ`åå‘è¿‡ç¨‹`ï¼ˆå»å™ªã€è¿˜åŸå’Œç”Ÿæˆç›®æ ‡ï¼‰ã€‚
- æ­£å‘æ‰©æ•£é˜¶æ®µï¼Œé€æ¸å¼•å…¥å™ªå£°ï¼Œç›´åˆ°å›¾åƒå˜æˆå®Œå…¨éšæœºçš„å™ªå£°ã€‚
- å†é€šè¿‡åå‘è¿‡ç¨‹ï¼Œä½¿ç”¨ä¸€ç³»åˆ—çš„`é©¬å°”ç§‘å¤«é“¾`è¿›è¡Œå»å™ªï¼Œå¾—åˆ°æœ€ç»ˆæ¸…æ™°çš„å›¾åƒæ•°æ®ã€‚
- ![](https://pica.zhimg.com/80/v2-09911fadad0b4ab0f787444db62c2bbe_1440w.webp?source=1940ef5c)

æ–°å‡ºç°çš„`æ‰©æ•£æ¨¡å‹`ï¼ˆDenoising Diffusion Probabilistic Modelï¼Œ`DDPM`ï¼‰ï¼Œæ•´ä½“åŸç†ä¸Šä¸ `VAE` æ›´åŠ æ¥è¿‘ã€‚
- X0 æ˜¯è¾“å…¥æ ·æœ¬ï¼Œå¦‚ä¸€å¼ åŸå§‹å›¾ç‰‡ï¼Œé€šè¿‡ T æ­¥**å‰å‘è¿‡ç¨‹**ï¼ˆForward processï¼‰é‡‡æ ·å˜æ¢ï¼Œæœ€åç”Ÿæˆäº†å™ªå£°å›¾åƒ XT ï¼Œç†è§£ä¸ºéšå˜é‡ zã€‚è¿™ä¸ªè¿‡ç¨‹é€šè¿‡é©¬å°”ç§‘å¤«é“¾å®ç°ã€‚

éšæœºè¿‡ç¨‹ä¸­ä¸€ä¸ªå®šç†
- ç¬¦åˆé©¬å°”ç§‘å¤«é“¾çŠ¶æ€è½¬ç§»çš„æ¨¡å‹ï¼Œå½“çŠ¶æ€è½¬ç§»åˆ°ä¸€å®šæ¬¡æ•°æ—¶ï¼Œæ¨¡å‹çŠ¶æ€æœ€ç»ˆæ”¶æ•›äºä¸€ä¸ª**å¹³ç¨³åˆ†å¸ƒ**ã€‚
- ç­‰æ•ˆäºæº¶è´¨åœ¨æº¶æ¶²ä¸­æº¶è§£çš„è¿‡ç¨‹ï¼Œéšç€æº¶è§£è¿‡ç¨‹çš„è¿›è¡Œï¼Œ**æº¶è´¨**ï¼ˆå™ªå£°ï¼‰æœ€ç»ˆä¼šæ•´ä½“åˆ†å¸ƒåˆ°**æº¶æ¶²**ï¼ˆæ ·æœ¬ï¼‰ä¸­ã€‚ç±»ä¼¼ VAE ä¸­çš„ encoderã€‚è€Œ**é€†å‘è¿‡ç¨‹**ï¼ˆReverse processï¼‰å¯ä»¥ç†è§£ä¸º decoderã€‚é€šè¿‡ T æ­¥æ¥è¿˜åŸåˆ°åŸå§‹æ ·æœ¬ã€‚


æ‰©æ•£æ¨¡å‹æ ¸å¿ƒåˆ›æ–°ï¼šå°†æ•°æ®ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª**é€æ­¥å»å™ªçš„é€†æ‰©æ•£**è¿‡ç¨‹ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°**æ•°æ®åˆ†å¸ƒçš„å¤æ‚ç»“æ„**ï¼ŒåŒæ—¶é¿å…äº† GANs è®­ç»ƒä¸­å¸¸è§çš„æ¨¡å¼å´©æºƒé—®é¢˜ã€‚

éšç€ Stable Diffusionã€Sora ç­‰ä»£è¡¨æ€§æ¨¡å‹çš„æ¨å‡ºï¼Œæ‰©æ•£æ¨¡å‹å·²æˆä¸ºå½“å‰ AIGC é¢†åŸŸçš„ä¸»æµæŠ€æœ¯ä¹‹ä¸€

## ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹

æ‰©æ•£æ¨¡å‹çµæ„Ÿæ¥è‡ª**éå¹³è¡¡çƒ­åŠ›å­¦**ã€‚é€šè¿‡å®šä¹‰äº†ä¸€ä¸ªæ‰©æ•£æ­¥éª¤çš„`é©¬å°”å¯å¤«é“¾`ï¼Œä»¥ç¼“æ…¢åœ°å°†éšæœºå™ªå£°æ·»åŠ åˆ°æ•°æ®ä¸­ï¼Œç„¶åå­¦ä¹ åè½¬æ‰©æ•£è¿‡ç¨‹ä»¥ä»å™ªå£°ä¸­æ„å»ºæ‰€éœ€çš„æ•°æ®æ ·æœ¬ã€‚
- å‘å¸ƒDALLÂ·Eçš„15ä¸ªæœˆåï¼ŒOpenAIåœ¨ä»Šå¹´æ˜¥å¤©å¸¦äº†ç»­ä½œDALLÂ·E 2ï¼Œä»¥å…¶æ›´åŠ æƒŠè‰³çš„æ•ˆæœå’Œä¸°å¯Œçš„å¯ç©æ€§è¿…é€Ÿå é¢†äº†å„å¤§AIç¤¾åŒºçš„å¤´æ¡ã€‚è¿‘å¹´æ¥ï¼Œéšç€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ã€æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion modelsï¼‰çš„å‡ºç°ï¼Œæ·±åº¦å­¦ä¹ å·²å‘ä¸–äººå±•ç°å…¶å¼ºå¤§çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼›åŠ ä¸ŠGPT-3ã€BERTç­‰NLPæ¨¡å‹çš„æˆåŠŸï¼Œäººç±»æ­£é€æ­¥æ‰“ç ´æ–‡æœ¬å’Œå›¾åƒçš„ä¿¡æ¯ç•Œé™ã€‚
- DALLÂ·E 2ä¸­ï¼Œåªéœ€è¾“å…¥ç®€å•çš„æ–‡æœ¬ï¼ˆpromptï¼‰ï¼Œå®ƒå°±å¯ä»¥ç”Ÿæˆå¤šå¼ 1024*1024çš„é«˜æ¸…å›¾åƒã€‚è¿™äº›å›¾åƒç”šè‡³å¯ä»¥å°†ä¸åˆå¸¸ç†çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä»¥è¶…ç°å®ä¸»ä¹‰çš„å½¢å¼åˆ›é€ å‡ºå¤©é©¬è¡Œç©ºçš„è§†è§‰æ•ˆæœï¼Œä¾‹å¦‚å›¾1ä¸­â€œå†™å®é£æ ¼çš„éª‘é©¬çš„å®‡èˆªå‘˜ï¼ˆAn astronaut riding a horse in a photorealistic styleï¼‰â€ã€‚

ã€2022-8-31ã€‘è‹å‰‘æ—çš„[ç”Ÿæˆæ‰©æ•£æ¨¡å‹æ¼«è°ˆ](https://kexue.fm/archives/9119)
- ç”Ÿæˆæ¨¡å‹ä¸­ï¼ŒVAEã€GANâ€œå¦‚é›·è´¯è€³â€ï¼Œè¿˜æœ‰ä¸€äº›æ¯”è¾ƒå°ä¼—çš„é€‰æ‹©ï¼Œå¦‚flowæ¨¡å‹ã€VQ-VAEç­‰ï¼Œé¢‡æœ‰äººæ°”ï¼Œå°¤å…¶æ˜¯VQ-VAEåŠå…¶å˜ä½“VQ-GANï¼Œè¿‘æœŸå·²ç»é€æ¸å‘å±•åˆ°â€œå›¾åƒçš„Tokenizerâ€çš„åœ°ä½ï¼Œç”¨æ¥ç›´æ¥è°ƒç”¨NLPçš„å„ç§é¢„è®­ç»ƒæ–¹æ³•ã€‚
- é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæœ¬æ¥æ›´å°ä¼—çš„é€‰æ‹©â€”â€”`æ‰©æ•£æ¨¡å‹`ï¼ˆDiffusion Modelsï¼‰â€”â€”æ­£åœ¨ç”Ÿæˆæ¨¡å‹é¢†åŸŸâ€œå¼‚å†›çªèµ·â€ï¼Œå½“å‰æœ€å…ˆè¿›çš„ä¸¤ä¸ªæ–‡æœ¬ç”Ÿæˆå›¾åƒâ€”â€” OpenAI çš„ `DALLÂ·E 2` å’Œ Googleçš„`Imagen`ï¼Œéƒ½æ˜¯åŸºäº`æ‰©æ•£æ¨¡å‹`æ¥å®Œæˆçš„ã€‚

ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„å¤§ç«ï¼Œå§‹äº2020å¹´æ‰€æå‡ºçš„[DDPM](https://arxiv.org/abs/2006.11239)ï¼ˆDenoising Diffusion Probabilistic Modelï¼‰ï¼Œè™½ç„¶ä¹Ÿç”¨äº†â€œ**æ‰©æ•£æ¨¡å‹**â€è¿™ä¸ªåå­—ï¼Œä½†äº‹å®ä¸Šé™¤äº†é‡‡æ ·è¿‡ç¨‹çš„å½¢å¼æœ‰ä¸€å®šçš„ç›¸ä¼¼ä¹‹å¤–ï¼ŒDDPMä¸ä¼ ç»ŸåŸºäº`æœ—ä¹‹ä¸‡`æ–¹ç¨‹é‡‡æ ·çš„æ‰©æ•£æ¨¡å‹å®Œå…¨ä¸ä¸€æ ·ï¼Œä¸€ä¸ªæ–°çš„èµ·ç‚¹ã€æ–°çš„ç¯‡ç« ã€‚

ã€2024-2-13ã€‘[æ·±å…¥ç†è§£3Dæ‰©æ•£æ¨¡å‹](https://www.toutiao.com/article/7326786220804047396)

æ‰©æ•£è¿‡ç¨‹å…·æœ‰å‘å›¾åƒæ·»åŠ å™ªå£°çš„æ­£å‘è¿‡ç¨‹å’Œä»å›¾åƒä¸­å»é™¤å™ªå£°çš„åå‘è¿‡ç¨‹ã€‚
- `å™ªå£°å›¾åƒ` = a â‹… `å™ªå£°è¾ƒå°çš„å›¾åƒ` + b â‹… `å™ªå£°`
- `å™ªå£°è¾ƒå°çš„å›¾åƒ` = (`å™ªå£°å›¾åƒ` - bâ‹… `å™ªå£°`)/a
- abæ˜¯å¸¸æ•°, æ‰€æœ‰ `å›¾åƒ`=ï¼ˆ`å™ªå£°å›¾åƒ` - b'Â·`å™ªå£°`ï¼‰/a'

ä¸»è¦æ­¥éª¤
- ä»çº¯å™ªå£°å¼€å§‹ä½œä¸ºå™ªå£°å›¾åƒ
- ä½¿ç”¨æ¨¡å‹é¢„æµ‹å™ªå£°ï¼Œå°†å›¾åƒæ¨å‘å™ªå£°è¾ƒå°‘çš„å›¾åƒ
- è¿›è¡Œä¸Šè¿°è®¡ç®—ä»¥è·å¾—å™ªå£°è¾ƒå°‘çš„å›¾åƒ


### æ•™ç¨‹


è§†é¢‘
- [æ‰©æ•£æ¨¡å‹çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå¯ä»¥ç”¨å®ƒç”Ÿæˆå›¾ç‰‡ã€è§†é¢‘ã€éŸ³ä¹ç­‰å†…å®¹ï¼Ÿ](https://www.bilibili.com/video/BV1fS7nznEUf/)
 

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114595750485272&bvid=BV1fS7nznEUf&cid=30226189134&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>


ã€2025-7-31ã€‘[AIå¦‚ä½•ä»â€œå™ªå£°â€ä¸­åˆ›é€ ç°å®ï¼šæ­ç§˜æ‰©æ•£æ¨¡å‹èƒŒåçš„åŸç†](https://www.bilibili.com/video/BV14J81zwEBC)

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114948139127983&bvid=BV14J81zwEBC&cid=31404656529&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>


### SD å¯è§†åŒ–

ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹ï¼Ÿ

æ‰©æ•£æ˜¯å‘ç”Ÿåœ¨ç²‰çº¢è‰²å›¾åƒä¿¡æ¯ç”Ÿæˆå™¨ç»„ä»¶å†…éƒ¨çš„è¿‡ç¨‹ã€‚ è¯¥ç»„ä»¶çš„è¾“å…¥ä¸ºç”¨äºè¡¨ç¤ºè¾“å…¥æ–‡æœ¬ä¿¡æ¯çš„ token åµŒå…¥ï¼Œå’Œä¸€ä¸ªèµ·å§‹çš„éšæœºå™ªå£°å›¾åƒä¿¡æ¯å¼ é‡ï¼Œç”Ÿæˆä¸€ä¸ªä¿¡æ¯å¼ é‡ï¼Œå›¾åƒè§£ç å™¨ä½¿ç”¨è¯¥ä¿¡æ¯å¼ é‡ç»˜åˆ¶æœ€ç»ˆå›¾åƒã€‚
- ![](https://pic4.zhimg.com/80/v2-ccbbd18c5fc37d3838a14edfc7a6a263_1440w.webp)
- è¿™ä¸ªè¿‡ç¨‹ä»¥å¤šæ­¥å½¢å¼è¿›è¡Œã€‚æ¯æ­¥æ·»åŠ æ›´å¤šçš„ç›¸å…³ä¿¡æ¯ã€‚ä¸ºäº†ç›´è§‚åœ°ç†è§£æ•´ä¸ªè¿‡ç¨‹ï¼Œå°†éšæœºæ½œå±‚å¼ é‡ï¼ˆlatentï¼‰ä¼ é€’ç»™è§†è§‰è§£ç å™¨ï¼Œçœ‹å®ƒæ˜¯å¦è½¬æ¢ä¸ºéšæœºè§†è§‰å™ªå£°ã€‚
- ![](https://pic2.zhimg.com/80/v2-41cdf8da7fa1c7a5b708459628403f7d_1440w.webp)
- æ‰©æ•£è¿‡ç¨‹æœ‰å¤šæ­¥ï¼Œæ¯æ­¥æ“ä½œä¸€ä¸ªè¾“å…¥æ½œå±‚å¼ é‡ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„æ½œå±‚å¼ é‡ã€‚æ–°çš„å¼ é‡æ›´å¥½åœ°é›†æˆäº†è¾“å…¥æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œå…¶ä¸­è§†è§‰ä¿¡æ¯æ¥è‡ªæ¨¡å‹è®­ç»ƒé›†ä¸­çš„å›¾åƒã€‚
- ![](https://pic2.zhimg.com/80/v2-475a085b3b302d3e674195e90479ce01_1440w.webp)
- ![](https://pic2.zhimg.com/80/v2-e3cae41c28f1f0dd34f30bd9ef9cb4fd_1440w.webp)

è¯¦è§åŸæ–‡:[illustrated-stable-diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)

ç«™ç‚¹ [poloclub](https://poloclub.github.io/) æä¾›å¤šç§æ¨¡å‹åŸç†å¯è§†åŒ–ï¼ŒåŒ…å«æ‰©æ•£æ¨¡å‹
- [Demo](https://poloclub.github.io/diffusion-explainer/) Learn how Stable Diffusion transfo
- ![](https://poloclub.github.io/diffusion-explainer/assets/gif/irr.gif)

## æ‰©æ•£æ¨¡å‹æ¦‚è§ˆ

ã€2023-4-5ã€‘æ‰©æ•£æ¨¡å‹(Diffusion Model)é¦–ç¯‡[ç»¼è¿°](https://zhuanlan.zhihu.com/p/562389931) 
- [Diffusion Models: A Comprehensive Survey of Methods and Applications](https://arxiv.org/abs/2209.00796)
- åŠ å·å¤§å­¦&Google Researchçš„Ming-Hsuan Yangã€æ–¯å¦ç¦å¤§å­¦ï¼ˆOpenAIï¼‰çš„Yang Songï¼ˆScore SDEä¸€ä½œï¼‰ã€åŒ—äº¬å¤§å­¦å´”æ–Œå®éªŒå®¤ä»¥åŠCMUã€UCLAã€è’™ç‰¹åˆ©å°”Milaç ”ç©¶é™¢ç­‰ä¼—ç ”ç©¶å›¢é˜Ÿï¼Œé¦–æ¬¡å¯¹ç°æœ‰çš„æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼ˆdiffusion modelï¼‰è¿›è¡Œäº†å…¨é¢çš„æ€»ç»“åˆ†æï¼Œä»diffusion modelç®—æ³•ç»†åŒ–åˆ†ç±»ã€å’Œå…¶ä»–äº”å¤§ç”Ÿæˆæ¨¡å‹çš„å…³è”ä»¥åŠåœ¨ä¸ƒå¤§é¢†åŸŸä¸­çš„åº”ç”¨ç­‰æ–¹é¢å±•å¼€ï¼Œæœ€åæå‡ºäº†diffusion modelçš„ç°æœ‰limitationå’Œæœªæ¥çš„å‘å±•æ–¹å‘ã€‚

`æ‰©æ•£æ¨¡å‹`ï¼ˆdiffusion modelsï¼‰æ˜¯æ·±åº¦ç”Ÿæˆæ¨¡å‹ä¸­æ–°çš„SOTAã€‚å…¶ä»–çš„äº”ç§ç”Ÿæˆæ¨¡å‹ GANï¼ŒVAEï¼ŒAutoregressive model, Normalizing flow, Energy-based modelã€‚
- æ‰©æ•£æ¨¡å‹åœ¨å›¾ç‰‡ç”Ÿæˆä»»åŠ¡ä¸­è¶…è¶Šäº†åŸSOTA:GANï¼Œå¹¶ä¸”åœ¨è¯¸å¤šåº”ç”¨é¢†åŸŸéƒ½æœ‰å‡ºè‰²çš„è¡¨ç°ï¼Œå¦‚è®¡ç®—æœºè§†è§‰ï¼ŒNLPã€æ³¢å½¢ä¿¡å·å¤„ç†ã€å¤šæ¨¡æ€å»ºæ¨¡ã€åˆ†å­å›¾å»ºæ¨¡ã€æ—¶é—´åºåˆ—å»ºæ¨¡ã€å¯¹æŠ—æ€§å‡€åŒ–ç­‰ã€‚
- æ­¤å¤–ï¼Œæ‰©æ•£æ¨¡å‹ä¸å…¶ä»–ç ”ç©¶é¢†åŸŸæœ‰ç€å¯†åˆ‡çš„è”ç³»ï¼Œå¦‚ç¨³å¥å­¦ä¹ ã€è¡¨ç¤ºå­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€‚ç„¶è€Œï¼ŒåŸå§‹çš„æ‰©æ•£æ¨¡å‹ä¹Ÿæœ‰ç¼ºç‚¹ï¼Œå®ƒçš„é‡‡æ ·é€Ÿåº¦æ…¢ï¼Œé€šå¸¸éœ€è¦æ•°åƒä¸ªè¯„ä¼°æ­¥éª¤æ‰èƒ½æŠ½å–ä¸€ä¸ªæ ·æœ¬ï¼›å®ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ— æ³•å’ŒåŸºäºä¼¼ç„¶çš„æ¨¡å‹ç›¸æ¯”ï¼›å®ƒæ³›åŒ–åˆ°å„ç§æ•°æ®ç±»å‹çš„èƒ½åŠ›è¾ƒå·®ã€‚å¦‚ä»Šå¾ˆå¤šç ”ç©¶å·²ç»ä»å®é™…åº”ç”¨çš„è§’åº¦è§£å†³ä¸Šè¿°é™åˆ¶åšå‡ºäº†è®¸å¤šåŠªåŠ›ï¼Œæˆ–ä»ç†è®ºè§’åº¦å¯¹æ¨¡å‹èƒ½åŠ›è¿›è¡Œäº†åˆ†æã€‚
- ![](https://pic1.zhimg.com/80/v2-3ce40580db330cd3d35fb4db24aa2438_1440w.webp)

ã€2024-5-27ã€‘ MIT åŠ©ç†æ•™æˆ Song Han çš„ 100å¤šé¡µ [DDPM ä»‹ç» ppt](https://www.dropbox.com/scl/fi/q8y9ap7mlucmiimyh3zl5/lec16.pdf)

<object type="application/pdf" data="https://www.dropbox.com/scl/fi/q8y9ap7mlucmiimyh3zl5/lec16.pdf"
           id="review" style="width:100%;  height:800px; margin-top:0px;  margin-left:0px" >
</object>

### è®ºæ–‡

- ã€2022-9-20ã€‘[æ‰©æ•£æ¨¡å‹å¤§å…¨](https://github.com/heejkoo/Awesome-Diffusion-Models)
- hugginface æ‰©æ•£æ¨¡å‹åŒ…:[diffusers](https://github.com/huggingface/diffusers/tree/main/examples)ï¼Œ[colabç¬”è®°](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb#scrollTo=13NnZ4rVioLs)
- demo: [stable-diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)

ç»å…¸è®ºæ–‡
- ã€ŠDeep Unsupervised Learning using Nonequilibrium Thermodynamicsã€‹ 2015å¹´ æ‰©æ•£æ¨¡å‹èµ·æº
- ã€ŠDenoising Diffusion Probabilistic Modelsã€‹ 2020å¹´ æ‰©æ•£æ¨¡å‹å…´èµ·, å¯¹åº”[pytorchå®ç°](https://github.com/lucidrains/denoising-diffusion-pytorch)
- ã€ŠImproved Denoising Diffusion Probabilistic Modelsã€‹ 2021å¹´ ç¬¬äºŒç¯‡è®ºæ–‡çš„æ”¹è¿›, å¯¹åº”[pytorchå®ç°](https://github.com/openai/improved-diffusion)

æŠ€æœ¯æ–‡ç« 
- [The recent rise of diffusion-based models](https://maciejdomagala.github.io/generative_models/2022/06/06/The-recent-rise-of-diffusion-based-models.html) å¯ä»¥äº†è§£åˆ°æ‰©æ•£æ¨¡å‹è¿‘å¹´æ¯”è¾ƒç»å…¸çš„åº”ç”¨
- [Introduction to Diffusion Models for Machine Learning](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/) ä»ä¸­å¯ä»¥äº†è§£åˆ°ä¸€ä¸ªå®ç°æ‰©æ•£æ¨¡å‹çš„åº“denoising_diffusion_pytorchï¼Œåšå®¢ä¸­æœ‰ä½¿ç”¨æ¡ˆä¾‹
- [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) ä¹Ÿæ˜¯æ‰©æ•£æ¨¡å‹çš„ä¸€ä¸ªç†è®ºä»‹ç»åšå®¢ï¼Œæ¨å¯¼æŒºè¯¦ç»†çš„
- [Diffusion Models as a kind of VAE](https://angusturner.github.io/generative_models/2021/06/29/diffusion-probabilistic-models-I.html) æ¢ç©¶äº†VAEå’Œæ‰©æ•£æ¨¡å‹çš„è”ç³»
- [The Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion) æ‰©æ•£æ¨¡å‹ç†è®ºå’Œä»£ç å®ç°ï¼Œä»£ç æˆ‘è¿›è¡Œç†è§£åŠ äº†æ³¨é‡Šä¸ç†è®ºå¯¹åº”ï¼Œæ–¹ä¾¿å¤§å®¶ç†è§£
- [An introduction to Diffusion Probabilistic Models](https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html) ä¹Ÿæ˜¯ä¸€ä¸ªä»‹ç»æ€§åšå®¢ï¼Œå…¬å¼ä¹Ÿå¾ˆå·¥æ•´

[æ‰©æ•£æ¨¡å‹åŸç†å’Œpytorchä»£ç å®ç°åˆå­¦èµ„æ–™æ±‡æ€»](https://blog.csdn.net/qq_44941689/article/details/126513283)

### æ¨¡å‹

æ¨¡å‹ä¸‹è½½
- [novelAI](https://huggingface.co/acheong08/secretAI/resolve/main/stableckpt/animefull-final-pruned/model.ckpt
stable_diffusion)
- [waifu_diffusion](https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt)
- [sd-v1-5](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt)
- [sd-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt)

SDæ¨¡å‹çš„ä¸»ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å‹:
- `autoencoder`:encoderå°†å›¾åƒå‹ç¼©åˆ°latentç©ºé—´ï¼Œè€Œdecoderå°†latentè§£ç ä¸ºå›¾åƒï¼›
- `CLIP text encoder`:æå–è¾“å…¥textçš„text embeddingsï¼Œé€šè¿‡cross attentionæ–¹å¼é€å…¥æ‰©æ•£æ¨¡å‹çš„UNetä¸­ä½œä¸ºconditionï¼›
  - SDé‡‡ç”¨CLIP text encoderæ¥å¯¹è¾“å…¥textæå–text embeddingsï¼Œå…·ä½“çš„æ˜¯é‡‡ç”¨ç›®å‰OpenAIæ‰€å¼€æºçš„æœ€å¤§CLIPæ¨¡å‹:clip-vit-large-patch14ï¼Œè¿™ä¸ªCLIPçš„text encoderæ˜¯ä¸€ä¸ªtransformeræ¨¡å‹ï¼ˆåªæœ‰encoderæ¨¡å—ï¼‰:å±‚æ•°ä¸º12ï¼Œç‰¹å¾ç»´åº¦ä¸º768ï¼Œæ¨¡å‹å‚æ•°å¤§å°æ˜¯123Mã€‚
- `UNet`:æ‰©æ•£æ¨¡å‹çš„ä¸»ä½“ï¼Œç”¨æ¥å®ç°æ–‡æœ¬å¼•å¯¼ä¸‹çš„latentç”Ÿæˆã€‚
  - SDçš„æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ª860Mçš„UNet
  - encoderéƒ¨åˆ†åŒ…æ‹¬3ä¸ªCrossAttnDownBlock2Dæ¨¡å—å’Œ1ä¸ªDownBlock2Dæ¨¡å—ï¼Œè€Œdecoderéƒ¨åˆ†åŒ…æ‹¬1ä¸ªUpBlock2Dæ¨¡å—å’Œ3ä¸ªCrossAttnUpBlock2Dæ¨¡å—ï¼Œä¸­é—´è¿˜æœ‰ä¸€ä¸ªUNetMidBlock2DCrossAttnæ¨¡å—ã€‚
  - encoderå’Œdecoderä¸¤ä¸ªéƒ¨åˆ†æ˜¯å®Œå…¨å¯¹åº”çš„ï¼Œä¸­é—´å­˜åœ¨skip connectionã€‚
  - æ³¨æ„3ä¸ªCrossAttnDownBlock2Dæ¨¡å—æœ€åå‡æœ‰ä¸€ä¸ª2xçš„downsampleæ“ä½œï¼Œè€ŒDownBlock2Dæ¨¡å—æ˜¯ä¸åŒ…å«ä¸‹é‡‡æ ·çš„ã€‚

æ¨¡å‹ç»“æ„
- ![](https://pic1.zhimg.com/80/v2-fddf45ed17a509336d1550833a257684_1440w.webp?source=1940ef5c)

å¯¹äºSDæ¨¡å‹
- autoencoder æ¨¡å‹å‚æ•°å¤§å°ä¸º84M
- CLIP text encoder æ¨¡å‹å¤§å°ä¸º123M
- è€Œ UNet å‚æ•°å¤§å°ä¸º 860M

æ‰€ä»¥ SD æ¨¡å‹æ€»å‚æ•°é‡çº¦ä¸º 1Bã€‚
- [è¯¦è§](https://www.zhihu.com/question/577079491/answer/3032168255?utm_campaign=shareopn&utm_medium=social&utm_oi=27211553832960&utm_psn=1649776451506360320&utm_source=wechat_session)


## DLM æ‰©æ•£è¯­è¨€æ¨¡å‹

æ‰©æ•£è¯­è¨€æ¨¡å‹ 

è¯¦è§ç«™å†…ä¸“é¢˜: [æ‰©æ•£è¯­è¨€æ¨¡å‹](diffusion_lm)




## å†å²

### ç†è®ºåŸºç¡€

#### 2020 DDPM å¥ åŸº

2020 å¹´ï¼ŒHo ç­‰äººæå‡º`å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹`(Denoising Diffusion Probabilistic Models, `DDPM`)ï¼Œ é¦–æ¬¡ç³»ç»Ÿæ„å»ºäº†æ‰©æ•£æ¨¡å‹çš„ç†è®ºæ¡†æ¶ã€‚

DDPM çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ•°æ®ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºä¸€ä¸ªä¸¤é˜¶æ®µçš„`é©¬å°”å¯å¤«é“¾`ï¼š
- **å‰å‘**æ‰©æ•£è¿‡ç¨‹ï¼šé€æ­¥å‘åˆå§‹æ•°æ®ä¸­æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œç›´è‡³æ•°æ®åˆ†å¸ƒå˜ä¸ºæ ‡å‡†é«˜æ–¯åˆ†å¸ƒ
- **åå‘**å»å™ªè¿‡ç¨‹ï¼šä»çº¯å™ªå£°å¼€å§‹ï¼Œé€šè¿‡å­¦ä¹ çš„å»å™ªæ¨¡å‹é€æ­¥æ¢å¤åŸå§‹æ•°

DDPM é‡è¦è´¡çŒ®åœ¨äºè¯æ˜äº†æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸ GAN ç›¸åª²ç¾çš„å›¾åƒè´¨é‡ï¼ŒåŒæ—¶è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œè¿™ä¸ºåç»­æ‰©æ•£æ¨¡å‹çš„å‘å±•å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚

#### 2021 DDIM

DDIMï¼šç¡®å®šæ€§é‡‡æ ·çš„çªç ´

2021 å¹´ï¼ŒSong ç­‰äººæå‡º`å»å™ªæ‰©æ•£éšå¼æ¨¡å‹` (Denoising Diffusion Implicit Models, `DDIM`) å¯¹ DDPM è¿›è¡Œäº†é‡è¦æ”¹è¿›ã€‚

DDIM æ ¸å¿ƒåˆ›æ–°
- å°†æ‰©æ•£è¿‡ç¨‹æ¨å¹¿åˆ°**éé©¬å°”å¯å¤«é“¾**ï¼Œå®ç°äº†ç¡®å®šæ€§é‡‡æ ·è·¯å¾„ï¼Œä»è€Œå¤§å¹…æé«˜äº†æ¨ç†æ•ˆç‡ã€‚

DDIM ä¸»è¦è´¡çŒ®ï¼š
- å®ç°äº†**ç¡®å®šæ€§é‡‡æ ·**ï¼Œå¤§å¹…å‡å°‘äº†ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬æ‰€éœ€çš„æ­¥æ•° (20 - 50 æ­¥å³å¯)
- è¯æ˜äº†æ‰©æ•£æ¨¡å‹å¯ä»¥è¿›è¡Œ**éšå˜é‡æ’å€¼**ï¼Œæ”¯æŒå›¾åƒç¼–è¾‘ç­‰é«˜çº§åŠŸèƒ½
- ä¸ºåç»­åŠ é€Ÿé‡‡æ ·æ–¹æ³•å¥ å®šäº†åŸºç¡€

DDIM ä½¿æ‰©æ•£æ¨¡å‹åœ¨ä¿æŒç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œæ¨ç†é€Ÿåº¦å¾—åˆ°æ˜¾è‘—æå‡ï¼Œä¸ºå…¶å®ç”¨åŒ–åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚

### åŠ é€Ÿé‡‡æ ·ä¸æ•ˆç‡æå‡

#### 2021 åŸºäºéšæœºå¾®åˆ†æ–¹ç¨‹çš„ç»Ÿä¸€æ¡†æ¶

2021 å¹´ï¼ŒSong ç­‰æå‡ºäº†åŸºäº`éšæœºå¾®åˆ†æ–¹ç¨‹` (SDE) çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå°†æ‰©æ•£æ¨¡å‹ä¸åˆ†æ•°åŒ¹é…æ–¹æ³•ç»Ÿä¸€èµ·æ¥ã€‚
- è®ºæ–‡ã€ŠScore-Based Generative Modeling through Stochastic Differential Equationsã€‹

è¿™ä¸€æ¡†æ¶çš„æ ¸å¿ƒè´¡çŒ®ï¼š
- å°†æ‰©æ•£è¿‡ç¨‹å»ºæ¨¡ä¸º**è¿ç»­æ—¶é—´**çš„éšæœºå¾®åˆ†æ–¹ç¨‹ï¼Œä½¿å¾— DDPM å¯ä»¥è¢«è§†ä¸º SDE çš„ç¦»æ•£åŒ–è¿‘ä¼¼
- æå‡ºäº†**æ¦‚ç‡æµ**å¸¸å¾®åˆ†æ–¹ç¨‹ (Probability Flow ODE)ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„é‡‡æ ·è¿‡ç¨‹

ä¸ºè®¾è®¡æ›´é«˜æ•ˆçš„é‡‡æ ·æ–¹æ³•æä¾›äº†ç†è®ºåŸºç¡€

è¿™ä¸€æ¡†æ¶çš„é‡è¦æ€§: ä¸ä»…åŠ æ·±äº†å¯¹æ‰©æ•£æ¨¡å‹æœ¬è´¨çš„ç†è§£ï¼Œè¿˜ä¸ºåç»­åŠ é€Ÿé‡‡æ ·æ–¹æ³•æä¾›äº†ç†è®ºæŒ‡å¯¼ï¼Œä½¿å¾—ç ”ç©¶è€…å¯ä»¥ä»è¿ç»­æ—¶é—´çš„è§’åº¦è®¾è®¡æ›´é«˜æ•ˆçš„ç¦»æ•£åŒ–æ–¹æ¡ˆã€‚

#### 2022 æ½œç©ºé—´æ‰©æ•£æ¨¡å‹ä¸ Stable Diffusion

2022 å¹´ï¼ŒRombach ç­‰äººæå‡º`æ½œç©ºé—´æ‰©æ•£æ¨¡å‹` (Latent Diffusion Models, LDM) æ˜¯æ‰©æ•£æ¨¡å‹å‘å±•å†ç¨‹ä¸­çš„åˆä¸€é‡è¦é‡Œç¨‹ç¢‘ã€‚

LDM æ ¸å¿ƒåˆ›æ–°: å°†æ‰©æ•£è¿‡ç¨‹ä»**åƒç´ **ç©ºé—´è½¬ç§»åˆ°**ä½ç»´æ½œ**ç©ºé—´ï¼Œä»è€Œå¤§å¹…é™ä½è®¡ç®—æˆæœ¬ï¼š
- å¼•å…¥å˜åˆ†è‡ªç¼–ç å™¨ (VAE) å°†é«˜ç»´å›¾åƒå‹ç¼©åˆ°ä½ç»´æ½œç©ºé—´
- åœ¨æ½œç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œæ˜¾è‘—å‡å°‘è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚
- ç»“åˆ CLIP æ–‡æœ¬ç¼–ç å™¨ï¼Œå®ç°äº†é«˜è´¨é‡çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ

LDM çš„é‡è¦åº”ç”¨æ˜¯ Stable Diffusionï¼Œè¿™ä¸€å¼€æºæ¨¡å‹ä½¿å¾—é«˜è´¨é‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæˆä¸ºå¯èƒ½ï¼Œæå¤§åœ°æ¨åŠ¨äº† AIGC æŠ€æœ¯çš„æ™®åŠã€‚

Stable Diffusion çš„å…³é”®ä¼˜åŠ¿åœ¨äºï¼š
- åªéœ€ 4GB æ˜¾å­˜å³å¯å¤„ç† 512Ã—512 å›¾åƒç”Ÿæˆ
- ç”Ÿæˆé€Ÿåº¦å¤§å¹…æå‡ï¼Œé€‚ç”¨äºå¹¿æ³›çš„è®¡ç®—è®¾å¤‡
- å¼€æºç”Ÿæ€ä¿ƒè¿›äº† AIGC åº”ç”¨çš„å¿«é€Ÿå‘å±•

LDM æ ‡å¿—ç€æ‰©æ•£æ¨¡å‹ä»å­¦æœ¯ç ”ç©¶èµ°å‘äº§ä¸šåº”ç”¨çš„é‡è¦è½¬æŠ˜ç‚¹ï¼Œä¸ºåç»­æ›´å¤šå®ç”¨åŒ–åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚

#### 2022 DPM - Solverï¼šé«˜é˜¶ ODE æ±‚è§£å™¨åŠ é€Ÿ

2022 å¹´ï¼ŒLu ç­‰äººæå‡º`æ‰©æ•£æ¦‚ç‡æ¨¡å‹æ±‚è§£å™¨` (Diffusion Probabilistic Model Solver, DPM - Solver) è¿›ä¸€æ­¥æé«˜äº†æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·æ•ˆç‡ã€‚

DPM - Solver æ ¸å¿ƒæ€æƒ³: å°†åå‘å»å™ªè¿‡ç¨‹è§†ä¸ºä¸€ä¸ªå¸¸å¾®åˆ†æ–¹ç¨‹ (ODE)**ï¼Œå¹¶åº”ç”¨é«˜é˜¶ ODE æ±‚è§£å™¨æ¥åŠ é€Ÿé‡‡æ ·ï¼š
- æå‡ºäº†åŸºäº Runge - Kutta æ–¹æ³•çš„é«˜é˜¶æ±‚è§£å™¨ï¼Œæ˜¾è‘—å‡å°‘äº†ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬æ‰€éœ€çš„æ­¥æ•°
- è¯æ˜äº†ä»…éœ€ 10 - 20 æ­¥å³å¯ç”Ÿæˆä¸ DDPM ç›¸å½“è´¨é‡çš„æ ·æœ¬
- æ”¯æŒè‡ªé€‚åº”æ­¥é•¿æ§åˆ¶ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡

DPM - Solver çš„é‡è¦æ€§åœ¨äºï¼Œä¸ä»…å¤§å¹…æé«˜äº†æ‰©æ•£æ¨¡å‹çš„**æ¨ç†é€Ÿåº¦**ï¼Œè¿˜ä½¿å¾—æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿé€‚åº”å®æ—¶åº”ç”¨åœºæ™¯ï¼Œå¦‚äº¤äº’å¼å›¾åƒç¼–è¾‘å’Œå®æ—¶è§†é¢‘ç”Ÿæˆã€‚

### å¯æ§ç”Ÿæˆä¸å¤šæ¨¡æ€æ‰©å±•

####  æ— åˆ†ç±»å™¨å¼•å¯¼æŠ€æœ¯

2022 å¹´ï¼ŒHo å’Œ Salimans æå‡º**æ— åˆ†ç±»å™¨å¼•å¯¼** (Classifier - Free Guidance) æŠ€æœ¯æ˜¯æé«˜æ‰©æ•£æ¨¡å‹å¯æ§æ€§çš„å…³é”®çªç ´ã€‚

è¿™ä¸€æŠ€æœ¯çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- æ— éœ€é¢å¤–è®­ç»ƒåˆ†ç±»å™¨ï¼Œç›´æ¥è®­ç»ƒæ¡ä»¶å’Œæ— æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„è”åˆæ¨¡å‹
- é€šè¿‡åœ¨æ¨ç†æ—¶è°ƒæ•´æ¡ä»¶ä¿¡å·çš„æƒé‡ï¼Œæ§åˆ¶ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§
- å®ç°äº†å¯¹ç”Ÿæˆè¿‡ç¨‹çš„ç²¾ç»†æ§åˆ¶ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„ç®€æ´æ€§

æ„ä¹‰
- æ‰©æ•£æ¨¡å‹åœ¨ä¸å¢åŠ æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå®ç°å¯¹ç”Ÿæˆè¿‡ç¨‹çš„æœ‰æ•ˆæ§åˆ¶ï¼Œä¸ºåç»­å¯æ§ç”Ÿæˆæ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚
- DALLãƒ»E 2ã€Stable Diffusion ç­‰çŸ¥åæ¨¡å‹å‡é‡‡ç”¨äº†è¿™ä¸€æŠ€æœ¯ã€‚

#### 2023 ControlNet æŠ€æœ¯

2023 å¹´ï¼ŒZhang ç­‰äººæå‡º ControlNet æŠ€æœ¯è¿›ä¸€æ­¥å¢å¼ºäº†æ‰©æ•£æ¨¡å‹çš„å¯æ§æ€§ã€‚

ControlNet çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ï¼š
- é€šè¿‡é¢å¤–çš„æ§åˆ¶ä¿¡å· (å¦‚è¾¹ç¼˜å›¾ã€æ·±åº¦å›¾ã€å§¿æ€å›¾ç­‰) ç²¾ç»†è°ƒæ§ç”Ÿæˆè¿‡ç¨‹
- å¼•å…¥é›¶åˆå§‹åŒ–æŠ€æœ¯ï¼Œä½¿å¾—é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥åœ¨ä¸å¤§é‡é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹æ¥å—æ–°çš„æ§åˆ¶ä¿¡å·
- å®ç°äº†å§¿åŠ¿æ§åˆ¶ã€ç»“æ„ä¿æŒç­‰é«˜çº§ç¼–è¾‘åŠŸèƒ½

ControlNet çš„é‡è¦è´¡çŒ®
- ä¸ºæ‰©æ•£æ¨¡å‹æä¾›äº†ä¸€ç§çµæ´»çš„æ¡ä»¶æ§åˆ¶æœºåˆ¶ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥æ›´ç²¾ç¡®åœ°æ§åˆ¶ç”Ÿæˆç»“æœï¼Œæå¤§åœ°æ‰©å±•äº†æ‰©æ•£æ¨¡å‹çš„åº”ç”¨åœºæ™¯ã€‚ä»è‰ºæœ¯åˆ›ä½œåˆ°å»ºç­‘è®¾è®¡ï¼ŒControlNet éƒ½å±•ç°äº†å¼ºå¤§çš„åº”ç”¨æ½œåŠ›ã€‚

#### çº§è”æ‰©æ•£æ¨¡å‹ä¸é«˜åˆ†è¾¨ç‡ç”Ÿæˆ

2022 - 2023 å¹´ï¼ŒGoogle ç ”ç©¶å›¢é˜Ÿå¼€å‘çš„ Imagen å’Œ eDiff - I æ¨¡å‹ä»£è¡¨äº†çº§è”æ‰©æ•£æ¨¡å‹çš„é‡è¦è¿›å±•ã€‚è¿™äº›æ¨¡å‹çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ï¼š
- é‡‡ç”¨çº§è”æ¶æ„ï¼Œåˆ†é˜¶æ®µæé«˜å›¾åƒåˆ†è¾¨ç‡ (å¦‚ 64â†’256â†’1024)
- ç»“åˆ T5 - XXL æ–‡æœ¬ç¼–ç å™¨ï¼Œå®ç°å¯¹å¤æ‚è¯­ä¹‰çš„ç²¾ç¡®ç†è§£
- é€šè¿‡å¤šé˜¶æ®µç”Ÿæˆï¼Œæ˜¾è‘—æé«˜äº†é«˜åˆ†è¾¨ç‡å›¾åƒçš„ç”Ÿæˆè´¨é‡

Imagen å’Œ eDiff - I çš„ä¸»è¦è´¡çŒ®åœ¨äºï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆæé«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ä¸”åœ¨è¯­ä¹‰å‡†ç¡®æ€§å’Œç»†èŠ‚ä¸°å¯Œåº¦æ–¹é¢è¾¾åˆ°äº†æ–°çš„ SOTA æ°´å¹³ã€‚è¿™ä¸€çªç ´ä¸ºæ‰©æ•£æ¨¡å‹åœ¨ä¸“ä¸šè®¾è®¡ã€å½±è§†åˆ¶ä½œç­‰é¢†åŸŸçš„åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚


### è§†é¢‘ä¸ 3D ç”Ÿæˆ

#### è§†é¢‘æ‰©æ•£æ¨¡å‹

2023 - 2024 å¹´ï¼Œè§†é¢‘ç”Ÿæˆé¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ï¼Œå¤šå®¶æœºæ„æ¨å‡ºäº†åŸºäºæ‰©æ•£æ¨¡å‹çš„è§†é¢‘ç”ŸæˆæŠ€æœ¯ã€‚ä»£è¡¨æ€§å·¥ä½œåŒ…æ‹¬ï¼š
- Imagen Video (Google)ï¼šå®ç°äº†æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆï¼Œæ”¯æŒ 1280Ã—768 åˆ†è¾¨ç‡å’Œ 24fps å¸§ç‡
- Make - A - Video (Meta)ï¼šæ— éœ€æˆå¯¹æ•°æ®è®­ç»ƒï¼Œå­¦ä¹ è§†é¢‘åŠ¨æ€å…ˆéªŒ
- CogVideoX - 5Bï¼šé€šè¿‡æ”¹è¿›æ¶æ„è®¾è®¡ï¼Œæé«˜äº†è§†é¢‘ç”Ÿæˆçš„æ—¶ç©ºä¸€è‡´æ€§

ç„¶è€Œï¼Œè§†é¢‘ç”Ÿæˆä»ç„¶é¢ä¸´å¤šé¡¹æŒ‘æˆ˜ï¼š
- è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æº
- æ—¶åºä¸€è‡´æ€§ä¼˜åŒ–å›°éš¾ï¼Œå®¹æ˜“å‡ºç°é—ªçƒå’Œç‰©ä½“æ¼‚ç§»
- é•¿è§†é¢‘ç”Ÿæˆçš„è¿è´¯æ€§é—®é¢˜å°šæœªå®Œå…¨è§£å†³

2025 å¹´ï¼ŒMIT å›¢é˜Ÿæå‡ºçš„æ‰©æ•£å¼ºåˆ¶ Transformer (Diffusion Forcing Transformer, DFoT) ç®—æ³•è§£å†³äº†é•¿è§†é¢‘ç”Ÿæˆçš„æŒ‘æˆ˜ã€‚DFoT é€šè¿‡å†å²å¼•å¯¼ (History Guidance) æœºåˆ¶ï¼Œåœ¨ä¸æ”¹å˜åŸæœ‰æ¶æ„çš„æƒ…å†µä¸‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç¨³å®šç”Ÿæˆ800 å¸§ä»¥ä¸Šçš„è¶…é•¿ç¯‡è§†é¢‘ï¼Œå°†è§†é¢‘ç”Ÿæˆé•¿åº¦æå‡äº†è¿‘ 50 å€ã€‚è¿™ä¸€çªç ´ä½¿å¾—æ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘å†…å®¹åˆ›ä½œé¢†åŸŸçš„åº”ç”¨å‰æ™¯æ›´åŠ å¹¿é˜”ã€‚

### 3D ç”ŸæˆæŠ€æœ¯

2022 - 2024 å¹´ï¼Œæ‰©æ•£æ¨¡å‹åœ¨ 3D ç”Ÿæˆé¢†åŸŸä¹Ÿå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ä»£è¡¨æ€§å·¥ä½œåŒ…æ‹¬ï¼š
- DreamFusion (Google, 2022)ï¼šå®ç°äº†ä»æ–‡æœ¬åˆ° 3D æ¨¡å‹çš„ç”Ÿæˆï¼Œæ— éœ€ 3D æ•°æ®è®­ç»ƒ
- Stable Diffusion 3D (StabilityAI, 2023)ï¼šç»“åˆæ‰©æ•£æ¨¡å‹ä¸æ˜¾å¼ 3D è¡¨ç¤ºï¼Œæé«˜äº† 3D ç”Ÿæˆè´¨é‡
- DiffRFï¼šé€šè¿‡è¾å°„åœºè¡¨ç¤ºï¼Œå®ç°äº†é«˜è´¨é‡çš„ 3D åœºæ™¯ç”Ÿæˆ

2025 å¹´ï¼Œæ¸…åå¤§å­¦å›¢é˜Ÿæå‡ºçš„ VideoScene æ¨¡å‹è¿›ä¸€æ­¥æ‰“é€šäº†è§†é¢‘åˆ° 3D çš„ç”Ÿæˆè·¯å¾„ã€‚VideoScene é‡‡ç”¨ "ä¸€æ­¥å¼" è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ 3D - aware leap flow distillation ç­–ç•¥ï¼Œé€šè¿‡è·³è·ƒå¼è·¨è¶Šå†—ä½™é™å™ªæ­¥éª¤ï¼Œæå¤§åœ°åŠ é€Ÿäº†æ¨ç†è¿‡ç¨‹ã€‚è¿™ä¸€æ¨¡å‹çš„åˆ›æ–°ç‚¹åœ¨äºï¼š
- é‡‡ç”¨ 3D è·ƒè¿æµè’¸é¦ç­–ç•¥ï¼Œç›´æ¥ä»å«æœ‰ä¸°å¯Œ 3D ä¿¡æ¯çš„ç²—ç•¥åœºæ™¯æ¸²æŸ“è§†é¢‘å¼€å§‹ç”Ÿæˆ
- å¼•å…¥åŠ¨æ€é™å™ªç­–ç•¥ï¼Œå……åˆ†åˆ©ç”¨ 3D å…ˆéªŒä¿¡æ¯
- åœ¨ä¿è¯é«˜è´¨é‡çš„åŒæ—¶å¤§å¹…æå‡ç”Ÿæˆæ•ˆç‡ï¼Œå•æ­¥ç”Ÿæˆç»“æœå³å¯åª²ç¾ä¼ ç»Ÿæ–¹æ³• 50 æ­¥çš„æ•ˆæœ

è¿™äº›è¿›å±•è¡¨æ˜ï¼Œæ‰©æ•£æ¨¡å‹åœ¨ 3D å†…å®¹ç”Ÿæˆé¢†åŸŸçš„åº”ç”¨æ½œåŠ›æ­£åœ¨é€æ­¥é‡Šæ”¾ï¼Œæœªæ¥æœ‰æœ›åœ¨æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

### å‰è¨€æŠ€æœ¯

å‰æ²¿æŠ€æœ¯

#### ä¸€è‡´æ€§æ¨¡å‹

2023 å¹´ï¼ŒOpenAI æå‡ºçš„ä¸€è‡´æ€§æ¨¡å‹ (Consistency Models) æ˜¯æ‰©æ•£æ¨¡å‹é¢†åŸŸçš„é‡è¦åˆ›æ–°ã€‚è¿™ä¸€æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³

æå‡ºäº†ä¸€æ­¥ç”Ÿæˆ (1 - Step Sampling) æ–¹æ³•ï¼ŒæŒ‘æˆ˜ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹çš„æ…¢é‡‡æ ·é—®é¢˜

é€šè¿‡è‡ªæ´½æ€§ (Consistency) çº¦æŸï¼Œå®ç°å¿«é€Ÿæ¨ç†

####  æ‰©æ•£ Transformer æ¶æ„

2023 å¹´ï¼ŒMeta å›¢é˜Ÿæå‡ºçš„æ‰©æ•£ Transformer (Diffusion Transformers, DiT) æ˜¯å¯¹ä¼ ç»Ÿ U-Net æ¶æ„çš„é‡è¦æ”¹è¿›ã€‚

DiT çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ï¼š
- ç”¨ Transformer æ›¿ä»£ä¼ ç»Ÿçš„ U - Net ä½œä¸ºæ‰©æ•£æ¨¡å‹çš„éª¨å¹²ç½‘ç»œ
- å¼•å…¥è‡ªé€‚åº”å±‚å½’ä¸€åŒ– (AdaLN) æŠ€æœ¯ï¼Œæœ‰æ•ˆæ•´åˆæ¡ä»¶ä¿¡æ¯
- æé«˜äº†æ¨¡å‹çš„æ‰©å±•æ€§ï¼Œé€‚ç”¨äºè¶…å¤§è§„æ¨¡è®­ç»ƒ (10 äº¿ + å‚æ•°)

DiT çš„æ¶æ„è®¾è®¡ä½¿å¾—æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å…¨å±€ä¾èµ–å…³ç³»ï¼Œæé«˜äº†ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚2025 å¹´ï¼Œç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº†å¤šå°ºåº¦æ‰©æ•£ Transformer (Multi - Scale Diffusion Transformer, MDiT)ï¼Œé€šè¿‡å°† DiT è§†ä¸ºè¯­ä¹‰è‡ªç¼–ç å™¨ï¼Œå®ç°äº† 3 å€çš„æ”¶æ•›é€Ÿåº¦æå‡å’Œ 7 å€çš„æ•´ä½“è®­ç»ƒåŠ é€Ÿã€‚

æ­¤å¤–ï¼ŒDiT åœ¨è§†é¢‘ç”Ÿæˆé¢†åŸŸçš„åº”ç”¨ä¹Ÿå–å¾—äº†é‡å¤§çªç ´ã€‚2024 å¹´ï¼ŒOpenAI æ¨å‡ºçš„ Sora æ¨¡å‹é‡‡ç”¨äº† DiT æ¶æ„ï¼Œå®ç°äº†æ–‡æœ¬åˆ°é•¿è§†é¢‘ (60 ç§’ä»¥ä¸Š) çš„ç”Ÿæˆï¼Œå¹¶å…·å¤‡ç‰©ç†æ¨¡æ‹Ÿå’Œä¸–ç•Œæ¨¡å‹èƒ½åŠ›ã€‚Sora çš„æˆåŠŸéªŒè¯äº† DiT æ¶æ„åœ¨å¤„ç†å¤æ‚æ—¶ç©ºæ•°æ®æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚


#### 2025 å¯é€†æ‰©æ•£æ¨¡å‹

2025 å¹´ï¼ŒåŒ—äº¬å¤§å­¦ã€é˜¿åœæœæ‹‰å›½ç‹ç§‘æŠ€å¤§å­¦å’Œå­—èŠ‚è·³åŠ¨è”åˆæå‡ºçš„å¯é€†æ‰©æ•£æ¨¡å‹ (Invertible Diffusion Models, IDM) æ˜¯æ‰©æ•£æ¨¡å‹é¢†åŸŸçš„æœ€æ–°çªç ´ã€‚è¿™ä¸€æ¨¡å‹é’ˆå¯¹å›¾åƒé‡å»ºä»»åŠ¡ä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- "å™ªå£°ä¼°è®¡" ä»»åŠ¡ä¸ "å›¾åƒé‡å»º" ä»»åŠ¡ä¹‹é—´çš„åå·®
- æ¨ç†é€Ÿåº¦æ…¢ã€æ•ˆç‡ä½çš„é—®é¢˜

IDM çš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š
- ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¡†æ¶ï¼šå°†æ‰©æ•£é‡‡æ ·è¿‡ç¨‹é‡æ–°å®šä¹‰ä¸ºæ•´ä½“çš„å›¾åƒé‡å»ºç½‘ç»œï¼Œç›´æ¥é’ˆå¯¹å›¾åƒé‡å»ºä»»åŠ¡è¿›è¡Œä¼˜åŒ–
- åŒå±‚å¯é€†ç½‘ç»œè®¾è®¡ï¼šé€šè¿‡å¯é€†ç½‘ç»œå‡å°‘å†…å­˜å¼€é”€ï¼Œä½¿å¾—å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç«¯åˆ°ç«¯è®­ç»ƒæˆä¸ºå¯èƒ½

å®éªŒç»“æœè¡¨æ˜ï¼ŒIDM åœ¨å›¾åƒå‹ç¼©æ„ŸçŸ¥é‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æå‡ï¼š
- åœ¨ PSNR æŒ‡æ ‡ä¸Šæ¯”å…¶ä»–æ¨¡å‹æé«˜äº† 2dB
- é‡‡æ ·æ­¥æ•°ä»åŸæœ¬çš„ 100 æ­¥å‡å°‘åˆ° 3 æ­¥ï¼Œæ¨ç†é€Ÿåº¦æå‡äº†çº¦ 15 å€

åœ¨åŒ»å­¦å½±åƒé¢†åŸŸçš„åº”ç”¨ä¹Ÿå–å¾—äº†è‰¯å¥½æ•ˆæœ

è¿™ä¸€æˆæœå±•ç¤ºäº†æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒé‡å»ºé¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºåŒ»å­¦æˆåƒã€é¥æ„Ÿç­‰é¢†åŸŸæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

## æ‰©æ•£æ¨¡å‹åŸç†

æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion modelsï¼‰å®šä¹‰äº†**æ­£å‘**å’Œ**é€†å‘**ä¸¤ä¸ªè¿‡ç¨‹
- **æ­£å‘**è¿‡ç¨‹: æˆ–**æ‰©æ•£**è¿‡ç¨‹, ä»çœŸå®æ•°æ®åˆ†å¸ƒé‡‡æ ·ï¼Œé€æ­¥å‘æ ·æœ¬æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œç”Ÿæˆå™ªå£°æ ·æœ¬åºåˆ—ï¼ŒåŠ å™ªè¿‡ç¨‹å¯ç”¨æ–¹å·®å‚æ•°æ§åˆ¶ï¼Œå½“æ—¶ï¼Œå¯è¿‘ä¼¼ç­‰åŒäºä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚
- ![](https://pic4.zhimg.com/80/v2-32e400aab292cd75d7167368746fffcf_1440w.webp)

æ ‡å‡†çš„`æ‰©æ•£æ¨¡å‹`ï¼ˆdiffusion modelsï¼‰æ¶‰åŠåˆ°**å›¾åƒå˜æ¢**ï¼ˆæ·»åŠ é«˜æ–¯å™ªå£°ï¼‰å’Œ**å›¾åƒåè½¬**ã€‚ä½†æ˜¯æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå¹¶ä¸å¼ºçƒˆä¾èµ–äºå›¾åƒé™è§£çš„é€‰æ‹©ã€‚é€šè¿‡å®éªŒè¯æ˜äº†åŸºäºå®Œå…¨ç¡®å®šæ€§çš„é™è§£ï¼ˆä¾‹å¦‚æ¨¡ç³Šã€masking ç­‰ï¼‰ï¼Œä¹Ÿå¯ä»¥è½»æ¾è®­ç»ƒä¸€ä¸ªæ‰©æ•£ç”Ÿæˆæ¨¡å‹ã€‚
- [é¡¹ç›®åœ°å€](https://github.com/arpitbansal297/cold-diffusion-models)
- [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2208.09392)

è¿™ä¸ªå·¥ä½œæˆåŠŸè´¨ç–‘äº†ç¤¾åŒºå¯¹æ‰©æ•£æ¨¡å‹çš„ç†è§£:å¹¶éä¾èµ–äº**æ¢¯åº¦éƒä¹‹ä¸‡åŠ¨åŠ›å­¦**ï¼ˆgradient Langevin dynamicsï¼‰æˆ–**å˜åˆ†æ¨ç†**ï¼ˆvariational inferenceï¼‰ã€‚

`DDPM`å«â€œ**æ¸å˜æ¨¡å‹**â€æ›´å‡†ç¡®ï¼Œæ‰©æ•£æ¨¡å‹è¿™ä¸€åå­—åè€Œå®¹æ˜“é€ æˆç†è§£ä¸Šçš„è¯¯è§£ï¼Œä¼ ç»Ÿæ‰©æ•£æ¨¡å‹çš„**èƒ½é‡æ¨¡å‹**ã€**å¾—åˆ†åŒ¹é…**ã€`æœ—ä¹‹ä¸‡`æ–¹ç¨‹ç­‰æ¦‚å¿µï¼Œå…¶å®è·ŸDDPMåŠå…¶åç»­å˜ä½“éƒ½æ²¡ä»€ä¹ˆå…³ç³»ã€‚
- DDPM æ•°å­¦æ¡†æ¶å…¶å®åœ¨ICML2015 è®ºæ–‡ã€ŠDeep Unsupervised Learning using Nonequilibrium Thermodynamicsã€‹å°±å·²ç»å®Œæˆäº†ï¼Œä½†DDPMæ˜¯é¦–æ¬¡å°†å®ƒåœ¨é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä¸Šè°ƒè¯•å‡ºæ¥äº†ï¼Œä»è€Œå¼•å¯¼å‡ºäº†åé¢çš„ç«çƒ­ã€‚ç”±æ­¤å¯è§ï¼Œä¸€ä¸ªæ¨¡å‹çš„è¯ç”Ÿå’Œæµè¡Œï¼Œå¾€å¾€è¿˜éœ€è¦æ—¶é—´å’Œæœºé‡

### Stable Diffusion

ã€2023-4-10ã€‘[å›¾è§£Stable Diffusion](https://zhuanlan.zhihu.com/p/617713156)
- jalammar [illustrated-stable-diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)

Stable Diffusionï¼ˆç®€ç§°SDï¼‰æ˜¯AIç»˜ç”»é¢†åŸŸçš„ä¸€ä¸ªæ ¸å¿ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿè¿›è¡Œ**æ–‡ç”Ÿå›¾**ï¼ˆtxt2imgï¼‰å’Œ**å›¾ç”Ÿå›¾**ï¼ˆimg2imgï¼‰ç­‰å›¾åƒç”Ÿæˆä»»åŠ¡ã€‚
- ä¸ Midjourney ä¸åŒçš„æ˜¯ï¼ŒStable Diffusion æ˜¯ä¸€ä¸ª**å®Œå…¨å¼€æº**çš„é¡¹ç›®ï¼ˆæ¨¡å‹ã€ä»£ç ã€è®­ç»ƒæ•°æ®ã€è®ºæ–‡ã€ç”Ÿæ€ç­‰å…¨éƒ¨å¼€æºï¼‰ï¼Œè¿™ä½¿å¾—å…¶èƒ½å¿«é€Ÿæ„å»ºå¼ºå¤§ç¹è£çš„ä¸Šä¸‹æ¸¸ç”Ÿæ€ï¼ˆAIç»˜ç”»ç¤¾åŒºã€åŸºäºSDçš„è‡ªè®­ç»ƒAIç»˜ç”»æ¨¡å‹ã€ä¸°å¯Œçš„è¾…åŠ©AIç»˜ç”»å·¥å…·ä¸æ’ä»¶ç­‰ï¼‰ï¼Œå¹¶ä¸”å¸å¼•äº†è¶Šæ¥è¶Šå¤šçš„AIç»˜ç”»çˆ±å¥½è€…åŠ å…¥å…¶ä¸­ï¼Œä¸AIè¡Œä¸šä»ä¸šè€…ä¸€èµ·æ¨åŠ¨AIGCé¢†åŸŸçš„å‘å±•ä¸æ™®æƒ ã€‚

å¯¹Stable Diffusionæ¨¡å‹çš„å…¨ç»´åº¦å„ä¸ªç»†èŠ‚åšä¸€ä¸ªæ·±å…¥æµ…å‡ºçš„åˆ†æä¸æ€»ç»“ï¼ˆSDæ¨¡å‹ç»“æ„è§£æã€SDæ¨¡å‹ç»å…¸åº”ç”¨åœºæ™¯ä»‹ç»ã€SDæ¨¡å‹æ€§èƒ½ä¼˜åŒ–ã€SDæ¨¡å‹ä»0åˆ°1ä¿å§†çº§è®­ç»ƒæ•™ç¨‹ï¼ŒSDæ¨¡å‹ä¸åŒAIç»˜ç”»æ¡†æ¶ä»0åˆ°1æ¨ç†è¿è¡Œä¿å§†çº§æ•™ç¨‹ã€æœ€æ–°SDæ¨¡å‹èµ„æºæ±‡æ€»åˆ†äº«ã€SDç›¸å…³é…å¥—å·¥å…·ä½¿ç”¨ç­‰

ã€2024-5-18ã€‘[æ·±å…¥æµ…å‡ºå®Œæ•´è§£æStable Diffusionï¼ˆSDï¼‰æ ¸å¿ƒåŸºç¡€çŸ¥è¯†](https://zhuanlan.zhihu.com/p/632809634)

Stable Diffusion å‘å¸ƒæ˜¯AI ç»˜ç”»é¢†åŸŸçš„ä¸€ä¸ªé‡Œç¨‹ç¢‘äº‹ä»¶ã€‚å®ƒçš„å‡ºç°ä½¿å¾—æ™®é€šäººä¹Ÿèƒ½ä½¿ç”¨é«˜æ€§èƒ½çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚
- ç”Ÿæˆçš„å›¾åƒæ•ˆæœæä½³ï¼Œé€Ÿåº¦è¿˜å¾ˆå¿«ï¼Œå¯¹ç¡¬ä»¶èµ„æºçš„è¦æ±‚ç›¸å¯¹è¾ƒä½ã€‚

Stable Diffusion ç”¨æ³•
- æ–‡æœ¬ç”Ÿæˆå›¾åƒ text2image
- ![](https://pic3.zhimg.com/80/v2-ac5018aeb9b47d5083a2f51d72456f2e_1440w.webp)
- ä¿®æ”¹å›¾åƒï¼ˆæ­¤æ—¶è¾“å…¥ä¸ºæ–‡æœ¬+å›¾åƒï¼‰
- ![](https://pic4.zhimg.com/80/v2-666a51f167fc14d37e0afa77b24dba03_1440w.webp)

### æ‰©æ•£æ¨¡å‹ç»„ä»¶

Stable Diffusion æ˜¯ç”±å¤šä¸ª**ç»„ä»¶**å’Œ**æ¨¡å‹**ç»„æˆçš„**ç³»ç»Ÿ**ï¼Œ è€Œéä¸€ä¸ªæ•´ä½“çš„æ¨¡å‹ã€‚
- ![](https://pic2.zhimg.com/80/v2-fe7093a950de6c95c0317575c61c1cf5_1440w.webp)
- `æ–‡æœ¬ç†è§£`ï¼ˆtext-understandingï¼‰ç»„ä»¶: æ•æ‰æ–‡æœ¬ä¸­çš„æ„å›¾ï¼Œå°†æ–‡æœ¬ä¿¡æ¯è½¬æ¢ä¸ºæ¨¡å‹èƒ½å¤Ÿç†è§£çš„æ•°å€¼è¡¨ç¤ºã€‚
  - æ–‡æœ¬ç¼–ç å™¨æ˜¯ä¸€ç§ç‰¹æ®Šçš„ Transformer è¯­è¨€æ¨¡å‹ï¼ˆCLIP æ¨¡å‹çš„æ–‡æœ¬ç¼–ç å™¨ï¼‰ã€‚ è·å–è¾“å…¥æ–‡æœ¬å¹¶è¾“å‡ºä»£è¡¨æ–‡æœ¬ä¸­æ¯ä¸ªå•è¯/token çš„æ•°å€¼è¡¨ç¤ºï¼ˆæ¯ä¸ª token ç”±ä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼‰
- `å›¾åƒç”Ÿæˆå™¨`ï¼ˆImage Generatorï¼‰ï¼Œä¹Ÿç”±å¤šä¸ªç»„ä»¶ç»„æˆã€‚ç”±ä»¥ä¸‹ä¸¤ä¸ªé˜¶æ®µç»„æˆ:
  - `å›¾åƒä¿¡æ¯ç”Ÿæˆå™¨`ï¼ˆImage Information Creatorï¼‰: Stable Diffusion æˆåŠŸçš„ç§˜è¯€ï¼Œæ˜¯æ€§èƒ½å’Œæ•ˆç‡é«˜äºä¹‹å‰å·¥ä½œçš„åŸå› ã€‚è¿è¡Œå¤šæ­¥æ¥ç”Ÿæˆå›¾åƒä¿¡æ¯ã€‚æ­¥æ•°å°±æ˜¯ Stable Diffusion ç•Œé¢æˆ–åº“ä¸­çš„steps å‚æ•°ï¼Œé€šå¸¸è®¾ä¸º 50 æˆ– 100ã€‚å›¾åƒä¿¡æ¯ç”Ÿæˆå™¨å®Œå…¨åœ¨å›¾åƒä¿¡æ¯ç©ºé—´ï¼ˆæˆ–è€…ç§°ä¸ºæ½œå±‚ç©ºé—´ latent spaceï¼‰ä¸­è¿›è¡Œå·¥ä½œ. â€œæ‰©æ•£ï¼ˆdiffusionï¼‰â€æè¿°çš„å°±æ˜¯è¯¥ç»„ä»¶çš„è¡Œä¸ºã€‚è¯¥ç»„ä»¶é€šè¿‡ä¸€æ­¥ä¸€æ­¥åœ°å¯¹ä¿¡æ¯è¿›è¡Œå¤„ç†ï¼Œä»è€Œå¾—åˆ°æœ€ç»ˆçš„é«˜è´¨é‡å›¾åƒï¼ˆç”±æ¥ä¸‹æ¥çš„å›¾åƒè§£ç å™¨ç»„ä»¶ç”Ÿæˆï¼‰ã€‚
  - `å›¾åƒè§£ç å™¨`ï¼ˆImage Decoderï¼‰: æ ¹æ®å›¾åƒä¿¡æ¯ç”Ÿæˆå™¨ç”Ÿæˆçš„ä¿¡æ¯ç”»å‡ºå›¾åƒã€‚ä¸åŒäºå¤šæ­¥è¿è¡Œçš„ä¿¡æ¯ç”Ÿæˆå™¨ï¼Œå›¾åƒè§£ç å™¨ä»…è¿è¡Œä¸€æ¬¡ï¼Œæ¥ç”Ÿæˆæœ€ç»ˆçš„åƒç´ çº§å›¾åƒã€‚
  - ![](https://pic3.zhimg.com/80/v2-52cbfea8baaf0385e1973b8baf15ccc2_1440w.webp)

Stable Diffusion ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼Œå„è‡ªç”±ä¸åŒçš„ç¥ç»ç½‘ç»œç»„æˆ:
- `ClipText` ç”¨äºæ–‡æœ¬ç¼–ç 
  - è¾“å…¥:æ–‡æœ¬
  - è¾“å‡º:77 ä¸ª token åµŒå…¥å‘é‡ï¼Œæ¯ä¸ªå‘é‡ 768 ç»´
- `UNet` + `Scheduler` ç”¨äºåœ¨æ½œå±‚ç©ºé—´ä¸­é€æ­¥åœ°åœ°å¤„ç†ï¼ˆæˆ–è€…è¯´æ‰©æ•£ï¼‰ä¿¡æ¯
  - è¾“å…¥:æ–‡æœ¬åµŒå…¥å’Œä¸€ä¸ªé«˜ç»´å™ªå£°å¼ é‡
  - è¾“å‡º:ç»è¿‡å¤„ç†å¾—åˆ°çš„ä¿¡æ¯å¼ é‡
- `AutoEncoder Decoder` æ ¹æ®ä¿¡æ¯å¼ é‡ç”»å‡ºå›¾åƒ
  - è¾“å…¥:ä¿¡æ¯å¼ é‡ï¼ˆç»´åº¦ (4, 64, 64)ï¼‰
  - è¾“å‡º:å›¾åƒï¼ˆç»´åº¦:(3, 512, 512)ï¼‰
- ![](https://pic4.zhimg.com/80/v2-e7224e525a72fdf4ea2bcbe5470a42cb_1440w.webp)

### DDPM åˆ†æ

DDPM ç¼ºç‚¹
- è®¾ç½®è¾ƒé•¿çš„æ‰©æ•£æ­¥æ•°æ‰èƒ½å¾—åˆ°å¥½çš„æ•ˆï¼Œè¿™å¯¼è‡´ç”Ÿæˆæ ·æœ¬çš„é€Ÿåº¦**è¾ƒæ…¢**
- æ¯”å¦‚æ‰©æ•£æ­¥æ•°ä¸º1000çš„è¯ï¼Œé‚£ä¹ˆç”Ÿæˆä¸€ä¸ªæ ·æœ¬å°±è¦æ¨¡å‹æ¨ç†1000æ¬¡ã€‚


### DDIM

ä»æœ€æ—©çš„ DDPM å¼€å§‹ï¼Œä¸€æ­¥æ­¥è¿˜åŸ Latent Diffusion Model (LDM)çš„é‡‡æ ·ç®—æ³•

DDPM é‡‡æ ·ç®—æ³•ï¼š

```py
def ddpm_sample(image_shape):
  ddpm_scheduler = DDPMScheduler() # ç»´æŠ¤æ‰©æ•£æ¨¡å‹çš„a,bç­‰å˜é‡
  unet = UNet() # unet, è®¡ç®—å»å™ªè¿‡ç¨‹ä¸­çš„å›¾åƒåº”è¯¥å»é™¤çš„å™ªå£°eps
  xt = randn(image_shape) # æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çº¯å™ªå£°å›¾åƒ
  T = 1000
  # é€æ­¥å»å™ª,æœ€ç»ˆå˜æˆä¸€å¹…å›¾ç‰‡
  for t in T ... 1: # 
    eps = unet(xt, t) # å½“å‰åº”è¯¥å»é™¤çš„å™ªå£°
    std = ddpm_scheduler.get_std(t) # å›¾åƒæ–¹å·®
    xt = ddpm_scheduler.get_xt_prev(xt, t, eps, std)
  return xt
```

`DDIM`ï¼ˆDenoising Diffusion Implicit Modelsï¼‰
- ã€2020-10-6ã€‘[Denoising Diffusion Implicit Models](https://arxiv.org/pdf/2010.02502)
- ã€2023-5-25ã€‘[æ‰©æ•£æ¨¡å‹ä¹‹DDIM](https://zhuanlan.zhihu.com/p/565698027)

`DDIM` å’Œ `DDPM` æœ‰ç›¸åŒçš„è®­ç»ƒç›®æ ‡ï¼Œä½†ä¸å†é™åˆ¶æ‰©æ•£è¿‡ç¨‹å¿…é¡»æ˜¯ä¸€ä¸ª`é©¬å°”å¡å¤«é“¾`ï¼Œè¿™ä½¿å¾—`DDIM`å¯ä»¥é‡‡ç”¨æ›´å°çš„é‡‡æ ·æ­¥æ•°æ¥åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹

`DDIM`å¦ä¸€ä¸ªç‰¹ç‚¹: ä»ä¸€ä¸ªéšæœºå™ªéŸ³ç”Ÿæˆæ ·æœ¬çš„è¿‡ç¨‹æ˜¯ä¸€ä¸ª**ç¡®å®š**çš„è¿‡ç¨‹ï¼ˆä¸­é—´æ²¡æœ‰åŠ å…¥éšæœºå™ªéŸ³ï¼‰ã€‚

`DDIM` å¯¹ `DDPM` çš„é‡‡æ ·è¿‡ç¨‹åšäº†ä¸¤ç‚¹æ”¹è¿›ï¼š
- 1) å»å™ªæœ‰æ•ˆæ­¥æ•°å¯ä»¥**å°‘äºTæ­¥**ï¼Œç”±å¦ä¸€ä¸ªå˜é‡ddim_stepså†³å®šï¼›
- 2) é‡‡æ ·æ–¹å·®å¤§å°å¯ä»¥ç”±etaå†³å®šã€‚

ddim æ‰©æ•£æ¨¡å‹æ”¹è¿›ï¼ŒåŠ é€Ÿï¼Œä¸å†éšæœºå»å™ªï¼Œè€Œæ˜¯é€‰å®šæ–¹å‘

å› æ­¤ï¼Œæ”¹è¿›å DDIMç®—æ³•ï¼š

```py
def ddim_sample(image_shape, ddim_steps = 20, eta = 0):
  """
    ddim_steps å»å™ªå¾ªç¯æ­¥æ•°
  """
  ddim_scheduler = DDIMScheduler()
  unet = UNet()
  xt = randn(image_shape)
  T = 1000
  timesteps = ddim_scheduler.get_timesteps(T, ddim_steps) # [1000, 950, 900, ...]
  for t in timesteps:
    eps = unet(xt, t)
    std = ddim_scheduler.get_std(t, eta)
    xt = ddim_scheduler.get_xt_prev(xt, t, eps, std)
  return xt
```


### LDM 

DDIM çš„åŸºç¡€ä¸Šï¼ŒLDM ä»ç”Ÿæˆ**åƒç´ ç©ºé—´**ä¸Šçš„å›¾åƒå˜ä¸ºç”Ÿæˆ**éšç©ºé—´**ä¸Šçš„å›¾åƒã€‚
- éšç©ºé—´å›¾åƒéœ€è¦å†åšä¸€æ¬¡**è§£ç **æ‰èƒ½å˜å›çœŸå®å›¾åƒã€‚

ä»ä»£ç ä¸Šæ¥çœ‹ï¼Œä½¿ç”¨LDMåï¼Œåªéœ€è¦å¤šå‡†å¤‡ä¸€ä¸ªVAEï¼Œå¹¶å¯¹æœ€åçš„éšç©ºé—´å›¾åƒztè§£ç ã€‚

```py
def ldm_ddim_sample(image_shape, ddim_steps = 20, eta = 0):
  ddim_scheduler = DDIMScheduler()
  vae = VAE()
  unet = UNet()
  zt = randn(image_shape)
  T = 1000
  timesteps = ddim_scheduler.get_timesteps(T, ddim_steps) # [1000, 950, 900, ...]
  for t in timesteps:
    eps = unet(zt, t)
    std = ddim_scheduler.get_std(t, eta)
    zt = ddim_scheduler.get_xt_prev(zt, t, eps, std)
  xt = vae.decoder.decode(zt)
  return xt
```

è€Œæƒ³ç”¨ LDM å®ç°æ–‡ç”Ÿå›¾ï¼Œåˆ™éœ€è¦ç»™ä¸€ä¸ªé¢å¤–çš„æ–‡æœ¬è¾“å…¥textã€‚
- æ–‡æœ¬ç¼–ç å™¨ä¼šæŠŠæ–‡æœ¬ç¼–ç æˆå¼ é‡cï¼Œè¾“å…¥è¿›unetã€‚
- å…¶ä»–åœ°æ–¹çš„å®ç°éƒ½å’Œä¹‹å‰çš„LDMä¸€æ ·ã€‚

```py
def ldm_text_to_image(image_shape, text, ddim_steps = 20, eta = 0):
  ddim_scheduler = DDIMScheduler()
  vae = VAE()
  unet = UNet()
  zt = randn(image_shape)
  T = 1000
  timesteps = ddim_scheduler.get_timesteps(T, ddim_steps) # [1000, 950, 900, ...]

  text_encoder = CLIP()
  c = text_encoder.encode(text)

  for t = timesteps:
    eps = unet(zt, t, c)
    std = ddim_scheduler.get_std(t, eta)
    zt = ddim_scheduler.get_xt_prev(zt, t, eps, std)
  xt = vae.decoder.decode(zt)
  return xt
```

æœ€å, è¿™ä¸ªèƒ½å®ç°æ–‡ç”Ÿå›¾çš„LDMå°±æ˜¯ Stable Diffusionã€‚

Stable Diffusion é‡‡æ ·ç®—æ³•çœ‹ä¸Šå»æ¯”è¾ƒå¤æ‚ï¼Œä»DDPMå¼€å§‹æŠŠå„ä¸ªåŠŸèƒ½éƒ½æ‹†å¼€æ¥çœ‹ï¼Œç†è§£èµ·æ¥å°±å®¹æ˜“äº†ã€‚



### UNet

2015 å¹´ï¼ŒOlaf Ronneberger ç­‰äººæå‡ºä¸€ç§ç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¶æ„ï¼ŒUNetï¼Œä¸“ä¸ºç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²è®¾è®¡ã€‚

UNet å› ä¸ºç½‘ç»œçš„æ•´ä½“ç»“æ„**å½¢ä¼¼å­—æ¯U**è€Œå¾—åã€‚
- Unet ä»¥å›¾åƒä½œä¸ºå…¥å£ï¼Œé€šè¿‡å‡å°‘é‡‡æ ·æ¥æ‰¾åˆ°è¯¥å›¾åƒçš„ä½ç»´è¡¨ç¤ºåå†é€šè¿‡å¢åŠ é‡‡æ ·å°†å›¾åƒæ¢å¤å›æ¥ã€‚
- UNet åœ¨**å›¾åƒåˆ†å‰²**ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç»†è¾¹ç•Œçš„åœºæ™¯ä¸­å¹¿æ³›åº”ç”¨ï¼Œå¦‚åŒ»å­¦å½±åƒåˆ†å‰²ã€å«æ˜Ÿå›¾åƒåˆ†å‰²ç­‰ã€‚

UNet æˆåŠŸæºäºå…¶æœ‰æ•ˆçš„**ç‰¹å¾æå–**ä¸**æ¢å¤æœºåˆ¶**ï¼Œç‰¹åˆ«æ˜¯è·³è·ƒè¿æ¥çš„è®¾è®¡ï¼Œä½¿å¾—ç¼–ç è¿‡ç¨‹ä¸­ä¸¢å¤±çš„ç»†èŠ‚èƒ½å¤Ÿé€šè¿‡è§£ç é˜¶æ®µæ¢å¤ã€‚


#### UNet æ¼”å˜

DDPMä¼šç”¨åˆ°ä¸€ä¸ªU-Netç¥ç»ç½‘ç»œunetï¼Œç”¨äºè®¡ç®—å»å™ªè¿‡ç¨‹ä¸­å›¾åƒåº”è¯¥å»é™¤çš„å™ªå£°eps

U-Net ç»“æ„

|U-Net é˜¶æ®µ|å˜åŒ–|å›¾è§£|
|---|---|---|
|DDIM|æ—©æœŸ; çº¯å·ç§¯|![](https://zhouyifan.net/2024/01/23/20230713-SD3/0-1.jpg)|
|DDPM|1. å·ç§¯å±‚->æ®‹å·®å·ç§¯æ¨¡å—,æ·±å±‚è¿˜æœ‰è‡ªæ³¨æ„åŠ›<br>2. æ¯å±‚è¿˜æœ‰ä¸ªçŸ­è·¯è¿æ¥|![](https://zhouyifan.net/2024/01/23/20230713-SD3/0-2.jpg)|
|LDM|å¢åŠ é¢å¤–çº¦æŸä¿¡æ¯,è‡ªæ³¨æ„åŠ›->äº¤å‰æ³¨æ„åŠ›(transformer)||
|Stable Diffusion|æ¯ä¸ªå¤§å±‚éƒ½æœ‰transformerå—,ä¸åªæ˜¯æ·±å±‚|![](https://zhouyifan.net/2024/01/23/20230713-SD3/0-3.jpg)|

[Stable Diffusion è§£è¯»ï¼ˆä¸‰ï¼‰ï¼šåŸç‰ˆå®ç°åŠDiffuserså®ç°æºç è§£è¯»](https://zhouyifan.net/2024/01/23/20230713-SD3/)


#### UNet ç½‘ç»œç»“æ„

ç‹¬ç‰¹ä¹‹å¤„
- ç¼–ç å™¨-è§£ç å™¨**å¯¹ç§°ç»“æ„**ï¼Œå¤šå°ºåº¦ä¸Šæœ‰æ•ˆæå–ç‰¹å¾å¹¶ç”Ÿæˆç²¾ç¡®çš„åƒç´ çº§åˆ†å‰²ç»“æœã€‚

- ![](https://pic1.zhimg.com/80/v2-fd8eafb834095ceb7f61c89dcd996748_1440w.webp?source=1940ef5c)

UNet è®¾è®¡ç†å¿µ: 
- å°†è¾“å…¥å›¾åƒç»è¿‡ä¸€ç³»åˆ—**å·ç§¯**å’Œ**ä¸‹é‡‡æ ·**æ“ä½œ, é€æ¸æå–**é«˜å±‚æ¬¡ç‰¹å¾**ï¼ˆç¼–ç è·¯å¾„ï¼‰
- ç„¶åé€šè¿‡**ä¸Šé‡‡æ ·**é€æ­¥æ¢å¤åŸå§‹çš„åˆ†è¾¨ç‡ï¼ˆè§£ç è·¯å¾„ï¼‰
- å¹¶å°†ç¼–ç è·¯å¾„ä¸­å¯¹åº”çš„ç‰¹å¾ä¸è§£ç è·¯å¾„è¿›è¡Œ`è·³è·ƒè¿æ¥`ï¼ˆskip connectionï¼‰, å¸®åŠ©ç½‘ç»œç»“åˆ**ä½å±‚æ¬¡ç»†èŠ‚ä¿¡æ¯**å’Œ**é«˜å±‚æ¬¡è¯­ä¹‰ä¿¡æ¯**ï¼Œå®ç°ç²¾ç¡®çš„åƒç´ çº§åˆ†å‰²ã€‚

UNet æ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆ:`ç¼–ç å™¨`å’Œ`è§£ç å™¨`ï¼Œä¸­é—´é€šè¿‡`è·³è·ƒè¿æ¥`ï¼ˆSkip Connectionsï¼‰ç›¸è¿ã€‚

Unet æ•´ä½“ç»“æ„åŒ…å«äº†4å±‚`ç¼–ç å™¨`å’Œ4å±‚`è§£ç å™¨`ã€‚ æ¯å±‚`ç¼–ç å™¨`å’Œ`è§£ç å™¨`ä¸­,å‡åŒ…å«äº†ä¸€ä¸ªä¸¤å±‚çš„å·ç§¯ç½‘ç»œ
- (1) UNet `ç¼–ç å™¨`ä»»åŠ¡: é€æ¸å‹ç¼©è¾“å…¥å›¾åƒçš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œæå–æ›´é«˜å±‚æ¬¡çš„ç‰¹å¾ã€‚
  - `ç¼–ç å™¨`å…·æœ‰4å±‚ç»“æ„ï¼Œæ¯å±‚ç”±ä¸€ä¸ªåŒå±‚å·ç§¯ç½‘ç»œæ„æˆã€‚
    - ç»è¿‡ä¸€å±‚**æœ€å¤§æ± åŒ–**ï¼ˆmax poolingï¼‰æå–å‡ºå…³é”®ç‰¹å¾ä¹‹åä¼ é€’åˆ°ä¸‹ä¸€å±‚ï¼Œæ¯æ¬¡æ± åŒ–æ“ä½œéƒ½ä¼šå°†å›¾åƒçš„ç©ºé—´ç»´åº¦å‡å°‘ä¸€åŠ
    - åŒæ—¶é€šè¿‡ Skip-Connection å°†ç»“æœä¼ é€’ç»™å¯¹åº”çš„è§£ç å™¨ã€‚
- (2) `UNet è§£ç å™¨` é€šè¿‡é€æ¸**æ¢å¤**å›¾åƒçš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œå°†ç¼–ç å™¨éƒ¨åˆ†æå–åˆ°çš„é«˜å±‚æ¬¡ç‰¹å¾æ˜ å°„å›åŸå§‹çš„å›¾åƒåˆ†è¾¨ç‡ã€‚
  - åŒæ—¶æ¥æ”¶äº†æ¥è‡ªä¸‹ä¸€å±‚ç½‘ç»œçš„è¾“å‡ºï¼Œä¸åŒå±‚ç¼–ç å™¨æ± åŒ–å‰çš„ç»“æœï¼Œé€šè¿‡æ‹¼æ¥åä¼ é€’åˆ°ä¸Šä¸€å±‚ã€‚
  - è§£ç å™¨åŒ…å«**åå·ç§¯**ï¼ˆä¸Šé‡‡æ ·ï¼‰æ“ä½œï¼Œå¹¶ç»“åˆæ¥`è‡ªç¼–ç å™¨`çš„ç›¸åº”ç‰¹å¾å±‚ï¼Œä»¥å®ç°ç²¾ç»†çš„è¾¹ç•Œæ¢å¤ã€‚
- (3) è·³è·ƒè¿æ¥: UNet çš„å…³é”®åˆ›æ–°ç‚¹ã€‚
  - æ¯ä¸ª`ç¼–ç å™¨`å±‚çš„è¾“å‡ºç‰¹å¾å›¾ä¸`è§£ç å™¨`ä¸­å¯¹åº”å±‚çš„ç‰¹å¾å›¾è¿›è¡Œæ‹¼æ¥ï¼Œå½¢æˆ`è·³è·ƒè¿æ¥`ã€‚å°†ç¼–ç å™¨ä¸­çš„**å±€éƒ¨**ä¿¡æ¯å’Œè§£ç å™¨ä¸­çš„**å…¨å±€**ä¿¡æ¯è¿›è¡Œèåˆï¼Œä»è€Œæé«˜åˆ†å‰²ç»“æœçš„ç²¾åº¦ã€‚



#### UNet å®ç°

UNet ä»£ç ç¤ºä¾‹

```py
class DoubleConv(nn.Module): 

    def __init__(self, in_ch, out_ch, mid_ch=None):
        super().__init__()
        if not mid_ch:
            mid_ch = out_ch
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(mid_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        x = self.conv(x)
        return x

class Down(nn.Module): # ç¼–ç å™¨
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_ch, out_ch):
        super(Down, self).__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),  # å…ˆè¿›è¡Œmaxpoolï¼Œå†è¿›è¡Œä¸¤å±‚é“¾æ¥
            DoubleConv(in_ch, out_ch)
        )

    def forward(self, x):
        x = self.maxpool_conv(x)
        return x

class Up(nn.Module): # è§£ç å™¨
    """
    up path
    conv_transpose => double_conv
    """

    def __init__(self, in_ch, out_ch, bilinear=True):
        super(Up, self).__init__()
        if bilinear:
            self.up = lambda x: nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_ch, out_ch, in_ch // 2)
        else:
            self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_ch, out_ch)

    def forward(self, x1, x2): 
        """
            conv output shape = (input_shape - Filter_shape + 2 * padding)/stride + 1
        """
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]  # [N,C,H,W],diffY refers to height
        diffX = x2.size()[3] - x1.size()[3]  # [N,C,H,W],diffX refers to width

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)  # åœ¨é€šé“å±‚å°†skipä¼ é€’è¿‡æ¥çš„æ•°æ®ä¸ä¸‹å±‚ä¼ é€’æ¥çš„æ•°æ®è¿›è¡Œæ‹¼æ¥
        x = self.conv(x)
        return x
```

ç½‘ç»œå®ç°

```py
import torch

import torch.nn as nn
import torch.nn.functional as F
from model.components import DoubleConv, InConv, Down, Up, OutConv


class Unet(nn.Module):

    def __init__(self, in_ch, out_ch, gpu_ids=None, bilinear=False):  # inch, å›¾ç‰‡çš„é€šé“æ•°ï¼Œ1è¡¨ç¤ºç°åº¦å›¾åƒï¼Œ3è¡¨ç¤ºå½©è‰²å›¾åƒ
        super(Unet, self).__init__()
        if gpu_ids is None:
            gpu_ids = []
        self.loss = None
        self.matrix_iou = None
        self.pred_y = None
        self.x = None
        self.y = None

        self.loss_stack = 0
        self.matrix_iou_stack = 0
        self.stack_count = 0
        self.display_names = ['loss_stack', 'matrix_iou_stack']

        self.gpu_ids = gpu_ids
        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if torch.cuda.is_available() else torch.device(
            'cpu')

        self.bilinear = bilinear
        factor = 2 if bilinear else 1

        self.bce_loss = nn.BCELoss()

        self.inc = (DoubleConv(in_ch, 64))
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)

        self.down3 = Down(256, 512)
        self.drop3 = nn.Dropout2d(0.5)

        self.down4 = Down(512, 1024)
        self.drop4 = nn.Dropout2d(0.5)

        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64 // factor, bilinear)

        self.out = OutConv(64, out_ch)

        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)

    def forward(self):
        x1 = self.inc(self.x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x4 = self.drop3(x4)
        x5 = self.down4(x4)
        x5 = self.drop4(x5)

        # skip connectionä¸é‡‡æ ·ç»“æœèåˆ
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.out(x)
        self.pred_y = nn.functional.sigmoid(x)

    def set_input(self, x, y):
        self.x = x.to(self.device)
        self.y = y.to(self.device)
        self.to(self.device)

    def optimize_params(self):
        self.forward()
        self._bce_iou_loss()
        _ = self.accu_iou()
        self.stack_count += 1
        self.zero_grad()
        self.loss.backward()
        self.optimizer.step()

    def accu_iou(self):
        y_pred = (self.pred_y > 0.5) * 1.0
        y_true = (self.y > 0.5) * 1.0

        pred_flat = y_pred.view(y_pred.numel())
        true_flat = y_true.view(y_true.numel())

        intersection = float(torch.sum(pred_flat * true_flat)) + 1e-7
        denominator = float(torch.sum(pred_flat + true_flat)) - intersection + 2e-7

        self.matrix_iou = intersection / denominator
        self.matrix_iou_stack += self.matrix_iou
        return self.matrix_iou

    def _bce_iou_loss(self):
        y_pred = self.pred_y
        y_true = self.y
        pred_flat = y_pred.view(y_pred.numel())
        true_flat = y_true.view(y_true.numel())

        intersection = torch.sum(pred_flat * true_flat) + 1e-7
        denominator = torch.sum(pred_flat + true_flat) - intersection + 1e-7
        iou = torch.div(intersection, denominator)
        bce_loss = self.bce_loss(pred_flat, true_flat)
        self.loss = bce_loss - iou + 1
        self.loss_stack += self.loss

    def get_current_losses(self):
        errors_ret = {}
        for name in self.display_names:
            if isinstance(name, str):
                errors_ret[name] = float(getattr(self, name)) / self.stack_count
        self.loss_stack = 0
        self.matrix_iou_stack = 0
        self.stack_count = 0
        return errors_ret

    def eval_iou(self):
        with torch.no_grad():
            self.forward()
            self._bce_iou_loss()
            _ = self.accu_iou()
            self.stack_count += 1

```


## diffuser


HuggingFace æ¨å‡ºåŸºäº Stable Diffusion çš„å°è£…åº“ `diffusers`

Diffusers å®ç°äº† safety_checker, é˜²æ­¢å†’çŠ¯æ€§æˆ–æœ‰å®³å†…å®¹çš„åŠŸèƒ½ï¼Œä½†è¯¥æ¨¡å‹æ”¹è¿›çš„å›¾åƒç”ŸæˆåŠŸèƒ½ä»ç„¶å¯ä»¥äº§ç”Ÿæ½œåœ¨çš„æœ‰å®³å†…å®¹
- [HuggingFace Diffuserså…¥é—¨æ•™ç¨‹-å¿«é€Ÿå¯¼è§ˆ](https://blog.bot-flow.com/diffusers-quicktour/)

Diffusers èƒ½å¤Ÿç”Ÿæˆ**å›¾åƒ**ã€**è¯­éŸ³**ã€**ä¸‰ç»´åˆ†å­ç»“æ„**ï¼Œä¸”åŒ…å«SOTAæ‰©æ•£æ¨¡å‹çš„è®­ç»ƒã€æ¨ç†**å·¥å…·ç®±**


ç‰¹æ€§
- DiffusionPipeline æ˜¯ä¸€ä¸ªé«˜çº§**ç«¯åˆ°ç«¯**ç±»ï¼Œä»é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­å¿«é€Ÿç”Ÿæˆç”¨äºæ¨ç†æ ·æœ¬ã€‚
- SOTA é¢„è®­ç»ƒæ¨¡å‹æ¶æ„å’Œæ¨¡å—ï¼Œå¯ç”¨ä½œåˆ›å»ºæ‰©æ•£æ¨¡å‹çš„æ„ä»¶ã€‚
- è®¸å¤šä¸åŒçš„**è°ƒåº¦å™¨**ç®—æ³•å¯æ§åˆ¶å¦‚ä½•åœ¨è®­ç»ƒä¸­æ·»åŠ å™ªå£°ï¼Œä»¥åŠå¦‚ä½•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”Ÿæˆå»å™ªå›¾åƒã€‚



### ç»„ä»¶

ä¸‰ä¸ªä¸»è¦ç»„ä»¶:
- `DiffusionPipeline`(æ‰©æ•£ç®¡é“):åŸºäºé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å¿«é€Ÿç”Ÿæˆæ ·æœ¬çš„å°è£…ç±»
- `Model`(æ¨¡å‹):é¢„è®­ç»ƒæ¨¡å‹æ¶æ„å’Œæ¨¡å—å¯ç”¨ä½œåˆ›å»ºæ‰©æ•£ç³»ç»Ÿçš„æ„å»ºå—ã€‚
- `Scheduler`(è°ƒåº¦å™¨):ç”¨äºæ§åˆ¶å¦‚ä½•åœ¨è®­ç»ƒä¸­æ·»åŠ å™ªå£°ä»¥åŠå¦‚ä½•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”Ÿæˆå»å™ªå›¾åƒçš„ç®—æ³•ã€‚
  - ä¸åŒçš„è°ƒåº¦å™¨å…·æœ‰ä¸åŒçš„å»å™ªé€Ÿåº¦å’Œè´¨é‡æƒè¡¡ï¼Œå¯è‡ªå®šä¹‰
  - é»˜è®¤: PNDMScheduler


### pipeline

å¸¸è§ pipeline
- AutoPipeline
  - æ–‡ç”Ÿå›¾ text2image: `AutoPipelineForText2Image`
  - å›¾ç”Ÿå›¾ image2iamge: `AutoPipelineForImage2Image`
  - å›¾åƒä¿®å¤ inpainting: `AutoPipelineForInpainting`
- `DiffusionPipeline` ç”¨é¢„è®­ç»ƒæ‰©æ•£ç³»ç»Ÿè¿›è¡Œæ¨ç†ï¼Œæœ€ç®€å•ã€‚ä¸€ä¸ªåŒ…å«**æ¨¡å‹**å’Œ**è°ƒåº¦ç¨‹åº**çš„ç«¯åˆ°ç«¯ç³»ç»Ÿã€‚å¼€ç®±å³ç”¨çš„DiffusionPipeline æ‰§è¡Œè®¸å¤šä»»åŠ¡


| **ä»»åŠ¡** | **æè¿°** | **ç®¡é“** |
| --- | --- | --- |
| æ— æ¡ä»¶å›¾åƒç”Ÿæˆ | ä»**é«˜æ–¯å™ªå£°**ç”Ÿæˆ**å›¾åƒ** | [æ— æ¡ä»¶å›¾åƒç”Ÿæˆ unconditional_image_generation](https://huggingface.co/docs/diffusers/using-diffusers/unconditional_image_generation) |
| æ–‡æœ¬å¼•å¯¼å›¾åƒç”Ÿæˆ | æ ¹æ®**æ–‡æœ¬æç¤º**ç”Ÿæˆ**å›¾åƒ** | [æ¡ä»¶å›¾åƒç”Ÿæˆ conditional_image_generation](https://huggingface.co/docs/diffusers/using-diffusers/conditional_image_generation) |
| æ–‡æœ¬å¼•å¯¼çš„**å›¾åƒåˆ°å›¾åƒ**ç¿»è¯‘ | æ ¹æ®**æ–‡æœ¬æç¤º**è°ƒæ•´**å›¾åƒ** | [img2img](https://huggingface.co/docs/diffusers/using-diffusers/img2img) |
| æ–‡æœ¬å¼•å¯¼**å›¾åƒä¿®å¤** | ç»™å®š**å›¾åƒ**ã€**è’™ç‰ˆ**å’Œ**æ–‡æœ¬æç¤º**ï¼Œå¡«å……å›¾åƒçš„**è’™ç‰ˆ**éƒ¨åˆ† | [inpaint](https://huggingface.co/docs/diffusers/using-diffusers/inpaint) |
| æ–‡æœ¬å¼•å¯¼**æ·±åº¦å›¾åƒç¿»è¯‘** | è°ƒæ•´ç”±**æ–‡æœ¬æç¤º**å¼•å¯¼çš„å›¾åƒéƒ¨åˆ†ï¼ŒåŒæ—¶é€šè¿‡æ·±åº¦ä¼°è®¡ä¿ç•™ç»“æ„ | [depth2img](https://huggingface.co/docs/diffusers/using-diffusers/depth2img) |



#### text2image


ç¤ºä¾‹ä»£ç 

```py
from diffusers import AutoPipelineForText2Image
import torch

pipe_txt2img = AutoPipelineForText2Image.from_pretrained(
    "dreamlike-art/dreamlike-photoreal-2.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

prompt = "cinematic photo of Godzilla eating sushi with a cat in a izakaya, 35mm photograph, film, professional, 4k, highly detailed"
generator = torch.Generator(device="cpu").manual_seed(37)
image = pipe_txt2img(prompt, generator=generator).images[0]
image
```


#### image2iamge


```py
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import load_image
import torch

pipe_img2img = AutoPipelineForImage2Image.from_pretrained(
    "dreamlike-art/dreamlike-photoreal-2.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-text2img.png")

prompt = "cinematic photo of Godzilla eating burgers with a cat in a fast food restaurant, 35mm photograph, film, professional, 4k, highly detailed"
generator = torch.Generator(device="cpu").manual_seed(53)
image = pipe_img2img(prompt, image=init_image, generator=generator).images[0]
image
```

#### inpainting


```py
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
import torch

pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-img2img.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-mask.png")

prompt = "cinematic photo of a owl, 35mm photograph, film, professional, 4k, highly detailed"
generator = torch.Generator(device="cpu").manual_seed(38)
image = pipeline(prompt, image=init_image, mask_image=mask_image, generator=generator, strength=0.4).images[0]
image
```



### æ¨¡å‹ Models


#### AutoPipeline

The [AutoPipeline](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/auto_pipeline) supports [Stable Diffusion](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/stable_diffusion/overview), [Stable Diffusion XL](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/stable_diffusion/stable_diffusion_xl), [ControlNet](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/controlnet), [Kandinsky 2.1](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/kandinsky.md), [Kandinsky 2.2](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/kandinsky_v22), and [DeepFloyd IF](https://huggingface.co/docs/diffusers/tutorials/autopipeline?autopipeline=inpainting../api/pipelines/deepfloyd_if) checkpoints.


#### from_pretrained

å¤§å¤šæ•°æ¨¡å‹é‡‡ç”¨**å™ªå£°**æ ·æœ¬ï¼Œå¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥é¢„æµ‹å™ªå£°æ®‹å·®ã€‚

å¯ä»¥æ··åˆæ­é…æ¨¡å‹æ¥åˆ›å»ºå…¶ä»–æ‰©æ•£ç³»ç»Ÿã€‚

æ¨¡å‹ç”¨ `from_pretrained()` æ–¹æ³•å¯åŠ¨ï¼Œ**æœ¬åœ°**ç¼“å­˜æ¨¡å‹æƒé‡ï¼Œä¸‹æ¬¡åŠ è½½æ¨¡å‹æ—¶é€Ÿåº¦ä¼šæ›´å¿«ã€‚

åŠ è½½ æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ¨¡å‹(UNet2DModel)ï¼Œå¸¦æœ‰åœ¨çŒ«å›¾åƒä¸Šè®­ç»ƒçš„æ£€æŸ¥ç‚¹:
- è®¿é—®æ¨¡å‹å‚æ•°ï¼Œè¯·è°ƒç”¨ `model.config`

```py
from diffusers import UNet2DModel

repo_id = "google/ddpm-cat-256"
model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)
model.config # è®¿é—®æ¨¡å‹å‚æ•°
```

æ¨¡å‹é…ç½®æ˜¯ä¸€ä¸ªğŸ§Šå†»ç»“çš„å­—å…¸ï¼Œåˆ›å»ºåæ— æ³•æ›´æ”¹ã€‚æœ‰æ„ä¸ºä¹‹ï¼Œç¡®ä¿ä¸€å¼€å§‹ç”¨äºå®šä¹‰æ¨¡å‹æ¶æ„çš„å‚æ•°ä¿æŒä¸å˜ï¼Œè€Œå…¶ä»–å‚æ•°ä»ç„¶å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œè°ƒæ•´ã€‚

ä¸€äº›é‡è¦å‚æ•°:
- `sample_size`: è¾“å…¥æ ·æœ¬**é«˜åº¦**å’Œ**å®½åº¦**å°ºå¯¸ã€‚
- `in_channels`: è¾“å…¥æ ·æœ¬è¾“å…¥**é€šé“æ•°**ã€‚
- `down_block_types`å’Œ`up_block_types`: åˆ›å»º UNet æ¶æ„çš„**ä¸‹é‡‡æ ·**å’Œ**ä¸Šé‡‡æ ·**æ¨¡å—ç±»å‹ã€‚
- `block_out_channels`: ä¸‹é‡‡æ ·å—çš„è¾“å‡ºé€šé“æ•°ï¼›ä¹Ÿä»¥ç›¸åçš„é¡ºåºç”¨äºä¸Šé‡‡æ ·å—çš„è¾“å…¥é€šé“çš„æ•°é‡ã€‚
- `layers_per_block`: æ¯ä¸ª UNet å—ä¸­å­˜åœ¨çš„ ResNet å—çš„æ•°é‡ã€‚

å¦‚éœ€æ¨ç†ï¼Œé¦–å…ˆéœ€è¦ä½¿ç”¨éšæœºé«˜æ–¯å™ªå£°åˆ›å»ºå›¾åƒ(å›¾åƒå¾€å¾€é€šè¿‡ä¸€ä¸ªå¤æ‚çš„å¤šç»´å¼ é‡è¡¨ç¤ºï¼Œä¸åŒçš„ç»´åº¦ä»£è¡¨ä¸åŒçš„å«ä¹‰)ï¼Œè¿™é‡Œå¼ é‡ shape æ˜¯ batch * channel * width * heightã€‚
- `batch`:ä¸€ä¸ªæ‰¹æ¬¡æƒ³ç”Ÿæˆçš„å›¾ç‰‡å¼ æ•°
- `channel`:ä¸€èˆ¬ä¸º3ï¼ŒRGBè‰²å½©ç©ºé—´
- `width`: å›¾åƒå®½
- `height`: å›¾åƒé«˜

```py
import torch

torch.manual_seed(0)
noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)
noisy_sample.shape
```

å¯¹äºæ¨ç†ï¼Œå°†**å™ªå£°å›¾åƒ**(noisy_sample)å’Œ**æ—¶é—´æ­¥é•¿**(timestep)ä¼ é€’ç»™æ¨¡å‹ã€‚
- æ—¶é—´æ­¥é•¿è¡¨ç¤ºè¾“å…¥å›¾åƒçš„å™ªå£°ç¨‹åº¦ï¼Œå¼€å§‹æ—¶å™ªå£°å¤šï¼Œç»“æŸæ—¶å™ªå£°å°‘ã€‚

è¿™æœ‰åŠ©äºæ¨¡å‹ç¡®å®šå…¶åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­çš„ä½ç½®ï¼Œæ˜¯æ›´æ¥è¿‘èµ·ç‚¹è¿˜æ˜¯æ›´æ¥è¿‘ç»ˆç‚¹ã€‚

ä½¿ç”¨æ ·ä¾‹æ–¹æ³•å¾—åˆ°æ¨¡å‹è¾“å‡º:

```py
with torch.no_grad():
    noisy_residual = model(sample=noisy_sample, timestep=2).sample
```

ä¸è¿‡ï¼Œè¦ç”Ÿæˆå®é™…ç¤ºä¾‹ï¼Œè¦ä¸€ä¸ª**è°ƒåº¦ç¨‹åº**æ¥æŒ‡å¯¼å»å™ªè¿‡ç¨‹ã€‚

å®Œæ•´ 

```py
from diffusers import UNet2DModel
import torch

# åŠ è½½æ¨¡å‹ load model
repo_id = "google/ddpm-cat-256"
model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)
model.config

# å™ªå£°è¾“å…¥ï¼ˆå™ªå£°å›¾åƒï¼‰ noise as input
torch.manual_seed(0)
noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)
noisy_sample.shape

# æ¨ç† inference
with torch.no_grad():
    # å™ªå£°å›¾åƒå’Œæ—¶é—´æ­¥é•¿ä¼ è¿›å»
    noisy_residual = model(sample=noisy_sample, timestep=2).sample
```

### è°ƒåº¦å™¨ Schedulers


ç»™å®šæ¨¡å‹è¾“å‡ºï¼Œè°ƒåº¦ç¨‹åºç®¡ç†ä»å™ªå£°æ ·æœ¬åˆ°å™ªå£°è¾ƒå°çš„æ ·æœ¬ - æœ¬ä¾‹ä¸­æ˜¯ noisy_residual.

Diffusers ç”¨äºæ„å»ºæ‰©æ•£ç³»ç»Ÿçš„å·¥å…·ç®±ã€‚è™½ç„¶ DiffusionPipeline æ˜¯ä½¿ç”¨é¢„æ„å»ºæ‰©æ•£ç³»ç»Ÿçš„ä¾¿æ·æ–¹æ³•ï¼Œä½†ä¹Ÿå¯ä»¥å•ç‹¬é€‰æ‹©è‡ªå·±çš„æ¨¡å‹å’Œè°ƒåº¦ç¨‹åºç»„ä»¶æ¥æ„å»ºè‡ªå®šä¹‰æ‰©æ•£ç³»ç»Ÿã€‚

è°ƒåº¦ç¨‹åºæ ¹æ®æ¨¡å‹çš„è¾“å‡ºç»“æœï¼ˆç¤ºä¾‹ä¸­æ¨¡å‹è¾“å‡ºç»“æœå°±æ˜¯å™ªå£°æ®‹å·®ï¼‰ï¼Œå°†å™ªå£°æ ·æœ¬è½¬æ¢ä¸ºå™ªå£°è¾ƒå°çš„æ ·æœ¬ã€‚

ç”¨å…¶ `DDPMScheduler` çš„ `from_config()`

```py
from diffusers import DDPMScheduler

scheduler = DDPMScheduler.from_pretrained(repo_id)
scheduler

# æ ¹æ®æ¨¡å‹çš„è¾“å‡ºç»“æœï¼ˆå™ªå£°æ®‹å·®ï¼‰ï¼Œå°†å™ªå£°æ ·æœ¬è½¬æ¢ä¸ºå™ªå£°è¾ƒå°çš„æ ·æœ¬ã€‚
less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample
less_noisy_sample.shape
```

è‡ªå®šä¹‰è°ƒåº¦å™¨

```py
from diffusers import EulerDiscreteScheduler

# è‡ªå®šä¹‰è°ƒåº¦ç¨‹åº: é»˜è®¤ PNDMScheduler æ›¿æ¢ä¸º EulerDiscreteScheduler
pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)
```
ğŸ’¡
- ä¸æ¨¡å‹ä¸åŒï¼Œè°ƒåº¦ç¨‹åºæ²¡æœ‰**å¯è®­ç»ƒçš„æƒé‡**å¹¶ä¸”**æ— å‚æ•°**

ä¸€äº›æœ€é‡è¦å‚æ•°:
- `num_train_timesteps`:å»å™ªè¿‡ç¨‹çš„é•¿åº¦ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œå°†éšæœºé«˜æ–¯å™ªå£°å¤„ç†ä¸ºæ•°æ®æ ·æœ¬æ‰€éœ€çš„æ—¶é—´æ­¥æ•°ã€‚
- `beta_schedule`:ç”¨äºæ¨ç†å’Œè®­ç»ƒçš„å™ªå£°è®¡åˆ’ç±»å‹ã€‚
- `beta_start` å’Œ `beta_end`:å™ªå£°è¡¨çš„å¼€å§‹å’Œç»“æŸå™ªå£°å€¼ã€‚

è¦é¢„æµ‹å™ªå£°ç¨ä½çš„å›¾åƒï¼Œéœ€è¦ä¼ å…¥: **æ¨¡å‹è¾“å‡º**(noisy residual)ã€**æ­¥é•¿**(timestep) å’Œ **å½“å‰æ ·æœ¬**(noisy sample)ã€‚

```py
less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample
less_noisy_sample.shape
```

å¦‚æœå°† less_noisy_sample ä½œä¸ºè¾“å…¥ï¼Œé€’å½’è°ƒç”¨ï¼Œå°†å¾—åˆ°ä¸€ä¸ªå™ªéŸ³æ›´å°ã€è´¨é‡æ›´å¥½çš„å›¾åƒï¼ç°åœ¨è®©æˆ‘ä»¬å°†æ‰€æœ‰å†…å®¹æ”¾åœ¨ä¸€èµ·å¹¶å¯è§†åŒ–æ•´ä¸ªå»å™ªè¿‡ç¨‹ã€‚

é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå¯¹å»å™ªå›¾åƒè¿›è¡Œåå¤„ç†å¹¶å°†å…¶æ˜¾ç¤ºä¸º `PIL.Image`:

ä¸ºäº†åŠ é€Ÿå»å™ªè¿‡ç¨‹ï¼Œè¯·å°†è¾“å…¥å’Œæ¨¡å‹ç§»è‡³ GPU:

```py
model.to("cuda")
noisy_sample = noisy_sample.to("cuda")
```

åˆ›å»ºå»å™ªå¾ªç¯æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ ·æœ¬çš„æ®‹å·®ï¼Œå¹¶ä½¿ç”¨è°ƒåº¦ç¨‹åºè®¡ç®—å™ªå£°è¾ƒå°çš„æ ·æœ¬:

```py
import tqdm
import PIL.Image
import numpy as np

# å»å™ªå›¾åƒåå¤„ç†
def display_sample(sample, i):
    image_processed = sample.cpu().permute(0, 2, 3, 1)
    image_processed = (image_processed + 1.0) * 127.5
    image_processed = image_processed.numpy().astype(np.uint8)

    image_pil = PIL.Image.fromarray(image_processed[0])
    display(f"Image at step {i}")
    display(image_pil)

# åˆ›å»ºå»å™ªå¾ªç¯ï¼Œé¢„æµ‹å™ªå£°è¾ƒå°çš„æ ·æœ¬çš„æ®‹å·®
sample = noisy_sample  
for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):
    # 1. é¢„æµ‹å™ªå£°æ®‹å·® predict noise residual
    with torch.no_grad():
        residual = model(sample, t).sample
    # 2. è®¡ç®—å™ªå£°å›¾åƒ compute less noisy image and set x_t -> x_t-1
    sample = scheduler.step(residual, t, sample).prev_sample
    # 3. å®šæœŸæŸ¥çœ‹å›¾åƒ optionally look at image
    if (i + 1) % 50 == 0:
        display_sample(sample, i + 1)

```

### æ¨ç†


æ¨ç† Inference code

æ¨¡å‹ã€è°ƒåº¦å™¨ã€å¯è§†åŒ–ã€æ¨ç†ç­‰
- [diffusersæ•™ç¨‹](https://juejin.cn/post/7280746811320533027)

#### å•æœº

```py
from diffusers import DDPMScheduler, UNet2DModel
from PIL import Image
import torch
import numpy as np

scheduler = DDPMScheduler.from_pretrained("google/ddpm-cat-256")
model = UNet2DModel.from_pretrained("google/ddpm-cat-256").to("cuda")
scheduler.set_timesteps(50)

sample_size = model.config.sample_size
noise = torch.randn((1, 3, sample_size, sample_size)).to("cuda")
input = noise

for t in scheduler.timesteps:
    with torch.no_grad():
        noisy_residual = model(input, t).sample
        prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample
        input = prev_noisy_sample

image = (input / 2 + 0.5).clamp(0, 1)
image = image.cpu().permute(0, 2, 3, 1).numpy()[0]
image = Image.fromarray((image * 255).round().astype("uint8"))
image
```

#### åˆ†å¸ƒå¼

Distributed inference åˆ†å¸ƒå¼

##### Accelerate


```py
from accelerate import PartialState
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
distributed_state = PartialState()
pipeline.to(distributed_state.device)

with distributed_state.split_between_processes(["a dog", "a cat"]) as prompt:
    result = pipeline(prompt).images[0]
    result.save(f"result_{distributed_state.process_index}.png")
```

shell ä»£ç 

```sh
accelerate launch run_distributed.py --num_processes=2
```

##### PyTorch Distributed


```py
import torch
import torch.distributed as dist
import torch.multiprocessing as mp

from diffusers import DiffusionPipeline

sd = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)


def run_inference(rank, world_size):
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

    sd.to(rank)

    if torch.distributed.get_rank() == 0:
        prompt = "a dog"
    elif torch.distributed.get_rank() == 1:
        prompt = "a cat"

    image = sd(prompt).images[0]
    image.save(f"./{'_'.join(prompt)}.png")
    
    
def main():
    world_size = 2
    mp.spawn(run_inference, args=(world_size,), nprocs=world_size, join=True)


if __name__ == "__main__":
    main()
```

shell ä»£ç 

```sh
torchrun run_distributed.py --nproc_per_node=2
```


### è®­ç»ƒ


#### å•æœº

è®­ç»ƒä»£ç 

```py
from accelerate import Accelerator
from huggingface_hub import HfFolder, Repository, whoami
from tqdm.auto import tqdm
from pathlib import Path
import os


def get_full_repo_name(model_id: str, organization: str = None, token: str = None):
    if token is None:
        token = HfFolder.get_token()
    if organization is None:
        username = whoami(token)["name"]
        return f"{username}/{model_id}"
    else:
        return f"{organization}/{model_id}"


def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):
    # Initialize accelerator and tensorboard logging
    accelerator = Accelerator(
        mixed_precision=config.mixed_precision,
        gradient_accumulation_steps=config.gradient_accumulation_steps,
        log_with="tensorboard",
        project_dir=os.path.join(config.output_dir, "logs"),
    )
    if accelerator.is_main_process:
        if config.push_to_hub:
            repo_name = get_full_repo_name(Path(config.output_dir).name)
            repo = Repository(config.output_dir, clone_from=repo_name)
        elif config.output_dir is not None:
            os.makedirs(config.output_dir, exist_ok=True)
        accelerator.init_trackers("train_example")

    # Prepare everything
    # There is no specific order to remember, you just need to unpack the
    # objects in the same order you gave them to the prepare method.
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, lr_scheduler
    )

    global_step = 0
    # Now you train the model
    for epoch in range(config.num_epochs):
        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)
        progress_bar.set_description(f"Epoch {epoch}")

        for step, batch in enumerate(train_dataloader):
            clean_images = batch["images"]
            # Sample noise to add to the images
            noise = torch.randn(clean_images.shape).to(clean_images.device)
            bs = clean_images.shape[0]

            # Sample a random timestep for each image
            timesteps = torch.randint(
                0, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device
            ).long()

            # Add noise to the clean images according to the noise magnitude at each timestep
            # (this is the forward diffusion process)
            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)

            with accelerator.accumulate(model):
                # Predict the noise residual
                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]
                loss = F.mse_loss(noise_pred, noise)
                accelerator.backward(loss)

                accelerator.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()

            progress_bar.update(1)
            logs = {"loss": loss.detach().item(), "lr": lr_scheduler.get_last_lr()[0], "step": global_step}
            progress_bar.set_postfix(**logs)
            accelerator.log(logs, step=global_step)
            global_step += 1

        # After each epoch you optionally sample some demo images with evaluate() and save the model
        if accelerator.is_main_process:
            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)

            if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:
                evaluate(config, epoch, pipeline)

            if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:
                if config.push_to_hub:
                    repo.push_to_hub(commit_message=f"Epoch {epoch}", blocking=True)
                else:
                    pipeline.save_pretrained(config.output_dir)
```





### å®‰è£…

å®‰è£…
- mac, pytorch, python 3.8~3.11


```sh
pip install --upgrade diffusers accelerate transformers
#pip install diffusers["torch"] transformers
```

å»ºè®®åœ¨ GPU ä¸Šè¿è¡Œï¼Œå› ä¸ºè¯¥æ¨¡å‹ç”±å¤§çº¦ 14 äº¿ä¸ªå‚æ•°ç»„æˆã€‚é€šè¿‡to("cuda")å³å¯å°†ç”Ÿæˆå™¨å¯¹è±¡ç§»è‡³GPU:

```py
pipeline.to("cuda")
```

ã€2024-9-29ã€‘Ubuntu + v100s ä¸Šæ‰§è¡ŒæŠ¥é”™

```sh
Failed to import diffusers.loaders.unet because of the following error (look up to see its traceback):
No module named 'peft.tuners.tuners_utils'
```



### ç¤ºä¾‹



ç®€æ˜“ç¤ºä¾‹

```py
from diffusers import DiffusionPipeline

# ==== åŠ è½½æƒé‡ ====
# ä¸‹è½½è¿œç¨‹æ¨¡å‹ï¼Œæ¯”è¾ƒå¤§ï¼Œé»˜è®¤ä¸‹è½½ç›®å½•ä¸º ~/.cache/huggingfaceï¼Œå¯é€šè¿‡ export HF_HOME=æŒ‡å®šç›®å½•ï¼Œæœ€å¥½å†™å…¥~/.bashrcæŒä¹…åŒ–
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
pipeline = DiffusionPipeline.from_pretrained("./stable-diffusion-v1-5", use_safetensors=True) # æœ¬åœ°æƒé‡

# è‡ªå®šä¹‰è°ƒåº¦ç¨‹åº: é»˜è®¤ PNDMScheduler æ›¿æ¢ä¸º EulerDiscreteScheduler
pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)

# ==== GPU ====
pipeline.to("cuda")
# ==== text2image ====
image = pipeline("An image of a squirrel in Picasso style").images[0]
image # å›¾åƒè¾“å‡ºåŒ…è£…åœ¨ä¸€ä¸ª PIL.Image å¯¹è±¡ä¸­
# ==== ä¿å­˜ ====
image.save("image_of_squirrel_painting.png") # ä¿å­˜å›¾åƒ

```

DiffusionPipeline ä¸‹è½½å¹¶ç¼“å­˜æ‰€æœ‰ modelã€tokenizationã€scheduling ç»„ä»¶ã€‚

ç¤ºä¾‹ä¸­, StableDiffusionPipeline ç”± UNet2DConditionModel å’Œ PNDMScheduler ç­‰ç»„æˆ:

```py
# pipeline
StableDiffusionPipeline {
  "_class_name": "StableDiffusionPipeline",
  "_diffusers_version": "0.21.4",
  ...,
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  ...,
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```

æ¡ˆä¾‹
- æ–‡ç”Ÿå›¾
- å›¾ç”Ÿå›¾

```py
from diffusers import StableDiffusionPipeline
from diffusers import StableDiffusionImg2ImgPipeline
from PIL import Image
import torch

# --------- æœ¬åœ°æ¨¡å‹ä¿¡æ¯ ----------
model_path = '/mnt/bd/wangqiwen-hl/models/video'
model_id = "runwayml/stable-diffusion-v1-5"

# --------- text2image ---------
#pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, cache_dir=model_path)
pipe = pipe.to("cuda")

prompt = "a man and a woman holding a cat and a dog"
prompt = "sexy lady walking on the bed"
negative_prompt = "distorted faces, low resolution"
images = pipe(prompt, num_images_per_prompt=3, negative_prompt=negative_prompt).images  
num = len(images)
print(f"ä¸€å…±ç”Ÿæˆäº†{num}å¼ å›¾ç‰‡, é»˜è®¤ä¿å­˜ç¬¬ä¸€å¼ ")
for i in range(num):
    images[i].save(f"output_{i+1}.png")
#image[0].save("output.png")

# --------- image2image ---------
pipeimg = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16, cache_dir=model_path)
pipeimg = pipe.to("cuda")
# é€‰å–ä¸€å¼ æ¥è¿›ä¸€æ­¥ä¿®æ”¹
from PIL import Image
init_image = Image.open("output_1.png").convert("RGB").resize((768, 512))
#Image.open("output_1.png").convert("RGB").resize((768, 512))

prompt = "add another girl"
prompt = "add more detail to make it more attractive"
images = pipe(prompt=prompt, num_images_per_prompt=3, negative_prompt=negative_prompt, image=init_image, strength=0.75, guidance_scale=7.5).images
num = len(images)
for i in range(num): 
    images[i].save(f"modify_{i+1}.png")
#images[0].save("output_modify.png")
```



## æ‰©æ•£æ¨¡å‹å¾®è°ƒ

Stable Diffusion ç”±äºåœ¨å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„è®­ç»ƒï¼Œå·²ç»å…·å¤‡äº†å¤§é‡æ¦‚å¿µçš„çŸ¥è¯†ã€‚

åœ¨è®­ç»ƒ LoRA æ—¶ï¼Œå……åˆ†åˆ©ç”¨è¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼Œå¹¶åŒºåˆ†â€œ`æ–°æ¦‚å¿µ`ï¼ˆNCï¼‰â€å’Œâ€œ`ä¿®æ”¹æ¦‚å¿µ`ï¼ˆMCï¼‰â€ã€‚
- `æ–°æ¦‚å¿µ`: åœ¨ Stable Diffusion åŸå§‹è®­ç»ƒä¸­ä¸å­˜åœ¨æˆ–æœªå¾—åˆ°å……åˆ†ä½“ç°çš„æ¦‚å¿µæˆ–å…ƒç´ ã€‚å¯èƒ½æ˜¯æ¨¡å‹ä¹‹å‰æœªé‡åˆ°è¿‡çš„ç‹¬ç‰¹ä¸»é¢˜ã€é£æ ¼æˆ–ç‰©å“ã€‚ä½¿ç”¨ NCs è¿›è¡Œè®­ç»ƒæ¶‰åŠå‘æ¨¡å‹å¼•å…¥å…¨æ–°ä¿¡æ¯ã€‚
  - ç›®æ ‡: æ‰©å±•æ¨¡å‹å¯¹è¿™äº›æ–°é¢–å…ƒç´ çš„â€œç†è§£â€ã€‚é€šå¸¸ä¼šåœ¨æ•°æ®é›†ä¸­æ·»åŠ â€œæ¿€æ´»æ ‡ç­¾â€æ¥è¡¨ç¤ºå®ƒä»¬ã€‚
- `ä¿®æ”¹æ¦‚å¿µ` (MC) æŒ‡æ¨¡å‹å·²ç»è¯†åˆ«ä½†å¯èƒ½æœªå‡†ç¡®æˆ–ä»¥æœŸæœ›æ–¹å¼è¡¨ç¤ºçš„æ¦‚å¿µã€‚
  - è¿™äº›å¯èƒ½æ˜¯ç°æœ‰ä¸»é¢˜ã€é£æ ¼æˆ–è§£é‡Šçš„å˜ä½“ã€‚è®­ç»ƒ MCs æ¶‰åŠè°ƒæ•´æˆ–ç²¾ç‚¼æ¨¡å‹çš„ç°æœ‰çŸ¥è¯†ã€‚
  - ç›®çš„: ä¸å¼•å…¥æ–°çŸ¥è¯†ï¼Œè€Œæ˜¯å¾®è°ƒå’Œç²¾ç‚¼æ¨¡å‹çš„ç°æœ‰ç†è§£ã€‚

è®­ç»ƒ LoRA æ¨¡å‹æ—¶ï¼Œéœ€è¦ç†è§£ Stable Diffusion çš„åŸºç¡€çŸ¥è¯†ï¼ˆå³æ¨¡å‹å·²ç»æŒæ¡å¾—å¾ˆå¥½çš„éƒ¨åˆ†ï¼‰ä»¥åŠå®ƒæ‰€ç¼ºä¹æˆ–è¯¯è§£çš„å†…å®¹ã€‚åŸºäºè¿™äº›çŸ¥è¯†ï¼Œç²¾å¿ƒç­–åˆ’è®­ç»ƒæ•°æ®é›†ï¼Œä»¥å¡«è¡¥è¿™äº›ç©ºç™½æˆ–çº æ­£é”™è¯¯ï¼Œæ— è®ºå±äº NC è¿˜æ˜¯ MCã€‚

ç„¶åï¼Œå¯ä»¥æˆ˜ç•¥æ€§åœ°ä½¿ç”¨æ¿€æ´»æ ‡ç­¾æ¥å¼•å…¥æ–°æ¦‚å¿µã€‚

é€šè¿‡è¿™ç§å¯¹ NC å’Œ MC çš„ç†è§£æ¥è®­ç»ƒ LoRAï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°å¼•å¯¼ Stable Diffusion ä¸ç‰¹å®šæ„¿æ™¯ä¿æŒä¸€è‡´ã€‚

è¯¦è§ [LoRA è®­ç»ƒè¿›é˜¶æŒ‡å—](https://zhuanlan.zhihu.com/p/719472252)


## æ‰©æ•£æ¨¡å‹æ¡ˆä¾‹

æ‰©æ•£æ¨¡å‹æœ‰å¾ˆå¤šåº”ç”¨ç‰ˆæœ¬

### DALL-E 1
 
DALLE-1 æ¨¡å‹å›¾
- ![](https://pic4.zhimg.com/80/v2-9c4d153d5e7c38fc29e34c46b7f75003_1440w.webp)
- é¦–å…ˆ, å›¾åƒåœ¨ç¬¬ä¸€é˜¶æ®µé€šè¿‡ `dVAE`ï¼ˆç¦»æ•£å˜åˆ†è‡ªåŠ¨ç¼–ç æœºï¼‰è®­ç»ƒå¾—åˆ°å›¾åƒçš„ image tokensã€‚æ–‡æœ¬ caption é€šè¿‡æ–‡æœ¬ç¼–ç å™¨å¾—åˆ° text tokensã€‚
- Text tokens å’Œ image tokens ä¼šä¸€èµ·æ‹¼æ¥èµ·æ¥ç”¨ä½œ Transformer çš„è®­ç»ƒã€‚
  - Transformer çš„ä½œç”¨æ˜¯å°† text tokens å›å½’åˆ° image tokensã€‚
  - å½“å®Œæˆè¿™æ ·çš„è®­ç»ƒä¹‹åï¼Œå®ç°äº†ä»æ–‡æœ¬ç‰¹å¾åˆ°å›¾åƒç‰¹å¾çš„å¯¹åº”ã€‚
- ç”Ÿæˆé˜¶æ®µï¼Œcaption é€šè¿‡ç¼–ç å™¨å¾—åˆ° text tokensï¼Œç„¶åé€šè¿‡ transformer å¾—åˆ° image tokensï¼Œæœ€å image tokens åœ¨é€šè¿‡ç¬¬ä¸€é˜¶æ®µè®­ç»ƒå¥½çš„ image decoder éƒ¨åˆ†ç”Ÿæˆå›¾åƒã€‚
  - å› ä¸ºå›¾åƒæ˜¯é€šè¿‡é‡‡æ ·ç”Ÿæˆï¼Œè¿™é‡Œè¿˜ä½¿ç”¨äº† `CLIP` æ¨¡å‹å¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œæ’åºï¼Œé€‰æ‹©ä¸æ–‡æœ¬ç‰¹å¾ç›¸ä¼¼åº¦æœ€é«˜çš„å›¾åƒä½œä¸ºæœ€ç»ˆçš„ç”Ÿæˆå¯¹è±¡ã€‚

### DALL-E 2

DALLE-2 æ¨¡å‹å›¾
- ![](https://pic1.zhimg.com/80/v2-fba4b48963c09cb9be65c598df8f2214_1440w.webp)
 
DALLE-2 æ¨¡å‹ç»“æ„ã€‚
- text encoder å’Œ image encoder å°±æ˜¯ç”¨ CLIP ä¸­çš„ç›¸åº”æ¨¡å—ã€‚åœ¨è®­ç»ƒé˜¶æ®µé€šè¿‡è®­ç»ƒ prior æ¨¡å—ï¼Œå°† text tokens å’Œ image tokens å¯¹åº”èµ·æ¥ã€‚
- åŒæ—¶è®­ç»ƒ GLIDE æ‰©æ•£æ¨¡å‹ï¼Œè¿™ä¸€æ­¥çš„ç›®çš„æ˜¯ä½¿å¾—è®­ç»ƒåçš„ GLIDE æ¨¡å‹å¯ä»¥ç”Ÿæˆä¿æŒåŸå§‹å›¾åƒç‰¹å¾ï¼Œè€Œå…·ä½“å†…å®¹ä¸åŒçš„å›¾åƒï¼Œè¾¾åˆ°ç”Ÿæˆå›¾åƒçš„å¤šæ ·æ€§ã€‚
- å½“ç”Ÿæˆå›¾åƒæ—¶ï¼Œæ¨¡å‹æ•´ä½“ç±»ä¼¼åœ¨ CLIP æ¨¡å‹ä¸­å¢åŠ äº† prior æ¨¡å—ï¼Œå®ç°äº†æ–‡æœ¬ç‰¹å¾åˆ°å›¾åƒç‰¹å¾çš„å¯¹åº”ã€‚ç„¶åé€šè¿‡æ›¿æ¢ image decoder ä¸º GLIDE æ¨¡å‹ï¼Œæœ€ç»ˆå®ç°äº†æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆã€‚

### DALL-E 3

ã€2023-10-07ã€‘DALL-E 3 æƒŠè‰³å‘å¸ƒï¼Œå®Œå…¨å…è´¹ï¼æ¯”è‚©Midjourneyçš„AIç»˜å›¾å·¥å…·

DALLÂ·E 3 æ²¡æœ‰ä¸€ä¸ªå•ç‹¬ç½‘å€ï¼Œè¦åœ¨Bingé‡Œé¢ä½¿ç”¨å®ƒ
- åˆ‡æ¢ä»£ç†åˆ°å…¶ä»–å›½å®¶ï¼Œç„¶åæ‰“å¼€[bing](https://www.bing.com/images/create?FORM=GDPCLS), ç›´æ¥è¾“å…¥ä¸­æ–‡
- æ¯ç”Ÿæˆä¸€å¼ ç…§ç‰‡éƒ½æ¶ˆè€—ç”µåŠ›ï¼Œåˆå§‹ç”µåŠ›æ˜¯100ç‚¹, ç›®å‰è¿˜æ˜¯å…è´¹


### Imagen (æœªå¼€æº)

Imagenæ¨¡å‹ç»“æ„å›¾
- ![](https://pic4.zhimg.com/80/v2-170fe8538abff5f42bfc9f2964c153cb_1440w.webp)
 
Imagen ç”Ÿæˆæ¨¡å‹è¿˜æ²¡æœ‰å…¬å¸ƒä»£ç å’Œæ¨¡å‹ï¼Œä»è®ºæ–‡ä¸­çš„æ¨¡å‹ç»“æ„æ¥çœ‹ï¼Œä¼¼ä¹é™¤äº†æ–‡æœ¬ç¼–ç å™¨ä¹‹å¤–ï¼Œæ˜¯ç”±ä¸€ä¸ªæ–‡æœ¬-å›¾åƒæ‰©æ•£æ¨¡å‹æ¥å®ç°å›¾åƒç”Ÿæˆå’Œä¸¤ä¸ªè¶…åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹æ¥æå‡å›¾åƒè´¨é‡ã€‚
 
### Imagic (æœªå¼€æº)

ImagicåŸç†å›¾
- ![](https://pic1.zhimg.com/80/v2-75c0c74a820c109767a3755b7ace675c_1440w.webp)
- æœ€æ–°çš„ Imagic æ¨¡å‹ï¼Œå·ç§°å¯ä»¥å®ç°é€šè¿‡æ–‡æœ¬å¯¹å›¾åƒè¿›è¡Œ **PS çº§åˆ«**çš„ä¿®æ”¹å†…å®¹ç”Ÿæˆã€‚ç›®å‰æ²¡æœ‰å…¬å¸ƒæ¨¡å‹å’Œä»£ç ã€‚
- ä»åŸç†å›¾æ¥çœ‹ï¼Œä¼¼ä¹æ˜¯é€šè¿‡åœ¨æ–‡æœ¬-å›¾åƒæ‰©æ•£æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å¯¹æ–‡æœ¬åµŒå…¥çš„æ”¹å˜å’Œä¼˜åŒ–æ¥å®ç°ç”Ÿæˆå†…å®¹çš„æ”¹å˜ã€‚å¦‚æœæŠŠæ‰©æ•£æ¨¡å‹æ›¿æ¢æˆç®€å•çš„ encoder å’Œ decoderï¼Œæœ‰ç‚¹ç±»ä¼¼äºåœ¨ VAE æ¨¡å‹ä¸Šåšä¸åŒäººè„¸çš„ç”Ÿæˆã€‚åªä¸è¿‡æ˜¯æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›å’Œç‰¹å¾ç©ºé—´è¦è¿œè¶…è¿‡ VAEã€‚

### Stable diffusion
 
Stable diffusion ç»“æ„å›¾
- ![](https://pic4.zhimg.com/80/v2-cf9e1315cbb45c4d49e14d275be39bd7_1440w.webp)

`Stable diffusion` æ˜¯ `Stability AI` å…¬å¸å¼€å‘å¹¶ä¸”å¼€æºçš„ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ã€‚

æœ´ç´ çš„ DDPM æ‰©æ•£æ¨¡å‹ï¼Œæ¯ä¸€æ­¥éƒ½åœ¨å¯¹**å›¾åƒ**ä½œâ€œåŠ å™ªâ€ã€â€œå»å™ªâ€æ“ä½œã€‚è€Œåœ¨ Stable diffusion æ¨¡å‹ä¸­ï¼Œå¯ä»¥ç†è§£ä¸ºæ˜¯å¯¹å›¾åƒè¿›è¡Œç¼–ç åçš„ **image tokens** ä½œåŠ å™ªå»å™ªã€‚è€Œåœ¨å»å™ªï¼ˆç”Ÿæˆï¼‰çš„è¿‡ç¨‹ä¸­ï¼ŒåŠ å…¥äº†æ–‡æœ¬ç‰¹å¾ä¿¡æ¯ç”¨æ¥å¼•å¯¼å›¾åƒç”Ÿæˆï¼ˆå›¾å³ Conditioning éƒ¨åˆ†ï¼‰ã€‚è·Ÿ VAE ä¸­çš„æ¡ä»¶ VAE å’Œ GAN ä¸­çš„æ¡ä»¶ GAN åŸç†æ˜¯ä¸€æ ·çš„ï¼Œé€šè¿‡åŠ å…¥è¾…åŠ©ä¿¡æ¯ï¼Œç”Ÿæˆéœ€è¦çš„å›¾åƒã€‚


## å®æ—¶æ‰©æ•£æ¨¡å‹

ã€2025-7-19ã€‘[ä¸–ç•Œé¦–ä¸ªå®æ—¶æ‰©æ•£æ¨¡å‹è¯ç”Ÿ](https://zhuanlan.zhihu.com/p/1930033424854394877)

### ä¸ºä»€ä¹ˆéœ€è¦å®æ—¶æ‰©æ•£æ¨¡å‹ï¼Ÿ

2022 å¹´ä»¥æ¥ï¼Œæ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰åœ¨**é™æ€**å›¾åƒç”Ÿæˆä¸Šå¤§æ”¾å¼‚å½©ï¼Œä½†è¦å°†å…¶åº”ç”¨äºå®æ—¶è§†é¢‘æµï¼Œåˆ™é¢ä¸´ï¼š
- **é«˜å»¶è¿Ÿ**ï¼šä¼ ç»Ÿæ‰©æ•£éœ€è¦ä¸Šç™¾ä¸ªé‡‡æ ·æ­¥éª¤ï¼›
- **è·¨å¸§ä¸€è‡´æ€§**ï¼šè§†é¢‘éœ€ä¿æŒè¿ç»­æ€§ï¼Œé¿å…é—ªçƒå’Œè·³å¸§ï¼›
- **æ— é™é•¿åº¦**ï¼šä¸€æ¬¡æ€§ç”Ÿæˆé•¿è§†é¢‘ä¼šè€—å°½æ˜¾å­˜ï¼Œä¸”æ— æ³•å®æ—¶è¾“å‡ºã€‚

ç›®å‰å¸‚é¢ä¸Šçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä¸€èˆ¬æœ‰ 5-10s å»¶è¿Ÿï¼Œä¸”æ¯ä¸ªç‰‡æ®µ 5-10s, è¦æƒ³è¾¾åˆ°å®æ—¶ç”Ÿæˆï¼Œå¿…é¡»åœ¨ 40ms å†…å®Œæˆå•å¸§å›¾åƒç”Ÿæˆ

Live Stream Diffusion (LSD)

###  MirageLSD

å®æ—¶è§†é¢‘å†…å®¹ç”Ÿæˆä¸åœºæ™¯è½¬æ¢æˆä¸ºäº†ä¼—å¤šåº”ç”¨åœºæ™¯çš„æ ¸å¿ƒéœ€æ±‚â€”â€”ä»ç›´æ’­äº’åŠ¨ã€æ¸¸æˆå¼€å‘åˆ°åŠ¨ç”»åˆ¶ä½œã€è™šæ‹Ÿè¯•è¡£ï¼Œä»»ä½•éœ€è¦â€œåœºæ™¯éšå¿ƒæ‰€æ¬²â€ çš„åœºåˆéƒ½æ¸´æœ›æ›´ä½å»¶è¿Ÿã€æ›´é«˜è´¨é‡ã€æ›´æ˜“é›†æˆçš„è§£å†³æ–¹æ¡ˆã€‚

[é¦–ä¸ªç›´æ’­æµæ‰©æ•£](https://cloud.tencent.com/developer/article/2543675)(LSD)AIæ¨¡å‹ï¼šMirageLSD
- å®æ—¶æŠŠ**ä»»æ„**è§†é¢‘æµè½¬æ¢æˆè‡ªå®šä¹‰æœè£…é£æ ¼â€”â€”è™šæ‹Ÿæ¢è£…æ–°ä½“éªŒ
- ä½“éªŒåœ¨çº¿ [Demo](https://mirage.decart.ai/) ï¼Œæ— é—¨æ§›è¯•ç©ï¼Œæ¯æ¬¡è¯•ç©5min

MirageLSD æ˜¯ Decart AI æœ€æ–°å‘å¸ƒçš„é¦–ä¸ª `ç›´æ’­æµæ‰©æ•£`ï¼ˆLive Stream Diffusion, LSDï¼‰ æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ 24 FPS ä¸‹ã€ç«¯åˆ°ç«¯å»¶è¿Ÿ <40ms çš„æ¡ä»¶ä¸‹ï¼Œå®æ—¶å°†ä»»æ„è§†é¢‘æµè½¬æ¢æˆä»»ä½•åœºæ™¯ï¼Œå¹¶æ”¯æŒ**æ— é™é•¿åº¦**è§†é¢‘çš„æŒç»­è¾“å‡ºã€‚

MirageLSD çš„å‡ºç°ï¼Œçªç ´ä»¥ä¸Šç“¶é¢ˆï¼Œå°†æ‰©æ•£æ¨¡å‹çœŸæ­£å¸¦å…¥å®æ—¶è§†é¢‘åº”ç”¨æ—¶ä»£ã€‚
- ç»§ ç¬¬ä¸€æ¬¾ Oasis åçš„æ–°æ¨¡å‹


Decart è‡ªç ” Live Stream Diffusionï¼ˆLSDï¼‰æ¨¡å‹ã€‚
- ä¿æŒæ—¶é—´è¿è´¯æ€§çš„åŒæ—¶ï¼Œé€å¸§ç”Ÿæˆè§†é¢‘ï¼Œå¹¶æ”¯æŒå®Œå…¨äº¤äº’å¼çš„è§†é¢‘åˆæˆã€‚
- ç”¨æˆ·å¯ä»¥åœ¨è§†é¢‘ç”Ÿæˆçš„åŒæ—¶ï¼Œè¿›è¡ŒæŒç»­æç¤ºã€å˜æ¢å’Œç¼–è¾‘ï¼Œå®ç°äº†çœŸæ­£çš„å®æ—¶äº¤äº’ã€‚

ä¸ºäº†å®ç°å®æ—¶ç”Ÿæˆï¼ŒLSDæ¨¡å‹é‡‡ç”¨äº†å¤šç§åˆ›æ–°æŠ€æœ¯ã€‚
- é¦–å…ˆï¼Œè®¾è®¡è‡ªå®šä¹‰çš„CUDAè¶…å¤§å†…æ ¸ï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘å¼€é”€å¹¶æé«˜ååé‡ã€‚
- å…¶æ¬¡ï¼Œåœ¨å¿«æ·è’¸é¦å’Œæ¨¡å‹å‰ªæçš„åŸºç¡€ä¸Šï¼Œå‡å°‘äº†æ¯å¸§æ‰€éœ€çš„è®¡ç®—é‡ã€‚
- æœ€åï¼Œä¼˜åŒ–æ¨¡å‹æ¶æ„ä»¥ä¸GPUç¡¬ä»¶å¯¹é½ï¼Œå®ç°äº†æœ€é«˜æ•ˆç‡ã€‚

è¿™äº›æŠ€æœ¯çš„å…±åŒä½œç”¨ï¼Œä½¿å¾— MirageLSD å“åº”é€Ÿåº¦æ¯”ä¹‹å‰çš„æ¨¡å‹æé«˜äº†**16å€**ï¼Œå®ç°äº†æ¯ç§’**24å¸§**çš„å®æ—¶è§†é¢‘ç”Ÿæˆã€‚

MirageLSD è¿˜è§£å†³äº†ä»¥å¾€è§†é¢‘æ¨¡å‹åœ¨ç”Ÿæˆé•¿è§†é¢‘æ—¶å®¹æ˜“å‡ºç°çš„**è¯¯å·®ç´¯ç§¯**é—®é¢˜ã€‚
- å¼•å…¥äº†**å†å²å¢å¼º**æŠ€æœ¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹å¹¶ä¿®æ­£è¾“å…¥ä¸­çš„ä¼ªå½±ï¼Œä»è€Œå¢å¼ºäº†å¯¹è‡ªå›å½’ç”Ÿæˆä¸­å¸¸è§æ¼‚ç§»çš„é²æ£’æ€§ã€‚

è¿™ä½¿å¾—MirageLSDæˆä¸ºé¦–ä¸ªèƒ½å¤Ÿæ— é™ç”Ÿæˆè§†é¢‘çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚

éšç€MirageLSDçš„æ¨å‡ºï¼Œæœªæ¥çš„è§†é¢‘å¨±ä¹å’Œç›´æ’­äº’åŠ¨å°†æ‹¥æœ‰æ›´å¤šçš„å¯èƒ½æ€§ã€‚

ç”¨æˆ·ä¸å†å—é™äºç›´æ’­è®¾å¤‡çš„æ€§èƒ½ï¼Œå³ä½¿è®¾å¤‡å†å·®ï¼Œä¹Ÿèƒ½é€šè¿‡MirageLSDå°†ç›´æ’­ç”»é¢è½¬åŒ–ä¸ºå…¨æ–°åœºæ™¯ï¼Œå®ç°â€œå®Œç¾ç›´æ’­â€ã€‚

åŒæ—¶ï¼ŒMirageLSDä¹Ÿä¸ºç§‘å¹»ç”µå½±åˆ¶ä½œã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„åˆ›æ–°æœºé‡ã€‚

including facial consistency, voice control, and precise object control

æ¥ä¸‹æ¥ï¼Œæ¢ç´¢å¢åŠ  audio, emotions, music


#### MirageLSD æ¶æ„

MirageLSD æ¶æ„è§£è¯»
1. **æ—¶ç©º U-Net æ ¸å¿ƒ**
  - è¾“å…¥ï¼šæ¥è‡ªæ‘„åƒå¤´ã€å±å¹•æ•è·ã€æ¸¸æˆå¼•æ“çš„è¿ç»­è§†é¢‘å¸§ã€‚
  - ç¼–ç å™¨ï¼šå¤šå±‚ 2D å·ç§¯åŠ  3D å·ç§¯æ··åˆï¼Œæå–å•å¸§ä¸ç›¸é‚»å¸§çš„æ—¶ç©ºç‰¹å¾ã€‚
  - æ—¶ç©ºæ³¨æ„åŠ›æ¨¡å—ï¼šåœ¨ U-Net çš„æ¯ä¸ªé˜¶æ®µåŠ å…¥è·¨å¸§ self-/cross-attentionï¼Œä¿è¯ç”»é¢ä¸€è‡´æ€§ã€‚
  - è§£ç å™¨ï¼šåŸºäºæ³¨æ„åŠ›èåˆåçš„ latentï¼Œé‡å»ºæˆç›®æ ‡åœºæ™¯çš„ RGB å¸§ã€‚
2. **ä½å»¶è¿Ÿé‡‡æ ·**ç­–ç•¥
  - æ”¹è‰¯ DDIMï¼šç”±åŸå§‹ 50+ æ­¥éª¤é™è‡³ 3â€“5 æ­¥éª¤ï¼Œå¹¶ç»“åˆå¯å­¦ä¹ çš„æ—¶é—´è°ƒåº¦å™¨ï¼ˆTime-Step Schedulerï¼‰ï¼Œåœ¨ä¿è¯ç”»è´¨çš„å‰æä¸‹æå¤§ç¼©çŸ­é‡‡æ ·æ—¶é—´ã€‚
  - æ¸è¿›å¼åˆ†è¾¨ç‡ï¼šå…ˆç”¨ä½åˆ†è¾¨ç‡å¿«é€Ÿç”Ÿæˆï¼Œå†é€šè¿‡è½»é‡çº§è¶…åˆ†ç½‘ç»œï¼ˆSuper-Resolution Netï¼‰æ¢å¤è‡³ç›®æ ‡åˆ†è¾¨ç‡ï¼Œè¿›ä¸€æ­¥å‡å°ä¸»æµç¨‹å»¶è¿Ÿã€‚
3. **å…‰æµå¼•å¯¼ä¸çŠ¶æ€ä¿æŒ**
  - åœ¨çº¿å…‰æµä¼°è®¡ï¼šé€šè¿‡é«˜æ•ˆçš„ FlowNet-lite è®¡ç®—ç›¸é‚»å¸§å…‰æµï¼Œå¹¶å°†å…¶å¼•å…¥æ—¶ç©ºæ³¨æ„åŠ›ï¼Œæå‡å¸§é—´ä¸€è‡´æ€§ã€‚
  - éšè—æ€ç¼“å­˜ï¼šç»´æŠ¤ä¸Šä¸€å¸§çš„ latent éšè—æ€ï¼Œä½œä¸ºä¸‹ä¸€å¸§ç”Ÿæˆçš„åˆå§‹æ¡ä»¶ï¼Œæ”¯æŒæ— é™é•¿åº¦è§†é¢‘çš„è¿ç»­æ¨ç†ã€‚


#### å®ç°

python å·¥å…·åŒ…

```sh
pip install mirage-lsd
```

ä½¿ç”¨

```py
import mirage_lsd

# åˆå§‹åŒ–
engine = mirage_lsd.StreamEngine(
    model="mirage-lsd-v1",
    device="cuda",
    fp16=True,
    max_steps=5,
    resolution=(720, 1280),
)

# å¯åŠ¨æ‘„åƒå¤´æµå¹¶æ¸²æŸ“åˆ°çª—å£
engine.start(input_source=0, on_frame=engine.render)
```

## æ‰©æ•£æ¨¡å‹ä¸è¶³

åŸå§‹æ‰©æ•£æ¨¡å‹ä¸‰ä¸ªä¸»è¦ç¼ºç‚¹:**é‡‡æ ·é€Ÿåº¦æ…¢**ï¼Œ**æœ€å¤§åŒ–ä¼¼ç„¶å·®**ã€**æ•°æ®æ³›åŒ–èƒ½åŠ›å¼±**

diffusion models æ”¹è¿›ç ”ç©¶åˆ†ä¸ºå¯¹åº”çš„ä¸‰ç±»:**é‡‡æ ·é€Ÿåº¦æå‡**ã€**æœ€å¤§ä¼¼ç„¶å¢å¼º**å’Œ**æ•°æ®æ³›åŒ–å¢å¼º**ã€‚

é¦–å…ˆè¯´æ˜æ”¹å–„çš„åŠ¨æœºï¼Œå†æ ¹æ®æ–¹æ³•çš„ç‰¹æ€§å°†æ¯ä¸ªæ”¹è¿›æ–¹å‘çš„ç ”ç©¶è¿›ä¸€æ­¥ç»†åŒ–åˆ†ç±»ï¼Œä»è€Œæ¸…æ¥šçš„å±•ç°æ–¹æ³•ä¹‹é—´çš„è”ç³»ä¸åŒºåˆ«ã€‚
- ![](https://pic3.zhimg.com/80/v2-fdd70cb55e77a157ba600b4329aa3796_1440w.webp)

æœªæ¥ç ”ç©¶æ–¹å‘
- A. é‡å®¡å‡è®¾ã€‚éœ€è¦é‡æ–°å®¡è§†å’Œåˆ†ææ‰©æ•£æ¨¡å‹ä¸­çš„è®¸å¤šå…¸å‹å‡è®¾ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æ‰©æ•£æ¨¡å‹çš„æ­£å‘è¿‡ç¨‹å®Œå…¨æ¶ˆé™¤äº†æ•°æ®ä¸­çš„æ‰€æœ‰ä¿¡æ¯å¹¶ä¸”ä½¿å…¶ç­‰æ•ˆäºå…ˆå‰åˆ†å¸ƒå¯èƒ½å¹¶ä¸æ€»æ˜¯æˆç«‹ã€‚å®é™…ä¸Šï¼Œå®Œå…¨åˆ é™¤ä¿¡æ¯æ˜¯åœ¨æœ‰é™æ—¶é—´å†…æ— æ³•å®ç°ï¼Œäº†è§£ä½•æ—¶åœæ­¢å‰å‘å™ªå£°å¤„ç†ä»¥åœ¨é‡‡æ ·æ•ˆç‡å’Œé‡‡æ ·è´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡æ˜¯éå¸¸æœ‰æ„ä¹‰çš„ã€‚
- B. diffusion model å·²ç»æˆä¸ºä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œå¯ä»¥åœ¨å¤§å¤šæ•°åº”ç”¨ä¸­ä¸ç”Ÿæˆå¯¹æŠ—æ€§ç½‘ç»œï¼ˆGANï¼‰ç«äº‰ï¼Œè€Œæ— éœ€è¯‰è¯¸å¯¹æŠ—æ€§è®­ç»ƒã€‚å¯¹äºç‰¹å®šçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£ä¸ºä»€ä¹ˆä»¥åŠä½•æ—¶æ‰©æ•£æ¨¡å‹ä¼šæ¯”å…¶ä»–ç½‘ç»œæ›´åŠ æœ‰æ•ˆï¼Œç†è§£æ‰©æ•£æ¨¡å‹å’Œå…¶ä»–ç”Ÿæˆæ¨¡å‹çš„åŒºåˆ«å°†æœ‰åŠ©äºé˜æ˜ä¸ºä»€ä¹ˆæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿä¼˜ç§€çš„æ ·æœ¬åŒæ—¶æ‹¥æœ‰é«˜ä¼¼ç„¶å€¼ã€‚å¦å¤–ï¼Œç³»ç»Ÿåœ°ç¡®å®šæ‰©æ•£æ¨¡å‹çš„å„ç§è¶…å‚æ•°ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚
- C. diffusion model å¦‚ä½•åœ¨éšç©ºé—´ä¸­æä¾›è‰¯å¥½çš„latent representationï¼Œä»¥åŠå¦‚ä½•å°†å…¶ç”¨äºdata manipulationçš„ä»»åŠ¡ä¹Ÿæ˜¯å€¼å¾—ç ”ç©¶çš„ã€‚
- D. å°† diffusion model å’Œ generative foundation model ç»“åˆï¼Œæ¢ç´¢æ›´å¤šç±»ä¼¼äºChatGPTï¼ŒGPT-4ç­‰æœ‰è¶£çš„AIGCåº”ç”¨

### æ‰©æ•£æ¨¡å‹ vs è¯­è¨€æ¨¡å‹

ã€2023-7-1ã€‘æ‰©æ•£æ¨¡å‹çš„ä½œå›¾ç¼ºç‚¹

æ‰©æ•£æ¨¡å‹
- ä¼˜åŠ¿
  - æ§åˆ¶æ¡ä»¶å¯è®¾ç½®
  - æ¨¡å‹è§„æ¨¡å¯æ§
- åŠ£åŠ¿
  - è¯­ä¹‰æ§åˆ¶ä¸å¤Ÿç²¾å‡†:ä»¥æ ‡ç­¾ä¸ºåŸºå‡†ï¼Œæ— æ³•è¯†åˆ«æ ‡ç­¾å±æ€§å…³ç³»ï¼Œå› ä¸º CLIP æ¨¡å‹
  - ç¼ºä¹è¯­ä¹‰é€»è¾‘æ€§:ç¬¬ä¸€ä¸ªäººåœ¨ç¬¬äºŒä¸ªäººçš„å·¦è¾¹ --- æ— æ³•è¯†åˆ«

è¯­è¨€æ¨¡å‹
- ä¼˜åŠ¿
  - ç†è§£è¯­è¨€ä¸åŠ¨ä½œ
  - æ›´å‹å¥½çš„äº¤äº’æ–¹å¼
  - ç»Ÿä¸€çš„ä»»åŠ¡æ¡†æ¶
- åŠ£åŠ¿
  - å¤§é‡æ•°æ®èµ„æº
  - å¤§é‡è®¡ç®—èµ„æº
  - ç¼ºä¹å¤šæ¨¡æ€æ§åˆ¶




# ç»“æŸ