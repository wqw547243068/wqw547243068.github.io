---
layout: post
title:   大模型微调 LLM Finetune
date:   2023-09-01 16:52:00
categories: 人工智能
tags: OpenAI ChatGPT AI 微调 吴恩达 
excerpt: GPT之类大模型微调方法
mathjax: true
permalink: /finetune
---

* content
{:toc}


# 大模型微调


## 微调知识



### 基础知识

【2023-8-18】[浅析大语言模型从预训练到微调的技术原理](https://zhuanlan.zhihu.com/p/647843722), ppt 总结预训练到微调的知识点
-   **LLaMA、ChatGLM、Falcon等大语言模型的比较**
  -   tokenizer、位置编码、Layer Normalization、激活函数等
-   **大语言模型的分布式训练技术**
  -   数据并行、张量模型并行、流水线并行、3D并行
  -   零冗余优化器ZeRO、CPU卸载技术ZeRo-offload
  -   混合精度训练、激活重计算技术
  -   Flash Attention、Paged Attention
-   **大语言模型的参数高效微调技术**
  -   prompt tuning、prefix tuning、adapter、LLaMA-adapter、 LoRA

![](https://pic2.zhimg.com/v2-49840d0d1956821bc42968d94ee0174d_b.jpg)

### 教程

【2023-8-25】吴恩达《微调大型语言模型》[Finetuning Large Language Models（中英字幕）](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
1. Learn the fundamentals of finetuning a large language model (LLM).
1. Understand how finetuning differs from prompt engineering, and when to use both.
1. Get practical experience with real data sets, and how to use techniques for your own projects.

内容
- 何时在LLM上应用细调
- 如何准备微调数据
- 如何训练和评估LLM
- 通过细调，用自己的数据训练模型，更新LLM中的神经网络权重，从而改变模型与提示工程和检索增强生成等其他方法的差异。细调可以使模型学习风格、形式，并通过更新模型以获取新知识来改善结果。

<iframe src="//player.bilibili.com/player.html?aid=575237949&bvid=BV1Rz4y1T7wz&cid=1246800686&page=2&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

### 微调目标

多种
- 单一：映射到具体任务，形式固定
- 多任务：多个任务微调

## OpenAI 微调

### GPT-3 微调

【2023-5-2】[OpenAI ChatGPT API 文档之 Fine-tuning（微调）](https://zhuanlan.zhihu.com/p/626140269)

GPT-3 开放互联网的大量文本上进行了预训练。当给出仅包含几个示例的提示，直观判断尝试执行的任务并生成看似合理的补全（completion），这通常称为“小样本学习（few-shot learning）”。

`微调`（Fine-tuning）通过训练超出提示范围的更多示例来改进小样本学习，在大量任务上取得更好的结果。模型经过微调后，不再需要在提示中提供示例。这可以节省成本并实现更低延迟的请求。
- [收费](https://openai.com/pricing)

微调可更好地利用 API 模型：
- 效果比提示（prompt）质量更高
- 能训练不适合提示的示例
- 提示较短而节省 token
- 更低的延迟请求

微调涉及以下步骤：
- 准备、上传训练数据
- 训练微调模型
- 使用微调模型

成功与否决定因素是训练数据。
- 大规模：数千或数万的例子
- 高质量：格式一致，没有缺失或错误的例子
- 代表性：训练数据类似于实际使用模型过程中的数据


#### 文本分类示例

【2023-5-17】【OpenAI中文文档】[精调GPT#1：精调GPT-3进行文本分类的最佳实践](https://zhuanlan.zhihu.com/p/628944148)

文本分类

```s
# 微调
{"prompt": "burger -->", "completion": " edible"}
{"prompt": "paper towels -->", "completion": " inedible"}
{"prompt": "vino -->", "completion": " edible"}
{"prompt": "bananas -->", "completion": " edible"}
{"prompt": "dog toy -->", "completion": " inedible"}
# 预测
toothpaste --> ？
```

#### 用不用指令

精调后的模型**不一定**要在提示词中包含**指令或例子**，模型可以从训练案例中学会任务。
- 单任务不建议加指令：
  - 尽管向其中添加指令并不会影响性能，但确实会增加每个API调用的成本。
- ![](https://pic4.zhimg.com/80/v2-7e21c6fbded57b761da693e0f6f22ff7_1440w.webp)

| Prompt | Tokens | Recommended |
| --- | --- | --- |
| "burger -->" | 3 | ✅ |
| "Label the following item as either edible or inedible. <br>Item: burger <br>Label:" | 20 | ❌ |
| "Item: cake <br>Category: edible <br>Item: pan <br>Category: inedible <br>Item: burger <br>Category:" | 26 | ❌ |

问题：<span style='color:blue'>会影响其他任务吗？</span>

当微调涉及多个任务时，指令就很有用了。
- 训练一个模型对文本字符串分类**多个特征**，就需要某种指令来告诉模型要哪种标签结果。

| Prompt | Completion | note |
| --- | --- | --- |
| "burger --> edible." | yes | 训练 |
| "burger --> handheld." | yes | 训练 |
| "car --> edible." | no | 训练 |
| "car --> edible." | no | 训练 |
| "cheese --> edible." | ??? | 预测 |

#### 提示词格式

分类问题的提示词应该<span style='color:red'>以某个文本序列结尾</span>，告诉模型输入的部分到此为止，接下来是分类的数据。
- 如果没有这种**信号**，模型可能追加额外的臆想出来的文本到分类标签上，比如：
  - burger edible (准确)
  - burger and fries edible (答非所问)
  - burger-patterned novelty tie inedible (不准确)
  - burger burger burger burger (没有产生标签)

分隔符序列样例：
- 确保所选择文本序列不会出现在其它文本中
- 比如，对Python代码分类的时候就要避免“###”或者“->”这样的符号）。否则所选的文本序列就没啥用了。

| Prompt | Recommend |
| --- | --- |
| burger | ❌ |
| burger --> | ✅ |
| burger<br>### | ✅ |
| burger >>> | ✅ |
| burger <br> Label | ✅ |

对大部分模型而言，提示词加上补全的总长度不能超过`2048`个token。
- text-davinci-002模型，限制在4000个token。

#### 如何选择标签

精调过程可以使用**任何**标签，无论这个标签包含具体语义（比如edible）还是没有具体语义（比如数字1）。
- 如果每个类别的训练数据很少，那么**语义标签**可能效果更好，这样模型还可以利用到其自身对标签含义的理解。

如果方便的话，推荐使用**单token**的标签。
- 按照【OpenAI中文文档】[API#2：如何使用tiktoken计算token数量提到的办法来计算字符串包含的token数量](https://zhuanlan.zhihu.com/p/626593576)。

单token的标签好处：
- 成本低
- 更容易获取概率，对于衡量信心指数、精度、召回率的时候很有用。
- 不会受到停止序列影响，不需要比较不同长度的结果

| Prompt | Label | Recommend |
| --- | --- | --- |
| "burger --> " | edible | ✅ |
| "burger --> " | 1 | ✅ |
| "burger --> " | yes | ✅ |
| "burger --> " | A burger can by eaten | ❌ |

冷知识：
- 所有小于500的整数都是由单个token表示的。

如果一定要使用多token的标签，推荐每个标签由不同的token开头。
- 如果多个标签由同一个token开头，出于采样的影响，模型最终可能是有偏的。

#### 要多少训练数据

多少训练数据
- 取决于任务和性能要求。

| Examples per label | Performance (rough estimate) |
|---|---|
| Hundreds | Decent |
| **Thousands** | Good |
| Tens of thousands or more | Great |


下图展示了如何通过增加训练样例来提升分类准确率。
- ![](https://pic3.zhimg.com/80/v2-b0bc2334779596b2e6cc27bdc760814a_1440w.webp)
- 一般有**几千**例子就能得到不错的效果了

具体可以实验：分别用不同规模的数据集验证效果
- 比如 25%、50%、100%，看看指标是否随着数据规模增长而提升。
- 如果使用准确度和训练数据量画折线图，100%处的斜率就代表着继续增加数据能够带来的收益。
- 注意，不能仅凭单次训练就来推断增加的数据在准确度上带来的价值，部分训练双倍的数据和一次完整的训练是不同的

#### 指标评估

如何评估精调之后的模型

评估精调模型的作用：
- 改进模型，便于优化
- 评估效果，判断是否足以上线交付

分类指标：
- 准确度
- F1
- 精确度 / 正面预测值 / 负面发现率
- 召回 / 敏感度
- 特异性
- AUROC
- AUPRC

使用哪种指标取决于特定应用以及如何权衡不同类型的错误。
- 检测一个少见但又很重要的事情，假阴性比假阳性的代价更大，那么可能会更关注`召回率`而非`准确率`。

OpenAI的API提供了选项来计算这些分类指标。如果启用，便会在精调的训练周期中定期计算这些指标。

为了启用分类指标，需要：
- 使用**单个token**的标签
- 提供**验证文件**（和训练文件格式相同）
- 设置**标识位** -- compute_classification_metrics
- 对于**多类别**分类，设置参数 -- classification_n_classes
- 对于**二分类**，设置参数 -- classification_positive_class

OpenAI CLI的精调调用案例

```sh
# For multiclass classification
openai.api.fine_tunes.create \
  -t <TRAIN_FILE_ID_OR_PATH> \ 
  -v <VALIDATION_FILE_OR_PATH> \
  -m <MODEL> \
  --compute_classification_metrics \
  --classification_n_classes <NUMBER_OF_CLASSES>

# For binary classification
openai.api.fine_tunes.create \
  -t <TRAIN_FILE_ID_OR_PATH> \
  -v <VALIDATION_FILE_OR_PATH> \
  -m <MODEL> \
  --compute_classification_metrics \
  --classification_n_classes 2 \
  --classification_positive_class <POSITIVE_CLASS_FROM_DATASET>
```

如果设置了--compute_classification_metrics，便会在结果文件中看到下面的指标。

对于多类别分类：
- classification/accuracy: accuracy
- classification/weighted_f1_score: weighted F-1 score

对于二分类：

下面的指标是基于分类阈值0.5计算的（比如当概率大于0.5的时候，样例就被分类为正样本）
- classification/accuracy
- classification/precision
- classification/recall
- classification/f{beta}
- classification/auroc - AUROC
- classification/auprc - AUPRC

以上评估都假设你分类所用的文本标签是单个token的标签，否则数字便是错的。

训练过程中的指标演化，通过Weights & Biases进行可视化。

#### 如何选择模型

如何选择正确的模型

OpenAI提供了5个模型可供精调：
- ada（最便宜也最快）
- babbage
- curie
- davinci
- text-davinci-002（最高质量）

具体用哪个模型取决于使用场景和质量、价格、速度方面的要求。一般的文本分类场景有两种：简单和复杂。
- 对于简单直接的任务，比如情感分类，更大的模型提供的收益是递减的
- 对于复杂任务，需要理解微妙的含义、推理、先验知识或代码能力，模型之间的差距就会很大，curie或者text-davinci-002这种复杂的模型更加契合。

一个项目最终可能会尝试所有的模型。按照开发路径来展示可能是这样：
- 使用**最便宜和最快**的模型来测试代码（ada）
- 使用**中等**的模型来进行早期的实验，检查数据集是否如预期一样工作（curie）
- 使用**最好**的模型执行更多的实验，看看性能的上限在哪里（text-davinci-002）
- 一旦有了好的结果，使用所有的模型执行训练，对比价格和性能，选择最符合需求的模型（所有模型）

另一个可能的开发场景是：
- 从小的数据集开始，训练最好的模型（text-davinci-002）
- 使用精调之后的模型来生成尽可能多的标签，把数据集的规模翻倍
- 使用新的数据集来训练更便宜的模型（ada）

#### 如何选择超参

如何选择训练的超参数

精调过程中有许多参数可以调整。一般来说，这些参数的默认值就能用，只有在明确带来表现提升的时候才应该去修改这些参数：
- 参数一：n_epochs，默认为4，控制每个样例被训练使用多少次。
  - 分类问题，见过将这个数字设为4或10得到不错的结果。小的数据集需要更多的轮次，大的数据集需要的轮次较少。
  - 如果训练准确率不高，可以加大这个值。如果看到训练的准确率较高，而验证的准确率不高（过拟合），则应降低这个值。
  - 通过将compute_classification_metrics设置为True，并额外提供一个与训练数据不重复的验证数据集文件。
- 参数二：batch_size，默认为空，控制单个训练批次中用到的数据量。
  - 这个参数在0.01-2%之间效果都不错，但是5%以上就不行了。一般来说，更大的批次适合用在更大的数据集上面。
- 参数三：learning_rate_multiplier，默认为空，控制模型权重更新的频率。
  - 这个参数在0.02-0.5之间效果都不错，更大的学习率需要更大的批次数据量才能奏效。
- 参数四：prompt_loss_weight，默认为0.1，控制模型学习的提示词与最后补完的token之间的比例。
  - 如果提示词相对于补完而言比较长，那就有必要缩小这个值以免过度学习提示词本身。在我们的实验中，将这个值设为0有时候略差，有时候效果差不多，取决于数据集的情况。

关于`prompt_loss_weight`

模型被精调时，会学习来生成`提示词`和`补全`中看到的文本。实际上，从模型精调的视角出发，`提示词`和`补全`之间的区别是不太明确的。
- 两者主要区别是模型从提示词的token上学的较少，而在补全的token上学的较多。
- 这个比例就是通过 `prompt_loss_weight` 控制的，默认是**10%**。
- 如果设置为**100%**，就意味着模型对提示词和补全的token是一视同仁。无论使用提示的全部文本，还是使用补完的全部文本，还是以某种比例切分，结果都是一样的。对于分类的任务，推荐100%。
- 如果设置为**0**，模型仅仅学习补全部分。不过即便在这种情况下，提示词仍然是必要的，它们为后续的补完设置了上下文。有时候看见0值会略微降低分类的效果，或者对于学习率更加敏感；其中一种假设是少量的提示词有助于保留或改进模型对输入的理解能力。

#### 如何设置推理参数

如何选择推理参数

推理参数
- model 模型选择，前面已介绍过。
- temperature 分了的时候要设置 temperature=0。正值会对补完结果添加随机性，对于创意性任务是有帮助的，但是对于分类这种确定性任务是有害的。
- max_tokens 
  - 如果使用单个token的标签，则需要设置 max_tokens=1
  - 如果使用多token的标签，则应设置为最长的那个标签的长度。
- stop
  - 如果标签长度不一，在补完的后面加上一个**停止序列**，比如“END”。然后在推理调用中设置 `stop='END'` 以免模型在补完标签之后还在不断地生成，如前面例子中的“`burger -> edible edible edible`”的情况。
  - 另一个选择是进行**后处理**，遍历补完的结果，寻找其匹配的标签。
- logit_bias
  - 如果使用单token标签，可以设置`logit_bias={“label1”: 100, “label2”:100, …}`，这里的“`label1`”指代的就是具体的标签。
  - 对于训练数据较少或者标签比较复杂的任务，模型可能会输出一些臆想的训练集中没有出现过的标签。`logit_bias`通过提升标签token的权重来避免非法的标签token的产生。
  - 如果将其与**多token标签**一起使用，那就要额外注意 标签是如何切分为token的，因为logit_bias仅对单个token起效，而非序列。
  - Logit_bias还可以用于设置特定标签的偏度，让出出现得更多或是更少。
- logprobs 获取每个标签的概率对于计算信心分数、召回精度等都有很大的帮助。
  - 设置logprobs=5，对于补完的每一个token位置上都会返回5个最有可能的token，以及其对应概率的自然对数。如果要得到其概率，需要使用自然常数求幂。这里返回的概率无关乎temperature参数，表示的是当temperature=1的时候表现出来的概率。
- echo
  - 如果某个标签的概率没有出现在结果列表中，echo参数就能派上用场了。如果echo设置为True且logprobs设置为一个数字，API的返回中就会纳入每个token的概率，不仅是补全的token，还有提示词中的token。所有，为了得到某个特定标签的概率，可以把这个标签纳入提示词中，再调用API，参数为echo=True，lobprobs=0并且max_tokens=0

#### 高级技巧

##### 增加推理步骤

对于需要推理的复杂任务，一个有用的技巧是在最后的答案之前加入推理步骤。给模型一些额外的时间和空间来大声思考，可以提升其获得正确答案的概率。

尽管一提到给众多例子写解释就有点令人发怵，但是你可以使用大语言模型来写这些解释。2022年Zelikman, Wu, et al. 的论文中提出了一个叫做STaR（自教授推理）的过程，其中使用少量样本的提示词，从{问题，答案}的数据集来生成一组{问题，**推理**，答案}的数据集。

![](https://pic4.zhimg.com/80/v2-c6dbe583128343a6f3b9b82bc5d35087_1440w.webp)

##### 精调一个已经精调过的模型

模型可以依次精调任意次数。有一种使用方法是，现在大量相关文本上（非结构化的领域文本或类似的分类结果）预训练模型，然后再在你想让模型完成的特定任务上精调一些案例。这个过程可能像下面这样：

-   步骤一：在大量廉价且相关的数据上精调
  -   非结构化领域文本，比如法律或医疗文本
  -   类似的任务数据，比如另一个大型的分类数据集
-   步骤二：在昂贵的标签化例子上精调
  -   比如，高质量文本或分类结果

![](https://pic4.zhimg.com/80/v2-4bbcc197fb560d686fe826aafc51f1eb_1440w.webp)

如果要精调一个已经精调过的模型，在创建精调任务的时候传入前面精调过的模型名字，其它参数不用改变。如果你的训练数据集要远小于之前的训练数据，那可能就需要将learning_rate_multiplier除以2到4。

#### 常见问题

精调文本分类过程中最常见的问题都和训练数据有关。

##### 常见问题一：缺少专用训练数据

一定要记住，训练数据不仅仅是从输入到答案之间的映射配对，更关键的是输入中需要包含足够的信息来推导出正确答案。

考察下面的训练数据：
- ![](https://pic2.zhimg.com/80/v2-f7a3d15a1fcf3db5a34211e5b3c77625_1440w.webp)

如果不知道这些学生为什么得到对应的分数，模型也就无法从中学习，更加没法判断Esmeralda的成绩是多少。

尤其是当大部分信息都有了，但是仍缺少一些信息的时候，会发生一些比较微妙的问题。比如我们要判断某一项费用是允许还是不允许，这取决于日期、地点或员工类型，那就要确保输入中包含了这些信息，不然就会像下面这样：
- ![](https://pic3.zhimg.com/80/v2-b38b262ea64f4cc2892a1a6c874166ce_1440w.webp)

##### 常见问题二：输入数据的格式不符合训练数据格式要求

当使用精调过的模型的时候，确保你提交的提示词格式和训练数据是一样的。

![](https://pic2.zhimg.com/80/v2-eb64ab96452799467e63339e2ea53c71_1440w.webp)

##### 更多案例

真实一致分类器
- ![](https://pic3.zhimg.com/80/v2-371d1eb0cc05046614b5cc1e30c589d2_1440w.webp)

情感分类器
- ![](https://pic3.zhimg.com/80/v2-f2ef85f6cd70357d67dae91e4a0fc602_1440w.webp)

邮件优先级分类
- ![](https://pic1.zhimg.com/80/v2-5aa8095f9463da2718316274fe5d7df8_1440w.webp)

逻辑关系检测器
- ![](https://pic3.zhimg.com/80/v2-6bf86b43dcdf3d65f422918a66ad6142_1440w.webp)


### GPT-3.5 Turbo 微调

【2023-8-23】[OpenAI 开放 GPT-3.5 Turbo 微调，网友：将 prompt 减少 90% 才实惠 ](https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz)
- 8月22日，OpenAI [宣布](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)企业现在可以使用自己的数据对 `GPT-3.5 Turbo` 进行**微调**，在原[Fine-tunes](https://platform.openai.com/docs/guides/fine-tuning)的基础上推出 Fine-tuning. OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。
- [fine-tuning api](https://platform.openai.com/docs/api-reference/fine-tuning), [forum](https://community.openai.com/t/gpt-3-5-turbo-fine-tuning-now-available-and-new-gpt3-models/327425)
- <span style='color:red'>传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型</span>。
- 今年秋天 OpenAI 将开放更先进的 GPT-4。

With this launch, developers can now run **supervised fine-tuning** to make this model perform better for their use cases.

Since the release of GPT-3.5 Turbo, developers and businesses have asked for the ability to customize the model to create unique and differentiated experiences for their users. With this launch, developers can now run supervised fine-tuning to make this model perform better for their use cases.

In our private beta, fine-tuning customers have been able to meaningfully improve model performance across common use cases, such as:
- Improved steerability: Fine-tuning allows businesses to make the model follow instructions better, such as making outputs terse or always responding in a given language. For instance, developers can use fine-tuning to ensure that the model always responds in German when prompted to use that language.
- Reliable output formatting: Fine-tuning improves the model's ability to consistently format responses—a crucial aspect for applications demanding a specific response format, such as code completion or composing API calls. A developer can use fine-tuning to more reliably convert user prompts into high-quality JSON snippets that can be used with their own systems.
- Custom tone: Fine-tuning is a great way to hone the qualitative feel of the model output, such as its tone, so it better fits the voice of businesses’ brands. A business with a recognizable brand voice can use fine-tuning for the model to be more consistent with their tone.

In addition to increased performance, fine-tuning also enables businesses to shorten their prompts while ensuring similar performance.  Fine-tuning with GPT-3.5-Turbo can also handle 4k tokens—double our previous fine-tuned models. Early testers have reduced prompt size by up to 90% by fine-tuning instructions into the model itself, speeding up each API call and cutting costs.

Fine-tuning is most powerful when combined with other techniques such as prompt engineering, information retrieval, and function calling. Check out our fine-tuning guide to learn more. Support for fine-tuning with function calling and gpt-3.5-turbo-16k will be coming later this fall.

#### finetune 功能

建议场景
- 设置回复风格、基调、格式、语言等
- 增强产生预期输出的**可靠性**
- **纠正**未能遵循复杂 Prompt 的问题
- 以特定方式处理许多**边缘情况**
- 执行**Prompt中难以阐明**的新技能或任务
- 通过 GPT4 completion结果Fine-tuning过的GPT-3.5-turbo模型，在特定场景下可以达到GPT4一样的效果，增加响应**速度**以及降低使用成本（特定领域高效的小模型）

开发者通过监督微调，可以实现个性化定制，适配各自业务场景，显著提高模型性能
- 更加**可控**：更好的遵循指令，如 精简回复、以特定语言风格。（不必再在prompt中强调用某种语言）
- **输出格式**更可靠：微调提升了模型回复的一致性，适用于要求特定格式输出的情形（代码补全/组合API调用/json输出）
- **角色定义**：微调让模型输出更加贴合某种角色，如 企业品牌代言人

除了性能提升，微调还能缩短 prompt 长度，同时保持效果。GPT-3.5-Turbo 微调版能处理 4k tokens（之前模型的两倍）. 早期测试发现，通过监督指令微调，prompt长度最多缩减 90%，api调用加速，削减成本。

GPT 的“微调”与 Llama2 之类的微调不同，因为不会调整网络的所有权重，只是会调整网络小部分。代价是 OpenAI 微调的成本较低，但功能也没有“真正的”微调强大。

GPT-3.5 Turbo 微调可处理 4k 个 tokens——可达之前微调模型的 2 倍。早期测试人员还对模型本身的**指令**进行了微调，从而将提示词长度缩短达 **90%**，成功加快每次 API 调用的速度并降低了执行成本。

#### finetune 成本

微调成本分为两个部分：初始**训练**成本与**使用**成本：
- 训练：0.008 美元/1K tokens
- 使用成本
  - 输入：0.012 美元/1K tokens
  - 输出：0.016 美元/1K tokens

|Model|Base Models-Input|Base Models-Output|Fine-tuned Models-Training|Fine-tuned Models-Input|Fine-tuned Models-Output|
|---|---|---|---|---|---|
|`babbage-002`|0.0004|0.0004|0.0004|0.0016|0.0016|
|`davinci-002`|0.002|0.002|0.006|0.012|0.012|
|`gpt-3.5-turbo-4k`|0.0015|0.002|0.008|0.012|0.016|
|`gpt-3.5-turbo-16k`|0.003|0.004|-|-|-|
|`gpt-4-8k`|0.03|0.06|-|-|-|
|`gpt-4-32k`|0.06|0.12|-|-|-|

注
- 单位 $/1k tokens
- [官方收费指南](https://openai.com/pricing)

例如
- gpt-3.5-turbo 微调作业中包含 10 万个 token 的训练文件。经过 3 个 epoch 训练轮次，预计成本为 2.40 美元。

微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 **8 倍**，因此用户确实必须处于 OpenAI 提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。

初版 GPT-3 基础模型（ada、babbage、curie 和 davinci）微调 将于 2024 年 1 月 4 日正式关闭。

OpenAI 如今发布了 babbage-002 和 davinci-002 作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新 API 端点/v1/fine_tuning/jobs 进行微调。


#### finetune 原理

【2023-8-24】[GPT-3.5 微调 API重磅发布：有史以来规模最大的 LoRA 即服务](https://mp.weixin.qq.com/s/GIIzEwRzXxkAffPDjtvvaw)

LoRA：英文全称 Low-Rank Adaptation of Large Language Models，大语言模型的低阶适应，微软研究人员为解决大语言模型微调而开发的一项技术。
- 冻结预训练的模型权重参数, 每个Transformer块里注入可训练层，由于不需要对模型的权重参数重新计算梯度，所以大大减少了需要训练的计算量。

研究发现: LoRA的微调质量与全模型微调相当

LoRA-as-a-service： LoRA 即服务。
- 这种模式类似于“软件即服务”（Software-as-a-Service，SaaS）或其他类似的服务模式，其中用户不需要自行部署和管理软件或技术，而是通过云服务提供商获得对其功能和服务的访问权

#### finetune 流程

微调实战
- 参考: [openai 3.5微调实战](https://github.com/LearnPrompt/LLMs-cookbook/tree/main/gpt3.5)
- 微调 `gpt-3.5-turbo-0613` 模型，**10条**数据（289个汉字，**5769**个字节），花费 0.16 刀; 按照 0.008 单价算，大概训练了3轮
- 数据示例：医疗监督问答数据集 [huatuo26M-testdatasets](https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets), 或去 [github](https://github.com/LearnPrompt/LLMs-cookbook/blob/main/gpt3.5/test_datasets.jsonl)找

<div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2023-08-29T13:15:51.115Z\&quot; agent=\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\&quot; etag=\&quot;UVFE8uh0TtQpR3knby8f\&quot; version=\&quot;21.6.8\&quot;&gt;\n  &lt;diagram name=\&quot;第 1 页\&quot; id=\&quot;YUrH7kkdw6S7EPocWAtV\&quot;&gt;\n    &lt;mxGraphModel dx=\&quot;1434\&quot; dy=\&quot;771\&quot; grid=\&quot;1\&quot; gridSize=\&quot;10\&quot; guides=\&quot;1\&quot; tooltips=\&quot;1\&quot; connect=\&quot;1\&quot; arrows=\&quot;1\&quot; fold=\&quot;1\&quot; page=\&quot;1\&quot; pageScale=\&quot;1\&quot; pageWidth=\&quot;827\&quot; pageHeight=\&quot;1169\&quot; math=\&quot;0\&quot; shadow=\&quot;0\&quot;&gt;\n      &lt;root&gt;\n        &lt;mxCell id=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;1\&quot; parent=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-4\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#f5f5f5;dashed=1;dashPattern=1 1;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;340\&quot; y=\&quot;90\&quot; width=\&quot;350\&quot; height=\&quot;190\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;CRyWcW9bKPYmjVe2kgWn-2\&quot; value=\&quot;ChatGPT 微调流程\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=0;fontSize=18;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;335\&quot; y=\&quot;10\&quot; width=\&quot;180\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;V9TQX8vlhKfmWj-25TbC-43\&quot; value=\&quot;2023-8-29&amp;lt;br&amp;gt;wqw547243068@163.com\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;550\&quot; y=\&quot;290\&quot; width=\&quot;170\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-6\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;198\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; value=\&quot;GPT-3.5 Turbo\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;100\&quot; width=\&quot;95\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-7\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0;entryY=0;entryDx=0;entryDy=12.5;entryPerimeter=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; value=\&quot;监督语料\&quot; style=\&quot;shape=cylinder3;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;size=15;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;160\&quot; y=\&quot;115\&quot; width=\&quot;60\&quot; height=\&quot;60\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot; value=\&quot;GPT-3.5 Turbo Finetune\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;225\&quot; width=\&quot;95\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-16\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;516.25\&quot; y=\&quot;183\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; value=\&quot;个人语料\&quot; style=\&quot;shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;370\&quot; y=\&quot;130\&quot; width=\&quot;84\&quot; height=\&quot;45\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-11\&quot; value=\&quot;① 准备语料\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot;&gt;\n          &lt;mxGeometry x=\&quot;-0.1467\&quot; y=\&quot;-1\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;39\&quot; y=\&quot;-3\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-21\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#97D077;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;240\&quot; y=\&quot;275\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; value=\&quot;\&quot; style=\&quot;shape=actor;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;175\&quot; y=\&quot;220\&quot; width=\&quot;30\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-12\&quot; value=\&quot;② 上传语料到OpenAI\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;280\&quot; y=\&quot;125\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-13\&quot; value=\&quot;OpenAI\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=1\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;470\&quot; y=\&quot;60\&quot; width=\&quot;70\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-15\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;538\&quot; y=\&quot;140\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;168\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-17\&quot; value=\&quot;③ 启动微调\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;590\&quot; y=\&quot;175\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-18\&quot; value=\&quot;④ 邮件通知任务完成&amp;lt;br&amp;gt;(返回模型名)\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;610\&quot; y=\&quot;220\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;19\&quot; y=\&quot;4\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-19\&quot; value=\&quot;⑤ 调用新模型\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;300\&quot; y=\&quot;260\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-23\&quot; value=\&quot;jsonl格式&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}\&quot; style=\&quot;shape=note;whiteSpace=wrap;html=1;backgroundOutline=1;darkOpacity=0.05;fillColor=#fff2cc;strokeColor=#d6b656;align=left;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;140\&quot; y=\&quot;40\&quot; width=\&quot;190\&quot; height=\&quot;70\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; value=\&quot;\&quot; style=\&quot;shape=image;html=1;verticalLabelPosition=bottom;verticalAlign=top;imageAspect=0;image=img/clipart/Gear_128x128.png\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;517.5\&quot; y=\&quot;156.5\&quot; width=\&quot;40\&quot; height=\&quot;53\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-25\&quot; value=\&quot;生成语料id\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;411\&quot; y=\&quot;118\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n      &lt;/root&gt;\n    &lt;/mxGraphModel&gt;\n  &lt;/diagram&gt;\n&lt;/mxfile&gt;\n&quot;}"></div>
<script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script>


完整版: [知乎](https://zhuanlan.zhihu.com/p/653239407?), [公众号](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649769352&idx=1&sn=e68c0ae1d3b2b1af8aeb3ace58f811e0&chksm=bec3d89589b45183f626a37b4c345254c527f0b68fb301e6e9abb88d6d78b2418697f534f049&token=622259072&lang=zh_CN#rd)

#### ① 数据处理

将jsonl格式（每行都是json串的文本文件）的数据（question, answer两个字段）转换为OpenAI要求的格式

```py
# 数据处理
import json
import random

def transform_jsonl(input_file_path, output_file_path):
    entries = []
    with open(input_file_path, 'r') as file:
        for line in file:
            entry = json.loads(line)
            entries.append(entry)
    # 随机抽取100个条目
    #sampled_entries = random.sample(entries, 100)
    sampled_entries = random.sample(entries, 10) # 至少10条数据

    with open(output_file_path, 'w') as outfile:
        for entry in sampled_entries:
            messages = []
            messages.append({"role": "system", "content": "You are an assistant"})
            user_message = {"role": "user", "content": entry["questions"]}
            assistant_message = {"role": "assistant", "content": entry["answers"]}
            messages.extend([user_message, assistant_message])
            result = {"messages": messages}
            json.dump(result, outfile, ensure_ascii=False)
            outfile.write('\n')

input_file_path = '~/test_datasets.jsonl' # 请替换为您的输入JSONL文件路径
output_file_path = '~/tmp.jsonl' # 请替换为您想要保存的输出JSONL文件路径
transform_jsonl(input_file_path, output_file_path)
```

数据示例：

```json
输入: {"questions": "做了腰间盘穿丁手术后，用盐泡脚可以吗", "answers": "问题分析：你好:你是由于身体出现了一些局部的腰部损伤这种情况应该进行调整的一般术后泡脚是可以的，不用担心。意见建议：治疗方案:你可以不知后注意休息，避免劳累过度就可以这种调整方法也可以住进你身体的一些嗯调理的啊！"}
输出: {"messages": [{"role": "system", "content": "You are an assistant that occasionally misspells words"}, {"role": "user", "content": "由于一次事故造成了左耳的残疾听力不是很好需要佩戴助听器戴上的效果还不错能和人正常交流但是最近一个月助听器里面总是有杂音影响了使用效果。耳聋佩戴的助听器有杂音怎么办？（）"}, {"role": "assistant", "content": "你好您所谓的杂音也有可能是听到的环境声音好的助听器对噪音是有压缩的出现这种情况是可以调试解决的如果是一般的助听器因为环境声音也同时放大了可能会觉得比较吵您的问题最好是到助听器店让专业的验配师帮您处理"}]}
// 官方数据示例
{
  "messages": [
    { "role": "system", "content": "You are an assistant that occasionally misspells words" },
    { "role": "user", "content": "Tell me a story." },
    { "role": "assistant", "content": "One day a student went to schoool." }
  ]
}
```


#### ② 上传文件

注意
- 单个训练文件<span style='color:red'>最大 50 MB</span>
- 一行数据是完整的json字符串，<span style='color:red'>最大token数目 4096，超出就截断</span>
- <span style='color:red'>最少训练条数：10</span>，一般50-100条就有提升，因场景而已
- 数据较少时，将效果好<span style='color:red'>system prompt放到训练数据中</span>
  - 数据：质量 > 数量
- 数据可以分为训练集、测试集，分开上传


```sh
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F "purpose=fine-tune" \
  -F "file=@path_to_your_file" 

# ------ 第三方  ----
curl --location 'https://api.openai.com/v1/files' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --form "purpose=fine-tune" \
  --form "file=@path_to_your_file" 
```

以上方法失效，错误信息
> The browser (or proxy) sent a request that this server could not understand.

python
- 【2023-9-20】升级文件上传代码

```py
import os
import openai

#openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

data_file = "your_file"
#data_file = val_file
openai.File.create(
  file=open(data_file, "rb"),
  user_provided_filename=data_file.split('/')[-1], # 自定义上传后的文件名，如 采用原文件名称（按/分割）
  purpose='fine-tune' # 固定，不能改
)
print('上传的文件信息: ', openai.File.list())
```

```py
# 上传至OpenAI
import requests
import openai

OPENAI_API_KEY='***'
url = "https://api.openai.com/v1/files"
headers = {
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
payload = {
    "purpose": "fine-tune",
}
print('数据路径: ', output_file_path)
files = {
    "file": open(output_file_path, "rb")
}

response = requests.post(url, headers=headers, data=payload, files=files)
print(response)
print('上传的文件信息: ', openai.File.list())
```

执行完毕后返回 文件列表

```json
上传的文件信息:  {
  "object": "list",
  "data": [
    {
      "object": "file",
      "id": "file-***",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 5769,
      "created_at": 1693304216,
      "status": "uploaded",
      "status_details": null
    },
    {
      "object": "file",
      "id": "file-****",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 1496,
      "created_at": 1693303804,
      "status": "processed",
      "status_details": null
    }
  ]
}
```

从中找到 本次上传文件 位置，如下标0, 或1

文件信息格式化，时间戳转换，便于查找

```py
from datetime import datetime
import pandas as pd

def timestamp2str(ts):
    cur_date = datetime.fromtimestamp(ts)
    local_date_str = datetime.strftime(cur_date ,'%Y-%m-%d %H:%M:%S')
    return local_date_str
    
df_file = pd.DataFrame(openai.File.list()['data'])
df_file['time'] = df_file['created_at'].map(timestamp2str) # 时间戳转str
df_file.sort_values('time') # 按时间排序
```


#### ③ 启动微调任务

使用官方默认参数

```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'
```

自定义参数
- 指定验证集
- 设置前缀
- 设置训练参数，如 epoches

超参优化
- 刚开始不用指定epoch，OpenAI自行设置，根据测试数据自行调整：
- 如果没有遵循指令，增加1-2个epoch
- 如果多样性低于预期，减少1-2个epoch


```sh
# ------ 第三方: 自定义训练参数  ----
curl --location 'https://api.openai.com/v1/fine_tuning/jobs' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --data '{
    "training_file": "file-****", // 训练集
    "validation_file": "file-****", // 测试集
    "hyperparameters":{
      "n_epochs":7
    },
    "suffix":"cutom-model-name", // 自定义模型前缀
    "model":"gpt-3.5-turbo-0613"
  }'

```


模型选择

```py
# 启动微调
import requests

OPENAI_API_KEY="sk-***"

url = "https://api.openai.com/v1/fine_tuning/jobs"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}

data = { 
    #"training_file": "file-XXXXXXXXXXX",
    "training_file": openai.File.list()['data'][1]['id'],
    "model": "gpt-3.5-turbo-0613"
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

终端返回

```json
{"object":"fine_tuning.job","id":"ftjob-***","model":"gpt-3.5-turbo-0613","created_at":1693304550,"finished_at":null,"fine_tuned_model":null,"organization_id":"org-LMrR8ZVsnE2MLQNXje4rARHo","result_files":[],"status":"created","validation_file":null,"training_file":"file-bPzn6eE00cvR3xNqb8lau6QN","hyperparameters":{"n_epochs":10},"trained_tokens":null}
```

#### 任务控制

**获取**训练信息

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-**** \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

**取消**训练任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/cancel \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

查看训练进度

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/events \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```


稍等片刻后，查看个人邮箱，记录新模型名

```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'
```

对应的Python指令

```py
# List 10 fine-tuning jobs
openai.FineTuningJob.list(limit=10)
# Retrieve the state of a fine-tune
openai.FineTuningJob.retrieve("ft-abc123")
# Cancel a job
openai.FineTuningJob.cancel("ft-abc123")
# List up to 10 events from a fine-tuning job
openai.FineTuningJob.list_events(id="ft-abc123", limit=10)
# Delete a fine-tuned model (must be an owner of the org the model was created in)
openai.Model.delete("ft-abc123")
```

#### ④ 使用微调模型

查看已有finetune任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&after=1 \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

看下新模型效果

```py
# 调用模型
import requests

url = "https://api.openai.com/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
# 从邮件里提取模型名称
new_model = 'text-davinci-003'
new_model = "gpt-3.5-turbo"
new_model = 'ft:gpt-3.5-turbo-0613:***'
data = {
    "model": new_model,
    "messages": [
        {
            "role": "system",
            "content": "You are an assistant"
        },
        {
            "role": "user",
            "content": "我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？"
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

返回结果

```json
{
  "id": "chatcmpl-****",
  "object": "chat.completion",
  "created": 1693305795,
  "model": "ft:gpt-3.5-turbo-0613:***",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "可能的原因如下： 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 4、如果一直测得较高，就是高血压，应引诱病院。"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 73,
    "completion_tokens": 219,
    "total_tokens": 292
  }
}
```


效果对比

question: 
> 我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？

Answer

**gpt-3.5**

> 血压读数130/80是较常见的健康血压范围内，但是具体的献血要求可能略有不同，医生可能基于献血的特殊需求或个人身体状况，选择较为严格的标准。以下是一些可能导致您不能献血的原因：
>1. 个人差异: 献血机构可能设定了较为严格的血压标准，以确保献血者的安全和健康。即使您的血压读数在正常范围内，但慎重考虑您的个人特殊情况或家族病史等因素也很重要。
>2. 动态血压: 血压是一个动态指标，受多种因素影响，如情绪、活动水平、环境等。可能您的血压在体检时正常，但在献血前被测量时升高。
>3. 紧张或焦虑: 对一些人来说，献血过程本身可能会引发一些紧张和焦虑，这可能会导致血压升高。这些情绪因素可能会影响到医生的判断。
> 
> 如果您对不能献血的原因有任何疑问，我建议您咨询相关医生或献血机构的工作人员，他们可以给您更具体的解释和指导。另外，您的血压读数仍然在健康范围内，您可以继续关注并保持良好的生活习惯，有助于保持健康的血压水平。

**finetune**

> 可能的原因如下： 
>- 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 
>- 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 
>- 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 
>- 4、如果一直测得较高，就是高血压，应引诱病院



简单微调过后不用写prompt也能让gpt-3.5-turbo-0613有更加专业的回复




# 结束