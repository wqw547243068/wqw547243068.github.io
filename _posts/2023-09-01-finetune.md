---
layout: post
title:   大模型（LLM）微调
date:   2023-09-01 16:52:00
categories: 人工智能
tags: OpenAI ChatGPT AI 微调 吴恩达 
excerpt: GPT之类大模型微调方法
mathjax: true
permalink: /finetune
---

* content
{:toc}


# 大模型微调


## 微调教程

【2023-8-25】吴恩达《微调大型语言模型》[Finetuning Large Language Models（中英字幕）](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
1. Learn the fundamentals of finetuning a large language model (LLM).
1. Understand how finetuning differs from prompt engineering, and when to use both.
1. Get practical experience with real data sets, and how to use techniques for your own projects.

内容
- 何时在LLM上应用细调
- 如何准备微调数据
- 如何训练和评估LLM
- 通过细调，使用自己的数据对模型进行训练，并更新LLM中的神经网络权重，从而改变模型与提示工程和检索增强生成等其他方法的差异。细调可以使模型学习风格、形式，并通过更新模型以获取新知识来改善结果。

<iframe src="//player.bilibili.com/player.html?aid=575237949&bvid=BV1Rz4y1T7wz&cid=1246800686&page=2&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>


## OpenAI 微调

### GPT-3 微调

【2023-5-2】[OpenAI ChatGPT API 文档之 Fine-tuning（微调）](https://zhuanlan.zhihu.com/p/626140269)

GPT-3 开放互联网的大量文本上进行了预训练。当给出仅包含几个示例的提示，直观判断尝试执行的任务并生成看似合理的补全（completion），这通常称为“小样本学习（few-shot learning）”。

`微调`（Fine-tuning）通过训练超出提示范围的更多示例来改进小样本学习，在大量任务上取得更好的结果。模型经过微调后，不再需要在提示中提供示例。这可以节省成本并实现更低延迟的请求。
- [收费](https://openai.com/pricing)

微调可更好地利用 API 模型：
- 效果比提示（prompt）质量更高
- 能训练不适合提示的示例
- 提示较短而节省 token
- 更低的延迟请求

微调涉及以下步骤：
- 准备、上传训练数据
- 训练微调模型
- 使用微调模型


### GPT-3.5 Turbo 微调

【2023-8-23】[OpenAI 开放 GPT-3.5 Turbo 微调，网友：将 prompt 减少 90% 才实惠 ](https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz)
- 8月22日，OpenAI [宣布](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)企业现在可以使用自己的数据对 `GPT-3.5 Turbo` 进行**微调**，在原[Fine-tunes](https://platform.openai.com/docs/guides/fine-tuning)的基础上推出 Fine-tuning. OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。
- [fine-tuning api](https://platform.openai.com/docs/api-reference/fine-tuning), [forum](https://community.openai.com/t/gpt-3-5-turbo-fine-tuning-now-available-and-new-gpt3-models/327425)
- <span style='color:red'>传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型</span>。
- 今年秋天 OpenAI 将开放更先进的 GPT-4。

With this launch, developers can now run **supervised fine-tuning** to make this model perform better for their use cases.

Since the release of GPT-3.5 Turbo, developers and businesses have asked for the ability to customize the model to create unique and differentiated experiences for their users. With this launch, developers can now run supervised fine-tuning to make this model perform better for their use cases.

In our private beta, fine-tuning customers have been able to meaningfully improve model performance across common use cases, such as:
- Improved steerability: Fine-tuning allows businesses to make the model follow instructions better, such as making outputs terse or always responding in a given language. For instance, developers can use fine-tuning to ensure that the model always responds in German when prompted to use that language.
- Reliable output formatting: Fine-tuning improves the model's ability to consistently format responses—a crucial aspect for applications demanding a specific response format, such as code completion or composing API calls. A developer can use fine-tuning to more reliably convert user prompts into high-quality JSON snippets that can be used with their own systems.
- Custom tone: Fine-tuning is a great way to hone the qualitative feel of the model output, such as its tone, so it better fits the voice of businesses’ brands. A business with a recognizable brand voice can use fine-tuning for the model to be more consistent with their tone.

In addition to increased performance, fine-tuning also enables businesses to shorten their prompts while ensuring similar performance.  Fine-tuning with GPT-3.5-Turbo can also handle 4k tokens—double our previous fine-tuned models. Early testers have reduced prompt size by up to 90% by fine-tuning instructions into the model itself, speeding up each API call and cutting costs.

Fine-tuning is most powerful when combined with other techniques such as prompt engineering, information retrieval, and function calling. Check out our fine-tuning guide to learn more. Support for fine-tuning with function calling and gpt-3.5-turbo-16k will be coming later this fall.

#### finetune 功能

建议场景
- 设置回复风格、基调、格式、语言等
- 增强产生预期输出的**可靠性**
- **纠正**未能遵循复杂 Prompt 的问题
- 以特定方式处理许多**边缘情况**
- 执行**Prompt中难以阐明**的新技能或任务
- 通过 GPT4 completion结果Fine-tuning过的GPT-3.5-turbo模型，在特定场景下可以达到GPT4一样的效果，增加响应**速度**以及降低使用成本（特定领域高效的小模型）

开发者通过监督微调，可以实现个性化定制，适配各自业务场景，显著提高模型性能
- 更加**可控**：更好的遵循指令，如 精简回复、以特定语言风格。（不必再在prompt中强调用某种语言）
- **输出格式**更可靠：微调提升了模型回复的一致性，适用于要求特定格式输出的情形（代码补全/组合API调用/json输出）
- **角色定义**：微调让模型输出更加贴合某种角色，如 企业品牌代言人

除了性能提升，微调还能缩短 prompt 长度，同时保持效果。GPT-3.5-Turbo 微调版能处理 4k tokens（之前模型的两倍）. 早期测试发现，通过监督指令微调，prompt长度最多缩减 90%，api调用加速，削减成本。

GPT 的“微调”与 Llama2 之类的微调不同，因为不会调整网络的所有权重，只是会调整网络小部分。代价是 OpenAI 微调的成本较低，但功能也没有“真正的”微调强大。

GPT-3.5 Turbo 微调可处理 4k 个 tokens——可达之前微调模型的 2 倍。早期测试人员还对模型本身的**指令**进行了微调，从而将提示词长度缩短达 **90%**，成功加快每次 API 调用的速度并降低了执行成本。

#### finetune 成本

微调成本分为两个部分：初始**训练**成本与**使用**成本：
- 训练：0.008 美元/1K tokens
- 使用成本
  - 输入：0.012 美元/1K tokens
  - 输出：0.016 美元/1K tokens

|Model|Base Models-Input|Base Models-Output|Fine-tuned Models-Training|Fine-tuned Models-Input|Fine-tuned Models-Output|
|---|---|---|---|---|---|
|`babbage-002`|0.0004|0.0004|0.0004|0.0016|0.0016|
|`davinci-002`|0.002|0.002|0.006|0.012|0.012|
|`gpt-3.5-turbo-4k`|0.0015|0.002|0.008|0.012|0.016|
|`gpt-3.5-turbo-16k`|0.003|0.004|-|-|-|
|`gpt-4-8k`|0.03|0.06|-|-|-|
|`gpt-4-32k`|0.06|0.12|-|-|-|

注
- 单位 $/1k tokens
- [官方收费指南](https://openai.com/pricing)

例如
- gpt-3.5-turbo 微调作业中包含 10 万个 token 的训练文件。经过 3 个 epoch 训练轮次，预计成本为 2.40 美元。

微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 **8 倍**，因此用户确实必须处于 OpenAI 提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。

初版 GPT-3 基础模型（ada、babbage、curie 和 davinci）微调 将于 2024 年 1 月 4 日正式关闭。

OpenAI 如今发布了 babbage-002 和 davinci-002 作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新 API 端点/v1/fine_tuning/jobs 进行微调。


#### finetune 原理

【2023-8-24】[GPT-3.5 微调 API重磅发布：有史以来规模最大的 LoRA 即服务](https://mp.weixin.qq.com/s/GIIzEwRzXxkAffPDjtvvaw)

LoRA：英文全称 Low-Rank Adaptation of Large Language Models，大语言模型的低阶适应，微软研究人员为解决大语言模型微调而开发的一项技术。
- 冻结预训练的模型权重参数, 每个Transformer块里注入可训练层，由于不需要对模型的权重参数重新计算梯度，所以大大减少了需要训练的计算量。

研究发现: LoRA的微调质量与全模型微调相当

LoRA-as-a-service： LoRA 即服务。
- 这种模式类似于“软件即服务”（Software-as-a-Service，SaaS）或其他类似的服务模式，其中用户不需要自行部署和管理软件或技术，而是通过云服务提供商获得对其功能和服务的访问权

#### finetune 流程

微调实战
- 参考: [openai 3.5微调实战](https://github.com/LearnPrompt/LLMs-cookbook/tree/main/gpt3.5)
- 微调 `gpt-3.5-turbo-0613` 模型，**10条**数据（289个汉字，**5769**个字节），花费 0.16 刀; 按照 0.008 单价算，大概训练了3轮
- 数据示例：医疗监督问答数据集 [huatuo26M-testdatasets](https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets), 或去 [github](https://github.com/LearnPrompt/LLMs-cookbook/blob/main/gpt3.5/test_datasets.jsonl)找

<div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2023-08-29T13:15:51.115Z\&quot; agent=\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\&quot; etag=\&quot;UVFE8uh0TtQpR3knby8f\&quot; version=\&quot;21.6.8\&quot;&gt;\n  &lt;diagram name=\&quot;第 1 页\&quot; id=\&quot;YUrH7kkdw6S7EPocWAtV\&quot;&gt;\n    &lt;mxGraphModel dx=\&quot;1434\&quot; dy=\&quot;771\&quot; grid=\&quot;1\&quot; gridSize=\&quot;10\&quot; guides=\&quot;1\&quot; tooltips=\&quot;1\&quot; connect=\&quot;1\&quot; arrows=\&quot;1\&quot; fold=\&quot;1\&quot; page=\&quot;1\&quot; pageScale=\&quot;1\&quot; pageWidth=\&quot;827\&quot; pageHeight=\&quot;1169\&quot; math=\&quot;0\&quot; shadow=\&quot;0\&quot;&gt;\n      &lt;root&gt;\n        &lt;mxCell id=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;1\&quot; parent=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-4\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#f5f5f5;dashed=1;dashPattern=1 1;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;340\&quot; y=\&quot;90\&quot; width=\&quot;350\&quot; height=\&quot;190\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;CRyWcW9bKPYmjVe2kgWn-2\&quot; value=\&quot;ChatGPT 微调流程\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=0;fontSize=18;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;335\&quot; y=\&quot;10\&quot; width=\&quot;180\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;V9TQX8vlhKfmWj-25TbC-43\&quot; value=\&quot;2023-8-29&amp;lt;br&amp;gt;wqw547243068@163.com\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;550\&quot; y=\&quot;290\&quot; width=\&quot;170\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-6\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;198\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; value=\&quot;GPT-3.5 Turbo\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;100\&quot; width=\&quot;95\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-7\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0;entryY=0;entryDx=0;entryDy=12.5;entryPerimeter=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; value=\&quot;监督语料\&quot; style=\&quot;shape=cylinder3;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;size=15;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;160\&quot; y=\&quot;115\&quot; width=\&quot;60\&quot; height=\&quot;60\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot; value=\&quot;GPT-3.5 Turbo Finetune\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;225\&quot; width=\&quot;95\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-16\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;516.25\&quot; y=\&quot;183\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; value=\&quot;个人语料\&quot; style=\&quot;shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;370\&quot; y=\&quot;130\&quot; width=\&quot;84\&quot; height=\&quot;45\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-11\&quot; value=\&quot;① 准备语料\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot;&gt;\n          &lt;mxGeometry x=\&quot;-0.1467\&quot; y=\&quot;-1\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;39\&quot; y=\&quot;-3\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-21\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#97D077;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;240\&quot; y=\&quot;275\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; value=\&quot;\&quot; style=\&quot;shape=actor;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;175\&quot; y=\&quot;220\&quot; width=\&quot;30\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-12\&quot; value=\&quot;② 上传语料到OpenAI\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;280\&quot; y=\&quot;125\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-13\&quot; value=\&quot;OpenAI\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=1\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;470\&quot; y=\&quot;60\&quot; width=\&quot;70\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-15\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;538\&quot; y=\&quot;140\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;168\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-17\&quot; value=\&quot;③ 启动微调\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;590\&quot; y=\&quot;175\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-18\&quot; value=\&quot;④ 邮件通知任务完成&amp;lt;br&amp;gt;(返回模型名)\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;610\&quot; y=\&quot;220\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;19\&quot; y=\&quot;4\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-19\&quot; value=\&quot;⑤ 调用新模型\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;300\&quot; y=\&quot;260\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-23\&quot; value=\&quot;jsonl格式&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}\&quot; style=\&quot;shape=note;whiteSpace=wrap;html=1;backgroundOutline=1;darkOpacity=0.05;fillColor=#fff2cc;strokeColor=#d6b656;align=left;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;140\&quot; y=\&quot;40\&quot; width=\&quot;190\&quot; height=\&quot;70\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; value=\&quot;\&quot; style=\&quot;shape=image;html=1;verticalLabelPosition=bottom;verticalAlign=top;imageAspect=0;image=img/clipart/Gear_128x128.png\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;517.5\&quot; y=\&quot;156.5\&quot; width=\&quot;40\&quot; height=\&quot;53\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-25\&quot; value=\&quot;生成语料id\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;411\&quot; y=\&quot;118\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n      &lt;/root&gt;\n    &lt;/mxGraphModel&gt;\n  &lt;/diagram&gt;\n&lt;/mxfile&gt;\n&quot;}"></div>
<script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script>


完整版: [知乎](https://zhuanlan.zhihu.com/p/653239407?), [公众号](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649769352&idx=1&sn=e68c0ae1d3b2b1af8aeb3ace58f811e0&chksm=bec3d89589b45183f626a37b4c345254c527f0b68fb301e6e9abb88d6d78b2418697f534f049&token=622259072&lang=zh_CN#rd)

#### ① 数据处理

将jsonl格式（每行都是json串的文本文件）的数据（question, answer两个字段）转换为OpenAI要求的格式

```py
# 数据处理
import json
import random

def transform_jsonl(input_file_path, output_file_path):
    entries = []
    with open(input_file_path, 'r') as file:
        for line in file:
            entry = json.loads(line)
            entries.append(entry)
    # 随机抽取100个条目
    #sampled_entries = random.sample(entries, 100)
    sampled_entries = random.sample(entries, 10) # 至少10条数据

    with open(output_file_path, 'w') as outfile:
        for entry in sampled_entries:
            messages = []
            messages.append({"role": "system", "content": "You are an assistant"})
            user_message = {"role": "user", "content": entry["questions"]}
            assistant_message = {"role": "assistant", "content": entry["answers"]}
            messages.extend([user_message, assistant_message])
            result = {"messages": messages}
            json.dump(result, outfile, ensure_ascii=False)
            outfile.write('\n')

input_file_path = '~/test_datasets.jsonl' # 请替换为您的输入JSONL文件路径
output_file_path = '~/tmp.jsonl' # 请替换为您想要保存的输出JSONL文件路径
transform_jsonl(input_file_path, output_file_path)
```

数据示例：

```json
输入: {"questions": "做了腰间盘穿丁手术后，用盐泡脚可以吗", "answers": "问题分析：你好:你是由于身体出现了一些局部的腰部损伤这种情况应该进行调整的一般术后泡脚是可以的，不用担心。意见建议：治疗方案:你可以不知后注意休息，避免劳累过度就可以这种调整方法也可以住进你身体的一些嗯调理的啊！"}
输出: {"messages": [{"role": "system", "content": "You are an assistant that occasionally misspells words"}, {"role": "user", "content": "由于一次事故造成了左耳的残疾听力不是很好需要佩戴助听器戴上的效果还不错能和人正常交流但是最近一个月助听器里面总是有杂音影响了使用效果。耳聋佩戴的助听器有杂音怎么办？（）"}, {"role": "assistant", "content": "你好您所谓的杂音也有可能是听到的环境声音好的助听器对噪音是有压缩的出现这种情况是可以调试解决的如果是一般的助听器因为环境声音也同时放大了可能会觉得比较吵您的问题最好是到助听器店让专业的验配师帮您处理"}]}
// 官方数据示例
{
  "messages": [
    { "role": "system", "content": "You are an assistant that occasionally misspells words" },
    { "role": "user", "content": "Tell me a story." },
    { "role": "assistant", "content": "One day a student went to schoool." }
  ]
}
```


#### ② 上传文件

注意
- 单个训练文件<span style='color:red'>最大 50 MB</span>
- 一行数据是完整的json字符串，<span style='color:red'>最大token数目 4096，超出就截断</span>
- <span style='color:red'>最少训练条数：10</span>，一般50-100条就有提升，因场景而已
- 数据较少时，将效果好<span style='color:red'>system prompt放到训练数据中</span>
  - 数据：质量 > 数量
- 数据可以分为训练集、测试集，分开上传


```sh
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F "purpose=fine-tune" \
  -F "file=@path_to_your_file" 

# ------ 第三方  ----
curl --location 'https://api.openai.com/v1/files' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --form "purpose=fine-tune" \
  --form "file=@path_to_your_file" 
```

以上方法失效，错误信息
> The browser (or proxy) sent a request that this server could not understand.

python
- 【2023-9-20】升级文件上传代码

```py
import os
import openai

#openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

data_file = "your_file"
#data_file = val_file
openai.File.create(
  file=open(data_file, "rb"),
  user_provided_filename=data_file.split('/')[-1], # 自定义上传后的文件名，如 采用原文件名称（按/分割）
  purpose='fine-tune' # 固定，不能改
)
print('上传的文件信息: ', openai.File.list())
```

```py
# 上传至OpenAI
import requests
import openai

OPENAI_API_KEY='***'
url = "https://api.openai.com/v1/files"
headers = {
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
payload = {
    "purpose": "fine-tune",
}
print('数据路径: ', output_file_path)
files = {
    "file": open(output_file_path, "rb")
}

response = requests.post(url, headers=headers, data=payload, files=files)
print(response)
print('上传的文件信息: ', openai.File.list())
```

执行完毕后返回 文件列表

```json
上传的文件信息:  {
  "object": "list",
  "data": [
    {
      "object": "file",
      "id": "file-***",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 5769,
      "created_at": 1693304216,
      "status": "uploaded",
      "status_details": null
    },
    {
      "object": "file",
      "id": "file-****",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 1496,
      "created_at": 1693303804,
      "status": "processed",
      "status_details": null
    }
  ]
}
```

从中找到 本次上传文件 位置，如下标0, 或1

文件信息格式化，时间戳转换，便于查找

```py
from datetime import datetime
import pandas as pd

def timestamp2str(ts):
    cur_date = datetime.fromtimestamp(ts)
    local_date_str = datetime.strftime(cur_date ,'%Y-%m-%d %H:%M:%S')
    return local_date_str
    
df_file = pd.DataFrame(openai.File.list()['data'])
df_file['time'] = df_file['created_at'].map(timestamp2str) # 时间戳转str
df_file.sort_values('time') # 按时间排序
```


#### ③ 启动微调任务

使用官方默认参数

```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'
```

自定义参数
- 指定验证集
- 设置前缀
- 设置训练参数，如 epoches

超参优化
- 刚开始不用指定epoch，OpenAI自行设置，根据测试数据自行调整：
- 如果没有遵循指令，增加1-2个epoch
- 如果多样性低于预期，减少1-2个epoch


```sh
# ------ 第三方: 自定义训练参数  ----
curl --location 'https://api.openai.com/v1/fine_tuning/jobs' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --data '{
    "training_file": "file-****", // 训练集
    "validation_file": "file-****", // 测试集
    "hyperparameters":{
      "n_epochs":7
    },
    "suffix":"cutom-model-name", // 自定义模型前缀
    "model":"gpt-3.5-turbo-0613"
  }'

```


模型选择

```py
# 启动微调
import requests

OPENAI_API_KEY="sk-***"

url = "https://api.openai.com/v1/fine_tuning/jobs"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}

data = { 
    #"training_file": "file-XXXXXXXXXXX",
    "training_file": openai.File.list()['data'][1]['id'],
    "model": "gpt-3.5-turbo-0613"
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

终端返回

```json
{"object":"fine_tuning.job","id":"ftjob-***","model":"gpt-3.5-turbo-0613","created_at":1693304550,"finished_at":null,"fine_tuned_model":null,"organization_id":"org-LMrR8ZVsnE2MLQNXje4rARHo","result_files":[],"status":"created","validation_file":null,"training_file":"file-bPzn6eE00cvR3xNqb8lau6QN","hyperparameters":{"n_epochs":10},"trained_tokens":null}
```

#### 任务控制

**获取**训练信息

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-**** \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

**取消**训练任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/cancel \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

查看训练进度

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/events \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```


稍等片刻后，查看个人邮箱，记录新模型名

```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'
```

对应的Python指令

```py
# List 10 fine-tuning jobs
openai.FineTuningJob.list(limit=10)
# Retrieve the state of a fine-tune
openai.FineTuningJob.retrieve("ft-abc123")
# Cancel a job
openai.FineTuningJob.cancel("ft-abc123")
# List up to 10 events from a fine-tuning job
openai.FineTuningJob.list_events(id="ft-abc123", limit=10)
# Delete a fine-tuned model (must be an owner of the org the model was created in)
openai.Model.delete("ft-abc123")
```

#### ④ 使用微调模型

查看已有finetune任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&after=1 \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

看下新模型效果

```py
# 调用模型
import requests

url = "https://api.openai.com/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
# 从邮件里提取模型名称
new_model = 'text-davinci-003'
new_model = "gpt-3.5-turbo"
new_model = 'ft:gpt-3.5-turbo-0613:***'
data = {
    "model": new_model,
    "messages": [
        {
            "role": "system",
            "content": "You are an assistant"
        },
        {
            "role": "user",
            "content": "我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？"
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

返回结果

```json
{
  "id": "chatcmpl-****",
  "object": "chat.completion",
  "created": 1693305795,
  "model": "ft:gpt-3.5-turbo-0613:***",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "可能的原因如下： 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 4、如果一直测得较高，就是高血压，应引诱病院。"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 73,
    "completion_tokens": 219,
    "total_tokens": 292
  }
}
```


效果对比

question: 
> 我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？

Answer

**gpt-3.5**

> 血压读数130/80是较常见的健康血压范围内，但是具体的献血要求可能略有不同，医生可能基于献血的特殊需求或个人身体状况，选择较为严格的标准。以下是一些可能导致您不能献血的原因：
>1. 个人差异: 献血机构可能设定了较为严格的血压标准，以确保献血者的安全和健康。即使您的血压读数在正常范围内，但慎重考虑您的个人特殊情况或家族病史等因素也很重要。
>2. 动态血压: 血压是一个动态指标，受多种因素影响，如情绪、活动水平、环境等。可能您的血压在体检时正常，但在献血前被测量时升高。
>3. 紧张或焦虑: 对一些人来说，献血过程本身可能会引发一些紧张和焦虑，这可能会导致血压升高。这些情绪因素可能会影响到医生的判断。
> 
> 如果您对不能献血的原因有任何疑问，我建议您咨询相关医生或献血机构的工作人员，他们可以给您更具体的解释和指导。另外，您的血压读数仍然在健康范围内，您可以继续关注并保持良好的生活习惯，有助于保持健康的血压水平。

**finetune**

> 可能的原因如下： 
>- 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 
>- 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 
>- 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 
>- 4、如果一直测得较高，就是高血压，应引诱病院



简单微调过后不用写prompt也能让gpt-3.5-turbo-0613有更加专业的回复




# 结束