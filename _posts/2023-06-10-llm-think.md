---
layout: post
title:  大语言模型（LLM）沉思录
date:   2023-06-10 12:00:00
categories: 深度学习 自然语言处理
tags: gpt ChatGPT LLM 大模型 AGI 世界模型 系统 快思考 慢思考 灾难 遗忘 幻觉
excerpt: 各个大模型表现究竟怎么样？如何评估大模型表现？LLM真的是AGI吗？
mathjax: true
permalink: /llm
---

* content
{:toc}

# LLM 大语言模型

## 名词

### 章鱼测试

章鱼测试
> “两位说英语的荒岛幸存者被困在相邻岛屿上，中间隔着危险水域。幸运的是，他们发现了前任居民留下的电报机，电报机通过一条水下电缆连接起来，他们能够通过电报传递信息。但是，他们不知道的是：附近水域里，生活着一个具备超级智能的章鱼，它劫持了水下电缆并拦截了他们之间传送的消息。尽管章鱼不懂英语，但其超级智能使其能够检测到电报信息文字的统计模式，并能准确表示各种电报信号间的统计关系。在章鱼觉得自己已经学好这些统计规律之后，它切断水下电缆，将自己两个长触手定位在电缆的两个末端，基于它所识别出来的统计模式，接收并自己来回复两名漂流者的电报信号。无论两位幸存者是否注意到交流对象已发生变化，章鱼发送出去的信息，在本质上似乎没有任何含义。毕竟，章鱼只是遵循它从人类之间的前期交流中学到的统计模式，而并没有看到过任何人类对信号的解释，比如“椰子”或“海水”所代表的真实含义。此外，章鱼甚至可能都不明白这些信号是具有意义的，或起到了促进交流的功能。“

## 思考

### LLM 真的有智能吗

【2023-6-1】[世界的参数倒影：为何GPT通过Next Token Prediction可以产生智能](https://mp.weixin.qq.com/s/liLVlhzBnQ8WwtvgSYoQkA)

把“章鱼测试”里的章鱼换成 ChatGPT 或 GPT-4，怎么看这个问题呢？
- 一种观点: 与“章鱼测试”看法类似，认为 GPT-4 这种LLM模型仅仅学会了语言中的**单词共现**等浅层的**表面统计关系**，其实并未具备智能，只是类似**鹦鹉学舌**的语言片段缝合怪而已；
  - 代表：除了OpenAI，还有 musk，Hinton，他不仅认为GPT 4具备类人智能，而且觉得将来人类这种碳基智能很可能是LLM这种硅基智能的引导启动程序(Booster)，
- 另外一种: GPT-4 不仅学会了语言元素间的表面统计关系，而且学到了人类语言甚至包括物理世界的**内在运行规律**，文字是由内在智能产生的，所以LLM具备类人智能。
  - 代表： AI大佬是LeCun，语言学界代表人物是乔姆斯基，都否认通过Next Token Prediction这种方式训练出来的大语言模型能够具备智能；


### LLM 是随机鹦鹉吗

【2023-5-28】[数学论证GPT-4不是随机鹦鹉：真如此的话整个宇宙都会坍缩](https://mp.weixin.qq.com/s/NsIaFwDfySNPnrJ2aLR6Fg)

随机鹦鹉
- 语言模型只是将其在庞大的训练数据中观察到的语素胡乱拼接在一起，根据概率生成文本，但不清楚文字背后的任何含义，就像一个随机的鹦鹉。
- 出自论文On The Dangers of Stochastic Parrots: Can Language Models Be Too Big

Jacob Bayless的工程师用数学方法得出惊人结论：
>- 根据统计规律预测下一词，所需的信息量50000^8000, 足以让整个宇宙都坍塌成黑洞。
>- 根据`贝肯斯坦上限`(Bekenstein bound)原理，如果把这些信息分配到空间当中，所需要的信息密度已经远超宇宙能承受的最大值。而这仅仅是把数据存储起来的消耗，更不必说还要进行运算了。

GPT-3的token字典中就有超过5万token。如果对每个词都逐一建立统计信息，n-gram模型中n值将高达8000。届时，需要存储的情景数量将达到$50000^8000$。

这是天文数字，足以让整个宇宙坍缩。因此，GPT是“随机鹦鹉”的猜测在理论上得到了一定程度的批驳。

两个实验
- 第一个实验：经典的农夫过河问题，将农夫、船、河分别替换成地球人、虫洞和银河系。狼、羊和菜则分别换成火星人、金星人和月球人。这样现有语料都不存在，可用来判断是否掌握了语言规律
  - GPT-4针对替换后的问题给出了正确的回答，GPT-3.5则没有。但它们并没有犯研究人员预想的“鹦鹉”错误——即在回答中出现狼、船、河等已被替换掉的词语
  - 这些现象都证明了现在的大语言模型的生成方式已经超越了“概率预测”。
- 第二个实验：数字排序。让GPT学习数字排序，究竟是只会记住给出过的数字顺序，还是真的研究出排序算法呢？
  - 从1-100中随机选择10个数字，并将其顺序打乱，将一共有这么多种情形：6.28*10^9
  - 只要GPT能够针对未知的排序问题给出正确的回答，便可以说明它们是真的研究出了排序算法。
  - 用 nanoGPT 做数字排序。结果显示，随着训练步数的增加，模型给出的数字顺序越来越完美。
  - 模型并不是仅仅根据学习的素材对未知的数字进行排序，而是已经掌握了背后的方法。


### LLM 一致性与能力

大型语言模型中的能力与一致性
- 「一致性 vs 能力」可以被认为是「准确性 vs 精确性」的更抽象的类比
- ![img](https://pic3.zhimg.com/80/v2-ea201f656a80f0b8ccbce544ad6f97d6_1440w.webp)

说明
- 模型能力是指模型执行特定任务或一组任务的能力。模型的能力通常通过它能够优化其目标函数的程度来评估。
- 一致性关注的是实际希望模型做什么，而不是它被训练做什么；「目标函数是否符合预期」，根据的是模型目标和行为在多大程度上符合人类的期望。

参考：[深入浅出，解析ChatGPT背后的工作原理](https://zhuanlan.zhihu.com/p/597100830)

### LLM 突现能力

只有大型模型才有的三种突现能力：
- `复杂推理`，大型模型在没有使用全部训练数据的情况下便显著优于以前的小型模型。
- `知识推理`，大型模型可能没有小模型效果好，但大模型不需要额外的知识来源（知识可能很昂贵，或者很难从非结构化数据中抽取）。
- `分布外鲁棒性`，这是之前进行模型精调时需要努力解决的问题。大型模型虽然在同分布情况下的效果不如以前的方法，但非同分布情况下的泛化性能却好得多。

（1）**复杂推理**

下面是一个GSM8K数据集中，用提示词显著超过精调的例子：

```s
问题：
克莱儿每天早饭都用 3 颗蛋做蛋卷，她 4 周会吃掉多少打鸡蛋？

克莱儿每天早饭都用3颗蛋做蛋卷。
一周有 7 天。
所以她一周会吃 3 * 7 = 21 颗蛋。
她4周会吃掉 4 * 21 = 84 颗蛋。
一打里面是 12 颗蛋。
所以 84 / 12 = 7。

答案是7。
```

这道题对于10岁的孩子很容易，但对语言模型却很难，主要是由于**数学和语言混合在一起**。

GSM8K 最初由 OpenAI 于 2021 年 10 月提出。当时用第一版GPT3在全部训练集上进行了精调，准确率约为 35%。这个结果让作者相当悲观，因为结果显示了语言模型的**缩放规律**：
- 随着模型大小呈**指数**增长，性能呈**线性**增长（我之后会讨论）。

因此，第 4.1 节中思考：
- “175B 模型似乎需要至少额外两个数量级的训练数据才能达到 80% 的求解率。”

- 三个月后，即 2022 年 1 月，Wei 等人 基于 540B PaLM 模型，仅使用了8个**思维链提示**示例便将准确率提高到56.6% （无需将训练集增加两个数量级）。
- 在 2022 年 3 月，Wang 等人 基于相同的 540B PaLM 模型，通过多数投票的方法将准确率提高到 74.4% 。当前的 SOTA 来自在 AI2 的工作（Fu et. al. Nov 2022），通过使用复杂思维链在 175B Codex 上实现了 82.9% 的准确率。

从以上进展可以看到，技术进步确实呈**指数级**增长。

思维链提示是一个展示模型随着规模突现出能力的典型例子：
- **突现能力**：尽管不需要 17500B，但模型大小确实要大于 100B ，才能使思维链的效果大于的仅有回答提示。所以这种能力只存在于大型模型中。
- **效果**：思想链提示的性能明显优于其之前的精调方法（目前还没有能公平对比提示词和微调的工作。但当思维链被提出的时候，尽管他们对于提示和精调的比较可能是不公平的，但确实比精调效果要好）。
- **标注效率**：思维链提示只需要 8 个示例的注释，而微调需要完整的训练集。

有些同学可能会认为模型能做小学数学代表不了什么（从某种意义上说，他们确实没有那么酷）。但 GSM8K 只是一个开始，最近的工作已经把前沿问题推向了高中、大学，甚至是国际数学奥林匹克问题。

（2）**知识推理**

下一个例子是需要**知识**的推理能力（例如问答和常识推理）。对大型模型进行提示不一定优于精调小型模型（哪个模型更好还有待观察）。但是这个情况下的注释效率被放大了，因为：
- 在许多数据集中，为了获得所需的背景/常识知识，（以前很小的）模型需要一个外部语料库/知识图谱来检索[13]，或者需要通过多任务学习在增强[14]的数据上进行训练
- 对于大型语言模型，可以直接去掉检索器[15]，仅依赖模型的内部知识[16]，且无需精调

与数学题的例子不同，GPT-3 并没有明显优于之前的精调模型。但它不需要从外部文档中检索，本身就包含了知识（虽然这些知识可能过时或者不可信，但选择哪种可信知识源超出了本文的讨论范围）。

为了理解这些结果的重要性，我们可以回顾一下历史：NLP 社区从一开始就面临着**如何有效编码知识**的挑战。人们一直在不断探究把知识保存在模型外部或者内部的方法。上世纪九十年代以来，人们一直试图将语言和世界的规则记录到一个巨大的图书馆中，将知识存储在模型之外。但这是十分困难的，毕竟我们无法穷举所有规则。因此，研究人员开始构建特定领域的知识库，来存储非结构化文本、半结构化（如维基百科）或完全结构化（如知识图谱）等形式的知识。
- 通常，**结构化知识很难构建**（因为要设计知识的结构体系），但**易于推理**（因为有体系结构），非结构化知识**易于构建**（直接存起来就行），但**很难用于推理**（没有体系结构）。
- 然而，语言模型提供了一种新的方法，可以轻松地从非结构化文本中提取知识，并在不需要预定义模式的情况下有效地根据知识进行推理。

下表为优缺点对比：

| 构建 |	推理 |
|----|--------|
| 结构化知识	| 难构建，需要设计体系结构并解析	容易推理，有用的结构已经定义好了 |
| 非结构化知识	| 容易构建，只存储文本即可	难推理，需要抽取有用的结构 |
| 语言模型	| 容易构建，在非结构化文本上训练	容易推理，使用提示词即可 |

（3）**分布外鲁棒性**

第三种能力是分布外鲁棒性。
- 在 2018 年至 2022 年期间，NLP、CV 和通用机器学习领域有大量关于分布偏移/对抗鲁棒性/组合生成的研究，人们发现当测试集分布与训练分布不同时，模型的行为性能可能会显著下降。
-然而，在大型语言模型的上下文学习中似乎并非如此。Si 等人在2022年的研究显示[17]：虽然 GPT-3 在同分布设置下比 RoBERTa 要差，但在非同分布设置下优于 RoBERTa，性能下降明显更小。
- 同样，在此实验中，同分布情况下基于提示词的 GPT-3 的效果并没有精调后的 RoBERTa要好。但它在三个其他分布（领域切换、噪声和对抗性扰动）中优于 RoBERTa，这意味着 GPT3 更加鲁棒。

此外，即使存在分布偏移，好的提示词所带来的泛化性能依旧会继续保持。

Fu 等人2022年[18]的研究显示，输入提示越复杂，模型的性能就越好。这种趋势在分布转移的情况下也会继续保持：无论测试分布与原分布不同、来自于噪声分布，或者是从另一个分布转移而来的，复杂提示始终优于简单提示。


（4）<span style='color:red'>突现能力推翻比例定律</span>

鉴于上文列出的优点，大家可能会开始觉得大型语言模型确实很好了。再回顾一下之前的工作，就会发现一个很奇怪的问题：
- GPT-3 在 2020 年就发布了，但为什么直到现在才发现并开始思考范式的转变？

这个问题的答案就藏在两种曲线中：`对数线性曲线`和`相变曲线`。图见原文
- ![](https://pic2.zhimg.com/80/v2-6142f0c0df2c189b7f4007ee93745531_1440w.webp)

- 最初，（OpenAI）研究者认为语言模型的性能与模型尺寸的关系可以通过**对数线性曲线**预测，即模型尺寸呈指数增长时，性能会随之线性增加。这种现象被称为语言模型的`缩放定律`，正如 Kaplan 等人在2020年[19]最初的GPT3文章[20]中讨论的那样。重要的是，即便最大的 GPT-3 在有提示的情况下也不能胜过小模型精调。所以当时并没有必要去使用昂贵的大模型（即使提示词的标注效率很高）。
- 直到2021年，Cobbe 等人[21]发现**缩放定律**同样适用于**精调**。这是一个有点悲观的发现，因为它意味着我们可能被锁定在模型规模上——虽然模型架构优化可能会在一定程度上提高模型性能，但效果仍会被锁定在一个区间内（对应模型规模），很难有更显著的突破。
- 在缩放定律的掌控下（2020年到2021），由于GPT-3无法胜过精调 T5-11B，同时T5-11B微调已经很麻烦了，所以NLP社区的关注点更多的是研究更小的模型或者高效参数适应。Prefix tuning[22]就是提示和适应交叉的一个例子，后来由 He 等人在 2021[23]统一。当时的逻辑很简单：如果精调效果更好，我们就应该在高效参数适应上多下功夫；如果提示词的方法更好，我们应该在训练大型语言模型上投入更多精力。
- 2022 年 1 月，`思维链`工作被放出来了。正如作者所展示的那样，思维链提示在性能-比例曲线中表现出明显的相变。当模型尺寸足够大时，性能会显著提高并明显超越比例曲线。当使用思维链进行提示时，大模型在复杂推理上的表现明显优于微调，在知识推理上的表现也很有竞争力，并且分布鲁棒性也存在一定的潜力。要达到这样的效果只需要8个左右的示例，这就是为什么范式可能会转变的原因。

参考：[ChatGPT出来后，我们是否真的面临范式转变?](https://mp.weixin.qq.com/s/q-Ng5uSiR-3EW2Lc6rnr8g)

【2023-2-21】模型应该多大才够？两个数字：<span style='color:blue'>62B 和 175B</span>。
- 模型至少需要62B，`思维链`效果才能大于标准的`提示词`方法。
  - 62B这个数字来自于 Chung 等人 2022 年工作的第五张表
  - 所有小于62B的模型，直接用提示词都好于思维链。
- 模型至少需要175B（GPT3的尺寸），思维链的效果才能大于`精调`小模型（T5 11B）的效果。
  - 理想的尺寸可以小于540B，在 Suzgun 等人2022年[25]的工作中，作者展示了175B的 InstructGPT 和 175B的 Codex 使用思维链都好于直接用提示词。

其他大型模型在思维链下的表现差了很多，甚至不能学到`思维链`，比如 `OPT`、`BLOOM` 和 `GPT-3` 的第一个版本。他们的尺寸都是175B。

两种模型可以做`思维链` (TODO: add discussions about UL2)：
- GPT3系列的模型，包括 text-davinci-002 和 code-davinci-002 (Codex)。这是仅有的两个具有强大突现能力并可公开访问的模型。
- a. 除了以上两个模型，其他GPT3模型，包括原来的 GPT3，text-davinci-001，以及其他更小的GPT-3模型，都不能做`思维链`。
- b. 当说“能做思维链”时，指使用思维链方法的效果比直接用提示词、精调T5-11B效果更好。
- c. 注意: code-davinci-002 在语言任务上的性能始终优于 text-davinci-002。这个观察非常有趣且耐人寻味。这表明基于代码数据训练的语言模型可以胜过根据语言训练的语言模型。
- PaLM系列模型，包括 PaLM、U-PaLM、Flan-PaLM 和 Minerva

详见：[ChatGPT的一小步，NLP范式转变的一大步](https://zhuanlan.zhihu.com/p/595500888)

### LLM 涌现能力

LLM 的涌现能力定义:
- 「<span style='color:blue'>在小模型中不存在但在大模型中出现的能力</span>」
- 当规模达到一定水平时，性能显著高于**随机**的状态。-- 相变现象

LLM 区别于以前的 PLM 的最显著特征

这种新模式与物理学中的**相变**现象密切相关。

【2023-4-4】LLM 三种代表性的涌现能力：
- **上下文学习**。GPT-3 正式引入了**上下文学习**能力：假设语言模型已经提供了自然语言指令和多个任务描述，可以通过完成输入文本的词序列来生成测试实例的预期输出，而无需额外的训练或梯度更新。
- **指令遵循**。通过对自然语言描述（即指令）格式化的多任务数据集的混合进行微调，LLM 在微小的任务上表现良好，这些任务也以指令的形式所描述。这种能力下，指令调优使 LLM 能够在不使用显式样本的情况下通过理解任务指令来执行新任务，这可以大大提高泛化能力。
- **循序渐进推理**。对于小语言模型，通常很难解决涉及多个推理步骤的复杂任务，例如数学学科单词问题。同时，通过思维链推理策略，LLM 可以通过利用涉及中间推理步骤的 prompt 机制来解决此类任务得出最终答案。据推测，这种能力可能是通过代码训练获得的。

ChatGPT 这么强的原因？
- <span style='color:blue'>因为足够“大”吗？是，但不全是。</span>
  - ChatGPT确实很大，背后模型是一个在有3000亿tokens上预训练的拥有1750亿个参数的大语言模型。但是，ChatGPT并不是目前世界上最大的模型
  - 比如，Google的`PaLM`的参数规模为5400亿，DeepMind的`Gogher`参数规模为2800亿，国内华为`盘古α`的参数规模为2000亿，`百度文心`的参数规模为2600亿。
  - 论参数规模，ChatGPT虽然跻身千亿俱乐部成员，但远远不是最大的那个。
- <span style='color:blue'>因为大量人工标注吗？不是</span>
  - ChatGPT背后的GPT 3.5，仅加入了数万条人工标注数据，相比于其预训练过程使用的3000亿tokens来说，可谓九牛一毛。
  - 目前学界倾向于认为ChatGPT通过海量文本预训练，掌握了基本的语法知识，以及大量世界知识，所谓“**知识注入**”。
  - 比如“地球是圆的”属于常识、或“对位芳纶全球消费量在8-9万吨，国内自给率是20%”属于投研领域专业知识，这些都属于“世界知识”的范畴，都是在模型预训练时注入的。
  - 相对的，人工标注数据，提供的则主要是**人类偏好知识**，比如礼貌的回答是好的，带有歧视性的回答是不好的等等。OpenAI的作者将其戏称为“`对齐税`”（Alignment Tax），即为了使回答满足人类的偏好而牺牲了部分模型的性能。

目前关于ChatGPT模型优秀能力的来源在学界众说纷纭，尚未有定论。但有两种猜想已经得到了绝大多数学者的支持，分别是“**涌现能力**”、以及“**代码训练**”。

[GPT-4太强，OpenAI也不懂！智能到底是怎么突然「涌现」的？](https://www.toutiao.com/article/7213261622469607992)
- [原文](https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316)

内行人也不明白，为什么模型规模在突破某一界限后，突然就「涌现」出了惊人的智能。出现智能是好事，但模型不可控、不可预测、不可解释的行为，却让整个学术界陷入了迷茫与深思。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/57e02e543e8b4ffcab61659b4f72067f~noop.image?_iz=58558&from=article.pc_detail&x-expires=1680362909&x-signature=piC6%2BOkYbLWM9TzaMmX%2FuvUkV%2BE%3D)

Google Research的计算机科学家`Ethan Dyer`参与组织了这次测试，希望通过204项任务，测试各种大型语言模型能力
- 虽然构建BIG-Bench数据集时已经准备好了迎接惊喜，但当真的见证这些模型能做到的时候，还是感到非常惊讶。这些模型只需要一个提示符：即接受一串文本作为输入，并且纯粹基于统计数据一遍又一遍地预测接下来是什么内容。
- 扩大规模可以提高已知任务的性能，但他们没有预料到模型会突然能够处理这么多新的、不可预测的任务。

`Dyer`最近参与的一项调研结果显示，<span style='color:blue'>LLM 可以产生数百种「涌现」（emergent）能力</span>，即大型模型可以完成的任务，小型模型无法完成，其中许多任务似乎与分析文本无关，比如从乘法计算到生成可执行的计算机代码，还包括基于Emoji符号的电影解码等。[论文](https://openreview.net/pdf?id=yzkSU5zdwD)
- 对于某些任务和某些模型，存在一个复杂性阈值，超过这个阈值，模型的功能就会突飞猛进。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/83f13abf816c410b8bb37308b6c485d7~noop.image?_iz=58558&from=article.pc_detail&x-expires=1680362909&x-signature=QLNdrMvIxNIcTSGxVAQhU7eKllw%3D)

大模型具有In-Context能力，这种能力不需要针对不同任务再进行适应性训练（微调），用的就是它自己本身的理解力。
- ![](https://qnimg.lovevivian.cn/paper-gpt3-4.jpg)

GPT-3的少样本学习在不同规模模型上的实验对比，提供几个信息：
- X-Shot在不同量级差别巨大，大模型就是有超能力。
- 大模型下，One-Shot效果明显大幅度提升；增加Prompt会进一步大幅度提升。
- Few-Shot的边际收益在递减。大概8-Shot以下时，Prompt作用明显，但从One-Shot到8-Shot，Prompt的作用也在递减。超过10-Shot时，Prompt基本没作用了。

**涌现的涌现**（The Emergence of Emergence）
- 生物学家、物理学家、生态学家和其他科学家使用「涌现」一词来描述当一大群事物作为一个整体时出现的自组织、集体行为。
  - 比如无生命的原子组合产生**活细胞**; 水分子产生**波浪**; 椋鸟的低语以变化但可识别的模式在天空中飞翔; 细胞使肌肉**运动**和心脏**跳动**。
- 涌现能力在涉及大量独立部分的系统中都有出现，但是研究人员直到最近才能够在 LLM 中发现这些能力，或许是因为这些模型已经发展到了足够大的规模。

通过增加模型中的参数数量以及其他因素，Transformer使语言模型的复杂性得以快速扩展，其中参数可以被认为是单词之间的连接，模型通过在训练期间调整这些连接的权重以改善预测结果。模型中的参数越多，建立联系的能力就越强，模拟人类语言的能力也就越强。

OpenAI 研究人员在2020年进行的一项分析发现，随着模型规模的扩大，它们的准确性和能力都有所提高。[论文](https://arxiv.org/pdf/2001.08361.pdf)
- 随着 GPT-3（拥有1750亿参数）和谷歌的 PaLM （可扩展至5400亿参数）等模型的发布，用户发现了越来越多的涌现能力。

与电影Emoji符号任务一样，研究人员没有料到用于预测文本的语言模型可以模仿计算机终端，许多涌现行为都展现了语言模型的Zero-shot或Few-shot学习能力，即LLM可以解决以前从未见过或很少见过的问题的能力。

大批研究人员发现了 LLM 可以超越训练数据约束的迹象，他们正在努力更好地掌握涌现的样子以及它是如何发生的，第一步就是完全地记录下来。

2020年，Dyer 和Google Research的其他人预测，LLM 将产生变革性影响，但这些影响具体是什么仍然是一个悬而未决的问题。他们要求各个研究团队提供困难且多样化任务的例子以找到语言模型的能力边界，这项工作也被称为「`超越模仿游戏的基准`」(BIG-bench，Beyond the Imitation Game Benchmark)项目，名字来源于`阿兰·图灵`提出的「`模仿游戏`」，即测试计算机是否能以令人信服的人性化方式回答问题，也叫做`图灵测试`。

**模型复杂性**并不是**唯一**驱动因素，如果数据质量足够高，一些意想不到的能力可以从参数较少的较小模型中获得，或者在较小的数据集上训练，此外query的措辞也会影响模型回复的准确性。示例：NeurIPS 上发表的CoT思维链技术，[论文](https://neurips.cc/Conferences/2022/ScheduleMultitrack?event=54087)
- **思维链提示**改变了模型的规模曲线，也改变了涌现的点，使用思维链式提示可以引发 BIG 实验中没有发现的涌现行为。

布朗大学研究语言计算模型的计算机科学家Ellie Pavlick认为，这些发现至少提出了两种可能性：
- 第一，如生物系统，大模型确实会自发地获得新的能力，可能从根本上学到了一些新的和不同的东西，而小尺寸模型中没有。当模型扩大规模时，会发生一些根本性的转变。
- 第二，看似突破性的事件可能是一个内部的、由统计数据驱动的、通过思维链式推理运作的过程，大型 LLM 可能只是学习启发式算法，对于那些参数较少或者数据质量较低的参数来说，启发式算法是无法实现的。

涌现导致了不可预测性，而不可预测性也随规模的扩大而增加，使研究人员难以预测广泛使用的后果。

涌现能力的另一个负面影响：
- 随着复杂性的增加，一些模型在回答中显示出新的**偏见**（biases）和**不准确性**。



### LLM 为什么会有涌现能力

【2023-4-4】[涌现能力是玄学吗？](https://www.zhihu.com/question/593496742)

大量个体涌现出单个个体不具备的能力。这是有实验基础的。
- 单个蚂蚁依靠信息素浓度前进，蚁群就有自动寻路的能力，这就是**蚁群算法**。
- 人类遵从简单获取金钱的规则，资本涌现出**羊吃人**的能力。

目前所有解释都是往涌现上一推，似乎问题就混过去了。

GPT 推理能力的产生基于如下原理：
- 记忆是一阶从原始数据到表征数据的相关性连接。
- 推理规则和推理方法本身是二阶记忆内部的相关性连接

小模型在二阶链接上的密度是稀疏的，特定大规模建模可以在二阶连接上超过50%，形成具有连通性的通路，就形成了似乎具备推理能力。

过去所谓的逻辑和原理都是人通过先验知识赋予的似乎不证自明的假设，但是在LLM中，这部分是可以产生的，当然需要正确的调教方法。这挑战了人类几百年来认为是不可动摇的归纳和演绎方法，现在看来归纳和演绎规则并非真正原理，这些其实都是可以解释和可以构造的。

总结一下，就是过去的调教和模型规模，导致其在高阶连接上是稀疏的，而GPT3.5以后高阶相关性的密度达到了全局性联通的边界。所以GPT让人产生了其可以逻辑推理和长程对话的感觉，这是一种表征而已。侧面证明了人类崇拜几千年的逻辑、公理、假设、真理、意义这类东西其实都是语言层面的，不过是形而上学。

从正面看，GPT摧毁了这些虚构的真理，其实是对人类的解放。同时负面看，GPT产生的这类逻辑和推理并非和人类意向完全一致，导致特定全局风险。

[作者](https://www.zhihu.com/question/593496742/answer/2966587547)

大语言模型为什么会产生如此神奇的“涌现能力”呢？
- 【2023-3-6】CoT一作 Jason Wei的ppt [New abilities in big language models](https://docs.google.com/presentation/d/1JyvLrfvLOTfGBWrNl7Gk6Mqn6LIgM2NTeRM2d6oyBow/edit#slide=id.g110339e1e35_0_0)，two new abilities of scale 大模型的两项新增能力
- ① Language models follow instructions. **遵从指令**
  - Finetuned language models are zero-shot learners (ICLR 2022). {J. Wei, M. Bosma, V. Zhao, K. Guu}, A. Yu, B. Lester, N. Du, A. Dai, & Q. Le. 
- ② Language models do chain of thought reasoning. **思维链**
  - Chain of thought prompting elicits reasoning in large language models 
- Emergence and reasoning in large language models - Jason Wei (Google)，[ppt](https://drive.google.com/file/d/1j_CM1fwl_EKB63VlreNUnrKMQsbZHagg/view), [youtube](https://www.youtube.com/watch?v=0Z1ZwY2K2-M)

Chain-of-thought prompting elicits reasoning in large language models (Wei et al., 2022).
- ○ Self-consistency improves chain-of-thought reasoning in language models (Wang et al., 2022).
- ○ Least-to-most prompting enables complex reasoning in large language models (Zhou et al., 2022).
- ○ Language models are multilingual chain-of-thought reasoners (Shi et al., 2022).
- ○ Challenging BIG-Bench tasks and whether chain-of-thought can solve them (Suzgun et al., 2022).

两种猜想已经得到了绝大多数学者的支持，分别是“**涌现能力**”、以及“**代码训练**”。
- （1）大语言模型的**涌现能力**（Emergent Abilities）
  - GPT-3模型其实早在2020年就已经公布，那为什么直到现在才引起大家的充分关注呢？因为2022年前，业界普遍认为GPT模型遵守`Scaling Law`，即<span style='color:blue'>随着模型规模指数级上升，模型性能实现线性增长</span>，所谓服从 `log-linear curve`。实证数据也证明了这一点，当时GPT-3模型的性能并不优于fine-tuned T5-11B 模型。
  - 2022年发生了变化，`CoT`（Chain-of-thought）技术诞生, <span style='color:blue'>直接突破了 `Scaling Law` 的限制，使得大语言模型的性能出现了颠覆式提升</span>。
  - 这项技术其实并不复杂。[图](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr03RJicpcJ0zVdYtvSLbIlDt67iboDFrTAvsC99Lr3pDa9Q6IOmXPlQPKzAgd9XdjIoYaxvNbibVs8zg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
  - ![图](https://pic2.zhimg.com/80/v2-5f91ae17b4e356329fabee97964a3221_1440w.webp)
  - 左侧是一个标准 prompt，模型回答简短且错误的；右侧模型输入加入一个标准的思考过程，然后惊讶地发现，模型的思考能力随之出现了显著提升，能够一步一步得出正确的结果了。
  - 思维链提示在性能-比例曲线中表现出明显的相变。当模型尺寸足够大时，性能会显著提高并明显超越比例曲线。
  - ![](https://image.woshipm.com/wp-files/2023/02/RAPK0MXAYGRvC1zUBS6V.jpg)
  - 这种prompt方式也被称为`one-shot` prompt，与此相对的是`zero-shot` / `few-shot` prompt。当然也可以直接在模型输入的最后，加上“Let's think step by step”来达到类似的效果。[img](https://pic2.zhimg.com/80/v2-5f91ae17b4e356329fabee97964a3221_1440w.webp)
  - ![img](https://pic2.zhimg.com/80/v2-5f91ae17b4e356329fabee97964a3221_1440w.webp)
  - 论文：
    - 2023.1.30, [Specializing Smaller Language Models towards Multi-Step Reasoning](https://arxiv.org/pdf/2301.12726.pdf), This paper addresses the problem of CoT reasoning for smaller models by model specialization. 
- （2）通过代码训练得到的**复杂推理能力**（Complex Reasoning）. 这个能力的奇妙程度相比第一点而言，可以说有过之而无不及。
  - ChatGPT 背后是Text-davinci-002模型，回溯ChatGPT的“模型家谱”，不难发现，Text-davinci-002 模型其实是基于 Code-davinci-002 模型经过指令微调的产物。
  - GPT-3模型复杂推理能力很弱。因为没有接受过代码数据训练
    - GPT-3的一个分支对**代码数据**进行了专项训练，Codex 模型中代码数据量约为 159G，基于此产生的 Code-davinci-002 模型神奇的具备了**思维推理能力**。
  - 不难看出，模型训练过程中，<span style='color:red'>是否引入“代码数据集”很有可能是模型是否具备复杂思维能力的关键变量</span>。

为什么？
- （1）“代码”是一种建立在具备高度**抽象性**和**逻辑性**的思维模式下的“语言”，人类创造了这些语言（C、Python、Java等等），编写了大量代码。现在把这些海量代码喂给大语言模型，模型从对大量代码的学习过程中，逐渐掌握了隐藏在代码背后的**抽象能力**与**逻辑能力**，进而涌现出在ChatGPT上感受到的“智能”。
  - “代码”可以理解为一种具备**高度逻辑性**的文本语料。因为不具备强逻辑性的代码会无法执行，而不像普通文本语料那样有着较高的逻辑自由度。
    - `面向对象编程`（OOP）是把客观世界中的实体抽象为**类**，对象则是类的实例化。对象与对象之间可以互相通信，从而来模拟了现实世界中不同实体之间联系；
    - `面向过程编程`（POP）则是把一个复杂的任务拆分为若干个步骤，然后一步一步加以实现。
- （2）由于代码中含有大量注释信息，<span style='color:blue'>注释信息与代码之间形成了（代码，描述）的数据对，意外的实现了多模态对齐的工作</span>，从而使得模型的推理能力大幅提升。

但是目前已经有大量实证证据表明“涌现能力”真实存在。
- 当模型规模达到某个阈值时，模型对某些问题的处理性能突然呈现快速增长，就像突然解锁了某种特殊能力一般。

最新研究表明，随着模型规模的进一步增长，还可能涌现出各式各样的特殊能力，其中有些能力并不关注（比如5位数加法的准确率大幅提升），但有一些能力则直接解决了NLP领域困扰大家多年的心头大患，比如**复杂推理能力**、**OOD鲁棒性**等。

其实学界每个概念都很直白且容易理解，比如
- OOD鲁棒性: `OOD`指 Out-Of-Distribution，即当**测试**数据集分布显著有别于**训练**数据集分布时，模型性能是否会出现大幅下降。由于现实世界是充满不确定性的，真实环境数据集遵循的分布完全可能发生偏移，因此OOD鲁棒性对于一个语言模型能否投入到真实环境使用而言非常重要。

如此棘手的难题，大语言模型直接通过“涌现能力”意外地解决了。
- 如图所示，GPT-3在OOD情形下显著超过 RoBERTa baseline。

这不禁让我们对未来充满了乐观的预期，随着模型规模的提升，是否会有更多NLP难题自动迎刃而解，“模型规模”难不成就是人类通向AGI（通用人工智能）的钥匙？
- 【2023-2-12】[ChatGPT在投资研究领域的应用初探及原理分析](https://mp.weixin.qq.com/s/lVBrKGthLxjtahYVjnR7jQ)


### Yann LeCun：机器学习不是AGI

【2023-3-24】Yann LeCun， 大型语言模型的意义和理解需要感官基础吗? 剧透: 是的!
- 纽约大学深度学习哲学 [The Philosophy of Deep Learning](https://phildeeplearning.github.io/)
- ppt: “[Do large language models need sensory grounding for meaning and understanding?](https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view?fbclid=IwAR2itiKMdM7LbpRs-YSKtLVFrHQLXKEEmNFAMI4xTY0SvROLJwN4bVKhs7M)”
- 【2023-3-27】评论：[GPT-4的研究路径没有前途？Yann LeCun给自回归判了死刑](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650871958&idx=2&sn=0464339517424e3a18041f265551f9f9), Yann LeCun 延续了一贯的犀利风格，直言不讳地指出「Machine Learning sucks!」「Auto-Regressive Generative Models Suck!」最后话题自然是回到「世界模型」

Machine Learning sucks! (compared to humans and animals)
- `Supervised learning` (SL) requires large numbers of labeled samples.
- `Reinforcement learning` (RL) requires insane amounts of trials.
- `Self-Supervised Learning` (SSL) requires large numbers of unlabeled samples.

Most current ML-based AI systems make stupid mistakes, do not reason nor plan

Animals and humans:
- Can learn new tasks very quickly.
- Understand how the world works
- Can reason and plan

Humans and animals have common sense, current machines, not so much (it’s very superficial).

与人、动物相比，机器学习为什么很差？
- 监督学习需要大量标注样本
- 强化学习需要大量试错样本
- 自监督学习需要大量非标注样本

而当前大部分基于机器学习的AI系统常常出现愚蠢错误，不会推理、规划

动物或人：
- 快速学习新任务
- 理解环境运行逻辑
- 推理、规划

人和动物具备常识，而机器表现得很肤浅

Auto-Regressive Large Language Models (AR-LLMs)
- Outputs one text token after another
- Tokens may represent words or subwords
- Encoder/predictor is a transformer architecture
  - With billions of parameters: typically from 1B to 500B
  - Training data: 1 to 2 trillion tokens
- LLMs for dialog/text generation:
  - BlenderBot, Galactica, LLaMA (FAIR), Alpaca (Stanford), LaMDA/Bard(Google), Chinchilla (DeepMind), ChatGPT (OpenAI), GPT-4 ??...
- Performance is amazing ... but ... they make stupid mistakes
  - Factual errors, logical errors, inconsistency, limited reasoning, toxicity...
- LLMs have no knowledge of the underlying reality
  - They have no common sense & they can’t plan their answer

Three challenges for AI & Machine Learning
1. Learning representations and predictive models of the world
  - Supervised and reinforcement learning require too many samples/trials
  - Self-supervised learning / learning dependencies / to fill in the blanks
    - learning to represent the world in a non task-specific way
    - Learning predictive models for planning and control
2. Learning to reason, like Daniel Kahneman’s “System 2”
  - Beyond feed-forward, System 1 subconscious computation.
  - Making reasoning compatible with learning.
  - Reasoning and planning as energy minimization.
3. Learning to plan complex action sequences
  - Learning hierarchical representations of action plans

当前机器学习研究者面前的有三大挑战：
- 一是学习**世界表征**和**预测模型**；
- 二是学习**推理**（LeCun 提到的 System 2 相关讨论参见 UCL[汪军教授报告](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650866823&idx=3&sn=acab8851959257d96ab50ad8d1e48bcd&chksm=84e4c0f9b39349ef5eadf3343495c1c104cb952ab17d5f8e36826530c40fbebbe8ac2783fd1c&scene=21#wechat_redirect)）；
- 三是学习计划复杂的动作序列。

### 世界模型

#### 双系统：快思考 & 慢思考

人脑思维双系统模型理论（Dual Process Theory）

认知心理学名著《**思考，快与慢**》（Thinking, Fast and Slow）中介绍 `双过程理论`（dual propcess theory）。人类认知过程需要两个密不可分的系统，其中
- System 1 负责**快速直觉式**思考 -- 感性
- System 2 则负责**慢速分析式**思考 -- 理性

人类的认知过程可分为两个相互关联但独立运作的系统：直觉型思维系统（**系统 1**）和反思型思维系统（**系统 2**）
- 直觉型思维（系统 1）是一种**快速、直观且自动**的思考方式，主要依赖于个体的**经验、情感和直觉**。
  - 这种方式对于解决**简单**问题和**日常决策**具有较高的效率，但在面临复杂问题和重大决策时可能导致偏差和错误。
- 反思型思维（系统 2），则是一种**深思熟虑、有意识且理性**的思考方式。该方式通过运用**逻辑推理、规则和分析**，为决策和问题解决提供了更加准确和合理的结果。
  - 然而，这种思维方式需要较多的认知资源和时间。

一些神经科学家包括研究深度学习的科学家提出了 `System 1` 和 `System 2` 的概念, 有`慢思考`（slowthinking）和`快思考`（fastthinking），`慢思考`是比较有**主观**意识的，可以进行规划、推理等。
- System 1 是应激性的、非常快的，同时是没有主观意识的。虽然可以解决一些问题，但无法解决所有问题。

大脑在人进行 System 1、System 2 或无意识、有意识做决策时，是不是用到了同一种机制呢？
- 它在大脑里反映的东西是不是在同一个区域呢？答案是否定的。

人类思维和决策过程并非单一系统所驱动，而是两个系统之间相互作用、互补和竞争的结果。在许多情况下，直觉型思维系统在决策中发挥主导作用；而在需要深入思考和理性判断的场合，反思型思维系统的作用则变得更为重要。

打电话时开车，开车这个动作只激活了大脑的一部分。当要有主观意识时，就变成了**全局性**的，即大脑的所有地方都被激活了。这时用现在的一些手段，比如 EEG、核磁共振大脑切片等，观察大脑哪个地方被激活以及哪个地方没有被激活。可以明显地观察到差别。



#### 什么是世界模型

A Cognitive Architecture capable of reasoning & planning

LeCun 提出了构建「世界」模型的想法，并在一篇题为《A path towards autonomous machine intelligence》的论文中进行了详细阐述
- [原视频链接](https://www.youtube.com/watch?v=DokLw1tILlw)
- [PPT 链接](https://drive.google.com/file/d/1Txb9ykr03Lda-oTLXbnlQsEe46V8mGzi/view)

构建一个能够进行推理和规划的认知架构。这个架构由 6 个独立的模块组成：
- 配置器（Configurator）模块；
- 感知模块（Perception module）；
- 世界模型（World model）；
- 成本模块（Cost module）；
- actor 模块；
- 短期记忆模块（Short-term memory module）。

这些模块的具体信息参考：[图灵奖获得者 Yann LeCun：未来几十年 AI 研究的最大挑战是「预测世界模型」](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650839081&idx=1&sn=f014b639541de68d7a115aa1ad96b33f&chksm=84e55c57b392d54104e20026682164235cc95892c7313c12bc7219ca0010982de9d3afb6a9db&scene=21#wechat_redirect), 文章中包含视频讲解

#### 如何构建世界模型

如何构建、训练世界模型？
- 未来几十年阻碍人工智能发展的真正障碍是为**世界模型**设计架构以及训练范式。
- 训练世界模型是自监督学习（SSL）中的一个典型例子，其基本思想是**模式补全**。对未来输入（或暂时未观察到的输入）的预测是模式补全的一个特例。

世界只能部分地预测。首先，如何表征预测中的不确定性。一个预测模型如何能代表多种预测？

**概率模型**在连续域中是难以实现的，而**生成式模型**必须预测世界的每一个细节。

基于此，LeCun 给出了一种解决方案：`联合嵌入预测架构`（Joint-Embedding Predictive Architecture，JEPA）。
- JEPA 不是生成式的，因为不能轻易地用于从 x 预测 y, 仅捕获 x 和 y 之间的依赖关系，而不显式生成 y 的预测。

生成式架构会预测 y 的所有的细节，包括不相关的；而 JEPA 会预测 y 的抽象表征。

有五种思路是需要「彻底抛弃」的：
- 放弃生成式模型，支持联合嵌入架构；
- 放弃自回归式生成；
- 放弃概率模型，支持能量模型；
- 放弃对比式方法，支持正则化方法；
- 放弃强化学习，支持模型预测控制。

他的建议是，只有在计划不能产生预测结果时才使用 RL，以调整世界模型或 critic。

与能量模型一样，可以使用对比方法训练 JEPA。但是，对比方法在高维空间中效率很低，所以更适合用非对比方法来训练它们。在 JEPA 的情况下，可以通过四个标准来完成，如下图所示：
1. 最大化 $s_x$ 关于 x 的信息量；
2. 最大化 $s_y$ 关于 y 的信息量；
3. 使 $s_y$ 容易从 $s_x$ 中预测；
4. 最小化用于预测潜在变量 z 的信息含量。

迈向自主式 AI 系统的步骤都有哪些？LeCun 也给出了自己的想法：
- 1、自监督学习
  - 学习世界的表征
  - 学习世界的预测模型
- 2、处理预测中的不确定性
  - 联合嵌入的预测架构
  - 能量模型框架
- 3、从观察中学习世界模型
  - 像动物和人类婴儿一样？
- 4、推理和规划
  - 与基于梯度的学习兼容
  - 没有符号，没有逻辑→向量和连续函数

其他的一些猜想包括：
- 预测是智能的本质：学习世界的预测模型是常识的基础
- 几乎所有的东西都是通过自监督学习得来的：低层次的特征、空间、物体、物理学、抽象表征...；几乎没有什么是通过强化、监督或模仿学习的
- 推理 = 模拟 / 预测 + 目标的优化：在计算上比自回归生成更强大。
- H-JEPA 与非对比性训练就是这样的：概率生成模型和对比方法是注定要失败的。
- 内在成本和架构驱动行为并决定学习的内容
- 情感是自主智能的必要条件：批评者或世界模型对结果的预期 + 内在的成本。

LeCun 总结了 AI 研究的当前挑战：（推荐阅读：[思考总结 10 年，图灵奖得主 Yann LeCun 指明下一代 AI 方向：自主机器智能](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650849483&idx=2&sn=8fff61962a8a2eb02cda90cdedadf26d&chksm=84e504b5b3928da3f557ec2c0c2ed7edfb3769d33ccad48ab270479949eaddc44bd56d017309&scene=21#wechat_redirect)）
- 从视频、图像、音频、文本中找到训练基于 H-JEPA 的世界模型的通用方法；
- 设计替代成本以驱动 H-JEPA 学习相关表征（预测只是其中之一）；
- 将 H-JEPA 集成到能够进行规划 / 推理的智能体中；
- 为存在不确定性的推理程序（基于梯度的方法、波束搜索、 MCTS....) 分层规划设计推理程序；
- 尽量减少在模型或批评者不准确的情况下使用 RL（这是不准确的，会导致不可预见的结）；

Position paper:
- [A path towards autonomous machine intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)
- Longer talk: search “LeCun Berkeley” on YouTube

Modular Architecture for Autonomous AI
- `Configurator` 配置器
  - Configures other modules for task
- `Perception` 感知器
  - Estimates state of the world
- `World Model` 世界模型
  - Predicts future world states
- `Cost` 计算不舒适度
  - Compute “discomfort”
- `Actor` 演员
  - Find optimal action sequences
- `Short-Term Memory` 短时记忆
  - Stores state-cost episodes
- ![](https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2022/03/Yann-LeCun-Meta-AI-world-model-architecture.jpeg?w=1392&ssl=1)
- 详见博文：[Meta’s Yann LeCun on his vision for human-level AI](https://bdtechtalks.com/2022/03/07/yann-lecun-ai-self-supervised-learning/)

#### I-JEPA

【2023-6-14】[LeCun世界模型出场！Meta首个“类人”模型，自监督学习众望所归](https://www.toutiao.com/article/7244395665281811005), [META官方](https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa)

LeCun在公开演讲中，再次批评了GPT大模型：<span style='color:red'>根据概率生成自回归的大模型，根本无法破除幻觉难题</span>。甚至直接发出断言：<span style='color:red'>GPT模型活不过5年</span>。

Meta震撼发布了一个「类人」的人工智能模型 I-JEPA，它可以比现有模型更准确地分析和完成缺失的图像。
- 论文地址: [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243)
- 图像联合嵌入预测架构`I-JEPA`模型，是史上第一个基于LeCun世界模型愿景关键部分的AI模型。

自监督学习的通用架构中，系统会学习捕捉不同输入之间的关系。目标是将高能量分配给不兼容的输入，将低能量分配给兼容的输入。

自监督学习的常见架构
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/bcd01573c416423ab32891b8175296c8~noop.image)

这三种架构的区别
- (a) 联合嵌入（不变）架构会学习为兼容的输入x、y输出相似的嵌入，为不兼容的输入输出不相似的嵌入。
- (b) 生成式架构会学习直接从兼容的信号x重建信号y，使用以附加变量z（可能是潜变量）为条件的解码器网络，以促进重建。
- (c) 联合嵌入预测架构学习从兼容信号x中预测信号y的嵌入，使用以附加变量z（可能是潜变量）为条件的预测网络，来促进预测。

划重点：
- I-JEPA 填充缺失片段时，用的就是有关世界的背景知识！而不是像其他模型那样，仅仅通过查看附近的像素。
- I-JEPA就是通过创建外部世界的内部模型来学习。在补全图像的过程中，它比较的是图像的抽象表征，而不是比较像素本身。

在多个计算机视觉任务上，`I-JEPA`都表现出了强大的性能，并且比其他广泛使用的CV模型计算效率高得多

CVPR 2023, 距离提出「世界模型」概念一年多，眼看着LeCun就要实现自己的星辰大海了。训练代码和模型已经开源。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/62697ade45094eee86c9ec90d5f5e185~noop.image)
- 创造出一个机器，学习世界如何运作的内部模型，更快速地学习，为完成复杂任务做出计划，并且随时应对不熟悉的新情况。

> 联合嵌入架构是人工智能的未来，而不是生成式


### 复杂推理

复杂交互式任务（complex interactive tasks）具有很大的挑战性，因为要求 LLM 不仅能理解动态变化的真实场景，还需要具备诸如多种高阶认知和推理能力
- 长期规划（long-horion planning）
- 任务分解（task 的 composition）
- 记忆储存（memorization）
- 常识推理（commonsense reasoning）
- 异常处理（exception handling）。

复杂的交互推理任务，传统智能体训练方法包括
- 1）**强化学习**（Reinforcement Learning）
  - 将交互式推理任务建模为**部分可观察的马尔可夫决策过程**（Partial Observable Markov Decision Process, `POMDP`），智能体通过反复尝试和学习最佳行动策略。常见的方法有 `DRRN`， `KG-A2C`，`CALM` 等。
- 2）**模仿学习**（Imitation Learning）
  - 将交互式推理任务建模为**序列到序列**（Seq2Seq）任务，将过去行动和当前环境观察作为输入，当前的行动作为输出，智能体被训练以模仿人类或专家的行为。Text Decision Transformer 是这个方向的基准方法。
- 3）利用**大型语言模型**（Large Language Model，简称 `LLM`）提示
  - 随着 LLM 的快速发展，尤其是 GPT-4 的出现，将 LLM 应用于复杂的交互式推理任务取得了显著的成果。除了通过传统方法直接让 LLM 根据过往行动和当前环境观察生成行动外，有研究
  - 直接调用 LLM 生成 action 候选池再结合环境重排序（SayCan）
  - 引入虚拟的 "think" 行动来生成子目标以实现更高效的行动（ReAct）
  - 任务失败后利用 LLM 总结原因并生成反思以提高下一次尝试的成功概率（Reflection）等多种方式。
  - ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/97a50ea6333a42b3a1037fe94988736f~noop.image)

虽然传统方法在简单任务中表现优异，但更复杂和具有挑战性的任务中的泛化能力受限
- 无论是基于**强化学习**的方法还是**行为克隆**（Behavior Cloning），在将大目标分解为多个子任务、实现长期记忆和处理环境中的未知异常（比如在导电性测试中找不到可以使用的灯泡）方面都面临诸多挑战。

LLM 提示方法展示出复杂任务中生成合理计划和根据人类反馈进行调整的能力，但同样存在一些问题和局限性。
- 每次预测行动都需要调用 LLM，导致整体推理效率低下且成本较高。
- 此外，ReAct 和 Reflection 两种方法还要针对每种未知任务类型进行适当的子目标人工标注，否则在现实世界情境中的推广可能会比较困难。

如何将 LLM 生成的计划转化为真实?
- SwiftSage：融合模仿学习与大模型规划的全新框架

### SwiftSage

【2023-6-15】[LLM+模仿学习，解决真实世界中的复杂任务：AI2提出SwiftSage](https://www.toutiao.com/article/7244800572787589690/)

AI2 (Allen Institute for AI) 的研究人员提出了 SwiftSage 智能体框架。通过`模仿学习`得到一个小型模型，然后将其与 LLM 进行融合。这样可以利用大量数据对小型模型进行微调，使其具备环境和任务相关的知识，并仅在需要时调用大型模型进行高阶推理。
- [论文链接](https://arxiv.org/abs/2305.17390)
- [项目网站](https://yuchenlin.xyz/swiftsage)

受到人脑思维双系统模型理论（Dual Process Theory）的启发，提出一种全新的结合模仿学习和语言模型（LLM）方法的框架 —— SwiftSage
- 将模仿学习和 LLM 方法的优势相互结合，以解决现实世界中的复杂数字任务，展现出了巨大的潜力和前景。

双模块推理系统：迅速决策的 `Swift` + 深思熟虑的 `Sage`

SwiftSage 是一个由两个主要模块组成的框架：**迅速决策**（Swift）模块和**深思熟虑**（Sage）模块。
- Swift 模块: 基于 encoder-decoder 的小型语言模型，它能编码短期记忆内容，例如先前的动作、当前观察结果、已访问的位置以及当前环境状态，并解码出下一步的行动。
  - 该模块模拟了系统 1 中快速、直观的思维特点。它的优势来自于大量的离线数据，通过在模仿学习中采用 behavior cloning 方法，Swift 模块可以充分了解目标环境中的设定以及更好地掌握任务的定义。
- Sage 模块: 类似系统 2 中深思熟虑的思维过程，利用 LLM（例如 GPT-4）来更好地进行规划。
  - Sage 模块包含两个 LLM Prompting 阶段，分别称为规划（planning）和融合（grounding）

为了协调 Swift 和 Sage 模块，研究者们提出了一种**启发式算法**，用于确定何时激活或停用 Sage 模块以及如何有效地将输出与动作缓存机制相结合。
- 默认情况下，智能体通常会采用 Swift 模块。
- 当 Swift 模块遇到困难时（例如，出现如下图的四种情况），智能体会改为执行 Sage 模块产生的动作缓存。

评测
- 30 个任务上的评估中，SwiftSage 的表现超过了之前的 SayCan、ReAct 和 Relfexion 等方法近 2 倍，并且大幅降低了 LLM 部分的计算成本。
- SwiftSage 在 LLM 推理中所需的每个行动的令牌数量大幅减少，因此在成本效益和效率方面，它比单纯依靠 Prompting LLM 方法表现得更为出色。平均来看，为了产生一个行动，Saycan 和 ReAct 需要近 2000 个 token，Reflexion 需要接近 3000 个 token，而 SwiftSage 仅需约 750 个 token。

## NLP发展

### LLM 时代 NLP何去何从

【2023-6-18】脉脉：[NLP只能做LLM吗](https://maimai.cn/web/gossip_detail/31940198?egid=2a0535dfa08543d590c87f95705396ef&gid=31940198&operation_id=YbqWJ5LswJsiGpT7FylvI&share_channel=2&share_euid=xIzg0vvUrlZY90OoDU4o74eiVcgaIvebMhYHAaiv2szYLE2rY_IWkCIY3llDXJIB)，[小红书地址](https://www.xiaohongshu.com/explore/641d48e0000000000800c757)

总结
- 果断甩掉包袱（过时技术）
- 深刻认知GPT的强大
  - 亲自体验GPT，掌握一手资料
  - 从小模型开始一步步验证
- 思考下一步：有模型、资源后能做什么
- 避开OpenAI正面竞争，寻找共赢，站在巨人肩膀上
  - 不做OpenAI已经做到、懒得做的事情
  - 做OpenAI想做但还没做到的事情
- 尽力争取资源：多卡，哪怕换导师、实验室甚至从学界切换到工业界
- 加强工程能力
  - science 和 engineering 和 product 三合一

<span style='color:blue'>LLM 时代，学术界 Dos and Don'ts</span>

- 不要背**历史包袱**
  - 如果自己的工作被颠覆了，直接扔掉，不用可惜，不要浪费时间续命
  - 旧技术必定被新技术颠覆，这是历史必然
- 不要做 OpenAI **已经做到**的事情，不要做OpenAI 能做只是**懒得做**的事情
  - 否则会被 OpenAI 降维打击
- 深刻地认识 GPT 的强大
  - 对 GPT 的负面批评，很多时候都是错的，这不是大模型的缺点，而是批评者对于大模型认知浅薄所致
  - 自己变成一个熟练的prompt engineer，花个一两周时间天天prompt GPT，这样才知道哪些不行，哪些只是觉得不行但其实它行
- 假设已经有了 GPT-3.5 **基础模型**，假设自己有**1k张卡**，思考能做什么
  - 用小模型（如LLaMA 7B）去验证，如果成功，再慢慢加大到 13B-30B，画出一条上升的曲线
  - 不一定要 scale 到最大的模型，只要自己的结论能够画出一条上升曲线，那么可以外推更大范围
- 做一点 OpenAI **想做但还没做到**的事情
  - 去 prompt GPT，看看哪里做不好，思考怎么做让它更好
- 哪些事情是 OpenAI **很难做到**的事情
  - 面向未来，思考哪些问题即使把现有技术全部拉满，依然做不好，然后去尝试解决这些问题
- **搞卡**
  - 无论如何都要有八卡 A100
  - 如果**导师**不给，可以考虑换导师
  - 如果**实验室**不给，可以考虑换实验室
  - 如果**学术界**怎样都没有，可以考虑换到**工业界**
- 不要再 care 刷 paper，只发最低数量能毕
  - 如果一篇能毕业，发一篇就行，如果三篇毕业，发三篇就行
  - 但是发出来的 paper一定要**保证质量**，尽量做到每篇 paper 质量**单调上升**
  - 不要把时间花在与 reviewer 相互拉扯上面，要把时间花在真正有意义的事情
- 加强**工程能力**，加强工程能力，加强工程能力能
  - 水 paper 但代码写得差的人非常多;
  - 代码写得好的 research 怎样都不会差
- 不要再纠结 science 和 engineering 和 product 的区别
  - 在现代 LLM 的视角下，这几个是**三位一体**


## LLM 问题

斯坦福 CS224N 课程
- ICL中的Zero-Shot Learning（零样本学习）和Few-Shot Learning（少样本学习）
- Instruction Finetuning 指令微调
- RLHF
  - 人工（human-in-the-loop）昂贵 → 建模人类偏好变成独立的NLP问题
  - 人工评判有噪声、错误 → 将集合直接排序问题变成pair-wise（点对）的对比问题，更可信
  - 优点：直接建模人类偏好，易于泛化
  - 问题：人类偏好不可信，据此建立的模型偏好更不可信
    - RL里常见问题是奖励破解（reward hacking）
    - 模型被鼓励输出看似权威、有用但枉顾事实的结果，导致编造事实、出现“幻觉”(hallucination)
    - 因此，模型的错误对齐问题值得研究
  - 改进：
    - RL from AI feedback
    - Finetuning LMs on their own outputs

|技术点|介绍|优点|缺点|
|---|---|---|---|
|ICL小样本学习|ICL中的零样本和少样本|不需要微调，只需提示工程、CoT就能提升效果|① context输入限制 <br>② 复杂任务还是需要梯度更新|
|指令微调|通过指令集进行参数更新|简单直接，容易泛化到新任务|① 众多任务的示例数据收集成本高<br>② LM优化目标与人工偏好错配|
|RLHF|基于人类反馈的强化学习训练|直接建模人类偏好，易于泛化|① 人类偏好不可信，据此建立的模型偏好更不可信<br>② 模型被鼓励输出看似权威、有用但枉顾事实的结果，导致编造事实、出现“幻觉”(hallucination)|
|||||


### 幻觉

#### 什么是幻觉

幻觉分为两类：内在幻觉 和 外在幻觉
- 内在幻觉指生成的输出与源内容**相矛盾**。
- 外在幻觉指生成的输出**无法从源内容中验证**。
  - 很多任务中这种幻觉可能有益，因为是模型从自己知识库里调用了知识，补充了源材料中没有的内容。
  - 但是，对于另一些严格需要根据源材料生成的任务，这样的幻觉就是有害的，而且很难发现。

不管是内在幻觉还是外在幻觉，都有可能是模型根据相似性泛化出来的，有可能是对的，有可能是错的，还有可能根本没办法判断对错。

用大模型做对于幻觉的容忍度比较低的任务时，需要想办法做验证。
- 比如摘要和翻译这样的任务，就需要小心。

#### 为什么会有幻觉？

幻觉原因
- 数据的质量不够好。Garbage in, Garbage out的基本原理对于大模型仍然是适用的。
  - 启发式数据集
  - 重复内容
  - 内在差异
- 训练和推理原因。
  - 不完善的表示学习
  - 错误的解码
  - 曝光偏差
  - 参数化知识偏差

图解
- ![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1e74d965b1254976be5acab3491ba4ef~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)


#### 解决方法

如何缓解幻觉。

从目前业界的效果来看，幻觉问题肯定是**没有被解决掉**的。

但是有一些思路可以缓解幻觉的产生。
- **强化学习**
- 用openai的服务时可以发现，其在服务端还有一个后处理的服务，如果生成了不合适的内容，就会被这个监控服务给处理掉。

总结
- 数据类方法
  - 构建可信数据集
  - 自动清理数据
  - 信息增强
- 模型和推理
  - 架构：编码器、注意力机制、解码器
  - 规划和骨架、强化学习、多任务学习、受控生成
- 后处理

图解
- ![幻觉](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/54d5bc7845964958a561ef120e28962e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

作者：[旭伦](https://juejin.cn/post/7241861929412460600)


### 灾难遗忘

`灾难性遗忘`
- 一个任务上训练出来的模型，如果在一个新任务上进行训练，就会大大降低原任务上的泛化性能，即之前的知识被严重遗忘了。
- 论文 [Attention-Based Selective Plasticity]()
- ![](https://pic1.zhimg.com/80/v2-25443b3a57c5d2178c4480abefe4cd70_1440w.webp)
- `样本遗忘`（example forgetting）是受到灾难性遗忘现象的启发而提出的，即在同一个任务的训练过程中，也可能会有遗忘现象，一个样本可能在训练过程中反复地学了忘，忘了学。
  - 详见：[深度学习中的样本遗忘问题 (ICLR-2019)](https://zhuanlan.zhihu.com/p/462224273)

- ‘灾难性遗忘’指人工智能系统，如深度学习模型，在学习新任务或适应新环境时，忘记或丧失了以前习得的一些能力。”腾讯人工智能实验室副主任俞栋博士说，“灾难性遗忘”会造成人工智能系统在原有任务或环境性能大幅下降。[参考](https://picture.iczhiku.com/weixin/message1587593113355.html)
- 除了传统新知识学习会覆盖旧知识之外，谷歌大脑还发现，在如超级玛丽等探索型游戏里，‘灾难性遗忘’会阻碍模型对新知识的学习。

灾难性遗忘是连接模型（connectionist models，即神经网络）的一个不可避免的特征。

持续学习( lifelong learning/continual learning)：
- 学习连贯的任务而不会忘记如何执行之前训练过的任务的能力。

灾难性遗忘（catastrophic forgetting）：
- 在一个顺序无标注的、可能随机切换的、同种任务可能长时间不复现的 任务序列中，AI对当前任务B进行学习时，对先前任务A的知识会突然地丢失的现象。通常发生在对任务A很重要的神经网络的权重正好满足任务B的目标时。

- 解决了“灾难性遗忘”问题后，模型就能具备持续学习的能力, 可以像人类一样不断获取新的知识、新的技能，同时能够最大化地保持旧的经验知识和技巧。

解决“灾难性遗忘”的方案有哪些？
- 多任务学习（最常见）, 把所有任务的训练数据同时放到一起，模型就可以针对多种任务进行联合优化。
- 根据新的任务知识来扩充模型结构，保证旧的知识经验不被损害。
  - 谷歌大脑所提出的“记忆碎片观察”方法正是对不同任务（场景）构建多个人工智能模型来进行学习。“模型扩充的方式从本质上并没有解决灾难性遗忘的问题，只是用多个模型来替代单个模型去学习多种任务，避免旧参数被覆盖。”
- 特殊神经网络结构
  - [Tree-CNN：一招解决深度学习中的「灾难性遗忘」](https://zhuanlan.zhihu.com/p/36097519), 树卷积神经网络，通过先将物体分为几个大类，然后再将各个大类依次进行划分、识别，就像树一样不断地开枝散叶，最终叶节点得到的类别就是我们所要识别的类。
  - Self-refreshing Memory Approaches：代码见[原文](https://juejin.cn/post/6976045096475033637)
    - self-refreshing memory 自更新的存储器来存储已经学到的知识，并利用该存储的知识来不断“提醒”学习器不要忘记之前的学到的知识，从而达到避免灾难性遗忘的目的
    - 递归网络吸引子：利用不断递归的混响过程来生成虚拟的知识实体（用来提醒学习器，以防止遗忘）
  - 知识蒸馏：2014年Hinton提出来蒸馏神经网络。 更多见[原文](https://juejin.cn/post/6976045096475033637)
    - 蒸馏神经网络的核心依据有两点：1) 训练完成的神经网络包含历史数据的输出分布信息; 2) 神经网络具有相似的输入会得到相似的输出的特点。
    - 蒸馏法通过对共享参数进行微调来实现对新知识的学习。
  - Transfer Techniques： 迁移学习 见[原文](https://juejin.cn/post/6976045096475033637)
    - 如何综合考虑旧参数与新数据得使得参数迁移到大家都满意的值

## LLM 优化方向

【2023-6-16】知乎专题：[大模型LLM领域，有哪些可以作为学术研究方向？](https://www.zhihu.com/question/595298808/answer/3071907155)

- **模型层**：
  - GPT系列，多模态系列，视觉类SAM：原生的工具调用能力；
  - 安全性：加密，可信任，联邦学习；
  - 新模型，新范式：长文本建模，不需要RLHF等；
  - 涌现问题的研究、黑盒的研究；
  - 并行、运算、显存的优化。EL-Attention，ZeRo，剪枝部署，蒸馏压缩。
- **接口层**：
  - 私有化部署；
  - Adapter，prefix，Lora；
  - Fusing。
- **应用层**：
  - Visual ChatGPT，HuggingGPT，AutoGPT，LangChain；
  - Prompt工程，向量库，dense retrieval；
  - 自我纠错，自我迭代，chain of thought的加强；
  - 评测数据集、新时代下的新任务，generatice agents等

假设自己已经有了GPT-3.5基础模型，假设自己有一千张卡，思考能做什么？然后用小的模型，比如LLaMa 7B去验证，如果成功，再慢慢加大到13B，30B，画出一条上升的曲线；不一定要scale到最大的模型，只要自己的结论能划出一条上升的曲线，那么这条曲线就可外推到更大。

源自知乎：[LessTalk](https://www.zhihu.com/question/595298808/answer/3071907155)

- 平台工具及工程化部署
- 小模型拟合大模型降低计算量
- 多模态的输入与输出
- Prompt Engineering
- 垂直领域应用 搜索+知识图谱、机器人、自动驾驶等

提纲
- 基础理论：大模型的基础理论是什么？
- 网络架构：Transformer是终极框架吗？
- 高效计算：如何使大模型更加高效？
- 高效适配：大模型如何适配到下游任务？
- 可控生成：如何实现大模型的可控生成？
- 安全可信：如何改善大模型中的安全伦理问题？
- 认知学习：如何使大模型获得高级认知能力？
- 创新应用：大模型有哪些创新应用？
- 数据评价：如何评估大模型的性能？
- 易用性：如何降低大模型的使用门槛？

作者：[zibuyu9](https://www.zhihu.com/question/595298808/answer/3047369015)

其它
- reasoning 逻辑推理：目前llm能力还不够的地方。比如能不能让llm做leetcode hard。进一步的，能不能自己创造新的知识，解决哥德巴赫猜想。
- compression and acceleration 模型压缩与加速：怎么把一个10b的模型弄到手机上并高速运行
- agent：怎么更好的给llm加上眼睛与手脚，让llm变成agent执行任务，并构造各种各样全新的benchmark。比如让agent发知乎回答以点赞多为目标。能不能通过RL把这件事做了?就和当年搞游戏ai一样。
- multi-modal 多模态：GPT-4没有开源，甚至没有技术细节，怎么做一个开源的逼近gpt-4的模型。mini-gpt4, llava是个不错的尝试。
- Hallucination 幻觉问题：GPT-4已经好了很多，但仍然没有完全解决。所以因此马斯克说要做TruthGPT. 要让LLM知之为知之不知为不知。这个难度其实很大。
- Evaluation。开源世界需要一套新的Evaluation的方法来评估llm的效果，从而方便推进开源llm的进展。
- dataset。这个是chatgpt被创造出来的源头。所以，能否多构建一个专家的数据库来帮助优化llm呢？每一份开源数据都非常有价值。

论文：[A PhD Student’s Perspective on Research in NLP in the Era of Very Large Language Models](https://arxiv.org/pdf/2305.12544.pdf)


### 图解

总结LLM各阶段优化方向

<div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2023-06-22T15:10:12.254Z\&quot; agent=\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\&quot; etag=\&quot;V_7K2ib4bP-NWsyXjMxV\&quot; version=\&quot;21.5.0\&quot;&gt;\n  &lt;diagram id=\&quot;xdYpP7w1t2VaaceZiyqw\&quot; name=\&quot;第 1 页\&quot;&gt;\n    &lt;mxGraphModel dx=\&quot;1242\&quot; dy=\&quot;795\&quot; grid=\&quot;1\&quot; gridSize=\&quot;10\&quot; guides=\&quot;1\&quot; tooltips=\&quot;1\&quot; connect=\&quot;1\&quot; arrows=\&quot;1\&quot; fold=\&quot;1\&quot; page=\&quot;1\&quot; pageScale=\&quot;1\&quot; pageWidth=\&quot;827\&quot; pageHeight=\&quot;1169\&quot; math=\&quot;0\&quot; shadow=\&quot;0\&quot;&gt;\n      &lt;root&gt;\n        &lt;mxCell id=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;1\&quot; parent=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-35\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#f9f7ed;strokeColor=#36393d;dashed=1;dashPattern=1 1;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;90\&quot; y=\&quot;300\&quot; width=\&quot;180\&quot; height=\&quot;360\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;wGYBfAiltT4hGnPjrrAm-8\&quot; value=\&quot;LLM改进方向\&quot; style=\&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=19;rotation=0;strokeWidth=3;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;242\&quot; y=\&quot;70\&quot; width=\&quot;216\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-1\&quot; value=\&quot;数据\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;fontSize=14;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;118\&quot; y=\&quot;180\&quot; width=\&quot;110\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-3\&quot; value=\&quot;训练\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;shadow=1;fontSize=14;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;113\&quot; y=\&quot;570\&quot; width=\&quot;120\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-6\&quot; value=\&quot;\&quot; style=\&quot;endArrow=classic;html=1;rounded=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontSize=13;strokeWidth=2;strokeColor=#808080;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-4\&quot; target=\&quot;zweJf7sKE0CawOek9Q0V-3\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry width=\&quot;50\&quot; height=\&quot;50\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;240\&quot; y=\&quot;275\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;410\&quot; y=\&quot;410\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-15\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;dashed=1;dashPattern=1 1;\&quot; parent=\&quot;1\&quot; source=\&quot;zweJf7sKE0CawOek9Q0V-3\&quot; target=\&quot;zweJf7sKE0CawOek9Q0V-11\&quot; edge=\&quot;1\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;250\&quot; y=\&quot;600\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-11\&quot; value=\&quot;复现\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;590\&quot; y=\&quot;535\&quot; width=\&quot;140\&quot; height=\&quot;120\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-12\&quot; value=\&quot;数据集：收集处理\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; parent=\&quot;zweJf7sKE0CawOek9Q0V-11\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-13\&quot; value=\&quot;三步走流程\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; parent=\&quot;zweJf7sKE0CawOek9Q0V-11\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-14\&quot; value=\&quot;硬件资源开销\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; parent=\&quot;zweJf7sKE0CawOek9Q0V-11\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-22\&quot; value=\&quot;改进&amp;lt;br&amp;gt;① 单词→字符&amp;lt;br&amp;gt;②解决了OOV问题\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;190\&quot; y=\&quot;450\&quot; width=\&quot;120\&quot; height=\&quot;60\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;zweJf7sKE0CawOek9Q0V-42\&quot; value=\&quot;2023-6-22&amp;lt;br&amp;gt;wqw547243068@163.com\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;120\&quot; y=\&quot;1210\&quot; width=\&quot;170\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-2\&quot; value=\&quot;效果\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=none;shadow=1;fontSize=14;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;113\&quot; y=\&quot;910\&quot; width=\&quot;120\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-3\&quot; value=\&quot;\&quot; style=\&quot;endArrow=classic;html=1;rounded=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontSize=13;strokeWidth=2;strokeColor=#808080;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-6\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-2\&quot;&gt;\n          &lt;mxGeometry width=\&quot;50\&quot; height=\&quot;50\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;283\&quot; y=\&quot;500\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;280\&quot; y=\&quot;790\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-5\&quot; value=\&quot;\&quot; style=\&quot;endArrow=classic;html=1;rounded=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontSize=13;strokeWidth=2;strokeColor=#808080;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;zweJf7sKE0CawOek9Q0V-1\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-4\&quot;&gt;\n          &lt;mxGeometry width=\&quot;50\&quot; height=\&quot;50\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;173\&quot; y=\&quot;240\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;173\&quot; y=\&quot;490\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-4\&quot; value=\&quot;模型\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#f8cecc;strokeColor=#b85450;shadow=1;fontSize=14;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;113\&quot; y=\&quot;340\&quot; width=\&quot;120\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-7\&quot; value=\&quot;\&quot; style=\&quot;endArrow=classic;html=1;rounded=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontSize=13;strokeWidth=2;strokeColor=#808080;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;zweJf7sKE0CawOek9Q0V-3\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-6\&quot;&gt;\n          &lt;mxGeometry width=\&quot;50\&quot; height=\&quot;50\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;173\&quot; y=\&quot;620\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;173\&quot; y=\&quot;780\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-6\&quot; value=\&quot;部署\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=none;shadow=1;fontSize=14;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;113\&quot; y=\&quot;740\&quot; width=\&quot;120\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-8\&quot; value=\&quot;问题\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;540\&quot; y=\&quot;860\&quot; width=\&quot;230\&quot; height=\&quot;150\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-37\&quot; value=\&quot;LLM评测\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-8\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;230\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-9\&quot; value=\&quot;知识准确性：幻觉，胡说八道\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-8\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;230\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-10\&quot; value=\&quot;复杂推理能力\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-8\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;230\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-11\&quot; value=\&quot;人类偏好对齐：RLHF不足\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-8\&quot;&gt;\n          &lt;mxGeometry y=\&quot;120\&quot; width=\&quot;230\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-12\&quot; value=\&quot;应用\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=none;shadow=1;fontSize=14;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;113\&quot; y=\&quot;1110\&quot; width=\&quot;120\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-13\&quot; value=\&quot;\&quot; style=\&quot;endArrow=classic;html=1;rounded=0;fontSize=13;strokeWidth=2;strokeColor=#808080;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-2\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-12\&quot;&gt;\n          &lt;mxGeometry width=\&quot;50\&quot; height=\&quot;50\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;167\&quot; y=\&quot;630\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;90\&quot; y=\&quot;750\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-14\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;dashed=1;dashPattern=1 1;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-2\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-8\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;243\&quot; y=\&quot;605\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;460\&quot; y=\&quot;960\&quot; as=\&quot;targetPoint\&quot; /&gt;\n            &lt;Array as=\&quot;points\&quot;&gt;\n              &lt;mxPoint x=\&quot;510\&quot; y=\&quot;935\&quot; /&gt;\n              &lt;mxPoint x=\&quot;510\&quot; y=\&quot;935\&quot; /&gt;\n            &lt;/Array&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-15\&quot; value=\&quot;工程落地\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;360\&quot; y=\&quot;708\&quot; width=\&quot;140\&quot; height=\&quot;180\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-16\&quot; value=\&quot;小型化\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-15\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-17\&quot; value=\&quot;本地部署\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-15\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-18\&quot; value=\&quot;性能：时延、并发\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-15\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-20\&quot; value=\&quot;数据安全\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-15\&quot;&gt;\n          &lt;mxGeometry y=\&quot;120\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-38\&quot; value=\&quot;输入、输出限制\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-15\&quot;&gt;\n          &lt;mxGeometry y=\&quot;150\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-19\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=-0.021;entryY=0.9;entryDx=0;entryDy=0;entryPerimeter=0;dashed=1;dashPattern=1 1;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-6\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-16\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;243\&quot; y=\&quot;605\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;370\&quot; y=\&quot;605\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-21\&quot; value=\&quot;生态系统\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;380\&quot; y=\&quot;1060\&quot; width=\&quot;140\&quot; height=\&quot;150\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxRectangle x=\&quot;550\&quot; y=\&quot;1040\&quot; width=\&quot;90\&quot; height=\&quot;30\&quot; as=\&quot;alternateBounds\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-22\&quot; value=\&quot;联网\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-21\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-23\&quot; value=\&quot;插件市场\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-21\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-24\&quot; value=\&quot;垂类应用\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-21\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-25\&quot; value=\&quot;LLM框架：LangChain\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-21\&quot;&gt;\n          &lt;mxGeometry y=\&quot;120\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-26\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;dashed=1;dashPattern=1 1;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-12\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-23\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;243\&quot; y=\&quot;775\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;367\&quot; y=\&quot;775\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-27\&quot; value=\&quot;数据集\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;560\&quot; y=\&quot;145\&quot; width=\&quot;140\&quot; height=\&quot;120\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-28\&quot; value=\&quot;预训练数据集：中英文\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-27\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-29\&quot; value=\&quot;指令集\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-27\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-30\&quot; value=\&quot;prompt数据集\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-27\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-31\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;dashed=1;dashPattern=1 1;entryX=-0.014;entryY=0.933;entryDx=0;entryDy=0;entryPerimeter=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;zweJf7sKE0CawOek9Q0V-1\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-28\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;243\&quot; y=\&quot;605\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;370\&quot; y=\&quot;605\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-32\&quot; value=\&quot;模型优化\&quot; style=\&quot;swimlane;fontStyle=0;childLayout=stackLayout;horizontal=1;startSize=30;horizontalStack=0;resizeParent=1;resizeParentMax=0;resizeLast=0;collapsible=1;marginBottom=0;whiteSpace=wrap;html=1;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;400\&quot; y=\&quot;305\&quot; width=\&quot;140\&quot; height=\&quot;120\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-33\&quot; value=\&quot;基座大模型：中文\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-32\&quot;&gt;\n          &lt;mxGeometry y=\&quot;30\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-34\&quot; value=\&quot;奖励模型\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-32\&quot;&gt;\n          &lt;mxGeometry y=\&quot;60\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-35\&quot; value=\&quot;RL环节优化\&quot; style=\&quot;text;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;spacingLeft=4;spacingRight=4;overflow=hidden;points=[[0,0.5],[1,0.5]];portConstraint=eastwest;rotatable=0;whiteSpace=wrap;html=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;sLKGas7Howqt66q8ozR_-32\&quot;&gt;\n          &lt;mxGeometry y=\&quot;90\&quot; width=\&quot;140\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;sLKGas7Howqt66q8ozR_-36\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=3;exitX=1;exitY=0.5;exitDx=0;exitDy=0;dashed=1;dashPattern=1 1;entryX=-0.007;entryY=0.067;entryDx=0;entryDy=0;entryPerimeter=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;sLKGas7Howqt66q8ozR_-4\&quot; target=\&quot;sLKGas7Howqt66q8ozR_-34\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;238\&quot; y=\&quot;215\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;408\&quot; y=\&quot;214\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n      &lt;/root&gt;\n    &lt;/mxGraphModel&gt;\n  &lt;/diagram&gt;\n&lt;/mxfile&gt;\n&quot;}"></div>
<script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script>


# 结束