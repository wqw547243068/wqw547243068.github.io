---
layout: post
title:   OpenAI服务及接口
date:   2023-02-18 16:52:00
categories: 人工智能
tags: OpenAI ChatGPT AI 微调 吴恩达 
excerpt: OpenAI提供的各种服务以及API接入信息
mathjax: true
permalink: /openai
---

* content
{:toc}

# OpenAI

## ChatGPT 调用前提

### ChatGPT prompt构成

完整示例

```py
import openai

openai.api_key = "YOUR API KEY HERE"
model_engine = "text-davinci-003"
chatbot_prompt = """
作为一个高级聊天机器人，你的主要目标是尽可能地协助用户。这可能涉及回答问题、提供有用的信息，或根据用户输入完成任务。为了有效地协助用户，重要的是在你的回答中详细和全面。使用例子和证据支持你的观点，并为你的建议或解决方案提供理由。

<conversation history>

User: <user input>
Chatbot:"""


def get_response(conversation_history, user_input):
    prompt = chatbot_prompt.replace(
        "<conversation_history>", conversation_history).replace("<user input>", user_input)
    # Get the response from GPT-3
    response = openai.Completion.create(
        engine=model_engine, prompt=prompt, max_tokens=2048, n=1, stop=None, temperature=0.5)
    # Extract the response from the response object
    response_text = response["choices"][0]["text"]
    chatbot_response = response_text.strip()
    return chatbot_response

def main():
    conversation_history = ""
    while True:
        user_input = input("> ")
        if user_input == "exit":
            break
        chatbot_response = get_response(conversation_history, user_input)
        print(f"Chatbot: {chatbot_response}")
        conversation_history += f"User: {user_input}\nChatbot: {chatbot_response}\n"
main()
```

### GPT-3 API vs ChatGPT Web

两种非官方 `ChatGPT API` 方法

|  方式   | 免费？  | 可靠性  | 质量 |
|  ----  | ----  | ----  | ----  |
| `ChatGPTAPI(GPT-3)`  | 否 | 	可靠 | 较笨 |
| `ChatGPTUnofficialProxyAPI(网页 accessToken)`  | 	是 |  相对不可靠 | 聪明 |

对比：
1. `ChatGPTAPI` 使用 `text-davinci-003` 通过官方`OpenAI`补全`API`模拟`ChatGPT`（最稳健的方法，但它不是免费的，并且没有使用针对聊天进行微调的模型）
2. `ChatGPTUnofficialProxyAPI` 使用非官方代理服务器访问 `ChatGPT` 的后端`API`，绕过`Cloudflare`（使用真实的的`ChatGPT`，非常轻量级，但依赖于第三方服务器，并且有速率限制）

【2023-2-26】[chatgpt-web](https://github.com/Chanzhaoyu/chatgpt-web) 用 Express 和 Vue3 搭建的同时支持 openAI Key 和 网页 accessToken 的 ChatGPT 演示网页


## OpenAI 收费

注意：价格上 OpenAI 最贵的 AIGC 语言模型达芬奇为每 0.02 美元 750 个单词，AIGC 图型模型价格仅为 0.020 美元一张。
- gpt3模型付费API试用版，注册一个账号送18美金，调用费用为每1000字消耗2美分（0.02美元/500汉字，一个汉字两个token），折合下来差不多0.1元250个汉字，这个字数包括问题和返回结果（非汉字时，花费更少）。 $ 1800/250=7.2 $
- ChatGPT单账户18美金免费访问量：1800×250÷30=15000次请求，平均250个汉字消耗0.01美元，用户平均请求长度30个汉字
- ChatGPT用的模型是gpt3.5，目前没公开API

OpenAI收费项目详情 [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/59a6bafac82b499ead7cf55655a38070~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=s8Ln7LiGS46ckzWdFS1nc5%2Big8U%3D)
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/59a6bafac82b499ead7cf55655a38070~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=s8Ln7LiGS46ckzWdFS1nc5%2Big8U%3D)
- 参考[ChatGPT 持续创造历史记录：AIGC，人工智能的旷世之作](https://www.toutiao.com/article/7196594313236251196)


## OpenAI 账户注册

国内无法注册账户，怎么办？
- ① 注册需要国外手机号，没有的话要用虚拟号，验证码1.2元/条，[详见](https://www.cnblogs.com/ranxi169/p/16954797.html)
- ② 嫌麻烦的话，淘宝上搜，有人提供注册服务，大概18元，[账号售卖](http://idea-activate.icu/ChatGPT/index.html)
- ③ 有人部署了 ChatGPT微信群

### 前置条件

前提条件：
- 1、一个邮箱账号 
  - 非163，OpenAI会提示无法注册
- 2、能够科学上网，具备代理网络的环境。
- 3、国外手机号，用于接收注册验证码。
  - 如果没有，通过第三方接码平台来注册国外手机号，支付宝要有 1.5 元人民币。
  - gv（google voice虚拟号）不行
  - 接码平台推荐：[sms-activate](https://sms-activate.org/getNumber)

注册短信平台并充值
- 先注册在线接受短信的虚拟号码 - SMS-Activate，注册好之后进行对应的充值


【2023-1-30】[一文教你快速注册OpenAI（ChatGPT），国内也可以](https://cloud.tencent.com/developer/article/2190154)

接码平台 
- 注册平台账户，俄罗斯的网站[sms-activate](https://sms-activate.org/en#)，可以提供全球各地的电话号码，用来做短信验证
- 充值：国内可以用支付宝充值，比如 0.2美元，对应1.43元，14卢比
- 左侧选择应用（OpenAI）、国家（推荐印度）
- 购买，大约10卢比
- 虚拟号生成，如：917079589203
  - 注意：虚拟号20min内有效

【2023-2-2】接码平台故障，无法登陆，改用别的
- 免费接码平台，[接号码](https://jiemahao.com/sms)，[smsonline](https://www.smsonline.cloud/zh/)，号码公开，基本都被人用过，OpenAI对每个手机号关联数目有限制，超限就报错：<span style='color:red'>This phone number is already linked to the maximum number of accounts.</span>
- 直接提供号码及验证码：[sms24](https://sms24.info/en/messages/OpenAI)，找了一堆，终于遇到一个捷克可用号码[420605118029](https://sms24.info/en/numbers/420605118029)，然而，迟迟收不到短信

【2023-5-2】虚拟号被OpenAI禁掉
> Your account was flagged for potential abuse. If you feel this is an error, please contact us at help.openai.com

[img](https://files.evlit.com/wp-content/uploads/2023/04/e735c2e2f0eda0a7eddc67a21cbebea6.jpeg)
- ![](https://files.evlit.com/wp-content/uploads/2023/04/e735c2e2f0eda0a7eddc67a21cbebea6.jpeg)

### 精简流程

注册OpenAI账户
- [OpenAI注册页面](https://beta.OpenAI.com/signup)，错误信息及对应解法
  - Signup is currently unavailable, please try again later. 某些国家限制，需要开全局代理
  - Too many signups from the same IP 同一个ip注册限制
- 邮箱认证：输入邮箱账户，一般用gmail，平台发送邮件
  - 注意别用163邮箱（提示不可用), qq邮箱可以
  - 使用vpn切到国外（香港不行），否则：<span style='color:red'>OpenAI's API is not available in your country</span>
  - [img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc290c2a7abf4c9faee9a392819d16e4~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?)
- 手机认证：打开邮件，启动手机认证
  - [接码平台](https://sms-activate.org/cn/getNumber)充值（卢比），选择国家（如印度），输入申请的虚拟号
  - 输入国外虚拟号，等待几分钟，[接码平台](https://sms-activate.org/cn/getNumber)会显示激活码（如705139）
- 填入激活码后，注册成功
- 登录[OpenAI](https://chat.OpenAI.com/auth/login)

## OpenAI API调用

官方 API 覆盖：Text completion 、Code completion、Chat completion、Image completion、Fine-tuning、Embedding、Speech to text、Moderation
- [Chat completion](https://platform.openai.com/docs/guides/chat/introduction)
- 【2023-3-2】刚发布没一会儿，api被禁，出现443错误，gpt-3.5-turbo刚被禁了，GPT-3的api也连累了
- 提交到[OpenAI社区](https://community.openai.com/t/443-error-for-both-text-davinc-003-and-gpt-3-5-turbo/82194)
- OpenAI提供的[应用示例集合](https://beta.OpenAI.com/examples)

### Embedding

官方[Embedding model](https://openai.com/blog/new-and-improved-embedding-model)
- Embeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts.
- The new model, `text-embedding-ada-002`, replaces five separate models for `text search`, `text similarity`, and `code search`, and outperforms our previous most capable model, `Davinci`, at most tasks, while being priced 99.8% lower.
- ![](https://cdn.openai.com/new-and-improved-embedding-model/draft-20221214a/vectors-2.svg)

#### curl调用

```sh
OPENAI_API_KEY="sk-******"
curl https://api.openai.com/v1/embeddings \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "Your text string goes here",
    "model": "text-embedding-ada-002"
  }'
```

返回格式：
- 1536 维

```json
{
  "data": [
    {
      "embedding": [
        0.002092766109853983,
        ...
        0.0026526579167693853
      ],
      "index": 0,
      "object": "embedding"
    }
  ],
  "model": "text-embedding-ada-002-v2",
  "object": "list",
  "usage": {
    "prompt_tokens": 12,
    "total_tokens": 12
  }
}
```

#### python调用

限速
- requests per min. Limit: 60 / min

```py
import openai

response = openai.Embedding.create(
  input="porcine pals say",
  model="text-embedding-ada-002"
)
# 限速, 每次请求后休息1s
import time
time.sleep(1)

```

改进版

```py
import openai

openai.api_key = "sk-***"

def emb(text):
    """
        embedding
    """
    res = {"code":0, "msg":"-", "data":{}}
    if not text:
        #print(f"输入为空!{text}")
        res.update({'code':-1, 'msg':'输入为空'})
        return res
    # 调用 api    
    response = openai.Embedding.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response['data'][0]['embedding']

def chat(text, model_name='gpt-3.5-turbo'):
    """
        openai chat 调用
    """
    res = {"code":0, "msg":"-", "data":{}}
    if not text:
        #print(f"输入为空!{text}")
        res.update({'code':-1, 'msg':'输入为空'})
        return res
    # 调用 chatgpt    
    completion = openai.ChatCompletion.create(
      #model="gpt-4", 
      #model="gpt-3.5-turbo", 
      model=model_name,
      max_tokens=100,
      temperature=1.2,
      messages=[{
          "role": "user", #  role (either “system”, “user”, or “assistant”) 
          "content": text}]
    )
    res['data']['role'] = completion['choices'][0]['message']['role']
    res['data']['content'] =  completion['choices'][0]['message']['content']
    return f"[{res['data']['role']}] {res['data']['content']}"
    #print(completion)

if __name__ == '__main__':
    test = "你好,你支持哪些插件"
    res = chat(test)
    print(res)
    res = emb(test)
    print(len(res))
```

#### go 调用

[go-openai](https://github.com/sashabaranov/go-openai)

```go
// go get github.com/sashabaranov/go-openai

package main

import (
	"context"
	"fmt"
	openai "github.com/sashabaranov/go-openai"
)

func main() {
	client := openai.NewClient("your token")
	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT3Dot5Turbo,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: "Hello!",
				},
			},
		},
	)

	if err != nil {
		fmt.Printf("ChatCompletion error: %v\n", err)
		return
	}

	fmt.Println(resp.Choices[0].Message.Content)
}
```

### ChatGPT 调用

API有两种方案
- 使用ChatGPT：浏览器调试，获取access_token，模拟登录后调用
- 使用gpt 3 官方api
- ChatGPT api：GPT-3.5

内测过程中调用是免费的，没有次数限制。此外，API接口调用不需要梯子或代理（使用代理反而可能会报错“Error communicating with OpenAI”），只需要API Key就可以了，且当前API Key使用免费。

现有大多数 ChatGPT API 实际上是 OpenAI `GPT3` 模型接口，模型名称为“`text-davinci-003`”，

安装使用

```sh
pip install OpenAI # 安装OpenAI
pip show OpenAI # 查看版本 Version: 0.8.0
pip install -U OpenAI # 更新，解决问题：module 'OpenAI' has no attribute 'Image'，python 3.8以上才行
```

### GPT-3接口（Completion）

Completion 接口

```py
import os
import OpenAI
print("欢迎使用ChatGPT智能问答，请在Q:后面输入你的问题，输入quit退出！")
OpenAI.api_key = "<OpenAI_key>"  # 填上你自己的API,或者把API加入系统的环境变量。
start_sequence = "\nA:"
restart_sequence = "\nQ: "
while True:
    prompt = input(restart_sequence)
    if prompt == 'quit':
        break
    else:
        try:
            response = OpenAI.Completion.create(
              model="text-davinci-003", # 使用davinci-003的模型，准确度更高。
              prompt = prompt,
              temperature=1,
              max_tokens=2000, # 限制回答长度，可以限制字数，如:写一个300字作文等。
              frequency_penalty=0,
              presence_penalty=0
            )
            print(start_sequence,response["choices"][0]["text"].strip())
        except Exception as exc: #捕获异常后打印出来
            print(exc)
```

或

```python
import os
import OpenAI

OpenAI.api_key = os.getenv("OpenAI_API_KEY")
# ------- 文本生成 ---------
prompt = """We’re releasing an API for accessing new AI models developed by OpenAI. Unlike most AI systems which are designed for one use-case, the API today provides a general-purpose “text in, text out” interface, allowing users to try it on virtually any English language task. You can now request access in order to integrate the API into your product, develop an entirely new application, or help us explore the strengths and limits of this technology."""

response = OpenAI.Completion.create(model="davinci", prompt=prompt, stop="\n", temperature=0.9, max_tokens=100)

# ------- 其它应用 ---------
response = OpenAI.Completion.create(
  engine="davinci",
  prompt="The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n\nHuman: Hello, who are you?\nAI: I am an AI created by OpenAI. How can I help you today?\nHuman: I'd like to cancel my subscription.\nAI:",
  temperature=0.9,
  max_tokens=150,
  top_p=1,
  frequency_penalty=0.0,
  presence_penalty=0.6,
  stop=["\n", " Human:", " AI:"]
)

print(response)
```

requests调ChatGPT
- 用requests实现的调用接口

```py
import requests,json
api_key="<OpenAI_key>" # 设置自己的API密匙
prompt = "" # 设置prompt初始值
# 设置headers
headers = {"Authorization":f"Bearer {api_key}"}
# 设置GPT-3的网址
api_url = "https://api.OpenAI.com/v1/completions"
#设置循环可以持续发问
while prompt != 'quit':
    prompt = input("Q: ")
    #设置请求参数
    data = {'prompt':prompt,
            "model":"text-davinci-003",
            'max_tokens':128,
            'temperature':1,
            }
    #发送HTTP POST请求
    response = requests.post(api_url,json = data,headers = headers)
    #解析响应
    resp = response.json()
    print("A:",resp["choices"][0]["text"].strip(),end="\n")
```

### ChatGPT（GPT 3.5）接口

【2023-3-2】OpenAI 提供 ChatGPT API（`gpt-3.5-turbo`），单次调用费用是 `text-davinc-003` 的 1/10

API_KEY 不要明文写代码里调用，会被OpenAI封禁
- [Your access was terminated due to violation of our policies](https://community.openai.com/t/your-access-was-terminated-due-to-violation-of-our-policies/88080)


### 代码调用

#### shell 版本

```sh
OPENAI_API_KEY="sk-***"
# 腾讯云函数
# curl https://service-4jhtjgo0-1317196971.hk.apigw.tencentcs.com/release \
curl https://api.openai.com/v1/chat/completions \
 -H "Authorization: Bearer $OPENAI_API_KEY" -H "Content-Type: application/json" \
 -d '{ "model": "gpt-3.5-turbo", "messages": [{"role": "user", "content": "What is the OpenAI mission?"}] }'
 ```

#### python 版本

```py
import openai

openai.api_key = 'sk-***'
completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo", 
  messages=[{
      "role": "user", #  role (either “system”, “user”, or “assistant”) 
      "content": "你好,写一段围棋代码,用Go语言"}]
)
print(completion['choices'][0]['message']['role'], completion['choices'][0]['message']['content'])
print(completion)
```

### 网页调用

#### web demo

Gradio web demo
- DEMO [examples](https://gradio.app/demos/) 

```py
import gradio as gr
import openai

openai.api_key = "sk-**"

def question_answer(role, question):
    if not question:
        return "输入为空..."
    completion = openai.ChatCompletion.create(
      model="gpt-3.5-turbo", 
      messages=[{
          "role": "user", #  role (either “system”, “user”, or “assistant”) 
          "content": question}
      ]
    )
    # 返回信息
    return (completion['choices'][0]['message']['role'], completion['choices'][0]['message']['content'])

gr.Interface(fn=question_answer, 
    # inputs=["text"], outputs=['text', "textbox"], # 简易用法
    inputs=[gr.components.Dropdown(label="Role", placeholder="user", choices=['system', 'user', 'assistant']),
        gr.inputs.Textbox(lines=5, label="Input Text", placeholder="问题/提示语(prompt)...")
    ],
    outputs=[gr.outputs.Textbox(label="Role"), gr.outputs.Textbox(label="Generated Text")],
    # ["highlight", "json", "html"], # 定制返回结果格式，3种输出分别用3种形式展示
    examples=[['你是谁？'], ['帮我算个数，六乘5是多少']],
    cache_examples=True, # 缓存历史案例
    title="ChatGPT Demo",
    description="A simplified version of DEMO [examples](https://gradio.app/demos/) "
).launch(share=True) # 启动 临时分享模式
#).launch() # 仅本地访问
```

#### ChatGPT 网页版

原方案：
- 从 [ChatGPT页面](https://chat.OpenAI.com/chat) 获取 session_token，使用 [revChatGPT](https://github.com/acheong08/ChatGPT) 直接访问web接口
- 但随着 ChatGPT 接入 Cloudflare 人机验证，这一方案难以在服务器顺利运行。

登陆 [OpenAI官网](http://chat.OpenAI.com/chat), 然后通过按下F12，进到调试模式，找到session_token

通过access_token来访问ChatGPT

```py
from asyncChatGPT.asyncChatGPT import Chatbot
import asyncio
config = {
  "Authorization":"eyJhbGciOiJSUzI1NiIs....85w"
}
chatbot = Chatbot(config, conversation_id=None)
while 1 == 1:
    text = input('Q:')
    if text == 'quit':
        break
    else:
        message = asyncio.run(chatbot.get_chat_response(text))['message']
        print('A:',message)
```

通过session_token来访问ChatGPT

```py
from revChatGPT.revChatGPT import Chatbot
config = {
    "email": "<YOUR_EMAIL>",
    "password": "<YOUR_PASSWORD>",
    "session_token": "eyJhbGciOiJkaXIiLCJl....7Q"
}
chatbot = Chatbot(config, conversation_id=None)
while 1==1:
    text = input("Q:")
    if text == 'quit':
        break
    else:
        response = chatbot.get_chat_response(text, output="text")
        print('A:',response['message'])
```

python flask 搭建 web 服务
- 安装组件：flask、flask-cors、gunicorn
- 服务端代码：callOpenAI.py文件
- 启动服务：python callOpenAI.py，然后通过浏览器访问：http://xx.xx.xx.xx:xxxx/callChatGPT?input=what is your name来进行开发调测
  - ![img](https://pic4.zhimg.com/80/v2-6d8158ddb8194f92cea951004a9bec2b_1440w.webp)
- 创建 wsgi.py，供gunicorn使用
- 创建 gunicorn.conf 文件
- 启动 gunicorn，正式投产调用接口

python组件
- （1）因为打算用python的flask进行快速的服务端调用，安装flask ： pip install flask
- （2）为解决跨域问题安装 flask cros： pip install flask-cors
- （3）安装专门针对flask的web服务进程gunicron：pip install gunicorn


```py
from flask import Flask,request
from flask_cors import CORS
import os
import openai
app = Flask(__name__)
CORS(app,supports_credentials=True)

@app.route('/',methods=['GET','POST'])
def hello_world():
	text=request.args.get('text')
	return text

@app.route('/callChatGPT',methods=['GET','POST'])
def callChatGPT():
	input = request.args.get('input')
	openai.api_key = "xxxxxxxx"
	#openai.api_key = os.getenv("OPENAI_API_KEY")
	response =  openai.Completion.create(model="text-davinci-003",prompt=input,temperature=0.5,max_tokens=500)
	return response.choices[0].text

if __name__ == "__main__":
	app.run(host='xx.xx.xx.xx',port=xxxx,debug=True)
```

wsgi.py

```py
from callOpenAI import app

if __name__ == "__main__":
	app.run()
```

同一目录下创建gunicorn.conf文件，内容如下：

```json
bind = "xx.xx.xx.xx:xxxx"
workers = 10
errorlog = "/var/www/chatGPT/gunicorn.error.log"
loglevel = "debug"
proc_name = "callChatGPT"
```

执行如下命令，即可以正式投产调用接口。

```sh
gunicorn --config gunicorn.conf wsgi:app
```

前端调用的时候，直接使用ajax可能会出现跨域调用问题，先要如前所示安装flask-cors，然后在代码中进行配置即可解决

```html
<html>
<head>  
<meta charset="utf-8" />
<title>chatGPT-AI问答系统</title>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<style>
    .question-container {
        padding: 10px;
    }
    .questions {
        padding: 10px;
    }
    .answers {
        padding: 10px;
    }
</style>
</head>
 <body>
    <div class="question-container">
        <h2>安联资管-chatGPT-AI问答系统</h2>
        <form>
            <div class="questions">
                <label>Questions:</label>
                <input type="text" id="question" name="提问" placeholder="在这里提问..."/>
            </div>
            <div class="answers">
                <label>Answers:</label>
                <textarea name="回答" disabled placeholder ="答案将展示在这里..." ></textarea>
            </div>
            <input type="submit" value="提交"/>
        </form>
    </div>
 <script>
    $(document).ready(function(){
         // Submit button click event
        $('form').on('submit', function(event){
            event.preventDefault();
             // Send the data to flask
            $.ajax({
              url: 'http://xx.xx.xx.xx:xxxx/callChatGPT',  // enter your flask endpoint here
              type: "GET",
              data: "input="+$('#question').val(),
              dataType: 'text',
              success: function(response) {
                console.log(JSON.stringify(response))
                  // check response and update answer box
                  if (response) {
                      alert("success");
                      $('.answers textarea').val(response);
                  } else {
                      alert("没有找到答案，请重新提问.");
                  }
              },
              error: function(xhr) {
                alert("异常: " + xhr.status + " " + xhr.statusText);
              }
            });
        });
    });
</script>
 </body>
</html>
```

注意，因服务端接口callChatGPT返回的是response.choices[0].text，是文本类型，因此前端的传入参数dataType要是text，response直接当成文本使用就可以了，不用再去解析，否则会报错。
- ![img](https://pic4.zhimg.com/80/v2-0fcd68bed5af325128cf3f67b5246643_1440w.webp)

参考：[手把手教你搭建基于chatGPT的智能机器人](https://zhuanlan.zhihu.com/p/604285542)

#### js+html

网页形式调用

```html
<html>
<script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
<script src="https://unpkg.com/axios/dist/axios.min.js"></script>
<head>
    <title> ChatGPT Demo </title>
</head>

<body>
<div id="app" style="display: flex;flex-flow: column;margin: 20 ">
    <scroll-view scroll-with-animation scroll-y="true" style="width: 100%;">
        <!-- 用来获取消息体高度 -->
        <view id="okk" scroll-with-animation>
            <!-- 消息 -->
            <view v-for="(x,i) in msgList" :key="i">
                <!-- 用户消息 头像可选加入-->
                <view v-if="x.my" style="display: flex;
                flex-direction: column;
                align-items: flex-end;">
                    <view style="width: 400rpx;">
                        <view style="border-radius: 35rpx;">
                            <text style="word-break: break-all;">{{x.msg}}</text>
                        </view>
                    </view>
                </view>
                <!-- 机器人消息 -->
                <view v-if="!x.my" style="display: flex;
                flex-direction: row;
                align-items: flex-start;">

                    <view style="width: 500rpx;">
                        <view style="border-radius: 35rpx;background-color: #f9f9f9;">
                            <text style="word-break: break-all;">{{x.msg}}</text>
                        </view>
                    </view>
                </view>
            </view>
            <view style="height: 130rpx;">
            </view>
        </view>
    </scroll-view>
    <!-- 底部导航栏 -->
    <view style="position: fixed;bottom:0px;width: 100%;display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;">
        <view style="font-size: 55rpx;display: flex;
        flex-direction: row;
        justify-content: space-around;
        align-items: center;width: 75%;
    margin: 20;">
            <input v-model="msg" type="text" style="width: 75%;
            height: 45px;
            border-radius: 50px;
            padding-left: 20px;
            margin-left: 10px;background-color: #f0f0f0;" @confirm="sendMsg" confirm-type="search"
                placeholder-class="my-neirong-sm" placeholder="用一句简短的话描述您的问题" />
            <button @click="sendMsg" :disabled="msgLoad" style="height: 45px;
            width: 20%;;
    color: #030303;    border-radius: 2500px;">{{sentext}}</button>
        </view>
    </view>
    </view>
</div>
</body>
</html>
<script>
    const { createApp } = Vue
    createApp({
        data() {
            return {
                //api: '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',
                api: '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',
                msgLoad: false,
                anData: {},
                sentext: '发送',

                animationData: {},
                showTow: false,
                msgList: [{
                    my: false,
                    msg: "你好我是OpenAI机器人,请问有什么问题可以帮助您?"
                }],
                msgContent: "",
                msg: ""
            }
        },
        methods: {
            sendMsg() {
                // 消息为空不做任何操作
                if (this.msg == "") {
                    return 0;
                }
                this.sentext = '请求中'
                this.msgList.push({
                    "msg": this.msg,
                    "my": true
                })
                console.log(this.msg);
                this.msgContent += ('YOU:' + this.msg + "\n")
                this.msgLoad = true
                // 清除消息
                this.msg = ""
                axios.post('https://api.OpenAI.com/v1/completions', {
                    prompt: this.msgContent, max_tokens: 2048, model: "text-davinci-003"
                }, {
                    headers: { 'content-type': 'application/json', 'Authorization': 'Bearer ' + this.api }
                }).then(res => {
                    console.log(res);
                    //let text = res.data.choices[0].text.replace("OpenAI:", "").replace("OpenAI：", "").replace(/^\n|\n$/g, "")
                    //let text = res.data.choices[0].text.replace(/^\n|\n$/g, "");
                    let text = res.data.choices[0].text.replace("\n", "<br>").replace(" ", "&nbsp;");
                    console.log(text);
                    this.msgList.push({
                        "msg": text,
                        "my": false
                    })
                    this.msgContent += (text + "\n")
                    this.msgLoad = false
                    this.sentext = '发送'
                })
            },
        }
    }).mount('#app')
</script>
```

### 手机app

【2023-2-11】[CCTV视频](https://www.toutiao.com/video/7198541558600499770/)里，台湾人在演示 [VoiceGPT](https://voicegpt.net/)，[VoiceGPT APK Download (version 1.35) 下载地址](https://voicegpt.net/voicegpt_135.apk) , 目前就安卓版，使用时需要代理
- 资讯：[ChatGPT Meets Voice: Say goodbye to typing and Hello to VoiceGPT](https://medium.com/@hokyjack/chatgpt-meets-voice-say-goodbye-to-typing-and-hello-to-voicegpt-45e90bb2aebf)

用kivy来编写手机界面版的ChatGPT
- kivy编写了一款在手机端访问的软件，目前软件的打包存在问题，只能在电脑端访问。
- 在Google的colab打包，但是打包后在安卓手机上安装成功，但是打开后就闪退，原因暂不明。
- ![img](https://pic4.zhimg.com/80/v2-024fe7e10fccbc1527e29bf01d1602f7_1440w.webp)

安装以下包：

```sh
python -m pip install docutils pygments pypiwin32 kivy.deps.sdl2 kivy.deps.glew
python -m pip install kivy.deps.gstreamer
python -m pip install kivy
python -m pip install kivy_examples
# 速度慢时，切换源
python -m pip install kivy -i https://pypi.tuna.tsinghua.edu.cn/simple
```

代码

```py
from kivy.app import App
from kivy.core.window import Window
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.textinput import TextInput
from kivy.uix.button import Button
import OpenAI
import pyperclip
class Application(BoxLayout):

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.orientation = "vertical"
        self.spacing = 5
        self.padding = 5
        self.create_widgets()
        Window.bind(on_request_close=self.end_func) # 窗口关联函数，更容易关闭
        OpenAI.api_key = "<OpenAI_key>" # 这里要替换成自己的api
    def end_func(self,*args):
        Window.close() 
    def create_widgets(self):
        # 显示文本框
        self.txinfo = TextInput(font_name='SIMSUN.TTC',font_size=18)
        self.txinfo.text = "欢迎使用OpenAI. 作者:Gordon QQ/VX 403096966 Esc可以退出程序。"
        # self.txinfocontainer = BoxLayout(orientation="vertical", size_hint_y=None)
        self.add_widget(self.txinfo)
    
        # 定义输入框
        self.entry = TextInput(font_name='SIMSUN.TTC',font_size=18)
        self.add_widget(self.entry)

        # 定义按钮
        self.btn = Button(text="发送请求", font_name ="SIMSUN.TTC",bold = True,font_size=20, on_release=self.button_func)
        self.add_widget(self.btn)
        self.btcopy = Button(text="复制回答", font_name ="SIMSUN.TTC",bold = True,font_size=20, on_release=self.button_copy)
        self.add_widget(self.btcopy)

    def button_copy(self, instance):
        pyperclip.copy(self.txinfo.text)

    def button_func(self, instance):
        prompt = self.entry.text
        if prompt !="":
            model_engine = "text-davinci-003"
            completions = OpenAI.Completion.create(
                engine=model_engine,
                prompt=prompt,
                max_tokens=1024,
                temperature=1,
            )
            message = completions.choices[0].text
            self.txinfo.insert_text("\n\nQ: "+prompt+"\nA: "+message.strip())
        self.entry.text = ''
class OpenAI(App):
    def build(self):
        return Application()

if __name__ == '__main__':
    OpenAI().run()
```


### 大模型微调


【2023-5-2】[OpenAI ChatGPT API 文档之 Fine-tuning（微调）](https://zhuanlan.zhihu.com/p/626140269)

GPT-3 开放互联网的大量文本上进行了预训练。当给出仅包含几个示例的提示，直观判断尝试执行的任务并生成看似合理的补全（completion），这通常称为“小样本学习（few-shot learning）”。

`微调`（Fine-tuning）通过训练超出提示范围的更多示例来改进小样本学习，在大量任务上取得更好的结果。模型经过微调后，不再需要在提示中提供示例。这可以节省成本并实现更低延迟的请求。
- [收费](https://openai.com/pricing)

微调可让更好地利用 API 提供的模型：
- 比设计提示（prompt）质量更高的结果
- 能够训练更多不适合提示的示例
- 由于提示较短而节省 token
- 更低的延迟请求

微调涉及以下步骤：
- 准备并上传训练数据
- 训练一个新微调模型
- 使用微调模型


#### 微调教程

【2023-8-25】吴恩达《微调大型语言模型》[Finetuning Large Language Models（中英字幕）](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
1. Learn the fundamentals of finetuning a large language model (LLM).
1. Understand how finetuning differs from prompt engineering, and when to use both.
1. Get practical experience with real data sets, and how to use techniques for your own projects.

内容
- 何时在LLM上应用细调
- 如何准备微调数据
- 如何训练和评估LLM
- 通过细调，使用自己的数据对模型进行训练，并更新LLM中的神经网络权重，从而改变模型与提示工程和检索增强生成等其他方法的差异。细调可以使模型学习风格、形式，并通过更新模型以获取新知识来改善结果。

<iframe src="//player.bilibili.com/player.html?aid=575237949&bvid=BV1Rz4y1T7wz&cid=1246800686&page=2&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>





#### 自定义api

【2023-9-1】可以针对openai工具包，设置 base_url，提升可控性
- 切换成内部服务 —— 突破访问限制
- 自定义 api key
- 调用方法同OpenAI，前提是 内部服务地址要按[OpenAI](https://platform.openai.com/docs/api-reference/introduction%EF%BC%89)规范实现接口

```sh
import openai
# http://10.154.44.82:9490/v1
openai.api_base = 'http://.....'
openai.api_key = "---"
```

案例
- 微软 azure cloud提供OpenAI服务
- 第三方代理，如：
  - 优质稳定的OpenAI的API接口-[xiaoyi-robot](https://github.com/xing61/xiaoyi-robot)

OpenAI 工具包

```py
import openai

openai.api_key = "sk-..."
openai.organization = "..."

# api 示例
completion = openai.Completion.create(
    prompt="<prompt>",
    model="text-davinci-003"
)
  
chat_completion = openai.ChatCompletion.create(
    messages="<messages>",
    model="gpt-4"
)

embedding = openai.Embedding.create(
  input="<input>",
  model="text-embedding-ada-002"
)
# batch 输入
inputs = ["A", "B", "C"] 

embedding = openai.Embedding.create(
  input=inputs,
  model="text-embedding-ada-002"
)
```

微软 Azure OpenAI 实现
- [How to switch between OpenAI and Azure OpenAI endpoints with Python](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints)
- 使用 deployment_id/engine 替代 model 参数

```py
import openai

openai.api_type = "azure"
openai.api_key = "..."
openai.api_base = "https://example-endpoint.openai.azure.com"
openai.api_version = "2023-05-15"  # subject to change

# api 调用
# 使用 deployment_id/engine 替代 model 参数
completion = openai.Completion.create(
    prompt="<prompt>",
    deployment_id="text-davinci-003"
    #engine="text-davinci-003" 
)
  
chat_completion = openai.ChatCompletion.create(
    messages="<messages>",
    deployment_id="gpt-4"
    #engine="gpt-4"

)

embedding = openai.Embedding.create(
  input="<input>",
  deployment_id="text-embedding-ada-002"
  #engine="text-embedding-ada-002"
)
# batch 输入
inputs = ["A", "B", "C"] #max array size=16

embedding = openai.Embedding.create(
  input=inputs,
  deployment_id="text-embedding-ada-002"
  #engine="text-embedding-ada-002"
)
```





#### GPT-3.5 Turbo 微调


【2023-8-23】[OpenAI 开放 GPT-3.5 Turbo 微调，网友：将 prompt 减少 90% 才实惠 ](https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz)
- 8月22日，OpenAI [宣布](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)企业现在可以使用自己的数据对 `GPT-3.5 Turbo` 进行**微调**，在原[Fine-tunes](https://platform.openai.com/docs/guides/fine-tuning)的基础上推出 Fine-tuning. OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。
- [fine-tuning api](https://platform.openai.com/docs/api-reference/fine-tuning), [forum](https://community.openai.com/t/gpt-3-5-turbo-fine-tuning-now-available-and-new-gpt3-models/327425)
- <span style='color:red'>传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型</span>。
- 今年秋天 OpenAI 将开放更先进的 GPT-4。



With this launch, developers can now run **supervised fine-tuning** to make this model perform better for their use cases.

Since the release of GPT-3.5 Turbo, developers and businesses have asked for the ability to customize the model to create unique and differentiated experiences for their users. With this launch, developers can now run supervised fine-tuning to make this model perform better for their use cases.

In our private beta, fine-tuning customers have been able to meaningfully improve model performance across common use cases, such as:
- Improved steerability: Fine-tuning allows businesses to make the model follow instructions better, such as making outputs terse or always responding in a given language. For instance, developers can use fine-tuning to ensure that the model always responds in German when prompted to use that language.
- Reliable output formatting: Fine-tuning improves the model's ability to consistently format responses—a crucial aspect for applications demanding a specific response format, such as code completion or composing API calls. A developer can use fine-tuning to more reliably convert user prompts into high-quality JSON snippets that can be used with their own systems.
- Custom tone: Fine-tuning is a great way to hone the qualitative feel of the model output, such as its tone, so it better fits the voice of businesses’ brands. A business with a recognizable brand voice can use fine-tuning for the model to be more consistent with their tone.

In addition to increased performance, fine-tuning also enables businesses to shorten their prompts while ensuring similar performance.  Fine-tuning with GPT-3.5-Turbo can also handle 4k tokens—double our previous fine-tuned models. Early testers have reduced prompt size by up to 90% by fine-tuning instructions into the model itself, speeding up each API call and cutting costs.

Fine-tuning is most powerful when combined with other techniques such as prompt engineering, information retrieval, and function calling. Check out our fine-tuning guide to learn more. Support for fine-tuning with function calling and gpt-3.5-turbo-16k will be coming later this fall.

开发者通过监督微调，可以实现个性化定制，适配各自业务场景，显著提高模型性能
- 更加**可控**：更好的遵循指令，如 精简回复、以特定语言风格。（不必再在prompt中强调用某种语言）
- **输出格式**更可靠：微调提升了模型回复的一致性，适用于要求特定格式输出的情形（代码补全/组合API调用/json输出）
- **角色定义**：微调让模型输出更加贴合某种角色，如 企业品牌代言人

除了性能提升，微调还能缩短 prompt 长度，同时保持效果。GPT-3.5-Turbo 微调版能处理 4k tokens（之前模型的两倍）. 早期测试发现，通过监督指令微调，prompt长度最多缩减 90%，api调用加速，削减成本。

GPT 的“微调”与 Llama2 之类的微调不同，因为不会调整网络的所有权重，只是会调整网络小部分。代价是 OpenAI 微调的成本较低，但功能也没有“真正的”微调强大。

GPT-3.5 Turbo 微调可处理 4k 个 tokens——可达之前微调模型的 2 倍。早期测试人员还对模型本身的**指令**进行了微调，从而将提示词长度缩短达 **90%**，成功加快每次 API 调用的速度并降低了执行成本。

微调成本分为两个部分：初始**训练**成本与**使用**成本：
- 训练：0.008 美元/1K tokens
- 使用成本
  - 输入：0.012 美元/1K tokens
  - 输出：0.016 美元/1K tokens

|Model|Base Models-Input|Base Models-Output|Fine-tuned Models-Training|Fine-tuned Models-Input|Fine-tuned Models-Output|
|---|---|---|---|---|---|
|`babbage-002`|0.0004|0.0004|0.0004|0.0016|0.0016|
|`davinci-002`|0.002|0.002|0.006|0.012|0.012|
|`gpt-3.5-turbo-4k`|0.0015|0.002|0.008|0.012|0.016|
|`gpt-3.5-turbo-16k`|0.003|0.004|-|-|-|
|`gpt-4-8k`|0.03|0.06|-|-|-|
|`gpt-4-32k`|0.06|0.12|-|-|-|

注
- 单位 $/1k tokens
- [官方收费指南](https://openai.com/pricing)

例如，gpt-3.5-turbo 微调作业中包含 10 万个 token 的训练文件。经过 3 个 epoch 训练轮次，预计成本为 2.40 美元。

微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 **8 倍**，因此用户确实必须处于 OpenAI 提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。

初版 GPT-3 基础模型（ada、babbage、curie 和 davinci）微调 将于 2024 年 1 月 4 日正式关闭。

OpenAI 如今发布了 babbage-002 和 davinci-002 作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新 API 端点/v1/fine_tuning/jobs 进行微调。

微调实战
- 参考: [openai 3.5微调实战](https://github.com/LearnPrompt/LLMs-cookbook/tree/main/gpt3.5)
- 微调 `gpt-3.5-turbo-0613` 模型，**10条**数据（289个汉字，**5769**个字节），花费 0.16 刀; 按照 0.008 单价算，大概训练了3轮
- 数据示例：医疗监督问答数据集 [huatuo26M-testdatasets](https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets), 或去 [github](https://github.com/LearnPrompt/LLMs-cookbook/blob/main/gpt3.5/test_datasets.jsonl)找

<div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2023-08-29T13:15:51.115Z\&quot; agent=\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\&quot; etag=\&quot;UVFE8uh0TtQpR3knby8f\&quot; version=\&quot;21.6.8\&quot;&gt;\n  &lt;diagram name=\&quot;第 1 页\&quot; id=\&quot;YUrH7kkdw6S7EPocWAtV\&quot;&gt;\n    &lt;mxGraphModel dx=\&quot;1434\&quot; dy=\&quot;771\&quot; grid=\&quot;1\&quot; gridSize=\&quot;10\&quot; guides=\&quot;1\&quot; tooltips=\&quot;1\&quot; connect=\&quot;1\&quot; arrows=\&quot;1\&quot; fold=\&quot;1\&quot; page=\&quot;1\&quot; pageScale=\&quot;1\&quot; pageWidth=\&quot;827\&quot; pageHeight=\&quot;1169\&quot; math=\&quot;0\&quot; shadow=\&quot;0\&quot;&gt;\n      &lt;root&gt;\n        &lt;mxCell id=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;1\&quot; parent=\&quot;0\&quot; /&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-4\&quot; value=\&quot;\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#f5f5f5;dashed=1;dashPattern=1 1;fontColor=#333333;strokeColor=#666666;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;340\&quot; y=\&quot;90\&quot; width=\&quot;350\&quot; height=\&quot;190\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;CRyWcW9bKPYmjVe2kgWn-2\&quot; value=\&quot;ChatGPT 微调流程\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=0;fontSize=18;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;335\&quot; y=\&quot;10\&quot; width=\&quot;180\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;V9TQX8vlhKfmWj-25TbC-43\&quot; value=\&quot;2023-8-29&amp;lt;br&amp;gt;wqw547243068@163.com\&quot; style=\&quot;text;html=1;align=left;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;\&quot; parent=\&quot;1\&quot; vertex=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;550\&quot; y=\&quot;290\&quot; width=\&quot;170\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-6\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;198\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; value=\&quot;GPT-3.5 Turbo\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;100\&quot; width=\&quot;95\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-7\&quot; value=\&quot;\&quot; style=\&quot;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0;entryY=0;entryDx=0;entryDy=12.5;entryPerimeter=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot; value=\&quot;监督语料\&quot; style=\&quot;shape=cylinder3;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;size=15;fillColor=#f5f5f5;fontColor=#333333;strokeColor=#666666;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;160\&quot; y=\&quot;115\&quot; width=\&quot;60\&quot; height=\&quot;60\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot; value=\&quot;GPT-3.5 Turbo Finetune\&quot; style=\&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=none;shadow=1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;490\&quot; y=\&quot;225\&quot; width=\&quot;95\&quot; height=\&quot;40\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-16\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;516.25\&quot; y=\&quot;183\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-8\&quot; value=\&quot;个人语料\&quot; style=\&quot;shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;370\&quot; y=\&quot;130\&quot; width=\&quot;84\&quot; height=\&quot;45\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#B3B3B3;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-3\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-11\&quot; value=\&quot;① 准备语料\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;N5nvKO04K80Mb7aMBe0Y-10\&quot;&gt;\n          &lt;mxGeometry x=\&quot;-0.1467\&quot; y=\&quot;-1\&quot; relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;39\&quot; y=\&quot;-3\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-21\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#97D077;strokeWidth=2;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-5\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;240\&quot; y=\&quot;275\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-9\&quot; value=\&quot;\&quot; style=\&quot;shape=actor;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;175\&quot; y=\&quot;220\&quot; width=\&quot;30\&quot; height=\&quot;50\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-12\&quot; value=\&quot;② 上传语料到OpenAI\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;280\&quot; y=\&quot;125\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-13\&quot; value=\&quot;OpenAI\&quot; style=\&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;strokeColor=none;fillColor=none;fontStyle=1\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;470\&quot; y=\&quot;60\&quot; width=\&quot;70\&quot; height=\&quot;30\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-15\&quot; value=\&quot;\&quot; style=\&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;strokeColor=#B3B3B3;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\&quot; edge=\&quot;1\&quot; parent=\&quot;1\&quot; source=\&quot;N5nvKO04K80Mb7aMBe0Y-1\&quot; target=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot;&gt;\n          &lt;mxGeometry relative=\&quot;1\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;538\&quot; y=\&quot;140\&quot; as=\&quot;sourcePoint\&quot; /&gt;\n            &lt;mxPoint x=\&quot;537.5999999999999\&quot; y=\&quot;168\&quot; as=\&quot;targetPoint\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-17\&quot; value=\&quot;③ 启动微调\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;590\&quot; y=\&quot;175\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-18\&quot; value=\&quot;④ 邮件通知任务完成&amp;lt;br&amp;gt;(返回模型名)\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;610\&quot; y=\&quot;220\&quot; as=\&quot;geometry\&quot;&gt;\n            &lt;mxPoint x=\&quot;19\&quot; y=\&quot;4\&quot; as=\&quot;offset\&quot; /&gt;\n          &lt;/mxGeometry&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-19\&quot; value=\&quot;⑤ 调用新模型\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;fontColor=#3333FF;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;300\&quot; y=\&quot;260\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-23\&quot; value=\&quot;jsonl格式&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}&amp;lt;br&amp;gt;{&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;}}\&quot; style=\&quot;shape=note;whiteSpace=wrap;html=1;backgroundOutline=1;darkOpacity=0.05;fillColor=#fff2cc;strokeColor=#d6b656;align=left;\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;140\&quot; y=\&quot;40\&quot; width=\&quot;190\&quot; height=\&quot;70\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-24\&quot; value=\&quot;\&quot; style=\&quot;shape=image;html=1;verticalLabelPosition=bottom;verticalAlign=top;imageAspect=0;image=img/clipart/Gear_128x128.png\&quot; vertex=\&quot;1\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;517.5\&quot; y=\&quot;156.5\&quot; width=\&quot;40\&quot; height=\&quot;53\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n        &lt;mxCell id=\&quot;N5nvKO04K80Mb7aMBe0Y-25\&quot; value=\&quot;生成语料id\&quot; style=\&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=none;\&quot; vertex=\&quot;1\&quot; connectable=\&quot;0\&quot; parent=\&quot;1\&quot;&gt;\n          &lt;mxGeometry x=\&quot;411\&quot; y=\&quot;118\&quot; as=\&quot;geometry\&quot; /&gt;\n        &lt;/mxCell&gt;\n      &lt;/root&gt;\n    &lt;/mxGraphModel&gt;\n  &lt;/diagram&gt;\n&lt;/mxfile&gt;\n&quot;}"></div>
<script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script>


完整版: [知乎](https://zhuanlan.zhihu.com/p/653239407?), [公众号](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649769352&idx=1&sn=e68c0ae1d3b2b1af8aeb3ace58f811e0&chksm=bec3d89589b45183f626a37b4c345254c527f0b68fb301e6e9abb88d6d78b2418697f534f049&token=622259072&lang=zh_CN#rd)

① 数据处理

将jsonl格式（每行都是json串的文本文件）的数据（question, answer两个字段）转换为OpenAI要求的格式

```py
# 数据处理
import json
import random

def transform_jsonl(input_file_path, output_file_path):
    entries = []
    with open(input_file_path, 'r') as file:
        for line in file:
            entry = json.loads(line)
            entries.append(entry)
    # 随机抽取100个条目
    #sampled_entries = random.sample(entries, 100)
    sampled_entries = random.sample(entries, 10) # 至少10条数据

    with open(output_file_path, 'w') as outfile:
        for entry in sampled_entries:
            messages = []
            messages.append({"role": "system", "content": "You are an assistant"})
            user_message = {"role": "user", "content": entry["questions"]}
            assistant_message = {"role": "assistant", "content": entry["answers"]}
            messages.extend([user_message, assistant_message])
            result = {"messages": messages}
            json.dump(result, outfile, ensure_ascii=False)
            outfile.write('\n')

input_file_path = '~/test_datasets.jsonl' # 请替换为您的输入JSONL文件路径
output_file_path = '~/tmp.jsonl' # 请替换为您想要保存的输出JSONL文件路径
transform_jsonl(input_file_path, output_file_path)
```

数据示例：

```json
输入: {"questions": "做了腰间盘穿丁手术后，用盐泡脚可以吗", "answers": "问题分析：你好:你是由于身体出现了一些局部的腰部损伤这种情况应该进行调整的一般术后泡脚是可以的，不用担心。意见建议：治疗方案:你可以不知后注意休息，避免劳累过度就可以这种调整方法也可以住进你身体的一些嗯调理的啊！"}
输出: {"messages": [{"role": "system", "content": "You are an assistant that occasionally misspells words"}, {"role": "user", "content": "由于一次事故造成了左耳的残疾听力不是很好需要佩戴助听器戴上的效果还不错能和人正常交流但是最近一个月助听器里面总是有杂音影响了使用效果。耳聋佩戴的助听器有杂音怎么办？（）"}, {"role": "assistant", "content": "你好您所谓的杂音也有可能是听到的环境声音好的助听器对噪音是有压缩的出现这种情况是可以调试解决的如果是一般的助听器因为环境声音也同时放大了可能会觉得比较吵您的问题最好是到助听器店让专业的验配师帮您处理"}]}
// 官方数据示例
{
  "messages": [
    { "role": "system", "content": "You are an assistant that occasionally misspells words" },
    { "role": "user", "content": "Tell me a story." },
    { "role": "assistant", "content": "One day a student went to schoool." }
  ]
}
```


② 上传文件

注意
- 单个训练文件最大 50 MB
- 一行数据是完整的json字符串，最大token数目 4096，超出就截断
- 最少训练条数：10，一般50-100条就有提升，因场景而已
- 数据较少时，将效果好system prompt放到训练数据中
- 数据可以分为训练集、测试集，分开上传


```sh
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F "purpose=fine-tune" \
  -F "file=@path_to_your_file" 

# ------ 第三方  ----
curl --location 'https://api.openai.com/v1/files' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --form "purpose=fine-tune" \
  --form "file=@path_to_your_file" 
```

python

```py
# 上传至OpenAI
import requests
import openai

OPENAI_API_KEY='***'
url = "https://api.openai.com/v1/files"
headers = {
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
payload = {
    "purpose": "fine-tune",
}
print('数据路径: ', output_file_path)
files = {
    "file": open(output_file_path, "rb")
}

response = requests.post(url, headers=headers, data=payload, files=files)
print(response)
print('上传的文件信息: ', openai.File.list())
```

执行完毕后返回 文件列表

```json
上传的文件信息:  {
  "object": "list",
  "data": [
    {
      "object": "file",
      "id": "file-***",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 5769,
      "created_at": 1693304216,
      "status": "uploaded",
      "status_details": null
    },
    {
      "object": "file",
      "id": "file-****",
      "purpose": "fine-tune",
      "filename": "tmp.jsonl",
      "bytes": 1496,
      "created_at": 1693303804,
      "status": "processed",
      "status_details": null
    }
  ]
}
```

从中找到 本次上传文件 位置，如下标0, 或1

③ 启动微调任务


```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'

# ------ 第三方: 自定义训练参数  ----
curl --location 'https://api.openai.com/v1/fine_tuning/jobs' \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --data '{
    "training_file": "file-****", // 训练集
    "validation_file": "file-****", // 测试集
    "hyperparameters":{
      "n_epochs":7
    },
    "suffix":"cutom-model-name", // 自定义模型前缀
    "model":"gpt-3.5-turbo-0613"
  }'

```


模型选择

```py
# 启动微调
import requests

OPENAI_API_KEY="sk-***"

url = "https://api.openai.com/v1/fine_tuning/jobs"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}

data = { 
    #"training_file": "file-XXXXXXXXXXX",
    "training_file": openai.File.list()['data'][1]['id'],
    "model": "gpt-3.5-turbo-0613"
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

终端返回

```json
{"object":"fine_tuning.job","id":"ftjob-***","model":"gpt-3.5-turbo-0613","created_at":1693304550,"finished_at":null,"fine_tuned_model":null,"organization_id":"org-LMrR8ZVsnE2MLQNXje4rARHo","result_files":[],"status":"created","validation_file":null,"training_file":"file-bPzn6eE00cvR3xNqb8lau6QN","hyperparameters":{"n_epochs":10},"trained_tokens":null}
```

获取训练信息

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-**** \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

取消训练任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/cancel \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

查看训练进度

```sh
curl https://api.openai.com/v1/fine_tuning/jobs/ft-****/events \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```


稍等片刻后，查看个人邮箱，记录新模型名

```sh
curl https://api.openai.com/v1/fine_tuning/jobs \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "training_file": "TRAINING_FILE_ID",
  "model": "gpt-3.5-turbo-0613"
}'
```

对应的Python指令

```py
# List 10 fine-tuning jobs
openai.FineTuningJob.list(limit=10)
# Retrieve the state of a fine-tune
openai.FineTuningJob.retrieve("ft-abc123")
# Cancel a job
openai.FineTuningJob.cancel("ft-abc123")
# List up to 10 events from a fine-tuning job
openai.FineTuningJob.list_events(id="ft-abc123", limit=10)
# Delete a fine-tuned model (must be an owner of the org the model was created in)
openai.Model.delete("ft-abc123")
```

④ 使用微调模型

查看已有finetune任务

```sh
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&after=1 \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
```

看下新模型效果


```py
# 调用模型
import requests

url = "https://api.openai.com/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {OPENAI_API_KEY}"
}
# 从邮件里提取模型名称
new_model = 'text-davinci-003'
new_model = "gpt-3.5-turbo"
new_model = 'ft:gpt-3.5-turbo-0613:***'
data = {
    "model": new_model,
    "messages": [
        {
            "role": "system",
            "content": "You are an assistant"
        },
        {
            "role": "user",
            "content": "我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？"
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
print(response.text)
```

返回结果

```json
{
  "id": "chatcmpl-****",
  "object": "chat.completion",
  "created": 1693305795,
  "model": "ft:gpt-3.5-turbo-0613:***",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "可能的原因如下： 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 4、如果一直测得较高，就是高血压，应引诱病院。"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 73,
    "completion_tokens": 219,
    "total_tokens": 292
  }
}
```

Web UI: 基于 gradio, [code](https://github.com/LearnPrompt/LLMs-cookbook/blob/main/gpt3.5/7_webui.py)

```py
import os
from functools import partial
import gradio as gr
import openai

class Messages_lst:
    def __init__(self):
        self.memory = []
    
    def update(self, role,message):
        if role == "user":
            user_turn = {"role": "user","content":message}
            self.memory.append(user_turn)
        elif role == "assistant":
            gpt_turn = {"role": "assistant","content":message}
            self.memory.append(gpt_turn)
    
    def get(self):
        return self.memory
    
messages_lst = Messages_lst()

def get_response(api_key_input, user_input):
    
    # print(api_key_input)
    print(user_input)

    messages_lst.update("user", user_input)
    messages = messages_lst.get()

    openai.api_key = api_key_input
    MODEL = "gpt-3.5-turbo"

    print(messages)

    response = openai.ChatCompletion.create(
        model=MODEL,
        messages = messages,
        temperature=0.5)
    assistant = response['choices'][0]['message']['content']
    messages_lst.update("assistant", assistant)
    # return assistant
    # 生成HTML字符串
    html_string = ""
    for message in messages_lst.get():
        if message["role"] == "user":
            html_string += f"<p><b>User:</b> {message['content']}</p>"
        else:
            html_string += f"<p><b>Assistant:</b> {message['content']}</p>"

    return html_string

def main():
    # api_key = os.environ.get("OPENAI_API_KEY")

    api_key_input = gr.components.Textbox(
        lines=1,
        label="Enter OpenAI API Key",
        type="password",
    )

    user_input = gr.components.Textbox(
        lines=3,
        label="Enter your message",
    )
    

    output_history = gr.outputs.HTML(
        label="Updated Conversation",
    )

    inputs = [
        api_key_input,
        user_input,
    ]

    iface = gr.Interface(
        fn=get_response,
        inputs=inputs,
        outputs=[output_history],
        title="GPT WebUi",
        description="A simple chatbot using Gradio",
        allow_flagging="never",
    )

    iface.launch()

if __name__ == '__main__':
    main()
```


效果对比

question: 
> 我在体检是正常的，但是去献血医生最是说我的血压高，不能献。血压是130、80这是为什么呢？

Answer

**gpt-3.5**

> 血压读数130/80是较常见的健康血压范围内，但是具体的献血要求可能略有不同，医生可能基于献血的特殊需求或个人身体状况，选择较为严格的标准。以下是一些可能导致您不能献血的原因：
>1. 个人差异: 献血机构可能设定了较为严格的血压标准，以确保献血者的安全和健康。即使您的血压读数在正常范围内，但慎重考虑您的个人特殊情况或家族病史等因素也很重要。
>2. 动态血压: 血压是一个动态指标，受多种因素影响，如情绪、活动水平、环境等。可能您的血压在体检时正常，但在献血前被测量时升高。
>3. 紧张或焦虑: 对一些人来说，献血过程本身可能会引发一些紧张和焦虑，这可能会导致血压升高。这些情绪因素可能会影响到医生的判断。
> 
> 如果您对不能献血的原因有任何疑问，我建议您咨询相关医生或献血机构的工作人员，他们可以给您更具体的解释和指导。另外，您的血压读数仍然在健康范围内，您可以继续关注并保持良好的生活习惯，有助于保持健康的血压水平。

**finetune**

> 可能的原因如下： 
>- 1、在献血时会有一些紧张，紧张会使血压升高。有的人可能并不是很紧张，但献血起码是一个小手术。 
>- 2、在献血之前会对献血者进行初检，其中就包括血压测量。如果血压较高，就不准献血。 
>- 3、在献血后有可能会感到血压低，因为抽取的是血浆，造成血容量减低，心排血量减少，以后体中的血压降落。 
>- 4、如果一直测得较高，就是高血压，应引诱病院



简单微调过后不用写prompt也能让gpt-3.5-turbo-0613有更加专业的回复

微调原理

【2023-8-24】[GPT-3.5 微调 API重磅发布：有史以来规模最大的 LoRA 即服务](https://mp.weixin.qq.com/s/GIIzEwRzXxkAffPDjtvvaw)

LoRA：英文全称 Low-Rank Adaptation of Large Language Models，大语言模型的低阶适应，微软研究人员为解决大语言模型微调而开发的一项技术。
- 冻结预训练的模型权重参数, 每个Transformer块里注入可训练层，由于不需要对模型的权重参数重新计算梯度，所以大大减少了需要训练的计算量。

研究发现: LoRA的微调质量与全模型微调相当

LoRA-as-a-service： LoRA 即服务。
- 这种模式类似于“软件即服务”（Software-as-a-Service，SaaS）或其他类似的服务模式，其中用户不需要自行部署和管理软件或技术，而是通过云服务提供商获得对其功能和服务的访问权




### 企业版

【2023-8-28】OpenAI 宣布推出 ChatGPT 企业版 (ChatGPT Enterprise)，也是迄今为止最强大的 ChatGPT 版本。提供企业级安全和隐私、无限的高速 GPT-4 访问、用于处理更长输入的更长上下文窗口、高级数据分析功能、自定义选项等等。其目的是吸引更广泛的企业客户，并提高产品收入。
- [Introducing ChatGPT Enterprise](https://openai.com/blog/introducing-chatgpt-enterprise)

ChatGPT 企业版 取消了所有**使用上限**，并且执行速度提高了**两倍**。企业版中包含 32k 上下文，允许用户处理四倍长的输入或文件，还提供对高级数据分析的无限制访问。

“此功能使技术和非技术团队能够在几秒钟内分析信息，无论是金融研究人员处理市场数据、营销人员分析调查结果还是数据科学家调试 ETL 脚本。”
- **无限制**访问 GPT-4（无使用上限）
- 更高速的 GPT-4 性能（速度提高 **2倍**）
- 无限制地访问**高级数据分析**（以前称为代码解释器）
- 32k token 上下文窗口，用于 4倍长的输入、文件或 follow-ups
- 可共享的聊天模板，供客户公司协作和构建通用工作流程
- 此外，ChatGPT 企业版提供了**静态数据加密** (AES-256) 和**传输中数据加密** (TLS 1.2+)，并已经过 SOC 2 Type 1 的合规性审核和认证。

OpenAI 还保证，不会使用客户数据来训练 OpenAI 模型。

目前，ChatGPT 已有`免费版`、`Plus 版`和`企业版`三个订阅方案。但 OpenAI 尚未给出企业版的统一定价，具体将取决于每家公司的使用情况和用例，需要单独询价。

## GPT-4 API

【2023-7-10】[GPT-4无法使用](https://community.openai.com/t/gpt-4-has-been-announced-to-be-available-for-all-api-users-but-it-is-still-not-available-for-me/290596)

### GPT-4 收费对比

【2023-3-23】[GPT-4 API 接口调用及价格分析](https://blog.csdn.net/jarodyv/article/details/129651507)

横向比较一下几个模型的单价
- gpt-4 prompt 比 gpt-3.5-turbo贵了14倍，gpt-4 completion 比 gpt-3.5-turbo贵了29倍！假设prompt和completion的字数为1:4（实际中completion往往比prompt要长），那么gpt-4接口的综合成本是gpt-3.5-turbo的27倍！
- gpt-3.5-turbo $20美元能处理750万字，而相同金额在gpt-4中只能处理30万字左右

| 模型 | $0.06 |	$0.03	| $0.002	| $0.02	| $0.002 |	$0.0005	| $0.0004 |
| --- | ---- |	----	| ----	| ----	| ---- |	----	| ---- |
| gpt-4(completion)	| gpt-4(prompt) |	gpt-3.5-turbo |	davinci	| curie	| babbage |	ada |
| gpt-4(completion) |	0	| 1	| 29	| 2	| 29	| 119	| 149 |
| gpt-4(prompt) | -0.5	| 0	| 14	| 0.5 |	14 | 59	| 74 |

GPT-4 收费对比

| 模型名称	| 描述	| 最大token数	| 训练数据 |
| ----	| ----	| ----	| ---- | 
| gpt-4	| 比 GPT-3.5 模型更强大，能够执行更复杂的任务，并针对聊天场景进行了优化。 会不断迭代更新。	| 8,192	| 截至2021年6月 |
| gpt-4-0314 |	gpt-4的2023年3月14日快照版本。此模型在接下来3个月内不会更新，有效期截止2023年6月14日。	| 8,192	| 截至2019年10月 |
| gpt-4-32k |	与 gpt-4 功能相同，但上下文长度是gpt-4 的4 倍。会不断迭代更新。 |	32,768	| 截至2021年6月 |
| gpt-4-32k-0314 |	gpt-4-32k的2023年3月14日快照版本。此模型在接下来3个月内不会更新，有效期截止2023年6月14日。	| 32,768	| 截至2019年10月 |

由于还在beta阶段，GPT-4 API的调用有频次限制：
- 40k tokens / 分钟
- 200 请求 / 分钟

这个频次对功能测试和概念验证来说已经足够了。

如果使用ChatGPT Plus体验GPT-4，有4小时100条消息的限制。

GPT-4 API的定价策略与之前模型不同。在GPT-4之前，接口定价按照token数统一收费，不区分是prompt的token还是生成响应的token。而GPT-4将prompt token和生成响应token分开计价，价格如下：
- $0.03美元 / 1K prompt token
- $0.06美元 / 1K 生成响应 token

这个价格相比 gpt-3.5-turbo 的 $0.002 / 1K tokens来说贵了至少15倍起。

### GPT-4 API

【2023-3-24】GPT-4使用

【2023-5-20】升级plus上看不到gpt-4选项

GPT-4 API Models
- model = gpt-4
- model = gpt-4-32k

```py
import OpenAI
# 直接以用户身份提问
messages=[{"role": "user", "content": As an intelligent AI model, if you could be any fictional character, who would you choose and why?}]
# 多个输入：提前传入系统话术
messages=[{"role": "system", "content": system_intel},
          {"role": "user", "content": prompt}])

response = openai.ChatCompletion.create(
model="gpt-4", max_tokens=100,
#model="gpt-4-32k", max_tokens=32768,
temperature=1.2,
messages = message)

print(response)
```

第三方

```py
from steamship import Steamship
# !pip install steamship
gpt = Steamship.use_plugin("gpt-4")
task = gpt.generate("你好")
task.wait()
```

## ChatGPT 参数

### api示例

```py
# 终端命令
# OpenAI api completions.create -m text-davinci-003 -p "Say this is a test" -t 0 -M 7 --stream
import OpenAI

OpenAI.api_key = "你的API Key"
#openai.Model.list() # 显示可用model
response = OpenAI.Completion.create(
  model="text-davinci-003", # 模型名称
  prompt="how are you", # 问题
  temperature=0.7, # 结果随机性，0-0.9 （稳定→随机）
  max_tokens=256, # 最大字数，汉字两位
  stream=False, # ChatGPT独有参数
  top_p=1, # 返回概率最大的1个
  frequency_penalty=0, 
  presence_penalty=0
)
# print(response)
for r in response:
  res += r["choices"][0]["text"]
res = res.replace('<|im_end|>', '')
print(res)
```

返回结果如下所示，结果在text字段中，可通过 response\["choices"]\[0]\["text"] 进行读取。

```json
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "text-davinci-003",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

参考：[ChatGPT官方API可以抢先体验了](https://mp.weixin.qq.com/s/Jms52U6UyFK6fO7rVRLeBw)


【2023-2-11】[GPT-3](https://platform.openai.com/docs/models/gpt-3) Model 参数说明： [官网](https://platform.openai.com/docs/models/finding-the-right-model)

| LATEST MODEL | DESCRIPTION | MAX REQUEST | TRAINING DATA | 
|---|---|---|---|
| `text-davinci-003` | Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports inserting completions within text. | 4,000 tokens | Up to Jun 2021 | 
| `text-curie-001` | Very capable, but faster and lower cost than Davinci. | 2,048 tokens | Up to Oct 2019 | 
| `text-babbage-001` | Capable of straightforward tasks, very fast, and lower cost. | 2,048 tokens | Up to Oct 2019 | 
| `text-ada-001` | Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost. | 2,048 tokens | Up to Oct 2019 | 

While `Davinci` is generally the most capable, the other models can perform certain tasks extremely well with significant speed or cost advantages. For example, `Curie` can perform many of the same tasks as Davinci, but faster and for 1/10th the cost.

We recommend using `Davinci` while experimenting since it will yield the best results. Once you’ve got things working, we encourage trying the other models to see if you can get the same results with lower latency. You may also be able to improve the other models’ performance by fine-tuning them on a specific task.

Older versions of our GPT-3 models are available as `davinci`, `curie`, `babbage`, and `ada`. These are meant to be used with our fine-tuning endpoints.

Your model can be one of: `ada`, `babbage`, `curie`, or `davinci`

各模型调用费用不同，davinci最贵，对比下来，只有最贵的 davinci 符合预期，18 刀的配额，算了一下大概也就问 1000 多个问题
- ![compare](https://pic4.zhimg.com/v2-eec1038143c132650af260e688bfa0f5_b.jpg)

如何查看可用模型？以Python[接口调用](https://platform.openai.com/docs/api-reference/introduction)为例

```py
import requests
import json

headers = {'Authorization': f'Bearer {openai.api_key}'}
#payload = {'key1': 'value1', 'key2': 'value2'}
url = 'https://api.openai.com/v1/models' # 查看可用模型
#r = requests.get("http://httpbin.org/get", params=payload)
r = requests.get(url, headers=headers) # header
#print(r.url) # 请求网址
#print(r.encoding) # 编码
res = json.loads(r.text) # 返回内容
json.dumps(res)
# ------------------
import pandas as pd
import datetime

info_list = []
for m in res['data']:
    tm = datetime.datetime.fromtimestamp(m['permission'][0]['created']).strftime('%Y-%m-%d %H:%M:%S')
    out = [m['id'], # m['root'], 
           # m['permission'][0]['organization'],
           tm, # m['permission'][0]['created'], 
           m['permission'][0]['allow_create_engine'],
           m['permission'][0]['allow_sampling'],
           m['permission'][0]['allow_logprobs'],
           m['permission'][0]['allow_view'],
           m['permission'][0]['allow_fine_tuning'],
           m['permission'][0]['is_blocking'],
          ]
    info_list.append(out)
    #print('\t'.join(map(str, out)))
df = pd.DataFrame(info_list, columns=['id', 'create_time','allow_create_engine', 'allow_sampling',
                                'allow_logprobs', 'allow_view', 'allow_fine_tuning','is_blocking' ])
df.sort_values('create_time', ascending=False)
print(df.to_markdown()) # 输出为markdown格式
```

结果示例：

|  id  | model_id                            | create_time         | allow_create_engine   | allow_sampling   | allow_logprobs   | allow_view   | allow_fine_tuning   | is_blocking   |
|---:|:------------------------------|:--------------------|:----------------------|:-----------------|:-----------------|:-------------|:--------------------|:--------------|
|  0 | babbage                       | 2022-11-22 10:51:41 | False                 | True             | True             | True         | False               | False         |
|  1 | code-davinci-002              | 2023-02-11 05:26:08 | False                 | True             | True             | True         | False               | False         |
|  2 | davinci                       | 2022-11-22 05:32:35 | False                 | True             | True             | True         | False               | False         |

### GPT-3 参数

GPT-3 模型调用方式如下，输入主要有7个参数：
- （1）`model`：模型名称，text-davinci-003
  - string, Required
  - ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.
- （2）`prompt`：问题或待补全内容，例如“how are you”。
  - string or array, Optional, Defaults to \<\|endoftext\|\> (分隔符，最为prompt初始值)
  - The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.
  - Note that \<\|endoftext\|\> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
- （3）`temperature`：控制结果**随机性**，0.0表示结果固定，随机性大可以设置为0.9。
  - number, Optional, Defaults to 1
  - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
  - We generally recommend altering this or top_p but not both.
- （4）`max_tokens`：最大返回字数（包括问题和答案），通常汉字占两个token。假设设置成100，如果prompt问题中有40个汉字，那么返回结果中最多包括10个汉字。
  -  ChatGPT API允许的最大token数量为 4097（大部分模型是2048），即max_tokens最大设置为4097减去prompt问题的token数量。
  - max_tokens, integer, Optional, Defaults to 16
  - The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of **2048** tokens (except for the newest models, which support **4096**).
- （5）`top_p`：设置为1即可
  - top_p, number, Optional, Defaults to 1
  - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  - We generally recommend altering this or temperature but not both.
- `n` 每个prompt生成几个结果（占用额度，慎用）
  - integer, Optional, Defaults to 1
  - How many completions to generate for each prompt.
  - Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
- （6）**frequency_penalty**：设置为0即可。
- （7）**presence_penalty**：设置为0即可。
- （8）`stream`：是否采用控制流的方式输出。（ChatGPT新增）
  - （1）如果stream取值为False，那么返回结果与 GPT3接口一致，完全返回全部文字结果，可通过 response\["choices"]\[0]\["text"]进行读取。但是，字数越多，等待返回时间越长，时间可参考控制流读出时的4字/每秒。
  - （2）如果steam取值为True时，那么返回结果是一个 Python generator，需要通过迭代获取结果，平均大约每秒钟4个字（33秒134字，39秒157字），读取程序如下所示。可以看到，读取结果的结束字段为“<\|im_end\|>”。
  - stream: boolean, Optional, Defaults to false
  - Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: \[DONE\] message.
- `logprobs` **似然概率**
  - logprobs: integer, Optional, Defaults to null
  - Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.
  - The maximum value for logprobs is **5**. If you need more than this, please contact us through our Help center and describe your use case.
- `suffix` 前缀
  - string, Optional, Defaults to null
  - The suffix that comes after a completion of inserted text.
- `echo` 补写之外返回提示语
  - echo: boolean, Optional, Defaults to false
  - Echo back the prompt in addition to the completion
- `stop` 停用句子（类似停用词），生成过程中不出现
  - stop: string or array, Optional, Defaults to null
  - Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
- `presence_penalty` 出现惩罚
  - number, Optional, Defaults to 0
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
- `frequency_penalty` 频率惩罚
  - number, Optional, Defaults to 0
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
- `best_of` 
  - integer, Optional, Defaults to 1
  - Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.
  - When used with n, `best_of` controls the number of candidate completions and n specifies how many to return – `best_of` must be greater than n.
  - Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.
- `logit_bias` 概率偏置
  - map, Optional, Defaults to null
  - Modify the likelihood of specified tokens appearing in the completion.
  - Accepts a **json object** that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both `GPT-2` and `GPT-3`) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
  - As an example, you can pass {"50256": -100} to prevent the <\|endoftext\|> token from being generated.
- `user` 用户标志符，便于OpenAI识别是否恶意调用
  - string, Optional
  - A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).


### ChatGPT 参数详解

Chat
- Given a chat conversation, the model will return a chat completion response.

Request body，[官方](https://platform.openai.com/docs/api-reference/chat/create)
- `model`, string, Required 模型名称，必备
  - ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.
- `messages`, array, Required prompt信息，必备
  - The messages to generate chat completions for, in the [chat format](https://platform.openai.com/docs/guides/chat/introduction).
- `temperature`, number, Optional, Defaults to 1 温度，0-2, 高温(0.8)使结果更随机, 低温(0.2)更加稳定
  - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
  - We generally recommend altering this or top_p but not both.
- `top_p`, number, Optional, Defaults to 1 采样策略, 超过top_p的字符才会考虑
  - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  - We generally recommend altering this or temperature but not both.
- `n`, integer, Optional, Defaults to 1 生成多少个回复
  - How many chat completion choices to generate for each input message.
- `stream`, boolean, Optional, Defaults to false 流式输出，默认否
  - If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a data: \[DONE] message. See the OpenAI Cookbook for [example code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
- `stop`, string or array, Optional, Defaults to null 生成多少个字符后停止，最多4组参数
  - Up to 4 sequences where the API will stop generating further tokens.
- `max_tokens`, integer, Optional, Defaults to inf 最长字符数
  - The maximum number of [tokens](https://platform.openai.com/tokenizer) to generate in the chat completion.
  - The total length of input tokens and generated tokens is limited by the model's context length.
- `presence_penalty`, number, Optional, Defaults to 0 重复字符惩罚，-2~2, 正数时，惩罚已经出现过的字符
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
  - See more information about [frequency and presence penalties](https://platform.openai.com/docs/api-reference/parameter-details).
- `frequency_penalty`, number, Optional, Defaults to 0 频次惩罚，-2~2, 正数时，已出现的字符按频率惩罚
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
  - See more information about [frequency and presence penalties](https://platform.openai.com/docs/api-reference/parameter-details).
- `logit_bias`, map, Optional, Defaults to null 概率偏置，给特定字符增加置信度
  - Modify the likelihood of specified tokens appearing in the completion.
  - Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
- `user`, string, Optional 标记是否终端用户
  - A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

curl

```sh
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

Parameters

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [{
    "role": "user", 
    "name": "Wang", // 新增
    "content": "Hello!"
    }]
}
```

【2023-6-24】name参数, [openai官方解释](https://platform.openai.com/docs/api-reference/chat/create)

name
> The name of the author of this message. name is required if role is function, and it should be the name of the function whose response is in the content. May contain a-z, A-Z, 0-9, and underscores, with a maximum length of 64 characters.

实测: name格式有要求（满足'^[a-zA-Z0-9_-]{1,64}$'），即便填了英文字符串，openai并没有当做用户名
>- question: 你好, 知道我是谁吗
>- answer: assistant 您好！很抱歉，作为人工智能助手，我没有能力识别您是谁。

Response

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "\n\nHello there, how may I assist you today?",
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

GPT-3.5 Turbo 的微调可处理 4k 个 tokens——可达之前微调模型的 2 倍。早期测试人员还对模型本身的指令进行了微调，从而将提示词长度缩短达 90%，成功加快每次 API 调用的速度并降低了执行成本。


### 流式输出

流式输出的好处
- GPT 一边响应一边返回结果，流式输出，响应效率大大提升；
- 另一方面是显著提升了用户体验，给我们的感觉就像是真实的对话一样，GPT 似乎在思考问题的答案。

调用流程
- ![](https://cdn.learnku.com/uploads/images/202306/22/111987/WC7pljzhlK.png!large)

【2023-8-28】[如何丝滑实现 ChatGPT 打字机流式回复？](https://learnku.com/articles/78210)
- Server-Sent Events： 服务端主动向客户端推送的技术，与 Websocket 有些类似，但是 SSE 并不支持客户端向服务端发送消息，即 SSE 为**单工通信**。
  - 服务端与客户端建立了 长连接，服务端源源不断地向客户端推送消息。服务端就相当于河流的上游，客户端就相当于河流的下游，水往低处流，这就是 SSE 的流式传输。
- Web Socket

[ChatGPT流式输出](https://chatgpt-java.unfbx.com/docs/core/chat_gpt_stream)

SDK有两个OpenAi客户端OpenAiClient和OpenAiStreamClient。
-   OpenAiClient支持OpenAI的所有接口，支持阻塞式输出聊天模型（gpt3.5 、4.0）。
-   OpenAiStreamClient支持OpenAI的流式输出聊天模型(gpt3.5 、4.0)。

推荐自定义OkHttpClient实现两个Client，公用一个OkHttpClient即可。

流式输出和阻塞输出类似，只需要创建OpenAiStreamClient传入自定义的EventSourceListener即可。

举例为**默认的SDK实现：ConsoleEventSourceListener**。

web实现参考：

| 流式输出实现方式 | 小程序 | 安卓 | ios | H5 |
| --- | --- | --- | --- | --- |
| SSE示例参考：[OpenAISSEEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAISSEEventSourceListener.java) | 不支持 | 支持 | 支持 | 支持 |
| WebSocket示例参考：[OpenAIWebSocketEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAIWebSocketEventSourceListener.java) | 支持 | 支持 | 支持 | 支持 |

## 账户升级plus

OpenAI升级不支持国内信用卡，paypal都不行

解法
1. 找有🇺🇸**信用卡的朋友代充**。首推这种方式，因为简单直接，手续费也不高。但不是每个人都有这样的渠道的，那就来看一个替代方式。
2. **注册一个虚拟信用卡**，这里列两个平台`nobepay`和`depay`.

### 升级流程

【2023-3-28】如何升级付费用户？官方渠道需要有境外银行卡，不好办。
- [国内开通Chat GPT Plus保姆级教程](https://chatgpt-plus.github.io/)
- ChatGPT Plus付费版升级流程。
- ![](https://chatgpt-plus.github.io/images/1.png)
- 欧易是港股上市，国内最大的交易所，Depay是最大的虚拟信用卡公司

[Chatgpt升级plus会员](https://enchanting-polonium-c95.notion.site/Chatgpt-plus-569b65dcc8b04290930303038eaeeb4f)

两种方案: `Depay` + `nobepay`
- (1) `Depay`: 如果有usdt（虚拟货币）可以选择平台 [Depay](https://depay.one/zh-cn/index.html)，kyc可认证可不认证。Depay 只支持u币入金。
  - depay 打开后填写手机，邮箱，国内手机号即可。
- (2) `nobepay`: 如果没有u币，可以选择 [nobepay](https://www.nobepay.com/app/login)，支付宝微信就能充值，身份必须认证
  - 【2023-5-19】[保姆级教程：NobePay从注册到充值开卡全过程](https://mailberry.com.cn/2023/03/register-nobepay/)
  - nobepay的充值开卡比较简单
  - 过程: 注册登录 -> kyc认证 -> 充值到nobepay钱包 -> 开通虚拟信用卡 -> 钱包里的钱转到信用卡里
- ![](https://enchanting-polonium-c95.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff35cc065-d1cf-47a6-8c52-d4b5c3232ec0%2FD63F8ACE-47D7-470C-B6F4-C9FC88AFE870.jpeg?id=13cc68dd-0509-4038-8781-87000a14a543&table=block&spaceId=5cde7fdc-e0aa-47f7-a6c9-ccff5735a6eb&width=1260&userId=&cache=v2)

nobepay充值支持`微信`, `支付宝`。depay只支持**虚拟货币**，充币usdt转换成美金usd后就能使用

申请开卡，有`visa`和`master` card两种

注意事项
1. 付款时开🪜全局代理，选🇺🇸路线，国内的ip会不行，包括🇭🇰。
2. nobepay平时海淘也能用，最低500起充，但这个平台不建议多充，怕跑路，只是作为个工具使用。
3. depay也是，因为我不懂加密货币，平时也不玩，这里只是作为一个工具用，我个人并不了解也不信任depay 这个平台,不能保证稳定性，所以大家别多充，万一平台跑路了呢🤔🤔
4. 有🇺🇸信用卡渠道的优先选美卡，费率低且简单。

openai付费升级的卡号怎么选
- chatgpt/OpenAI：除欧洲卡段474362其他都可以，建议使用新上线卡段
- 主要是IP问题，如果被拒多换换

美国的免税州有：[地址生成器](https://www.fakepersongenerator.com/Index/generate)
- 蒙大拿州（Montana）
- 俄勒冈州（Oregon）
- 阿拉斯加州（Alaska）
- 特拉华州（Delaware）
- 新罕布什尔州（New Hampshire）

美国各州[简称](https://www.qidulp.com/article/p/3663)
- ![](https://ywserver.qidulp.com/public/img/8a/8a232fa479626b691df4dc66c0cfb400.jpg)



### 升级被拒原因

信用卡被拒，提示：
> ”你的信用卡被拒绝了，请尝试用借记卡支付“

信用卡被拒可能有以下几个原因：
- 信用卡确实不支持，比 Depay 的虚拟信用卡的号段被 OpenAI/ChatGPT 拒绝。可以尝试更换虚拟信用卡，Depay 支持申请多张。
- 网络环境被 Stripe 风控，挂全局代理 + 浏览器无痕模式再试，总之挂代理和不挂代理都试一下
- 全局代理 + 浏览器无痕模式 + 更换 IP 失败次数超过 3-5 次，不建议继续尝试，这种情况可以考虑更换 ChatGPT 账号 + 无痕 + 更换梯子重新订阅试试。

2023年3月24日更新：
- 如果买的ChatGPT帐号，或者自己注册，但是使用过**多个IP登录**（不同的国家和地区），升级ChatGPT的可能性不大，多半会卡在支付环节
- 建议换**新号**，这是VPS大玩家跟几百个网友交流后得出的结论
  - VPS大玩家用的是卡头为531847的美国虚拟信用卡，可以自定义帐单地址（使用免税州的地址）
- 解决方案：[ChatGPT Plus如何购买？信用卡付款失败怎么办？如何使用Apple Pay升级ChatGPT Plus](https://www.vpsdawanjia.com/6220.html)

VPS大玩家一般在Google地图上找真实地址，找地址的方法如下：
- 打开Google 地图，拉到美国那边，在地图上选一个州，放大后找当地的店铺地址或者别的机构，点一下就会在左边显示地址，具体方法参见：[如何在谷歌(Google)地图上找一个真实的美国地址](https://www.vpsdawanjia.com/2594.html)。

如果帐号曾经付款失败过，出现了以下提示：
- Your credit card was declined.Try paying with a debit card instead.
- 您的信用卡被拒绝了。请尝试用借记卡支付。
- 你的卡已被拒绝。

那这个号可能就基本上告别ChatGPT Plus了，大概率是不能付款成功的，只能换新号。可能的原因：
- 使用不干净的IP登录过ChatGPT，这个号被OpenAI列入了黑名单。

有个网友就是这个原因导致即使换IP（使用远程桌面机服务器）、换卡、换帐单地址都不能正常支付。使用干净的IP，重新注册一个新号就可以了。

### 虚拟信用卡

除了531847虚拟卡能购买Plus，556766、556735、556305以及558068这几个卡头也可以给ChatGPT付款。可以在[这里](www.vvacard.com)获得这种卡

VPS大玩家注册及使用ChatGPT的环境：美国Windows服务器，通过远程桌面连接使用, [教程](https://www.vpsdawanjia.com/6049.html)

虚拟信用卡扣款记录：
- ![](https://www.vpsdawanjia.com/wp-content/uploads/2023/03/531847chatgpt.png)

### 升级Plus

输入虚拟信用卡卡号，过期时间、CVV以及邮编，下面输入姓名、帐单地址，然后点“Set up payment method”。
- 现在的虚拟信用卡，一般都可以指定姓名，帐单地址，可以过AVS验证。
- 这里用的是556305虚拟信用卡，也是一张美国的虚拟信用卡。
- 同样用的是俄勒冈州（OR）的地址，免消费税。
- 2023年3月31日更新：
  - 现在绑卡的时候，要预扣5美元，一般会在7天内释放，不是实际扣款，然后在每个月的月底按照实际的使用金额结算。
- ![](https://www.vpsdawanjia.com/wp-content/uploads/2023/03/setpaymentmothed.png)

### GPT-4功能

GPT-4有限制：GPT-4 currently has a cap of 25 messages every 3 hours. 每3小时只能交互25次。

ChatGPT plus账户上支持选择GPT-4模型
- ![](https://chatgpt-plus.github.io/images/gpt4-3.png)

GPT-4功能 [参考](https://chatgpt-plus.github.io/page/2/)
- ![](https://chatgpt-plus.github.io/images/gpt4-4.png)
- 相比于GPT-3.5，GPT-4是新一代多模态大模型。GPT-4不仅支持文本，还支持图像输入。
- ![](https://chatgpt-plus.github.io/images/gpt4-5.gif)

访问ChatGPT Plus就拥有`Default`和`Legacy`双模型回答，以及快速、稳定的AI回复。
- ![](https://chatgpt-plus.github.io/images/10.png)

ChatGPT Plus中的default mode和legacy mode有什么区别？
- default mode就是Turbo mode，更有情感和活力，会有趣一些，不过回答上偏更加简洁，省去了之前legacy mode一些细节。
- legacy mode则更适合学术论文，不像Turbo Mode回答那么大众，适合科研，论文。
- 更详细的比较可以[参考](https://www.reddit.com/r/ChatGPT/comments/111skny/the_differences_between_default_and_legacy_models/)

### 取消Plus订阅

如何取消ChatGPT Plus的自动订阅？
- Depay信用卡其实没有透支功能，只是相当于借记卡，理论上说只要你不往卡里充钱，其实不必担心下个月被扣款。
- 不过，保险起见，你还是可以取消自动订阅，方法是：
- 打开ChatGPT首页并登录——左下角——My Account——Manage My Subscription——Cancel Plan



# 结束
