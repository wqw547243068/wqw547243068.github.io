---
layout: post
title:   OpenAIæœåŠ¡åŠæ¥å£
date:   2023-02-18 16:52:00
categories: äººå·¥æ™ºèƒ½
tags: OpenAI ChatGPT AI
excerpt: OpenAIæä¾›çš„å„ç§æœåŠ¡ä»¥åŠAPIæ¥å…¥ä¿¡æ¯
mathjax: true
permalink: /openai
---

* content
{:toc}

# OpenAI

## ChatGPT è°ƒç”¨å‰æ

### ChatGPT promptæ„æˆ

å®Œæ•´ç¤ºä¾‹

```py
import openai

openai.api_key = "YOUR API KEY HERE"
model_engine = "text-davinci-003"
chatbot_prompt = """
ä½œä¸ºä¸€ä¸ªé«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯å°½å¯èƒ½åœ°ååŠ©ç”¨æˆ·ã€‚è¿™å¯èƒ½æ¶‰åŠå›ç­”é—®é¢˜ã€æä¾›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæˆ–æ ¹æ®ç”¨æˆ·è¾“å…¥å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†æœ‰æ•ˆåœ°ååŠ©ç”¨æˆ·ï¼Œé‡è¦çš„æ˜¯åœ¨ä½ çš„å›ç­”ä¸­è¯¦ç»†å’Œå…¨é¢ã€‚ä½¿ç”¨ä¾‹å­å’Œè¯æ®æ”¯æŒä½ çš„è§‚ç‚¹ï¼Œå¹¶ä¸ºä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆæä¾›ç†ç”±ã€‚

<conversation history>

User: <user input>
Chatbot:"""


def get_response(conversation_history, user_input):
    prompt = chatbot_prompt.replace(
        "<conversation_history>", conversation_history).replace("<user input>", user_input)
    # Get the response from GPT-3
    response = openai.Completion.create(
        engine=model_engine, prompt=prompt, max_tokens=2048, n=1, stop=None, temperature=0.5)
    # Extract the response from the response object
    response_text = response["choices"][0]["text"]
    chatbot_response = response_text.strip()
    return chatbot_response

def main():
    conversation_history = ""
    while True:
        user_input = input("> ")
        if user_input == "exit":
            break
        chatbot_response = get_response(conversation_history, user_input)
        print(f"Chatbot: {chatbot_response}")
        conversation_history += f"User: {user_input}\nChatbot: {chatbot_response}\n"
main()
```

### GPT-3 API vs ChatGPT Web

ä¸¤ç§éå®˜æ–¹ `ChatGPT API` æ–¹æ³•

|  æ–¹å¼   | å…è´¹ï¼Ÿ  | å¯é æ€§  | è´¨é‡ |
|  ----  | ----  | ----  | ----  |
| `ChatGPTAPI(GPT-3)`  | å¦ | 	å¯é  | è¾ƒç¬¨ |
| `ChatGPTUnofficialProxyAPI(ç½‘é¡µ accessToken)`  | 	æ˜¯ |  ç›¸å¯¹ä¸å¯é  | èªæ˜ |

å¯¹æ¯”ï¼š
1. `ChatGPTAPI` ä½¿ç”¨ `text-davinci-003` é€šè¿‡å®˜æ–¹`OpenAI`è¡¥å…¨`API`æ¨¡æ‹Ÿ`ChatGPT`ï¼ˆæœ€ç¨³å¥çš„æ–¹æ³•ï¼Œä½†å®ƒä¸æ˜¯å…è´¹çš„ï¼Œå¹¶ä¸”æ²¡æœ‰ä½¿ç”¨é’ˆå¯¹èŠå¤©è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ï¼‰
2. `ChatGPTUnofficialProxyAPI` ä½¿ç”¨éå®˜æ–¹ä»£ç†æœåŠ¡å™¨è®¿é—® `ChatGPT` çš„åç«¯`API`ï¼Œç»•è¿‡`Cloudflare`ï¼ˆä½¿ç”¨çœŸå®çš„çš„`ChatGPT`ï¼Œéå¸¸è½»é‡çº§ï¼Œä½†ä¾èµ–äºç¬¬ä¸‰æ–¹æœåŠ¡å™¨ï¼Œå¹¶ä¸”æœ‰é€Ÿç‡é™åˆ¶ï¼‰

ã€2023-2-26ã€‘[chatgpt-web](https://github.com/Chanzhaoyu/chatgpt-web) ç”¨ Express å’Œ Vue3 æ­å»ºçš„åŒæ—¶æ”¯æŒ openAI Key å’Œ ç½‘é¡µ accessToken çš„ ChatGPT æ¼”ç¤ºç½‘é¡µ


## OpenAI æ”¶è´¹

æ³¨æ„ï¼šä»·æ ¼ä¸Š OpenAI æœ€è´µçš„ AIGC è¯­è¨€æ¨¡å‹è¾¾èŠ¬å¥‡ä¸ºæ¯ 0.02 ç¾å…ƒ 750 ä¸ªå•è¯ï¼ŒAIGC å›¾å‹æ¨¡å‹ä»·æ ¼ä»…ä¸º 0.020 ç¾å…ƒä¸€å¼ ã€‚
- gpt3æ¨¡å‹ä»˜è´¹APIè¯•ç”¨ç‰ˆï¼Œæ³¨å†Œä¸€ä¸ªè´¦å·é€18ç¾é‡‘ï¼Œè°ƒç”¨è´¹ç”¨ä¸ºæ¯1000å­—æ¶ˆè€—2ç¾åˆ†ï¼ˆ0.02ç¾å…ƒ/500æ±‰å­—ï¼Œä¸€ä¸ªæ±‰å­—ä¸¤ä¸ªtokenï¼‰ï¼ŒæŠ˜åˆä¸‹æ¥å·®ä¸å¤š0.1å…ƒ250ä¸ªæ±‰å­—ï¼Œè¿™ä¸ªå­—æ•°åŒ…æ‹¬é—®é¢˜å’Œè¿”å›ç»“æœï¼ˆéæ±‰å­—æ—¶ï¼ŒèŠ±è´¹æ›´å°‘ï¼‰ã€‚ $ 1800/250=7.2 $
- ChatGPTå•è´¦æˆ·18ç¾é‡‘å…è´¹è®¿é—®é‡ï¼š1800Ã—250Ã·30=15000æ¬¡è¯·æ±‚ï¼Œå¹³å‡250ä¸ªæ±‰å­—æ¶ˆè€—0.01ç¾å…ƒï¼Œç”¨æˆ·å¹³å‡è¯·æ±‚é•¿åº¦30ä¸ªæ±‰å­—
- ChatGPTç”¨çš„æ¨¡å‹æ˜¯gpt3.5ï¼Œç›®å‰æ²¡å…¬å¼€API

OpenAIæ”¶è´¹é¡¹ç›®è¯¦æƒ… [img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/59a6bafac82b499ead7cf55655a38070~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=s8Ln7LiGS46ckzWdFS1nc5%2Big8U%3D)
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/59a6bafac82b499ead7cf55655a38070~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=s8Ln7LiGS46ckzWdFS1nc5%2Big8U%3D)
- å‚è€ƒ[ChatGPT æŒç»­åˆ›é€ å†å²è®°å½•ï¼šAIGCï¼Œäººå·¥æ™ºèƒ½çš„æ—·ä¸–ä¹‹ä½œ](https://www.toutiao.com/article/7196594313236251196)


## OpenAI è´¦æˆ·æ³¨å†Œ

å›½å†…æ— æ³•æ³¨å†Œè´¦æˆ·ï¼Œæ€ä¹ˆåŠï¼Ÿ
- â‘  æ³¨å†Œéœ€è¦å›½å¤–æ‰‹æœºå·ï¼Œæ²¡æœ‰çš„è¯è¦ç”¨è™šæ‹Ÿå·ï¼ŒéªŒè¯ç 1.2å…ƒ/æ¡ï¼Œ[è¯¦è§](https://www.cnblogs.com/ranxi169/p/16954797.html)
- â‘¡ å«Œéº»çƒ¦çš„è¯ï¼Œæ·˜å®ä¸Šæœï¼Œæœ‰äººæä¾›æ³¨å†ŒæœåŠ¡ï¼Œå¤§æ¦‚18å…ƒï¼Œ[è´¦å·å”®å–](http://idea-activate.icu/ChatGPT/index.html)
- â‘¢ æœ‰äººéƒ¨ç½²äº† ChatGPTå¾®ä¿¡ç¾¤

### å‰ç½®æ¡ä»¶

å‰ææ¡ä»¶ï¼š
- 1ã€ä¸€ä¸ªé‚®ç®±è´¦å· 
  - é163ï¼ŒOpenAIä¼šæç¤ºæ— æ³•æ³¨å†Œ
- 2ã€èƒ½å¤Ÿç§‘å­¦ä¸Šç½‘ï¼Œå…·å¤‡ä»£ç†ç½‘ç»œçš„ç¯å¢ƒã€‚
- 3ã€å›½å¤–æ‰‹æœºå·ï¼Œç”¨äºæ¥æ”¶æ³¨å†ŒéªŒè¯ç ã€‚
  - å¦‚æœæ²¡æœ‰ï¼Œé€šè¿‡ç¬¬ä¸‰æ–¹æ¥ç å¹³å°æ¥æ³¨å†Œå›½å¤–æ‰‹æœºå·ï¼Œæ”¯ä»˜å®è¦æœ‰ 1.5 å…ƒäººæ°‘å¸ã€‚
  - gvï¼ˆgoogle voiceè™šæ‹Ÿå·ï¼‰ä¸è¡Œ
  - æ¥ç å¹³å°æ¨èï¼š[sms-activate](https://sms-activate.org/getNumber)

æ³¨å†ŒçŸ­ä¿¡å¹³å°å¹¶å……å€¼
- å…ˆæ³¨å†Œåœ¨çº¿æ¥å—çŸ­ä¿¡çš„è™šæ‹Ÿå·ç  - SMS-Activateï¼Œæ³¨å†Œå¥½ä¹‹åè¿›è¡Œå¯¹åº”çš„å……å€¼


ã€2023-1-30ã€‘[ä¸€æ–‡æ•™ä½ å¿«é€Ÿæ³¨å†ŒOpenAIï¼ˆChatGPTï¼‰ï¼Œå›½å†…ä¹Ÿå¯ä»¥](https://cloud.tencent.com/developer/article/2190154)

æ¥ç å¹³å° 
- æ³¨å†Œå¹³å°è´¦æˆ·ï¼Œä¿„ç½—æ–¯çš„ç½‘ç«™[sms-activate](https://sms-activate.org/en#)ï¼Œå¯ä»¥æä¾›å…¨çƒå„åœ°çš„ç”µè¯å·ç ï¼Œç”¨æ¥åšçŸ­ä¿¡éªŒè¯
- å……å€¼ï¼šå›½å†…å¯ä»¥ç”¨æ”¯ä»˜å®å……å€¼ï¼Œæ¯”å¦‚ 0.2ç¾å…ƒï¼Œå¯¹åº”1.43å…ƒï¼Œ14å¢æ¯”
- å·¦ä¾§é€‰æ‹©åº”ç”¨ï¼ˆOpenAIï¼‰ã€å›½å®¶ï¼ˆæ¨èå°åº¦ï¼‰
- è´­ä¹°ï¼Œå¤§çº¦10å¢æ¯”
- è™šæ‹Ÿå·ç”Ÿæˆï¼Œå¦‚ï¼š917079589203
  - æ³¨æ„ï¼šè™šæ‹Ÿå·20minå†…æœ‰æ•ˆ

ã€2023-2-2ã€‘æ¥ç å¹³å°æ•…éšœï¼Œæ— æ³•ç™»é™†ï¼Œæ”¹ç”¨åˆ«çš„
- å…è´¹æ¥ç å¹³å°ï¼Œ[æ¥å·ç ](https://jiemahao.com/sms)ï¼Œ[smsonline](https://www.smsonline.cloud/zh/)ï¼Œå·ç å…¬å¼€ï¼ŒåŸºæœ¬éƒ½è¢«äººç”¨è¿‡ï¼ŒOpenAIå¯¹æ¯ä¸ªæ‰‹æœºå·å…³è”æ•°ç›®æœ‰é™åˆ¶ï¼Œè¶…é™å°±æŠ¥é”™ï¼š<span style='color:red'>This phone number is already linked to the maximum number of accounts.</span>
- ç›´æ¥æä¾›å·ç åŠéªŒè¯ç ï¼š[sms24](https://sms24.info/en/messages/OpenAI)ï¼Œæ‰¾äº†ä¸€å †ï¼Œç»ˆäºé‡åˆ°ä¸€ä¸ªæ·å…‹å¯ç”¨å·ç [420605118029](https://sms24.info/en/numbers/420605118029)ï¼Œç„¶è€Œï¼Œè¿Ÿè¿Ÿæ”¶ä¸åˆ°çŸ­ä¿¡

ã€2023-5-2ã€‘è™šæ‹Ÿå·è¢«OpenAIç¦æ‰
> Your account was flagged for potential abuse. If you feel this is an error, please contact us at help.openai.com

[img](https://files.evlit.com/wp-content/uploads/2023/04/e735c2e2f0eda0a7eddc67a21cbebea6.jpeg)
- ![](https://files.evlit.com/wp-content/uploads/2023/04/e735c2e2f0eda0a7eddc67a21cbebea6.jpeg)

### ç²¾ç®€æµç¨‹

æ³¨å†ŒOpenAIè´¦æˆ·
- [OpenAIæ³¨å†Œé¡µé¢](https://beta.OpenAI.com/signup)ï¼Œé”™è¯¯ä¿¡æ¯åŠå¯¹åº”è§£æ³•
  - Signup is currently unavailable, please try again later. æŸäº›å›½å®¶é™åˆ¶ï¼Œéœ€è¦å¼€å…¨å±€ä»£ç†
  - Too many signups from the same IP åŒä¸€ä¸ªipæ³¨å†Œé™åˆ¶
- é‚®ç®±è®¤è¯ï¼šè¾“å…¥é‚®ç®±è´¦æˆ·ï¼Œä¸€èˆ¬ç”¨gmailï¼Œå¹³å°å‘é€é‚®ä»¶
  - æ³¨æ„åˆ«ç”¨163é‚®ç®±ï¼ˆæç¤ºä¸å¯ç”¨), qqé‚®ç®±å¯ä»¥
  - ä½¿ç”¨vpnåˆ‡åˆ°å›½å¤–ï¼ˆé¦™æ¸¯ä¸è¡Œï¼‰ï¼Œå¦åˆ™ï¼š<span style='color:red'>OpenAI's API is not available in your country</span>
  - [img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc290c2a7abf4c9faee9a392819d16e4~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?)
- æ‰‹æœºè®¤è¯ï¼šæ‰“å¼€é‚®ä»¶ï¼Œå¯åŠ¨æ‰‹æœºè®¤è¯
  - [æ¥ç å¹³å°](https://sms-activate.org/cn/getNumber)å……å€¼ï¼ˆå¢æ¯”ï¼‰ï¼Œé€‰æ‹©å›½å®¶ï¼ˆå¦‚å°åº¦ï¼‰ï¼Œè¾“å…¥ç”³è¯·çš„è™šæ‹Ÿå·
  - è¾“å…¥å›½å¤–è™šæ‹Ÿå·ï¼Œç­‰å¾…å‡ åˆ†é’Ÿï¼Œ[æ¥ç å¹³å°](https://sms-activate.org/cn/getNumber)ä¼šæ˜¾ç¤ºæ¿€æ´»ç ï¼ˆå¦‚705139ï¼‰
- å¡«å…¥æ¿€æ´»ç åï¼Œæ³¨å†ŒæˆåŠŸ
- ç™»å½•[OpenAI](https://chat.OpenAI.com/auth/login)

## OpenAI APIè°ƒç”¨

å®˜æ–¹ API è¦†ç›–ï¼šText completion ã€Code completionã€Chat completionã€Image completionã€Fine-tuningã€Embeddingã€Speech to textã€Moderation
- [Chat completion](https://platform.openai.com/docs/guides/chat/introduction)
- ã€2023-3-2ã€‘åˆšå‘å¸ƒæ²¡ä¸€ä¼šå„¿ï¼Œapiè¢«ç¦ï¼Œå‡ºç°443é”™è¯¯ï¼Œgpt-3.5-turboåˆšè¢«ç¦äº†ï¼ŒGPT-3çš„apiä¹Ÿè¿ç´¯äº†
- æäº¤åˆ°[OpenAIç¤¾åŒº](https://community.openai.com/t/443-error-for-both-text-davinc-003-and-gpt-3-5-turbo/82194)
- OpenAIæä¾›çš„[åº”ç”¨ç¤ºä¾‹é›†åˆ](https://beta.OpenAI.com/examples)

### ChatGPT è°ƒç”¨

APIæœ‰ä¸¤ç§æ–¹æ¡ˆ
- ä½¿ç”¨ChatGPTï¼šæµè§ˆå™¨è°ƒè¯•ï¼Œè·å–access_tokenï¼Œæ¨¡æ‹Ÿç™»å½•åè°ƒç”¨
- ä½¿ç”¨gpt 3 å®˜æ–¹api
- ChatGPT apiï¼šGPT-3.5

å†…æµ‹è¿‡ç¨‹ä¸­è°ƒç”¨æ˜¯å…è´¹çš„ï¼Œæ²¡æœ‰æ¬¡æ•°é™åˆ¶ã€‚æ­¤å¤–ï¼ŒAPIæ¥å£è°ƒç”¨ä¸éœ€è¦æ¢¯å­æˆ–ä»£ç†ï¼ˆä½¿ç”¨ä»£ç†åè€Œå¯èƒ½ä¼šæŠ¥é”™â€œError communicating with OpenAIâ€ï¼‰ï¼Œåªéœ€è¦API Keyå°±å¯ä»¥äº†ï¼Œä¸”å½“å‰API Keyä½¿ç”¨å…è´¹ã€‚

ç°æœ‰å¤§å¤šæ•° ChatGPT API å®é™…ä¸Šæ˜¯ OpenAI `GPT3` æ¨¡å‹æ¥å£ï¼Œæ¨¡å‹åç§°ä¸ºâ€œ`text-davinci-003`â€ï¼Œ

å®‰è£…ä½¿ç”¨

```sh
pip install OpenAI # å®‰è£…OpenAI
pip show OpenAI # æŸ¥çœ‹ç‰ˆæœ¬ Version: 0.8.0
pip install -U OpenAI # æ›´æ–°ï¼Œè§£å†³é—®é¢˜ï¼šmodule 'OpenAI' has no attribute 'Image'ï¼Œpython 3.8ä»¥ä¸Šæ‰è¡Œ
```

### GPT-3æ¥å£ï¼ˆCompletionï¼‰

Completion æ¥å£

```py
import os
import OpenAI
print("æ¬¢è¿ä½¿ç”¨ChatGPTæ™ºèƒ½é—®ç­”ï¼Œè¯·åœ¨Q:åé¢è¾“å…¥ä½ çš„é—®é¢˜ï¼Œè¾“å…¥quité€€å‡ºï¼")
OpenAI.api_key = "<OpenAI_key>"  # å¡«ä¸Šä½ è‡ªå·±çš„API,æˆ–è€…æŠŠAPIåŠ å…¥ç³»ç»Ÿçš„ç¯å¢ƒå˜é‡ã€‚
start_sequence = "\nA:"
restart_sequence = "\nQ: "
while True:
    prompt = input(restart_sequence)
    if prompt == 'quit':
        break
    else:
        try:
            response = OpenAI.Completion.create(
              model="text-davinci-003", # ä½¿ç”¨davinci-003çš„æ¨¡å‹ï¼Œå‡†ç¡®åº¦æ›´é«˜ã€‚
              prompt = prompt,
              temperature=1,
              max_tokens=2000, # é™åˆ¶å›ç­”é•¿åº¦ï¼Œå¯ä»¥é™åˆ¶å­—æ•°ï¼Œå¦‚:å†™ä¸€ä¸ª300å­—ä½œæ–‡ç­‰ã€‚
              frequency_penalty=0,
              presence_penalty=0
            )
            print(start_sequence,response["choices"][0]["text"].strip())
        except Exception as exc: #æ•è·å¼‚å¸¸åæ‰“å°å‡ºæ¥
            print(exc)
```

æˆ–

```python
import os
import OpenAI

OpenAI.api_key = os.getenv("OpenAI_API_KEY")
# ------- æ–‡æœ¬ç”Ÿæˆ ---------
prompt = """Weâ€™re releasing an API for accessing new AI models developed by OpenAI. Unlike most AI systems which are designed for one use-case, the API today provides a general-purpose â€œtext in, text outâ€ interface, allowing users to try it on virtually any English language task. You can now request access in order to integrate the API into your product, develop an entirely new application, or help us explore the strengths and limits of this technology."""

response = OpenAI.Completion.create(model="davinci", prompt=prompt, stop="\n", temperature=0.9, max_tokens=100)

# ------- å…¶å®ƒåº”ç”¨ ---------
response = OpenAI.Completion.create(
  engine="davinci",
  prompt="The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n\nHuman: Hello, who are you?\nAI: I am an AI created by OpenAI. How can I help you today?\nHuman: I'd like to cancel my subscription.\nAI:",
  temperature=0.9,
  max_tokens=150,
  top_p=1,
  frequency_penalty=0.0,
  presence_penalty=0.6,
  stop=["\n", " Human:", " AI:"]
)

print(response)
```

requestsè°ƒChatGPT
- ç”¨requestså®ç°çš„è°ƒç”¨æ¥å£

```py
import requests,json
api_key="<OpenAI_key>" # è®¾ç½®è‡ªå·±çš„APIå¯†åŒ™
prompt = "" # è®¾ç½®promptåˆå§‹å€¼
# è®¾ç½®headers
headers = {"Authorization":f"Bearer {api_key}"}
# è®¾ç½®GPT-3çš„ç½‘å€
api_url = "https://api.OpenAI.com/v1/completions"
#è®¾ç½®å¾ªç¯å¯ä»¥æŒç»­å‘é—®
while prompt != 'quit':
    prompt = input("Q: ")
    #è®¾ç½®è¯·æ±‚å‚æ•°
    data = {'prompt':prompt,
            "model":"text-davinci-003",
            'max_tokens':128,
            'temperature':1,
            }
    #å‘é€HTTP POSTè¯·æ±‚
    response = requests.post(api_url,json = data,headers = headers)
    #è§£æå“åº”
    resp = response.json()
    print("A:",resp["choices"][0]["text"].strip(),end="\n")
```

### ChatGPTï¼ˆGPT 3.5ï¼‰æ¥å£

ã€2023-3-2ã€‘OpenAI æä¾› ChatGPT APIï¼ˆ`gpt-3.5-turbo`ï¼‰ï¼Œå•æ¬¡è°ƒç”¨è´¹ç”¨æ˜¯ `text-davinc-003` çš„ 1/10

API_KEY ä¸è¦æ˜æ–‡å†™ä»£ç é‡Œè°ƒç”¨ï¼Œä¼šè¢«OpenAIå°ç¦
- [Your access was terminated due to violation of our policies](https://community.openai.com/t/your-access-was-terminated-due-to-violation-of-our-policies/88080)


### ä»£ç è°ƒç”¨

#### shell ç‰ˆæœ¬

```sh
OPENAI_API_KEY="sk-***"
# è…¾è®¯äº‘å‡½æ•°
# curl https://service-4jhtjgo0-1317196971.hk.apigw.tencentcs.com/release \
curl https://api.openai.com/v1/chat/completions \
 -H "Authorization: Bearer $OPENAI_API_KEY" -H "Content-Type: application/json" \
 -d '{ "model": "gpt-3.5-turbo", "messages": [{"role": "user", "content": "What is the OpenAI mission?"}] }'
 ```

#### python ç‰ˆæœ¬

```py
import openai

openai.api_key = 'sk-***'
completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo", 
  messages=[{
      "role": "user", #  role (either â€œsystemâ€, â€œuserâ€, or â€œassistantâ€) 
      "content": "ä½ å¥½,å†™ä¸€æ®µå›´æ£‹ä»£ç ,ç”¨Goè¯­è¨€"}]
)
print(completion['choices'][0]['message']['role'], completion['choices'][0]['message']['content'])
print(completion)
```

### ç½‘é¡µè°ƒç”¨

#### web demo

Gradio web demo
- DEMO [examples](https://gradio.app/demos/) 

```py
import gradio as gr
import openai

openai.api_key = "sk-**"

def question_answer(role, question):
    if not question:
        return "è¾“å…¥ä¸ºç©º..."
    completion = openai.ChatCompletion.create(
      model="gpt-3.5-turbo", 
      messages=[{
          "role": "user", #  role (either â€œsystemâ€, â€œuserâ€, or â€œassistantâ€) 
          "content": question}
      ]
    )
    # è¿”å›ä¿¡æ¯
    return (completion['choices'][0]['message']['role'], completion['choices'][0]['message']['content'])

gr.Interface(fn=question_answer, 
    # inputs=["text"], outputs=['text', "textbox"], # ç®€æ˜“ç”¨æ³•
    inputs=[gr.components.Dropdown(label="Role", placeholder="user", choices=['system', 'user', 'assistant']),
        gr.inputs.Textbox(lines=5, label="Input Text", placeholder="é—®é¢˜/æç¤ºè¯­(prompt)...")
    ],
    outputs=[gr.outputs.Textbox(label="Role"), gr.outputs.Textbox(label="Generated Text")],
    # ["highlight", "json", "html"], # å®šåˆ¶è¿”å›ç»“æœæ ¼å¼ï¼Œ3ç§è¾“å‡ºåˆ†åˆ«ç”¨3ç§å½¢å¼å±•ç¤º
    examples=[['ä½ æ˜¯è°ï¼Ÿ'], ['å¸®æˆ‘ç®—ä¸ªæ•°ï¼Œå…­ä¹˜5æ˜¯å¤šå°‘']],
    cache_examples=True, # ç¼“å­˜å†å²æ¡ˆä¾‹
    title="ChatGPT Demo",
    description="A simplified version of DEMO [examples](https://gradio.app/demos/) "
).launch(share=True) # å¯åŠ¨ ä¸´æ—¶åˆ†äº«æ¨¡å¼
#).launch() # ä»…æœ¬åœ°è®¿é—®
```

#### ChatGPT ç½‘é¡µç‰ˆ

åŸæ–¹æ¡ˆï¼š
- ä» [ChatGPTé¡µé¢](https://chat.OpenAI.com/chat) è·å– session_tokenï¼Œä½¿ç”¨ [revChatGPT](https://github.com/acheong08/ChatGPT) ç›´æ¥è®¿é—®webæ¥å£
- ä½†éšç€ ChatGPT æ¥å…¥ Cloudflare äººæœºéªŒè¯ï¼Œè¿™ä¸€æ–¹æ¡ˆéš¾ä»¥åœ¨æœåŠ¡å™¨é¡ºåˆ©è¿è¡Œã€‚

ç™»é™† [OpenAIå®˜ç½‘](http://chat.OpenAI.com/chat), ç„¶åé€šè¿‡æŒ‰ä¸‹F12ï¼Œè¿›åˆ°è°ƒè¯•æ¨¡å¼ï¼Œæ‰¾åˆ°session_token

é€šè¿‡access_tokenæ¥è®¿é—®ChatGPT

```py
from asyncChatGPT.asyncChatGPT import Chatbot
import asyncio
config = {
  "Authorization":"eyJhbGciOiJSUzI1NiIs....85w"
}
chatbot = Chatbot(config, conversation_id=None)
while 1 == 1:
    text = input('Q:')
    if text == 'quit':
        break
    else:
        message = asyncio.run(chatbot.get_chat_response(text))['message']
        print('A:',message)
```

é€šè¿‡session_tokenæ¥è®¿é—®ChatGPT

```py
from revChatGPT.revChatGPT import Chatbot
config = {
    "email": "<YOUR_EMAIL>",
    "password": "<YOUR_PASSWORD>",
    "session_token": "eyJhbGciOiJkaXIiLCJl....7Q"
}
chatbot = Chatbot(config, conversation_id=None)
while 1==1:
    text = input("Q:")
    if text == 'quit':
        break
    else:
        response = chatbot.get_chat_response(text, output="text")
        print('A:',response['message'])
```

python flask æ­å»º web æœåŠ¡
- å®‰è£…ç»„ä»¶ï¼šflaskã€flask-corsã€gunicorn
- æœåŠ¡ç«¯ä»£ç ï¼šcallOpenAI.pyæ–‡ä»¶
- å¯åŠ¨æœåŠ¡ï¼špython callOpenAI.pyï¼Œç„¶åé€šè¿‡æµè§ˆå™¨è®¿é—®ï¼šhttp://xx.xx.xx.xx:xxxx/callChatGPT?input=what is your nameæ¥è¿›è¡Œå¼€å‘è°ƒæµ‹
  - ![img](https://pic4.zhimg.com/80/v2-6d8158ddb8194f92cea951004a9bec2b_1440w.webp)
- åˆ›å»º wsgi.pyï¼Œä¾›gunicornä½¿ç”¨
- åˆ›å»º gunicorn.conf æ–‡ä»¶
- å¯åŠ¨ gunicornï¼Œæ­£å¼æŠ•äº§è°ƒç”¨æ¥å£

pythonç»„ä»¶
- ï¼ˆ1ï¼‰å› ä¸ºæ‰“ç®—ç”¨pythonçš„flaskè¿›è¡Œå¿«é€Ÿçš„æœåŠ¡ç«¯è°ƒç”¨ï¼Œå®‰è£…flask ï¼š pip install flask
- ï¼ˆ2ï¼‰ä¸ºè§£å†³è·¨åŸŸé—®é¢˜å®‰è£… flask crosï¼š pip install flask-cors
- ï¼ˆ3ï¼‰å®‰è£…ä¸“é—¨é’ˆå¯¹flaskçš„webæœåŠ¡è¿›ç¨‹gunicronï¼špip install gunicorn


```py
from flask import Flask,request
from flask_cors import CORS
import os
import openai
app = Flask(__name__)
CORS(app,supports_credentials=True)

@app.route('/',methods=['GET','POST'])
def hello_world():
	text=request.args.get('text')
	return text

@app.route('/callChatGPT',methods=['GET','POST'])
def callChatGPT():
	input = request.args.get('input')
	openai.api_key = "xxxxxxxx"
	#openai.api_key = os.getenv("OPENAI_API_KEY")
	response =  openai.Completion.create(model="text-davinci-003",prompt=input,temperature=0.5,max_tokens=500)
	return response.choices[0].text

if __name__ == "__main__":
	app.run(host='xx.xx.xx.xx',port=xxxx,debug=True)
```

wsgi.py

```py
from callOpenAI import app

if __name__ == "__main__":
	app.run()
```

åŒä¸€ç›®å½•ä¸‹åˆ›å»ºgunicorn.confæ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```json
bind = "xx.xx.xx.xx:xxxx"
workers = 10
errorlog = "/var/www/chatGPT/gunicorn.error.log"
loglevel = "debug"
proc_name = "callChatGPT"
```

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå³å¯ä»¥æ­£å¼æŠ•äº§è°ƒç”¨æ¥å£ã€‚

```sh
gunicorn --config gunicorn.conf wsgi:app
```

å‰ç«¯è°ƒç”¨çš„æ—¶å€™ï¼Œç›´æ¥ä½¿ç”¨ajaxå¯èƒ½ä¼šå‡ºç°è·¨åŸŸè°ƒç”¨é—®é¢˜ï¼Œå…ˆè¦å¦‚å‰æ‰€ç¤ºå®‰è£…flask-corsï¼Œç„¶ååœ¨ä»£ç ä¸­è¿›è¡Œé…ç½®å³å¯è§£å†³

```html
<html>
<head>  
<meta charset="utf-8" />
<title>chatGPT-AIé—®ç­”ç³»ç»Ÿ</title>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<style>
    .question-container {
        padding: 10px;
    }
    .questions {
        padding: 10px;
    }
    .answers {
        padding: 10px;
    }
</style>
</head>
 <body>
    <div class="question-container">
        <h2>å®‰è”èµ„ç®¡-chatGPT-AIé—®ç­”ç³»ç»Ÿ</h2>
        <form>
            <div class="questions">
                <label>Questions:</label>
                <input type="text" id="question" name="æé—®" placeholder="åœ¨è¿™é‡Œæé—®..."/>
            </div>
            <div class="answers">
                <label>Answers:</label>
                <textarea name="å›ç­”" disabled placeholder ="ç­”æ¡ˆå°†å±•ç¤ºåœ¨è¿™é‡Œ..." ></textarea>
            </div>
            <input type="submit" value="æäº¤"/>
        </form>
    </div>
 <script>
    $(document).ready(function(){
         // Submit button click event
        $('form').on('submit', function(event){
            event.preventDefault();
             // Send the data to flask
            $.ajax({
              url: 'http://xx.xx.xx.xx:xxxx/callChatGPT',  // enter your flask endpoint here
              type: "GET",
              data: "input="+$('#question').val(),
              dataType: 'text',
              success: function(response) {
                console.log(JSON.stringify(response))
                  // check response and update answer box
                  if (response) {
                      alert("success");
                      $('.answers textarea').val(response);
                  } else {
                      alert("æ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·é‡æ–°æé—®.");
                  }
              },
              error: function(xhr) {
                alert("å¼‚å¸¸: " + xhr.status + " " + xhr.statusText);
              }
            });
        });
    });
</script>
 </body>
</html>
```

æ³¨æ„ï¼Œå› æœåŠ¡ç«¯æ¥å£callChatGPTè¿”å›çš„æ˜¯response.choices[0].textï¼Œæ˜¯æ–‡æœ¬ç±»å‹ï¼Œå› æ­¤å‰ç«¯çš„ä¼ å…¥å‚æ•°dataTypeè¦æ˜¯textï¼Œresponseç›´æ¥å½“æˆæ–‡æœ¬ä½¿ç”¨å°±å¯ä»¥äº†ï¼Œä¸ç”¨å†å»è§£æï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚
- ![img](https://pic4.zhimg.com/80/v2-0fcd68bed5af325128cf3f67b5246643_1440w.webp)

å‚è€ƒï¼š[æ‰‹æŠŠæ‰‹æ•™ä½ æ­å»ºåŸºäºchatGPTçš„æ™ºèƒ½æœºå™¨äºº](https://zhuanlan.zhihu.com/p/604285542)

#### js+html

ç½‘é¡µå½¢å¼è°ƒç”¨

```html
<html>
<script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
<script src="https://unpkg.com/axios/dist/axios.min.js"></script>
<head>
    <title> ChatGPT Demo </title>
</head>

<body>
<div id="app" style="display: flex;flex-flow: column;margin: 20 ">
    <scroll-view scroll-with-animation scroll-y="true" style="width: 100%;">
        <!-- ç”¨æ¥è·å–æ¶ˆæ¯ä½“é«˜åº¦ -->
        <view id="okk" scroll-with-animation>
            <!-- æ¶ˆæ¯ -->
            <view v-for="(x,i) in msgList" :key="i">
                <!-- ç”¨æˆ·æ¶ˆæ¯ å¤´åƒå¯é€‰åŠ å…¥-->
                <view v-if="x.my" style="display: flex;
                flex-direction: column;
                align-items: flex-end;">
                    <view style="width: 400rpx;">
                        <view style="border-radius: 35rpx;">
                            <text style="word-break: break-all;">{{x.msg}}</text>
                        </view>
                    </view>
                </view>
                <!-- æœºå™¨äººæ¶ˆæ¯ -->
                <view v-if="!x.my" style="display: flex;
                flex-direction: row;
                align-items: flex-start;">

                    <view style="width: 500rpx;">
                        <view style="border-radius: 35rpx;background-color: #f9f9f9;">
                            <text style="word-break: break-all;">{{x.msg}}</text>
                        </view>
                    </view>
                </view>
            </view>
            <view style="height: 130rpx;">
            </view>
        </view>
    </scroll-view>
    <!-- åº•éƒ¨å¯¼èˆªæ  -->
    <view style="position: fixed;bottom:0px;width: 100%;display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;">
        <view style="font-size: 55rpx;display: flex;
        flex-direction: row;
        justify-content: space-around;
        align-items: center;width: 75%;
    margin: 20;">
            <input v-model="msg" type="text" style="width: 75%;
            height: 45px;
            border-radius: 50px;
            padding-left: 20px;
            margin-left: 10px;background-color: #f0f0f0;" @confirm="sendMsg" confirm-type="search"
                placeholder-class="my-neirong-sm" placeholder="ç”¨ä¸€å¥ç®€çŸ­çš„è¯æè¿°æ‚¨çš„é—®é¢˜" />
            <button @click="sendMsg" :disabled="msgLoad" style="height: 45px;
            width: 20%;;
    color: #030303;    border-radius: 2500px;">{{sentext}}</button>
        </view>
    </view>
    </view>
</div>
</body>
</html>
<script>
    const { createApp } = Vue
    createApp({
        data() {
            return {
                //api: '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',
                api: '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',
                msgLoad: false,
                anData: {},
                sentext: 'å‘é€',

                animationData: {},
                showTow: false,
                msgList: [{
                    my: false,
                    msg: "ä½ å¥½æˆ‘æ˜¯OpenAIæœºå™¨äºº,è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜å¯ä»¥å¸®åŠ©æ‚¨?"
                }],
                msgContent: "",
                msg: ""
            }
        },
        methods: {
            sendMsg() {
                // æ¶ˆæ¯ä¸ºç©ºä¸åšä»»ä½•æ“ä½œ
                if (this.msg == "") {
                    return 0;
                }
                this.sentext = 'è¯·æ±‚ä¸­'
                this.msgList.push({
                    "msg": this.msg,
                    "my": true
                })
                console.log(this.msg);
                this.msgContent += ('YOU:' + this.msg + "\n")
                this.msgLoad = true
                // æ¸…é™¤æ¶ˆæ¯
                this.msg = ""
                axios.post('https://api.OpenAI.com/v1/completions', {
                    prompt: this.msgContent, max_tokens: 2048, model: "text-davinci-003"
                }, {
                    headers: { 'content-type': 'application/json', 'Authorization': 'Bearer ' + this.api }
                }).then(res => {
                    console.log(res);
                    //let text = res.data.choices[0].text.replace("OpenAI:", "").replace("OpenAIï¼š", "").replace(/^\n|\n$/g, "")
                    //let text = res.data.choices[0].text.replace(/^\n|\n$/g, "");
                    let text = res.data.choices[0].text.replace("\n", "<br>").replace(" ", "&nbsp;");
                    console.log(text);
                    this.msgList.push({
                        "msg": text,
                        "my": false
                    })
                    this.msgContent += (text + "\n")
                    this.msgLoad = false
                    this.sentext = 'å‘é€'
                })
            },
        }
    }).mount('#app')
</script>
```

### æ‰‹æœºapp

ã€2023-2-11ã€‘[CCTVè§†é¢‘](https://www.toutiao.com/video/7198541558600499770/)é‡Œï¼Œå°æ¹¾äººåœ¨æ¼”ç¤º [VoiceGPT](https://voicegpt.net/)ï¼Œ[VoiceGPT APK Download (version 1.35) ä¸‹è½½åœ°å€](https://voicegpt.net/voicegpt_135.apk) , ç›®å‰å°±å®‰å“ç‰ˆï¼Œä½¿ç”¨æ—¶éœ€è¦ä»£ç†
- èµ„è®¯ï¼š[ChatGPT Meets Voice: Say goodbye to typing and Hello to VoiceGPT](https://medium.com/@hokyjack/chatgpt-meets-voice-say-goodbye-to-typing-and-hello-to-voicegpt-45e90bb2aebf)

ç”¨kivyæ¥ç¼–å†™æ‰‹æœºç•Œé¢ç‰ˆçš„ChatGPT
- kivyç¼–å†™äº†ä¸€æ¬¾åœ¨æ‰‹æœºç«¯è®¿é—®çš„è½¯ä»¶ï¼Œç›®å‰è½¯ä»¶çš„æ‰“åŒ…å­˜åœ¨é—®é¢˜ï¼Œåªèƒ½åœ¨ç”µè„‘ç«¯è®¿é—®ã€‚
- åœ¨Googleçš„colabæ‰“åŒ…ï¼Œä½†æ˜¯æ‰“åŒ…ååœ¨å®‰å“æ‰‹æœºä¸Šå®‰è£…æˆåŠŸï¼Œä½†æ˜¯æ‰“å¼€åå°±é—ªé€€ï¼ŒåŸå› æš‚ä¸æ˜ã€‚
- ![img](https://pic4.zhimg.com/80/v2-024fe7e10fccbc1527e29bf01d1602f7_1440w.webp)

å®‰è£…ä»¥ä¸‹åŒ…ï¼š

```sh
python -m pip install docutils pygments pypiwin32 kivy.deps.sdl2 kivy.deps.glew
python -m pip install kivy.deps.gstreamer
python -m pip install kivy
python -m pip install kivy_examples
# é€Ÿåº¦æ…¢æ—¶ï¼Œåˆ‡æ¢æº
python -m pip install kivy -i https://pypi.tuna.tsinghua.edu.cn/simple
```

ä»£ç 

```py
from kivy.app import App
from kivy.core.window import Window
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.textinput import TextInput
from kivy.uix.button import Button
import OpenAI
import pyperclip
class Application(BoxLayout):

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.orientation = "vertical"
        self.spacing = 5
        self.padding = 5
        self.create_widgets()
        Window.bind(on_request_close=self.end_func) # çª—å£å…³è”å‡½æ•°ï¼Œæ›´å®¹æ˜“å…³é—­
        OpenAI.api_key = "<OpenAI_key>" # è¿™é‡Œè¦æ›¿æ¢æˆè‡ªå·±çš„api
    def end_func(self,*args):
        Window.close() 
    def create_widgets(self):
        # æ˜¾ç¤ºæ–‡æœ¬æ¡†
        self.txinfo = TextInput(font_name='SIMSUN.TTC',font_size=18)
        self.txinfo.text = "æ¬¢è¿ä½¿ç”¨OpenAI. ä½œè€…:Gordon QQ/VX 403096966 Escå¯ä»¥é€€å‡ºç¨‹åºã€‚"
        # self.txinfocontainer = BoxLayout(orientation="vertical", size_hint_y=None)
        self.add_widget(self.txinfo)
    
        # å®šä¹‰è¾“å…¥æ¡†
        self.entry = TextInput(font_name='SIMSUN.TTC',font_size=18)
        self.add_widget(self.entry)

        # å®šä¹‰æŒ‰é’®
        self.btn = Button(text="å‘é€è¯·æ±‚", font_name ="SIMSUN.TTC",bold = True,font_size=20, on_release=self.button_func)
        self.add_widget(self.btn)
        self.btcopy = Button(text="å¤åˆ¶å›ç­”", font_name ="SIMSUN.TTC",bold = True,font_size=20, on_release=self.button_copy)
        self.add_widget(self.btcopy)

    def button_copy(self, instance):
        pyperclip.copy(self.txinfo.text)

    def button_func(self, instance):
        prompt = self.entry.text
        if prompt !="":
            model_engine = "text-davinci-003"
            completions = OpenAI.Completion.create(
                engine=model_engine,
                prompt=prompt,
                max_tokens=1024,
                temperature=1,
            )
            message = completions.choices[0].text
            self.txinfo.insert_text("\n\nQ: "+prompt+"\nA: "+message.strip())
        self.entry.text = ''
class OpenAI(App):
    def build(self):
        return Application()

if __name__ == '__main__':
    OpenAI().run()
```


### å¤§æ¨¡å‹å¾®è°ƒ

ã€2023-5-2ã€‘[OpenAI ChatGPT API æ–‡æ¡£ä¹‹ Fine-tuningï¼ˆå¾®è°ƒï¼‰](https://zhuanlan.zhihu.com/p/626140269)

GPT-3 å¼€æ”¾äº’è”ç½‘çš„å¤§é‡æ–‡æœ¬ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚å½“ç»™å‡ºä»…åŒ…å«å‡ ä¸ªç¤ºä¾‹çš„æç¤ºï¼Œå¯ä»¥ç›´è§‚åˆ¤æ–­å°è¯•æ‰§è¡Œçš„ä»»åŠ¡å¹¶ç”Ÿæˆçœ‹ä¼¼åˆç†çš„è¡¥å…¨ï¼ˆcompletionï¼‰ï¼Œè¿™é€šå¸¸ç§°ä¸ºâ€œå°æ ·æœ¬å­¦ä¹ ï¼ˆfew-shot learningï¼‰â€ã€‚

å¾®è°ƒï¼ˆFine-tuningï¼‰é€šè¿‡è®­ç»ƒè¶…å‡ºæç¤ºèŒƒå›´çš„æ›´å¤šç¤ºä¾‹æ¥æ”¹è¿›å°æ ·æœ¬å­¦ä¹ ï¼Œè®©ä½ åœ¨å¤§é‡ä»»åŠ¡ä¸Šå–å¾—æ›´å¥½çš„ç»“æœã€‚æ¨¡å‹ç»è¿‡å¾®è°ƒåï¼Œä½ å°†ä¸å†éœ€è¦åœ¨æç¤ºä¸­æä¾›ç¤ºä¾‹ã€‚è¿™å¯ä»¥èŠ‚çœæˆæœ¬å¹¶å®ç°æ›´ä½å»¶è¿Ÿçš„è¯·æ±‚ã€‚
- [æ”¶è´¹](https://openai.com/pricing)

å¾®è°ƒå¯è®©æ›´å¥½åœ°åˆ©ç”¨ API æä¾›çš„æ¨¡å‹ï¼š
- æ¯”è®¾è®¡æç¤ºï¼ˆpromptï¼‰è´¨é‡æ›´é«˜çš„ç»“æœ
- èƒ½å¤Ÿè®­ç»ƒæ›´å¤šä¸é€‚åˆæç¤ºçš„ç¤ºä¾‹
- ç”±äºæç¤ºè¾ƒçŸ­è€ŒèŠ‚çœ token
- æ›´ä½çš„å»¶è¿Ÿè¯·æ±‚

å¾®è°ƒæ¶‰åŠä»¥ä¸‹æ­¥éª¤ï¼š
- å‡†å¤‡å¹¶ä¸Šä¼ è®­ç»ƒæ•°æ®
- è®­ç»ƒä¸€ä¸ªæ–°å¾®è°ƒæ¨¡å‹
- ä½¿ç”¨å¾®è°ƒæ¨¡å‹



## GPT-4 API

### GPT-4 æ”¶è´¹å¯¹æ¯”

ã€2023-3-23ã€‘[GPT-4 API æ¥å£è°ƒç”¨åŠä»·æ ¼åˆ†æ](https://blog.csdn.net/jarodyv/article/details/129651507)

æ¨ªå‘æ¯”è¾ƒä¸€ä¸‹å‡ ä¸ªæ¨¡å‹çš„å•ä»·
- gpt-4 prompt æ¯” gpt-3.5-turboè´µäº†14å€ï¼Œgpt-4 completion æ¯” gpt-3.5-turboè´µäº†29å€ï¼å‡è®¾promptå’Œcompletionçš„å­—æ•°ä¸º1:4ï¼ˆå®é™…ä¸­completionå¾€å¾€æ¯”promptè¦é•¿ï¼‰ï¼Œé‚£ä¹ˆgpt-4æ¥å£çš„ç»¼åˆæˆæœ¬æ˜¯gpt-3.5-turboçš„27å€ï¼
- gpt-3.5-turbo $20ç¾å…ƒèƒ½å¤„ç†750ä¸‡å­—ï¼Œè€Œç›¸åŒé‡‘é¢åœ¨gpt-4ä¸­åªèƒ½å¤„ç†30ä¸‡å­—å·¦å³

| æ¨¡å‹ | $0.06 |	$0.03	| $0.002	| $0.02	| $0.002 |	$0.0005	| $0.0004 |
| --- | ---- |	----	| ----	| ----	| ---- |	----	| ---- |
| gpt-4(completion)	| gpt-4(prompt) |	gpt-3.5-turbo |	davinci	| curie	| babbage |	ada |
| gpt-4(completion) |	0	| 1	| 29	| 2	| 29	| 119	| 149 |
| gpt-4(prompt) | -0.5	| 0	| 14	| 0.5 |	14 | 59	| 74 |

GPT-4 æ”¶è´¹å¯¹æ¯”

| æ¨¡å‹åç§°	| æè¿°	| æœ€å¤§tokenæ•°	| è®­ç»ƒæ•°æ® |
| ----	| ----	| ----	| ---- | 
| gpt-4	| æ¯” GPT-3.5 æ¨¡å‹æ›´å¼ºå¤§ï¼Œèƒ½å¤Ÿæ‰§è¡Œæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œå¹¶é’ˆå¯¹èŠå¤©åœºæ™¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ ä¼šä¸æ–­è¿­ä»£æ›´æ–°ã€‚	| 8,192	| æˆªè‡³2021å¹´6æœˆ |
| gpt-4-0314 |	gpt-4çš„2023å¹´3æœˆ14æ—¥å¿«ç…§ç‰ˆæœ¬ã€‚æ­¤æ¨¡å‹åœ¨æ¥ä¸‹æ¥3ä¸ªæœˆå†…ä¸ä¼šæ›´æ–°ï¼Œæœ‰æ•ˆæœŸæˆªæ­¢2023å¹´6æœˆ14æ—¥ã€‚	| 8,192	| æˆªè‡³2019å¹´10æœˆ |
| gpt-4-32k |	ä¸ gpt-4 åŠŸèƒ½ç›¸åŒï¼Œä½†ä¸Šä¸‹æ–‡é•¿åº¦æ˜¯gpt-4 çš„4 å€ã€‚ä¼šä¸æ–­è¿­ä»£æ›´æ–°ã€‚ |	32,768	| æˆªè‡³2021å¹´6æœˆ |
| gpt-4-32k-0314 |	gpt-4-32kçš„2023å¹´3æœˆ14æ—¥å¿«ç…§ç‰ˆæœ¬ã€‚æ­¤æ¨¡å‹åœ¨æ¥ä¸‹æ¥3ä¸ªæœˆå†…ä¸ä¼šæ›´æ–°ï¼Œæœ‰æ•ˆæœŸæˆªæ­¢2023å¹´6æœˆ14æ—¥ã€‚	| 32,768	| æˆªè‡³2019å¹´10æœˆ |

ç”±äºè¿˜åœ¨betaé˜¶æ®µï¼ŒGPT-4 APIçš„è°ƒç”¨æœ‰é¢‘æ¬¡é™åˆ¶ï¼š
- 40k tokens / åˆ†é’Ÿ
- 200 è¯·æ±‚ / åˆ†é’Ÿ

è¿™ä¸ªé¢‘æ¬¡å¯¹åŠŸèƒ½æµ‹è¯•å’Œæ¦‚å¿µéªŒè¯æ¥è¯´å·²ç»è¶³å¤Ÿäº†ã€‚

å¦‚æœä½¿ç”¨ChatGPT Plusä½“éªŒGPT-4ï¼Œæœ‰4å°æ—¶100æ¡æ¶ˆæ¯çš„é™åˆ¶ã€‚

GPT-4 APIçš„å®šä»·ç­–ç•¥ä¸ä¹‹å‰æ¨¡å‹ä¸åŒã€‚åœ¨GPT-4ä¹‹å‰ï¼Œæ¥å£å®šä»·æŒ‰ç…§tokenæ•°ç»Ÿä¸€æ”¶è´¹ï¼Œä¸åŒºåˆ†æ˜¯promptçš„tokenè¿˜æ˜¯ç”Ÿæˆå“åº”çš„tokenã€‚è€ŒGPT-4å°†prompt tokenå’Œç”Ÿæˆå“åº”tokenåˆ†å¼€è®¡ä»·ï¼Œä»·æ ¼å¦‚ä¸‹ï¼š
- $0.03ç¾å…ƒ / 1K prompt token
- $0.06ç¾å…ƒ / 1K ç”Ÿæˆå“åº” token

è¿™ä¸ªä»·æ ¼ç›¸æ¯” gpt-3.5-turbo çš„ $0.002 / 1K tokensæ¥è¯´è´µäº†è‡³å°‘15å€èµ·ã€‚

### GPT-4 API

ã€2023-3-24ã€‘GPT-4ä½¿ç”¨

```py
from steamship import Steamship
# !pip install steamship
gpt = Steamship.use_plugin("gpt-4")
task = gpt.generate("ä½ å¥½")
task.wait()
```

## ChatGPT å‚æ•°

### apiç¤ºä¾‹

```py
# ç»ˆç«¯å‘½ä»¤
# OpenAI api completions.create -m text-davinci-003 -p "Say this is a test" -t 0 -M 7 --stream
import OpenAI

OpenAI.api_key = "ä½ çš„API Key"
#openai.Model.list() # æ˜¾ç¤ºå¯ç”¨model
response = OpenAI.Completion.create(
  model="text-davinci-003", # æ¨¡å‹åç§°
  prompt="how are you", # é—®é¢˜
  temperature=0.7, # ç»“æœéšæœºæ€§ï¼Œ0-0.9 ï¼ˆç¨³å®šâ†’éšæœºï¼‰
  max_tokens=256, # æœ€å¤§å­—æ•°ï¼Œæ±‰å­—ä¸¤ä½
  stream=False, # ChatGPTç‹¬æœ‰å‚æ•°
  top_p=1, # è¿”å›æ¦‚ç‡æœ€å¤§çš„1ä¸ª
  frequency_penalty=0, 
  presence_penalty=0
)
# print(response)
for r in response:
  res += r["choices"][0]["text"]
res = res.replace('<|im_end|>', '')
print(res)
```

è¿”å›ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼Œç»“æœåœ¨textå­—æ®µä¸­ï¼Œå¯é€šè¿‡ response\["choices"]\[0]\["text"] è¿›è¡Œè¯»å–ã€‚

```json
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "text-davinci-003",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

å‚è€ƒï¼š[ChatGPTå®˜æ–¹APIå¯ä»¥æŠ¢å…ˆä½“éªŒäº†](https://mp.weixin.qq.com/s/Jms52U6UyFK6fO7rVRLeBw)


ã€2023-2-11ã€‘[GPT-3](https://platform.openai.com/docs/models/gpt-3) Model å‚æ•°è¯´æ˜ï¼š [å®˜ç½‘](https://platform.openai.com/docs/models/finding-the-right-model)

| LATEST MODEL | DESCRIPTION | MAX REQUEST | TRAINING DATA | 
|---|---|---|---|
| `text-davinci-003` | Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports inserting completions within text. | 4,000 tokens | Up to Jun 2021 | 
| `text-curie-001` | Very capable, but faster and lower cost than Davinci. | 2,048 tokens | Up to Oct 2019 | 
| `text-babbage-001` | Capable of straightforward tasks, very fast, and lower cost. | 2,048 tokens | Up to Oct 2019 | 
| `text-ada-001` | Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost. | 2,048 tokens | Up to Oct 2019 | 

While `Davinci` is generally the most capable, the other models can perform certain tasks extremely well with significant speed or cost advantages. For example, `Curie` can perform many of the same tasks as Davinci, but faster and for 1/10th the cost.

We recommend using `Davinci` while experimenting since it will yield the best results. Once youâ€™ve got things working, we encourage trying the other models to see if you can get the same results with lower latency. You may also be able to improve the other modelsâ€™ performance by fine-tuning them on a specific task.

Older versions of our GPT-3 models are available as `davinci`, `curie`, `babbage`, and `ada`. These are meant to be used with our fine-tuning endpoints.

Your model can be one of: `ada`, `babbage`, `curie`, or `davinci`

å„æ¨¡å‹è°ƒç”¨è´¹ç”¨ä¸åŒï¼Œdavinciæœ€è´µï¼Œå¯¹æ¯”ä¸‹æ¥ï¼Œåªæœ‰æœ€è´µçš„ davinci ç¬¦åˆé¢„æœŸï¼Œ18 åˆ€çš„é…é¢ï¼Œç®—äº†ä¸€ä¸‹å¤§æ¦‚ä¹Ÿå°±é—® 1000 å¤šä¸ªé—®é¢˜
- ![compare](https://pic4.zhimg.com/v2-eec1038143c132650af260e688bfa0f5_b.jpg)

å¦‚ä½•æŸ¥çœ‹å¯ç”¨æ¨¡å‹ï¼Ÿä»¥Python[æ¥å£è°ƒç”¨](https://platform.openai.com/docs/api-reference/introduction)ä¸ºä¾‹

```py
import requests
import json

headers = {'Authorization': f'Bearer {openai.api_key}'}
#payload = {'key1': 'value1', 'key2': 'value2'}
url = 'https://api.openai.com/v1/models' # æŸ¥çœ‹å¯ç”¨æ¨¡å‹
#r = requests.get("http://httpbin.org/get", params=payload)
r = requests.get(url, headers=headers) # header
#print(r.url) # è¯·æ±‚ç½‘å€
#print(r.encoding) # ç¼–ç 
res = json.loads(r.text) # è¿”å›å†…å®¹
json.dumps(res)
# ------------------
import pandas as pd
import datetime

info_list = []
for m in res['data']:
    tm = datetime.datetime.fromtimestamp(m['permission'][0]['created']).strftime('%Y-%m-%d %H:%M:%S')
    out = [m['id'], # m['root'], 
           # m['permission'][0]['organization'],
           tm, # m['permission'][0]['created'], 
           m['permission'][0]['allow_create_engine'],
           m['permission'][0]['allow_sampling'],
           m['permission'][0]['allow_logprobs'],
           m['permission'][0]['allow_view'],
           m['permission'][0]['allow_fine_tuning'],
           m['permission'][0]['is_blocking'],
          ]
    info_list.append(out)
    #print('\t'.join(map(str, out)))
df = pd.DataFrame(info_list, columns=['id', 'create_time','allow_create_engine', 'allow_sampling',
                                'allow_logprobs', 'allow_view', 'allow_fine_tuning','is_blocking' ])
df.sort_values('create_time', ascending=False)
print(df.to_markdown()) # è¾“å‡ºä¸ºmarkdownæ ¼å¼
```

ç»“æœç¤ºä¾‹ï¼š

|  id  | model_id                            | create_time         | allow_create_engine   | allow_sampling   | allow_logprobs   | allow_view   | allow_fine_tuning   | is_blocking   |
|---:|:------------------------------|:--------------------|:----------------------|:-----------------|:-----------------|:-------------|:--------------------|:--------------|
|  0 | babbage                       | 2022-11-22 10:51:41 | False                 | True             | True             | True         | False               | False         |
|  1 | code-davinci-002              | 2023-02-11 05:26:08 | False                 | True             | True             | True         | False               | False         |
|  2 | davinci                       | 2022-11-22 05:32:35 | False                 | True             | True             | True         | False               | False         |

### GPT-3 å‚æ•°

GPT-3 æ¨¡å‹è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼Œè¾“å…¥ä¸»è¦æœ‰7ä¸ªå‚æ•°ï¼š
- ï¼ˆ1ï¼‰`model`ï¼šæ¨¡å‹åç§°ï¼Œtext-davinci-003
  - string, Required
  - ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.
- ï¼ˆ2ï¼‰`prompt`ï¼šé—®é¢˜æˆ–å¾…è¡¥å…¨å†…å®¹ï¼Œä¾‹å¦‚â€œhow are youâ€ã€‚
  - string or array, Optional, Defaults to \<\|endoftext\|\> (åˆ†éš”ç¬¦ï¼Œæœ€ä¸ºpromptåˆå§‹å€¼)
  - The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.
  - Note that \<\|endoftext\|\> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
- ï¼ˆ3ï¼‰`temperature`ï¼šæ§åˆ¶ç»“æœ**éšæœºæ€§**ï¼Œ0.0è¡¨ç¤ºç»“æœå›ºå®šï¼Œéšæœºæ€§å¤§å¯ä»¥è®¾ç½®ä¸º0.9ã€‚
  - number, Optional, Defaults to 1
  - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
  - We generally recommend altering this or top_p but not both.
- ï¼ˆ4ï¼‰`max_tokens`ï¼šæœ€å¤§è¿”å›å­—æ•°ï¼ˆåŒ…æ‹¬é—®é¢˜å’Œç­”æ¡ˆï¼‰ï¼Œé€šå¸¸æ±‰å­—å ä¸¤ä¸ªtokenã€‚å‡è®¾è®¾ç½®æˆ100ï¼Œå¦‚æœprompté—®é¢˜ä¸­æœ‰40ä¸ªæ±‰å­—ï¼Œé‚£ä¹ˆè¿”å›ç»“æœä¸­æœ€å¤šåŒ…æ‹¬10ä¸ªæ±‰å­—ã€‚
  -  ChatGPT APIå…è®¸çš„æœ€å¤§tokenæ•°é‡ä¸º 4097ï¼ˆå¤§éƒ¨åˆ†æ¨¡å‹æ˜¯2048ï¼‰ï¼Œå³max_tokensæœ€å¤§è®¾ç½®ä¸º4097å‡å»prompté—®é¢˜çš„tokenæ•°é‡ã€‚
  - max_tokens, integer, Optional, Defaults to 16
  - The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of **2048** tokens (except for the newest models, which support **4096**).
- ï¼ˆ5ï¼‰`top_p`ï¼šè®¾ç½®ä¸º1å³å¯
  - top_p, number, Optional, Defaults to 1
  - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  - We generally recommend altering this or temperature but not both.
- `n` æ¯ä¸ªpromptç”Ÿæˆå‡ ä¸ªç»“æœï¼ˆå ç”¨é¢åº¦ï¼Œæ…ç”¨ï¼‰
  - integer, Optional, Defaults to 1
  - How many completions to generate for each prompt.
  - Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
- ï¼ˆ6ï¼‰**frequency_penalty**ï¼šè®¾ç½®ä¸º0å³å¯ã€‚
- ï¼ˆ7ï¼‰**presence_penalty**ï¼šè®¾ç½®ä¸º0å³å¯ã€‚
- ï¼ˆ8ï¼‰`stream`ï¼šæ˜¯å¦é‡‡ç”¨æ§åˆ¶æµçš„æ–¹å¼è¾“å‡ºã€‚ï¼ˆChatGPTæ–°å¢ï¼‰
  - ï¼ˆ1ï¼‰å¦‚æœstreamå–å€¼ä¸ºFalseï¼Œé‚£ä¹ˆè¿”å›ç»“æœä¸ GPT3æ¥å£ä¸€è‡´ï¼Œå®Œå…¨è¿”å›å…¨éƒ¨æ–‡å­—ç»“æœï¼Œå¯é€šè¿‡ response\["choices"]\[0]\["text"]è¿›è¡Œè¯»å–ã€‚ä½†æ˜¯ï¼Œå­—æ•°è¶Šå¤šï¼Œç­‰å¾…è¿”å›æ—¶é—´è¶Šé•¿ï¼Œæ—¶é—´å¯å‚è€ƒæ§åˆ¶æµè¯»å‡ºæ—¶çš„4å­—/æ¯ç§’ã€‚
  - ï¼ˆ2ï¼‰å¦‚æœsteamå–å€¼ä¸ºTrueæ—¶ï¼Œé‚£ä¹ˆè¿”å›ç»“æœæ˜¯ä¸€ä¸ª Python generatorï¼Œéœ€è¦é€šè¿‡è¿­ä»£è·å–ç»“æœï¼Œå¹³å‡å¤§çº¦æ¯ç§’é’Ÿ4ä¸ªå­—ï¼ˆ33ç§’134å­—ï¼Œ39ç§’157å­—ï¼‰ï¼Œè¯»å–ç¨‹åºå¦‚ä¸‹æ‰€ç¤ºã€‚å¯ä»¥çœ‹åˆ°ï¼Œè¯»å–ç»“æœçš„ç»“æŸå­—æ®µä¸ºâ€œ<\|im_end\|>â€ã€‚
  - stream: boolean, Optional, Defaults to false
  - Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: \[DONE\] message.
- `logprobs` **ä¼¼ç„¶æ¦‚ç‡**
  - logprobs: integer, Optional, Defaults to null
  - Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.
  - The maximum value for logprobs is **5**. If you need more than this, please contact us through our Help center and describe your use case.
- `suffix` å‰ç¼€
  - string, Optional, Defaults to null
  - The suffix that comes after a completion of inserted text.
- `echo` è¡¥å†™ä¹‹å¤–è¿”å›æç¤ºè¯­
  - echo: boolean, Optional, Defaults to false
  - Echo back the prompt in addition to the completion
- `stop` åœç”¨å¥å­ï¼ˆç±»ä¼¼åœç”¨è¯ï¼‰ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­ä¸å‡ºç°
  - stop: string or array, Optional, Defaults to null
  - Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
- `presence_penalty` å‡ºç°æƒ©ç½š
  - number, Optional, Defaults to 0
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
- `frequency_penalty` é¢‘ç‡æƒ©ç½š
  - number, Optional, Defaults to 0
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
- `best_of` 
  - integer, Optional, Defaults to 1
  - Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.
  - When used with n, `best_of` controls the number of candidate completions and n specifies how many to return â€“ `best_of` must be greater than n.
  - Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.
- `logit_bias` æ¦‚ç‡åç½®
  - map, Optional, Defaults to null
  - Modify the likelihood of specified tokens appearing in the completion.
  - Accepts a **json object** that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both `GPT-2` and `GPT-3`) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
  - As an example, you can pass {"50256": -100} to prevent the <\|endoftext\|> token from being generated.
- `user` ç”¨æˆ·æ ‡å¿—ç¬¦ï¼Œä¾¿äºOpenAIè¯†åˆ«æ˜¯å¦æ¶æ„è°ƒç”¨
  - string, Optional
  - A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).


### ChatGPT å‚æ•°è¯¦è§£

Chat
- Given a chat conversation, the model will return a chat completion response.

Request bodyï¼Œ[å®˜æ–¹](https://platform.openai.com/docs/api-reference/chat/create)
- `model`, string, Required æ¨¡å‹åç§°ï¼Œå¿…å¤‡
  - ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.
- `messages`, array, Required promptä¿¡æ¯ï¼Œå¿…å¤‡
  - The messages to generate chat completions for, in the [chat format](https://platform.openai.com/docs/guides/chat/introduction).
- `temperature`, number, Optional, Defaults to 1 æ¸©åº¦ï¼Œ0-2, é«˜æ¸©(0.8)ä½¿ç»“æœæ›´éšæœº, ä½æ¸©(0.2)æ›´åŠ ç¨³å®š
  - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
  - We generally recommend altering this or top_p but not both.
- `top_p`, number, Optional, Defaults to 1 é‡‡æ ·ç­–ç•¥, è¶…è¿‡top_pçš„å­—ç¬¦æ‰ä¼šè€ƒè™‘
  - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  - We generally recommend altering this or temperature but not both.
- `n`, integer, Optional, Defaults to 1 ç”Ÿæˆå¤šå°‘ä¸ªå›å¤
  - How many chat completion choices to generate for each input message.
- `stream`, boolean, Optional, Defaults to false æµå¼è¾“å‡ºï¼Œé»˜è®¤å¦
  - If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a data: \[DONE] message. See the OpenAI Cookbook for [example code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
- `stop`, string or array, Optional, Defaults to null ç”Ÿæˆå¤šå°‘ä¸ªå­—ç¬¦ååœæ­¢ï¼Œæœ€å¤š4ç»„å‚æ•°
  - Up to 4 sequences where the API will stop generating further tokens.
- `max_tokens`, integer, Optional, Defaults to inf æœ€é•¿å­—ç¬¦æ•°
  - The maximum number of [tokens](https://platform.openai.com/tokenizer) to generate in the chat completion.
  - The total length of input tokens and generated tokens is limited by the model's context length.
- `presence_penalty`, number, Optional, Defaults to 0 é‡å¤å­—ç¬¦æƒ©ç½šï¼Œ-2~2, æ­£æ•°æ—¶ï¼Œæƒ©ç½šå·²ç»å‡ºç°è¿‡çš„å­—ç¬¦
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
  - See more information about [frequency and presence penalties](https://platform.openai.com/docs/api-reference/parameter-details).
- `frequency_penalty`, number, Optional, Defaults to 0 é¢‘æ¬¡æƒ©ç½šï¼Œ-2~2, æ­£æ•°æ—¶ï¼Œå·²å‡ºç°çš„å­—ç¬¦æŒ‰é¢‘ç‡æƒ©ç½š
  - Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
  - See more information about [frequency and presence penalties](https://platform.openai.com/docs/api-reference/parameter-details).
- `logit_bias`, map, Optional, Defaults to null æ¦‚ç‡åç½®ï¼Œç»™ç‰¹å®šå­—ç¬¦å¢åŠ ç½®ä¿¡åº¦
  - Modify the likelihood of specified tokens appearing in the completion.
  - Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
- `user`, string, Optional æ ‡è®°æ˜¯å¦ç»ˆç«¯ç”¨æˆ·
  - A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

curl

```sh
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

Parameters

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "Hello!"}]
}
```

Response

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "\n\nHello there, how may I assist you today?",
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

## è´¦æˆ·å‡çº§plus

OpenAIå‡çº§ä¸æ”¯æŒå›½å†…ä¿¡ç”¨å¡ï¼Œpaypaléƒ½ä¸è¡Œ

è§£æ³•
1. æ‰¾æœ‰ğŸ‡ºğŸ‡¸**ä¿¡ç”¨å¡çš„æœ‹å‹ä»£å……**ã€‚é¦–æ¨è¿™ç§æ–¹å¼ï¼Œå› ä¸ºç®€å•ç›´æ¥ï¼Œæ‰‹ç»­è´¹ä¹Ÿä¸é«˜ã€‚ä½†ä¸æ˜¯æ¯ä¸ªäººéƒ½æœ‰è¿™æ ·çš„æ¸ é“çš„ï¼Œé‚£å°±æ¥çœ‹ä¸€ä¸ªæ›¿ä»£æ–¹å¼ã€‚
2. **æ³¨å†Œä¸€ä¸ªè™šæ‹Ÿä¿¡ç”¨å¡**ï¼Œè¿™é‡Œåˆ—ä¸¤ä¸ªå¹³å°`nobepay`å’Œ`depay`.

### å‡çº§æµç¨‹

ã€2023-3-28ã€‘å¦‚ä½•å‡çº§ä»˜è´¹ç”¨æˆ·ï¼Ÿå®˜æ–¹æ¸ é“éœ€è¦æœ‰å¢ƒå¤–é“¶è¡Œå¡ï¼Œä¸å¥½åŠã€‚
- [å›½å†…å¼€é€šChat GPT Plusä¿å§†çº§æ•™ç¨‹](https://chatgpt-plus.github.io/)
- ChatGPT Plusä»˜è´¹ç‰ˆå‡çº§æµç¨‹ã€‚
- ![](https://chatgpt-plus.github.io/images/1.png)
- æ¬§æ˜“æ˜¯æ¸¯è‚¡ä¸Šå¸‚ï¼Œå›½å†…æœ€å¤§çš„äº¤æ˜“æ‰€ï¼ŒDepayæ˜¯æœ€å¤§çš„è™šæ‹Ÿä¿¡ç”¨å¡å…¬å¸

[Chatgptå‡çº§plusä¼šå‘˜](https://enchanting-polonium-c95.notion.site/Chatgpt-plus-569b65dcc8b04290930303038eaeeb4f)

ä¸¤ç§æ–¹æ¡ˆ: `Depay` + `nobepay`
- (1) `Depay`: å¦‚æœæœ‰usdtï¼ˆè™šæ‹Ÿè´§å¸ï¼‰å¯ä»¥é€‰æ‹©å¹³å° [Depay](https://depay.one/zh-cn/index.html)ï¼Œkycå¯è®¤è¯å¯ä¸è®¤è¯ã€‚Depay åªæ”¯æŒuå¸å…¥é‡‘ã€‚
  - depay æ‰“å¼€åå¡«å†™æ‰‹æœºï¼Œé‚®ç®±ï¼Œå›½å†…æ‰‹æœºå·å³å¯ã€‚
- (2) `nobepay`: å¦‚æœæ²¡æœ‰uå¸ï¼Œå¯ä»¥é€‰æ‹© [nobepay](https://www.nobepay.com/app/login)ï¼Œæ”¯ä»˜å®å¾®ä¿¡å°±èƒ½å……å€¼ï¼Œèº«ä»½å¿…é¡»è®¤è¯
  - ã€2023-5-19ã€‘[ä¿å§†çº§æ•™ç¨‹ï¼šNobePayä»æ³¨å†Œåˆ°å……å€¼å¼€å¡å…¨è¿‡ç¨‹](https://mailberry.com.cn/2023/03/register-nobepay/)
  - nobepayçš„å……å€¼å¼€å¡æ¯”è¾ƒç®€å•
  - è¿‡ç¨‹: æ³¨å†Œç™»å½• -> kycè®¤è¯ -> å……å€¼åˆ°nobepayé’±åŒ… -> å¼€é€šè™šæ‹Ÿä¿¡ç”¨å¡ -> é’±åŒ…é‡Œçš„é’±è½¬åˆ°ä¿¡ç”¨å¡é‡Œ
- ![](https://enchanting-polonium-c95.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff35cc065-d1cf-47a6-8c52-d4b5c3232ec0%2FD63F8ACE-47D7-470C-B6F4-C9FC88AFE870.jpeg?id=13cc68dd-0509-4038-8781-87000a14a543&table=block&spaceId=5cde7fdc-e0aa-47f7-a6c9-ccff5735a6eb&width=1260&userId=&cache=v2)

nobepayå……å€¼æ”¯æŒ`å¾®ä¿¡`, `æ”¯ä»˜å®`ã€‚depayåªæ”¯æŒ**è™šæ‹Ÿè´§å¸**ï¼Œå……å¸usdtè½¬æ¢æˆç¾é‡‘usdåå°±èƒ½ä½¿ç”¨

ç”³è¯·å¼€å¡ï¼Œæœ‰`visa`å’Œ`master` cardä¸¤ç§

æ³¨æ„äº‹é¡¹
1. ä»˜æ¬¾æ—¶å¼€ğŸªœå…¨å±€ä»£ç†ï¼Œé€‰ğŸ‡ºğŸ‡¸è·¯çº¿ï¼Œå›½å†…çš„ipä¼šä¸è¡Œï¼ŒåŒ…æ‹¬ğŸ‡­ğŸ‡°ã€‚
2. nobepayå¹³æ—¶æµ·æ·˜ä¹Ÿèƒ½ç”¨ï¼Œæœ€ä½500èµ·å……ï¼Œä½†è¿™ä¸ªå¹³å°ä¸å»ºè®®å¤šå……ï¼Œæ€•è·‘è·¯ï¼Œåªæ˜¯ä½œä¸ºä¸ªå·¥å…·ä½¿ç”¨ã€‚
3. depayä¹Ÿæ˜¯ï¼Œå› ä¸ºæˆ‘ä¸æ‡‚åŠ å¯†è´§å¸ï¼Œå¹³æ—¶ä¹Ÿä¸ç©ï¼Œè¿™é‡Œåªæ˜¯ä½œä¸ºä¸€ä¸ªå·¥å…·ç”¨ï¼Œæˆ‘ä¸ªäººå¹¶ä¸äº†è§£ä¹Ÿä¸ä¿¡ä»»depay è¿™ä¸ªå¹³å°,ä¸èƒ½ä¿è¯ç¨³å®šæ€§ï¼Œæ‰€ä»¥å¤§å®¶åˆ«å¤šå……ï¼Œä¸‡ä¸€å¹³å°è·‘è·¯äº†å‘¢ğŸ¤”ğŸ¤”
4. æœ‰ğŸ‡ºğŸ‡¸ä¿¡ç”¨å¡æ¸ é“çš„ä¼˜å…ˆé€‰ç¾å¡ï¼Œè´¹ç‡ä½ä¸”ç®€å•ã€‚

openaiä»˜è´¹å‡çº§çš„å¡å·æ€ä¹ˆé€‰
- chatgpt/OpenAIï¼šé™¤æ¬§æ´²å¡æ®µ474362å…¶ä»–éƒ½å¯ä»¥ï¼Œå»ºè®®ä½¿ç”¨æ–°ä¸Šçº¿å¡æ®µ
- ä¸»è¦æ˜¯IPé—®é¢˜ï¼Œå¦‚æœè¢«æ‹’å¤šæ¢æ¢

ç¾å›½çš„å…ç¨å·æœ‰ï¼š[åœ°å€ç”Ÿæˆå™¨](https://www.fakepersongenerator.com/Index/generate)
- è’™å¤§æ‹¿å·ï¼ˆMontanaï¼‰
- ä¿„å‹’å†ˆå·ï¼ˆOregonï¼‰
- é˜¿æ‹‰æ–¯åŠ å·ï¼ˆAlaskaï¼‰
- ç‰¹æ‹‰åå·ï¼ˆDelawareï¼‰
- æ–°ç½•å¸ƒä»€å°”å·ï¼ˆNew Hampshireï¼‰

ç¾å›½å„å·[ç®€ç§°](https://www.qidulp.com/article/p/3663)
- ![](https://ywserver.qidulp.com/public/img/8a/8a232fa479626b691df4dc66c0cfb400.jpg)



### å‡çº§è¢«æ‹’åŸå› 

ä¿¡ç”¨å¡è¢«æ‹’ï¼Œæç¤ºï¼š
> â€ä½ çš„ä¿¡ç”¨å¡è¢«æ‹’ç»äº†ï¼Œè¯·å°è¯•ç”¨å€Ÿè®°å¡æ”¯ä»˜â€œ

ä¿¡ç”¨å¡è¢«æ‹’å¯èƒ½æœ‰ä»¥ä¸‹å‡ ä¸ªåŸå› ï¼š
- ä¿¡ç”¨å¡ç¡®å®ä¸æ”¯æŒï¼Œæ¯” Depay çš„è™šæ‹Ÿä¿¡ç”¨å¡çš„å·æ®µè¢« OpenAI/ChatGPT æ‹’ç»ã€‚å¯ä»¥å°è¯•æ›´æ¢è™šæ‹Ÿä¿¡ç”¨å¡ï¼ŒDepay æ”¯æŒç”³è¯·å¤šå¼ ã€‚
- ç½‘ç»œç¯å¢ƒè¢« Stripe é£æ§ï¼ŒæŒ‚å…¨å±€ä»£ç† + æµè§ˆå™¨æ— ç—•æ¨¡å¼å†è¯•ï¼Œæ€»ä¹‹æŒ‚ä»£ç†å’Œä¸æŒ‚ä»£ç†éƒ½è¯•ä¸€ä¸‹
- å…¨å±€ä»£ç† + æµè§ˆå™¨æ— ç—•æ¨¡å¼ + æ›´æ¢ IP å¤±è´¥æ¬¡æ•°è¶…è¿‡ 3-5 æ¬¡ï¼Œä¸å»ºè®®ç»§ç»­å°è¯•ï¼Œè¿™ç§æƒ…å†µå¯ä»¥è€ƒè™‘æ›´æ¢ ChatGPT è´¦å· + æ— ç—• + æ›´æ¢æ¢¯å­é‡æ–°è®¢é˜…è¯•è¯•ã€‚

2023å¹´3æœˆ24æ—¥æ›´æ–°ï¼š
- å¦‚æœä¹°çš„ChatGPTå¸å·ï¼Œæˆ–è€…è‡ªå·±æ³¨å†Œï¼Œä½†æ˜¯ä½¿ç”¨è¿‡**å¤šä¸ªIPç™»å½•**ï¼ˆä¸åŒçš„å›½å®¶å’Œåœ°åŒºï¼‰ï¼Œå‡çº§ChatGPTçš„å¯èƒ½æ€§ä¸å¤§ï¼Œå¤šåŠä¼šå¡åœ¨æ”¯ä»˜ç¯èŠ‚
- å»ºè®®æ¢**æ–°å·**ï¼Œè¿™æ˜¯VPSå¤§ç©å®¶è·Ÿå‡ ç™¾ä¸ªç½‘å‹äº¤æµåå¾—å‡ºçš„ç»“è®º
  - VPSå¤§ç©å®¶ç”¨çš„æ˜¯å¡å¤´ä¸º531847çš„ç¾å›½è™šæ‹Ÿä¿¡ç”¨å¡ï¼Œå¯ä»¥è‡ªå®šä¹‰å¸å•åœ°å€ï¼ˆä½¿ç”¨å…ç¨å·çš„åœ°å€ï¼‰
- è§£å†³æ–¹æ¡ˆï¼š[ChatGPT Pluså¦‚ä½•è´­ä¹°ï¼Ÿä¿¡ç”¨å¡ä»˜æ¬¾å¤±è´¥æ€ä¹ˆåŠï¼Ÿå¦‚ä½•ä½¿ç”¨Apple Payå‡çº§ChatGPT Plus](https://www.vpsdawanjia.com/6220.html)

VPSå¤§ç©å®¶ä¸€èˆ¬åœ¨Googleåœ°å›¾ä¸Šæ‰¾çœŸå®åœ°å€ï¼Œæ‰¾åœ°å€çš„æ–¹æ³•å¦‚ä¸‹ï¼š
- æ‰“å¼€Google åœ°å›¾ï¼Œæ‹‰åˆ°ç¾å›½é‚£è¾¹ï¼Œåœ¨åœ°å›¾ä¸Šé€‰ä¸€ä¸ªå·ï¼Œæ”¾å¤§åæ‰¾å½“åœ°çš„åº—é“ºåœ°å€æˆ–è€…åˆ«çš„æœºæ„ï¼Œç‚¹ä¸€ä¸‹å°±ä¼šåœ¨å·¦è¾¹æ˜¾ç¤ºåœ°å€ï¼Œå…·ä½“æ–¹æ³•å‚è§ï¼š[å¦‚ä½•åœ¨è°·æ­Œ(Google)åœ°å›¾ä¸Šæ‰¾ä¸€ä¸ªçœŸå®çš„ç¾å›½åœ°å€](https://www.vpsdawanjia.com/2594.html)ã€‚

å¦‚æœå¸å·æ›¾ç»ä»˜æ¬¾å¤±è´¥è¿‡ï¼Œå‡ºç°äº†ä»¥ä¸‹æç¤ºï¼š
- Your credit card was declined.Try paying with a debit card instead.
- æ‚¨çš„ä¿¡ç”¨å¡è¢«æ‹’ç»äº†ã€‚è¯·å°è¯•ç”¨å€Ÿè®°å¡æ”¯ä»˜ã€‚
- ä½ çš„å¡å·²è¢«æ‹’ç»ã€‚

é‚£è¿™ä¸ªå·å¯èƒ½å°±åŸºæœ¬ä¸Šå‘Šåˆ«ChatGPT Plusäº†ï¼Œå¤§æ¦‚ç‡æ˜¯ä¸èƒ½ä»˜æ¬¾æˆåŠŸçš„ï¼Œåªèƒ½æ¢æ–°å·ã€‚å¯èƒ½çš„åŸå› ï¼š
- ä½¿ç”¨ä¸å¹²å‡€çš„IPç™»å½•è¿‡ChatGPTï¼Œè¿™ä¸ªå·è¢«OpenAIåˆ—å…¥äº†é»‘åå•ã€‚

æœ‰ä¸ªç½‘å‹å°±æ˜¯è¿™ä¸ªåŸå› å¯¼è‡´å³ä½¿æ¢IPï¼ˆä½¿ç”¨è¿œç¨‹æ¡Œé¢æœºæœåŠ¡å™¨ï¼‰ã€æ¢å¡ã€æ¢å¸å•åœ°å€éƒ½ä¸èƒ½æ­£å¸¸æ”¯ä»˜ã€‚ä½¿ç”¨å¹²å‡€çš„IPï¼Œé‡æ–°æ³¨å†Œä¸€ä¸ªæ–°å·å°±å¯ä»¥äº†ã€‚

### è™šæ‹Ÿä¿¡ç”¨å¡

é™¤äº†531847è™šæ‹Ÿå¡èƒ½è´­ä¹°Plusï¼Œ556766ã€556735ã€556305ä»¥åŠ558068è¿™å‡ ä¸ªå¡å¤´ä¹Ÿå¯ä»¥ç»™ChatGPTä»˜æ¬¾ã€‚å¯ä»¥åœ¨[è¿™é‡Œ](www.vvacard.com)è·å¾—è¿™ç§å¡

VPSå¤§ç©å®¶æ³¨å†ŒåŠä½¿ç”¨ChatGPTçš„ç¯å¢ƒï¼šç¾å›½WindowsæœåŠ¡å™¨ï¼Œé€šè¿‡è¿œç¨‹æ¡Œé¢è¿æ¥ä½¿ç”¨, [æ•™ç¨‹](https://www.vpsdawanjia.com/6049.html)

è™šæ‹Ÿä¿¡ç”¨å¡æ‰£æ¬¾è®°å½•ï¼š
- ![](https://www.vpsdawanjia.com/wp-content/uploads/2023/03/531847chatgpt.png)

### å‡çº§Plus

è¾“å…¥è™šæ‹Ÿä¿¡ç”¨å¡å¡å·ï¼Œè¿‡æœŸæ—¶é—´ã€CVVä»¥åŠé‚®ç¼–ï¼Œä¸‹é¢è¾“å…¥å§“åã€å¸å•åœ°å€ï¼Œç„¶åç‚¹â€œSet up payment methodâ€ã€‚
- ç°åœ¨çš„è™šæ‹Ÿä¿¡ç”¨å¡ï¼Œä¸€èˆ¬éƒ½å¯ä»¥æŒ‡å®šå§“åï¼Œå¸å•åœ°å€ï¼Œå¯ä»¥è¿‡AVSéªŒè¯ã€‚
- è¿™é‡Œç”¨çš„æ˜¯556305è™šæ‹Ÿä¿¡ç”¨å¡ï¼Œä¹Ÿæ˜¯ä¸€å¼ ç¾å›½çš„è™šæ‹Ÿä¿¡ç”¨å¡ã€‚
- åŒæ ·ç”¨çš„æ˜¯ä¿„å‹’å†ˆå·ï¼ˆORï¼‰çš„åœ°å€ï¼Œå…æ¶ˆè´¹ç¨ã€‚
- 2023å¹´3æœˆ31æ—¥æ›´æ–°ï¼š
  - ç°åœ¨ç»‘å¡çš„æ—¶å€™ï¼Œè¦é¢„æ‰£5ç¾å…ƒï¼Œä¸€èˆ¬ä¼šåœ¨7å¤©å†…é‡Šæ”¾ï¼Œä¸æ˜¯å®é™…æ‰£æ¬¾ï¼Œç„¶ååœ¨æ¯ä¸ªæœˆçš„æœˆåº•æŒ‰ç…§å®é™…çš„ä½¿ç”¨é‡‘é¢ç»“ç®—ã€‚
- ![](https://www.vpsdawanjia.com/wp-content/uploads/2023/03/setpaymentmothed.png)

### GPT-4åŠŸèƒ½

GPT-4æœ‰é™åˆ¶ï¼šGPT-4 currently has a cap of 25 messages every 3 hours. æ¯3å°æ—¶åªèƒ½äº¤äº’25æ¬¡ã€‚

ChatGPT plusè´¦æˆ·ä¸Šæ”¯æŒé€‰æ‹©GPT-4æ¨¡å‹
- ![](https://chatgpt-plus.github.io/images/gpt4-3.png)

GPT-4åŠŸèƒ½ [å‚è€ƒ](https://chatgpt-plus.github.io/page/2/)
- ![](https://chatgpt-plus.github.io/images/gpt4-4.png)
- ç›¸æ¯”äºGPT-3.5ï¼ŒGPT-4æ˜¯æ–°ä¸€ä»£å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚GPT-4ä¸ä»…æ”¯æŒæ–‡æœ¬ï¼Œè¿˜æ”¯æŒå›¾åƒè¾“å…¥ã€‚
- ![](https://chatgpt-plus.github.io/images/gpt4-5.gif)

è®¿é—®ChatGPT Pluså°±æ‹¥æœ‰`Default`å’Œ`Legacy`åŒæ¨¡å‹å›ç­”ï¼Œä»¥åŠå¿«é€Ÿã€ç¨³å®šçš„AIå›å¤ã€‚
- ![](https://chatgpt-plus.github.io/images/10.png)

ChatGPT Plusä¸­çš„default modeå’Œlegacy modeæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
- default modeå°±æ˜¯Turbo modeï¼Œæ›´æœ‰æƒ…æ„Ÿå’Œæ´»åŠ›ï¼Œä¼šæœ‰è¶£ä¸€äº›ï¼Œä¸è¿‡å›ç­”ä¸Šåæ›´åŠ ç®€æ´ï¼Œçœå»äº†ä¹‹å‰legacy modeä¸€äº›ç»†èŠ‚ã€‚
- legacy modeåˆ™æ›´é€‚åˆå­¦æœ¯è®ºæ–‡ï¼Œä¸åƒTurbo Modeå›ç­”é‚£ä¹ˆå¤§ä¼—ï¼Œé€‚åˆç§‘ç ”ï¼Œè®ºæ–‡ã€‚
- æ›´è¯¦ç»†çš„æ¯”è¾ƒå¯ä»¥[å‚è€ƒ](https://www.reddit.com/r/ChatGPT/comments/111skny/the_differences_between_default_and_legacy_models/)

### å–æ¶ˆPlusè®¢é˜…

å¦‚ä½•å–æ¶ˆChatGPT Plusçš„è‡ªåŠ¨è®¢é˜…ï¼Ÿ
- Depayä¿¡ç”¨å¡å…¶å®æ²¡æœ‰é€æ”¯åŠŸèƒ½ï¼Œåªæ˜¯ç›¸å½“äºå€Ÿè®°å¡ï¼Œç†è®ºä¸Šè¯´åªè¦ä½ ä¸å¾€å¡é‡Œå……é’±ï¼Œå…¶å®ä¸å¿…æ‹…å¿ƒä¸‹ä¸ªæœˆè¢«æ‰£æ¬¾ã€‚
- ä¸è¿‡ï¼Œä¿é™©èµ·è§ï¼Œä½ è¿˜æ˜¯å¯ä»¥å–æ¶ˆè‡ªåŠ¨è®¢é˜…ï¼Œæ–¹æ³•æ˜¯ï¼š
- æ‰“å¼€ChatGPTé¦–é¡µå¹¶ç™»å½•â€”â€”å·¦ä¸‹è§’â€”â€”My Accountâ€”â€”Manage My Subscriptionâ€”â€”Cancel Plan



# ç»“æŸ
